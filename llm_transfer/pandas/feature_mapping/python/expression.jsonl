{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index"], "Title": ["DataFrame.index"], "Feature": ["DataFrame.index"], "Description": "The index (row labels) of the DataFrame.\nThe index of a DataFrame is a series of labels that identify each row.\nThe labels can be integers, strings, or any other hashable type. The index\nis used for label-based access and alignment, and can be accessed or\nmodified using this attribute.", "Examples": [">>> df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Aritra'],\n...                    'Age': [25, 30, 35],\n...                    'Location': ['Seattle', 'New York', 'Kona']},\n...                   index=([10, 20, 30]))\n>>> df.index\nIndex([10, 20, 30], dtype='int64')"], "Parameters": [], "Returns": [["pandas.Index", "The index labels of the DataFrame."]], "Category": ["Dataframe"], "index": 0}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns"], "Title": ["DataFrame.columns"], "Feature": ["DataFrame.columns"], "Description": "The column labels of the DataFrame.", "Examples": [">>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n>>> df\n     A  B\n0    1  3\n1    2  4\n>>> df.columns\nIndex(['A', 'B'], dtype='object')"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 1}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_flags.html#pandas.DataFrame.set_flags"], "Title": ["DataFrame.set_flags"], "Feature": ["DataFrame.set_flags"], "Description": "Return a new object with updated flags.\nSee also DataFrame.attrsGlobal metadata applying to this dataset.DataFrame.flagsGlobal flags applying to this object.\nNotes\nThis method returns a new object that’s a view on the same data as the input. Mutating the input or the output values will be reflected in the other.\nThis method is intended to be used in method chains.\n“Flags” differ from “metadata”. Flags reflect properties of the pandas object (the Series or DataFrame). Metadata refer to properties of the dataset, and should be stored inDataFrame.attrs.", "Examples": [">>> df = pd.DataFrame({\"A\": [1, 2]})\n>>> df.flags.allows_duplicate_labels\nTrue\n>>> df2 = df.set_flags(allows_duplicate_labels=False)\n>>> df2.flags.allows_duplicate_labels\nFalse"], "Parameters": [["copy bool, default False", "Specify if a copy of the object should be made.Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas. You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True"], ["allows_duplicate_labels bool, optional", "Whether the returned object allows duplicate labels."]], "Returns": [["Series or DataFrame", "The same type as the caller."]], "Category": ["Dataframe"], "index": 2}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts"], "Title": ["DataFrame.value_counts"], "Feature": ["DataFrame.value_counts"], "Description": "Return a Series containing the frequency of each distinct row in the Dataframe.\nNotes\nThe returned Series will have a MultiIndex with one level per input\ncolumn but an Index (non-multi) for a single label. By default, rows\nthat contain any NA values are omitted from the result. By default,\nthe resulting Series will be in descending order so that the first\nelement is the most frequently-occurring row.", "Examples": [">>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n...                    'num_wings': [2, 0, 0, 0]},\n...                   index=['falcon', 'dog', 'cat', 'ant'])\n>>> df\n        num_legs  num_wings\nfalcon         2          2\ndog            4          0\ncat            4          0\nant            6          0"], "Parameters": [["subset label or list of labels, optional", "Columns to use when counting unique combinations."], ["normalize bool, default False", "Return proportions rather than frequencies."], ["sort bool, default True", "Sort by frequencies when True. Sort by DataFrame column values when False."], ["ascending bool, default False", "Sort in ascending order."], ["dropna bool, default True", "Don’t include counts of rows that contain NA values."]], "Returns": [["Series"]], "Category": ["Dataframe"], "index": 3}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html#pandas.DataFrame.add_prefix"], "Title": ["DataFrame.add_prefix"], "Feature": ["DataFrame.add_prefix"], "Description": "Prefix labels with string prefix.\nFor Series, the row labels are prefixed.\nFor DataFrame, the column labels are prefixed.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s\n0    1\n1    2\n2    3\n3    4\ndtype: int64"], "Parameters": [["prefix str", "The string to add before each label."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None"]], "Returns": [["Series or DataFrame", "New Series or DataFrame with updated labels."]], "Category": ["Dataframe"], "index": 4}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_suffix.html#pandas.DataFrame.add_suffix"], "Title": ["DataFrame.add_suffix"], "Feature": ["DataFrame.add_suffix"], "Description": "Suffix labels with string suffix.\nFor Series, the row labels are suffixed.\nFor DataFrame, the column labels are suffixed.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s\n0    1\n1    2\n2    3\n3    4\ndtype: int64"], "Parameters": [["suffix str", "The string to add after each label."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None"]], "Returns": [["Series or DataFrame", "New Series or DataFrame with updated labels."]], "Category": ["Dataframe"], "index": 5}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.align.html#pandas.DataFrame.align"], "Title": ["DataFrame.align"], "Feature": ["DataFrame.align"], "Description": "Align two objects on their axes with the specified join method.\nJoin method is specified for each axis Index.", "Examples": [">>> df = pd.DataFrame(\n...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n... )\n>>> other = pd.DataFrame(\n...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n...     columns=[\"A\", \"B\", \"C\", \"D\"],\n...     index=[2, 3, 4],\n... )\n>>> df\n   D  B  E  A\n1  1  2  3  4\n2  6  7  8  9\n>>> other\n    A    B    C    D\n2   10   20   30   40\n3   60   70   80   90\n4  600  700  800  900"], "Parameters": [["other DataFrame or Series"], ["join {‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’", "Type of alignment to be performed. left: use only keys from left frame, preserve key order. right: use only keys from right frame, preserve key order. outer: use union of keys from both frames, sort keys lexicographically. inner: use intersection of keys from both frames,\npreserve the order of the left keys."], ["axis allowed axis of the other object, default None", "Align on index (0), columns (1), or both (None)."], ["level int or level name, default None", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["copy bool, default True", "Always returns new objects. If copy=False and no reindexing is\nrequired then original objects are returned. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["fill_value scalar, default np.nan", "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value."], ["method {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None", "Method to use for filling holes in reindexed Series: pad / ffill: propagate last valid observation forward to next valid. backfill / bfill: use NEXT valid observation to fill gap."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["fill_axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0", "Filling axis, method and limit."], ["broadcast_axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None", "Broadcast values along this axis, if aligning two objects of\ndifferent dimensions."]], "Returns": [["tuple of (Series/DataFrame, type of other)", "Aligned objects."]], "Category": ["Dataframe"], "index": 6}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at_time.html#pandas.DataFrame.at_time"], "Title": ["DataFrame.at_time"], "Feature": ["DataFrame.at_time"], "Description": "Select values at particular time of day (e.g., 9:30AM).", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='12h')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n                     A\n2018-04-09 00:00:00  1\n2018-04-09 12:00:00  2\n2018-04-10 00:00:00  3\n2018-04-10 12:00:00  4"], "Parameters": [["time datetime.time or str", "The values to select."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "For Series this parameter is unused and defaults to 0."]], "Returns": [["Series or DataFrame"]], "Category": ["Dataframe"], "index": 7}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.between_time.html#pandas.DataFrame.between_time"], "Title": ["DataFrame.between_time"], "Feature": ["DataFrame.between_time"], "Description": ["Select values between particular times of the day (e.g., 9:00-9:30 AM).\nBy setting start_time to be later than end_time, you can get the times that are not between the two times."], "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n                     A\n2018-04-09 00:00:00  1\n2018-04-10 00:20:00  2\n2018-04-11 00:40:00  3\n2018-04-12 01:00:00  4"], "Parameters": [["start_time datetime.time or str", "Initial time as a time filter limit."], ["end_time datetime.time or str", "End time as a time filter limit."], ["inclusive {“both”, “neither”, “left”, “right”}, default “both”", "Include boundaries; whether to set each bound as closed or open."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Determine range time on index or columns value.\nFor Series this parameter is unused and defaults to 0."]], "Returns": [["Series or DataFrame", "Data from the original object filtered to the specified dates range."]], "Category": ["Dataframe"], "index": 8}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop"], "Title": ["DataFrame.drop"], "Feature": ["DataFrame.drop"], "Description": "Drop specified labels from rows or columns.\nRemove rows or columns by specifying label names and corresponding\naxis, or by directly specifying index or column names. When using a\nmulti-index, labels on different levels can be removed by specifying\nthe level. See the user guide for more information about the now unused levels.", "Examples": [">>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n...                   columns=['A', 'B', 'C', 'D'])\n>>> df\n   A  B   C   D\n0  0  1   2   3\n1  4  5   6   7\n2  8  9  10  11"], "Parameters": [["labels single label or list-like", "Index or column labels to drop. A tuple will be used as a single\nlabel and not treated as a list-like."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Whether to drop labels from the index (0 or ‘index’) or\ncolumns (1 or ‘columns’)."], ["index single label or list-like", "Alternative to specifying axis ( labels, axis=0 is equivalent to index=labels )."], ["columns single label or list-like", "Alternative to specifying axis ( labels, axis=1 is equivalent to columns=labels )."], ["level int or level name, optional", "For MultiIndex, level from which the labels will be removed."], ["inplace bool, default False", "If False, return a copy. Otherwise, do operation\nin place and return None."], ["errors {‘ignore’, ‘raise’}, default ‘raise’", "If ‘ignore’, suppress error and only existing labels are\ndropped."]], "Returns": [["DataFrame or None", "Returns DataFrame or None DataFrame with the specified\nindex or column labels removed or None if inplace=True."]], "Category": ["Dataframe"], "index": 9}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html#pandas.DataFrame.drop_duplicates"], "Title": ["DataFrame.drop_duplicates"], "Feature": ["DataFrame.drop_duplicates"], "Description": "Return DataFrame with duplicate rows removed.\nConsidering certain columns is optional. Indexes, including time indexes\nare ignored.\nSee alsoDataFrame.value_countsCount unique combinations of columns.", "Examples": [">>> df = pd.DataFrame({\n...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n...     'rating': [4, 4, 3.5, 15, 5]\n... })\n>>> df\n    brand style  rating\n0  Yum Yum   cup     4.0\n1  Yum Yum   cup     4.0\n2  Indomie   cup     3.5\n3  Indomie  pack    15.0\n4  Indomie  pack     5.0"], "Parameters": [["subset column label or sequence of labels, optional", "Only consider certain columns for identifying duplicates, by\ndefault use all of the columns."], ["keep {‘first’, ‘last’, False }, default ‘first’", "Determines which duplicates (if any) to keep. ‘first’ : Drop duplicates except for the first occurrence. ‘last’ : Drop duplicates except for the last occurrence. False : Drop all duplicates."], ["inplace bool, default False", "Whether to modify the DataFrame rather than creating a new one."], ["ignore_index bool, default False", "If True , the resulting axis will be labeled 0, 1, …, n - 1."]], "Returns": [["DataFrame or None", "DataFrame with duplicates removed or None if inplace=True ."]], "Category": ["Dataframe"], "index": 10}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated"], "Title": ["DataFrame.duplicated"], "Feature": ["DataFrame.duplicated"], "Description": "Return boolean Series denoting duplicate rows.\nConsidering certain columns is optional.", "Examples": [">>> df = pd.DataFrame({\n...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n...     'rating': [4, 4, 3.5, 15, 5]\n... })\n>>> df\n    brand style  rating\n0  Yum Yum   cup     4.0\n1  Yum Yum   cup     4.0\n2  Indomie   cup     3.5\n3  Indomie  pack    15.0\n4  Indomie  pack     5.0"], "Parameters": [["subset column label or sequence of labels, optional", "Only consider certain columns for identifying duplicates, by\ndefault use all of the columns."], ["keep {‘first’, ‘last’, False}, default ‘first’", "Determines which duplicates (if any) to mark. first : Mark duplicates as True except for the first occurrence. last : Mark duplicates as True except for the last occurrence. False : Mark all duplicates as True ."]], "Returns": [["Series", "Boolean series for each duplicated rows."]], "Category": ["Dataframe"], "index": 11}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html#pandas.DataFrame.equals"], "Title": ["DataFrame.equals"], "Feature": ["DataFrame.equals"], "Description": "Test whether two objects contain the same elements.\nThis function allows two Series or DataFrames to be compared against\neach other to see if they have the same shape and elements. NaNs in\nthe same location are considered equal.\nThe row/column index do not need to have the same type, as long\nas the values are considered equal. Corresponding columns and\nindex must be of the same dtype.\nSee alsoSeries.eqCompare two Series objects of the same length and return a Series where each element is True if the element in each Series is equal, False otherwise.DataFrame.eqCompare two DataFrame objects of the same shape and return a DataFrame where each element is True if the respective element in each DataFrame is equal, False otherwise.testing.assert_series_equalRaises an AssertionError if left and right are not equal. Provides an easy interface to ignore inequality in dtypes, indexes and precision among others.testing.assert_frame_equalLike assert_series_equal, but targets DataFrames.numpy.array_equalReturn True if two arrays have the same shape and elements, False otherwise.", "Examples": [">>> df = pd.DataFrame({1: [10], 2: [20]})\n>>> df\n    1   2\n0  10  20"], "Parameters": [["other Series or DataFrame", "The other Series or DataFrame to be compared with the first."]], "Returns": [["bool", "True if all elements are the same in both objects, False\notherwise."]], "Category": ["Dataframe"], "index": 12}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype"], "Title": ["DataFrame.astype"], "Feature": ["DataFrame.astype"], "Description": "Cast a pandas object to a specified dtype.", "Examples": [">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n>>> df = pd.DataFrame(data=d)\n>>> df.dtypes\ncol1    int64\ncol2    int64\ndtype: object"], "Parameters": [["dtype str, data type, Series or Mapping of column name -> data type", "Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to cast entire pandas object to the same type. Alternatively, use a mapping, e.g. {col: dtype, …}, where col is a column label and dtype is a numpy.dtype or Python type to cast one or more of the DataFrame’s columns to column-specific types."], ["copy bool, default True", "Return a copy when copy=True (be very careful setting copy=False as changes to values then may propagate to other pandas objects). Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas. You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True"], ["errors {‘raise’, ‘ignore’}, default ‘raise’", "Control raising of exceptions on invalid data for provided dtype. raise : allow exceptions to be raised ignore : suppress exceptions. On error return original object."]], "Returns": [["same type as caller"]], "Category": ["Dataframe"], "index": 13}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html#pandas.DataFrame.filter"], "Title": ["DataFrame.filter"], "Feature": ["DataFrame.filter"], "Description": "Subset the dataframe rows or columns according to the specified index labels.\nNote that this routine does not filter a dataframe on its\ncontents. The filter is applied to the labels of the index.\nNotes\nTheitems,like, and regex parameters are\nenforced to be mutually exclusive.\naxis defaults to the info axis that is used when indexing\nwith[].", "Examples": [">>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n...                   index=['mouse', 'rabbit'],\n...                   columns=['one', 'two', 'three'])\n>>> df\n        one  two  three\nmouse     1    2      3\nrabbit    4    5      6"], "Parameters": [["items list-like", "Keep labels from axis which are in items."], ["like str", "Keep labels from axis for which “like in label == True”."], ["regex str (regular expression)", "Keep labels from axis for which re.search(regex, label) == True."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "The axis to filter on, expressed either as an index (int)\nor axis name (str). By default this is the info axis, ‘columns’ for\nDataFrame. For Series this parameter is unused and defaults to None ."]], "Returns": [["same type as input object"]], "Category": ["Dataframe"], "index": 14}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first.html#pandas.DataFrame.first"], "Title": ["DataFrame.first"], "Feature": ["DataFrame.first"], "Description": "Select initial periods of time series data based on a date offset.\nPlease create a mask and filter using.loc instead.\nFor a DataFrame with a sorted DatetimeIndex, this function can\nselect the first few rows based on a date offset.", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n            A\n2018-04-09  1\n2018-04-11  2\n2018-04-13  3\n2018-04-15  4"], "Parameters": [["offset str, DateOffset or dateutil.relativedelta", "The offset length of the data that will be selected. For instance,\n‘1ME’ will display all the rows having their index within the first month."]], "Returns": [["Series or DataFrame", "A subset of the caller."]], "Category": ["Dataframe"], "index": 15}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax"], "Title": ["DataFrame.idxmax"], "Feature": ["DataFrame.idxmax"], "Description": "Return index of first occurrence of maximum over requested axis.\nNA/null values are excluded.\nNotes\nThis method is the DataFrame version of ndarray.argmax.", "Examples": [">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n...                     'co2_emissions': [37.2, 19.66, 1712]},\n...                   index=['Pork', 'Wheat Products', 'Beef'])"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["numeric_only bool, default False", "Include only float , int or boolean data."]], "Returns": [["Series", "Indexes of maxima along the specified axis."]], "Category": ["Dataframe"], "index": 16}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin"], "Title": ["DataFrame.idxmin"], "Feature": ["DataFrame.idxmin"], "Description": "Return index of first occurrence of minimum over requested axis.\nNA/null values are excluded.\nNotes\nThis method is the DataFrame version of ndarray.argmin.", "Examples": [">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n...                     'co2_emissions': [37.2, 19.66, 1712]},\n...                   index=['Pork', 'Wheat Products', 'Beef'])"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["numeric_only bool, default False", "Include only float , int or boolean data."]], "Returns": [["Series", "Indexes of minima along the specified axis."]], "Category": ["Dataframe"], "index": 17}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last.html#pandas.DataFrame.last"], "Title": ["DataFrame.last"], "Feature": ["DataFrame.last"], "Description": "Select final periods of time series data based on a date offset.\nPlease create a mask and filter using.locinstead.\nFor a DataFrame with a sorted DatetimeIndex, this function\nselects the last few rows based on a date offset.\nNotes\nDeprecated since version 2.1.0:Please create a mask and filter using.loc instead", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n            A\n2018-04-09  1\n2018-04-11  2\n2018-04-13  3\n2018-04-15  4"], "Parameters": [["offset str, DateOffset, dateutil.relative delta", "The offset length of the data that will be selected. For instance,\n‘3D’ will display all the rows having their index within the last 3 days."]], "Returns": [["Series or DataFrame", "A subset of the caller."]], "Category": ["Dataframe"], "index": 18}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex"], "Title": ["DataFrame.reindex"], "Feature": ["DataFrame.reindex"], "Description": "Conform DataFrame to new index with optional filling logic.\nPlaces NA/NaN in locations having no value in the previous index. A new object\nis produced unless the new index is equivalent to the current one and copy=False.", "Examples": [">>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n>>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n...                   index=index)\n>>> df\n           http_status  response_time\nFirefox            200           0.04\nChrome             200           0.02\nSafari             404           0.07\nIE10               404           0.08\nKonqueror          301           1.00"], "Parameters": [["labels array-like, optional", "New labels / index to conform the axis specified by ‘axis’ to."], ["index array-like, optional", "New labels for the index. Preferably an Index object to avoid\nduplicating data."], ["columns array-like, optional", "New labels for the columns. Preferably an Index object to avoid\nduplicating data."], ["axis int or str, optional", "Axis to target. Can be either the axis name (‘index’, ‘columns’)\nor number (0, 1)."], ["method {None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index. None (default): don’t fill gaps pad / ffill: Propagate last valid observation forward to next\nvalid. backfill / bfill: Use next valid observation to fill gap. nearest: Use nearest valid observations to fill gap."], ["copy bool, default True", "Return a new object, even if the passed indexes are the same. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value scalar, default np.nan", "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value."], ["limit int, default None", "Maximum number of consecutive elements to forward or backward fill."], ["tolerance optional", "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations most\nsatisfy the equation abs(index[indexer] - target) <= tolerance . Tolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type."]], "Returns": [["DataFrame with changed index."]], "Category": ["Dataframe"], "index": 19}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex_like.html#pandas.DataFrame.reindex_like"], "Title": ["DataFrame.reindex_like"], "Feature": ["DataFrame.reindex_like"], "Description": "Return an object with matching indices as other object.\nConform the object to the same index on all axes. Optional\nfilling logic, placing NaN in locations having no value\nin the previous index. A new object is produced unless the\nnew index is equivalent to the current one and copy=False.\nNotes\nSame as calling.reindex(index=other.index,columns=other.columns,...).", "Examples": [">>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n...                     [31, 87.8, 'high'],\n...                     [22, 71.6, 'medium'],\n...                     [35, 95, 'medium']],\n...                    columns=['temp_celsius', 'temp_fahrenheit',\n...                             'windspeed'],\n...                    index=pd.date_range(start='2014-02-12',\n...                                        end='2014-02-15', freq='D'))"], "Parameters": [["other Object of the same data type", "Its row and column indices are used to define the new indices\nof this object."], ["method {None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index. None (default): don’t fill gaps pad / ffill: propagate last valid observation forward to next\nvalid backfill / bfill: use next valid observation to fill gap nearest: use nearest valid observations to fill gap."], ["copy bool, default True", "Return a new object, even if the passed indexes are the same. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["limit int, default None", "Maximum number of consecutive labels to fill for inexact matches."], ["tolerance optional", "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance . Tolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type."]], "Returns": [["Series or DataFrame", "Same type as caller, but with changed indices on each axis."]], "Category": ["Dataframe"], "index": 20}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#pandas.DataFrame.rename"], "Title": ["DataFrame.rename"], "Feature": ["DataFrame.rename"], "Description": "Rename columns or index labels.\nFunction / dict values must be unique (1-to-1). Labels not contained in\na dict / Series will be left as-is. Extra labels listed don’t throw an\nerror.\nSee the user guide for more.", "Examples": [">>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n>>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n   a  c\n0  1  4\n1  2  5\n2  3  6"], "Parameters": [["mapper dict-like or function", "Dict-like or function transformations to apply to\nthat axis’ values. Use either mapper and axis to\nspecify the axis to target with mapper , or index and columns ."], ["index dict-like or function", "Alternative to specifying axis ( mapper, axis=0 is equivalent to index=mapper )."], ["columns dict-like or function", "Alternative to specifying axis ( mapper, axis=1 is equivalent to columns=mapper )."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Axis to target with mapper . Can be either the axis name\n(‘index’, ‘columns’) or number (0, 1). The default is ‘index’."], ["copy bool, default True", "Also copy underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["inplace bool, default False", "Whether to modify the DataFrame rather than creating a new one.\nIf True then value of copy is ignored."], ["level int or level name, default None", "In case of a MultiIndex, only rename labels in the specified\nlevel."], ["errors {‘ignore’, ‘raise’}, default ‘ignore’", "If ‘raise’, raise a KeyError when a dict-like mapper , index ,\nor columns contains labels that are not present in the Index\nbeing transformed.\nIf ‘ignore’, existing keys will be renamed and extra keys will be\nignored."]], "Returns": [["DataFrame or None", "DataFrame with the renamed axis labels or None if inplace=True ."]], "Category": ["Dataframe"], "index": 21}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename_axis.html#pandas.DataFrame.rename_axis"], "Title": ["DataFrame.rename_axis"], "Feature": ["DataFrame.rename_axis"], "Description": "Set the name of the axis for the index or columns.\nNotes\nDataFrame.rename_axis supports two calling conventions\n(index=index_mapper,columns=columns_mapper,...)(mapper,axis={'index','columns'},...)\nThe first calling convention will only modify the names of\nthe index and/or the names of the Index object that is the columns.\nIn this case, the parametercopyis ignored.\nThe second calling convention will modify the names of the\ncorresponding index if mapper is a list or a scalar.\nHowever, if mapper is dict-like or a function, it will use the\ndeprecated behavior of modifying the axis labels.\nWehighly recommend using keyword arguments to clarify your\nintent.", "Examples": [">>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n>>> s\n0       dog\n1       cat\n2    monkey\ndtype: object\n>>> s.rename_axis(\"animal\")\nanimal\n0    dog\n1    cat\n2    monkey\ndtype: object"], "Parameters": [["mapper scalar, list-like, optional", "Value to set the axis name attribute."], ["index, columns scalar, list-like, dict-like or function, optional", "A scalar, list-like, dict-like or functions transformations to\napply to that axis’ values.\nNote that the columns parameter is not allowed if the\nobject is a Series. This parameter only apply for DataFrame\ntype objects. Use either mapper and axis to\nspecify the axis to target with mapper , or index and/or columns ."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to rename. For Series this parameter is unused and defaults to 0."], ["copy bool, default None", "Also copy underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["inplace bool, default False", "Modifies the object directly, instead of creating a new Series\nor DataFrame."]], "Returns": [["Series, DataFrame, or None", "The same type as the caller or None if inplace=True ."]], "Category": ["Dataframe"], "index": 22}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index"], "Title": ["DataFrame.reset_index"], "Feature": ["DataFrame.reset_index"], "Description": "Reset the index, or a level of it.\nReset the index of the DataFrame, and use the default one instead.\nIf the DataFrame has a MultiIndex, this method can remove one or more\nlevels.", "Examples": [">>> df = pd.DataFrame([('bird', 389.0),\n...                    ('bird', 24.0),\n...                    ('mammal', 80.5),\n...                    ('mammal', np.nan)],\n...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n...                   columns=('class', 'max_speed'))\n>>> df\n         class  max_speed\nfalcon    bird      389.0\nparrot    bird       24.0\nlion    mammal       80.5\nmonkey  mammal        NaN"], "Parameters": [["level int, str, tuple, or list, default None", "Only remove the given levels from the index. Removes all levels by\ndefault."], ["drop bool, default False", "Do not try to insert index into dataframe columns. This resets\nthe index to the default integer index."], ["inplace bool, default False", "Whether to modify the DataFrame rather than creating a new one."], ["col_level int or str, default 0", "If the columns have multiple levels, determines which level the\nlabels are inserted into. By default it is inserted into the first\nlevel."], ["col_fill object, default ‘’", "If the columns have multiple levels, determines how the other\nlevels are named. If None then the index name is repeated."], ["allow_duplicates bool, optional, default lib.no_default", "Allow duplicate column labels to be created."], ["names int, str or 1-dimensional list, default None", "Using the given string, rename the DataFrame column which contains the\nindex data. If the DataFrame has a MultiIndex, this has to be a list or\ntuple with length equal to the number of levels."]], "Returns": [["DataFrame or None", "DataFrame with the new index or None if inplace=True ."]], "Category": ["Dataframe"], "index": 23}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html#pandas.DataFrame.convert_dtypes"], "Title": ["DataFrame.convert_dtypes"], "Feature": ["DataFrame.convert_dtypes"], "Description": "Convert columns to the best possible dtypes using dtypes support in gpd.NA.\nNotes\nBy default,convert_dtypes will attempt to convert a Series (or each Series in a DataFrame) to dtypes that support pd.NA. By using the options convert_string,convert_integer,convert_boolean and convert_floating, it is possible to turn off individual conversions toStringDtype, the integer extension types,Boolean Dtype or floating extension types, respectively.\nFor object-dtyped columns, if infer_objects is True, use the inference rules as during normal Series/DataFrame construction.  Then, if possible,convert toStringDtype,Boolean Dtype or an appropriate integer or floating extension type, otherwise leave as object.\nIf the dtype is integer, convert to an appropriate integer extension type.\nIf the dtype is numeric, and consists of all integers, convert to an appropriate integer extension type. Otherwise, convert to an appropriate floating extension type.\nIn the future, as new dtypes are added that support pd.NA, the results of this method will change to support those new dtypes.", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n...     }\n... )"], "Parameters": [["infer_objects bool, default True", "Whether object dtypes should be converted to the best possible types."], ["convert_string bool, default True", "Whether object dtypes should be converted to StringDtype() ."], ["convert_integer bool, default True", "Whether, if possible, conversion can be done to integer extension types."], ["convert_boolean bool, defaults True", "Whether object dtypes should be converted to BooleanDtypes() ."], ["convert_floating bool, defaults True", "Whether, if possible, conversion can be done to floating extension types.\nIf convert_integer is also True, preference will be give to integer dtypes if the floats can be faithfully casted to integers."], ["dtype_backend {‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "Back-end data type applied to the resultant DataFrame (still experimental). Behaviour is as follows: \"numpy_nullable\" : returns nullable-dtype-backed DataFrame (default). \"pyarrow\" : returns pyarrow-backed nullable ArrowDtype DataFrame."]], "Returns": [["Series or DataFrame", "Copy of input object with new dtype."]], "Category": ["Dataframe"], "index": 24}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html#pandas.DataFrame.set_axis"], "Title": ["DataFrame.set_axis"], "Feature": ["DataFrame.set_axis"], "Description": "Assign desired index to given axis.\nIndexes for column or row labels can be changed by assigning\na list-like or Index.", "Examples": [">>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})"], "Parameters": [["labels list-like, Index", "The values for the new index."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to update. The value 0 identifies the rows. For Series this parameter is unused and defaults to 0."], ["copy bool, default True", "Whether to make a copy of the underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["DataFrame", "An object of type DataFrame."]], "Category": ["Dataframe"], "index": 25}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index"], "Title": ["DataFrame.set_index"], "Feature": ["DataFrame.set_index"], "Description": "Set the DataFrame index using existing columns.\nSet the DataFrame index (row labels) using one or more existing\ncolumns or arrays (of the correct length). The index can replace the\nexisting index or expand on it.", "Examples": [">>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n...                    'year': [2012, 2014, 2013, 2014],\n...                    'sale': [55, 40, 84, 31]})\n>>> df\n   month  year  sale\n0      1  2012    55\n1      4  2014    40\n2      7  2013    84\n3     10  2014    31"], "Parameters": [["keys label or array-like or list of labels/arrays", "This parameter can be either a single column key, a single array of\nthe same length as the calling DataFrame, or a list containing an\narbitrary combination of column keys and arrays. Here, “array”\nencompasses Series , Index , np.ndarray , and\ninstances of Iterator ."], ["drop bool, default True", "Delete columns to be used as the new index."], ["append bool, default False", "Whether to append columns to existing index."], ["inplace bool, default False", "Whether to modify the DataFrame rather than creating a new one."], ["verify_integrity bool, default False", "Check the new index for duplicates. Otherwise defer the check until\nnecessary. Setting to False will improve the performance of this\nmethod."]], "Returns": [["DataFrame or None", "Changed row labels or None if inplace=True ."]], "Category": ["Dataframe"], "index": 26}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.take.html#pandas.DataFrame.take"], "Title": ["DataFrame.take"], "Feature": ["DataFrame.take"], "Description": "Return the elements in the given positional indices along an axis.\nThis means that we are not indexing according to actual values in\nthe index attribute of the object. We are indexing according to the\nactual position of the element in the object.", "Examples": [">>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n...                    ('parrot', 'bird', 24.0),\n...                    ('lion', 'mammal', 80.5),\n...                    ('monkey', 'mammal', np.nan)],\n...                   columns=['name', 'class', 'max_speed'],\n...                   index=[0, 2, 3, 1])\n>>> df\n     name   class  max_speed\n0  falcon    bird      389.0\n2  parrot    bird       24.0\n3    lion  mammal       80.5\n1  monkey  mammal        NaN"], "Parameters": [["indices array-like", "An array of ints indicating which positions to take."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\nFor Series this parameter is unused and defaults to 0."], ["**kwargs", "For compatibility with numpy.take() . Has no effect on the\noutput."]], "Returns": [["same type as caller", "An array-like containing the elements taken from the object."]], "Category": ["Dataframe"], "index": 27}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truncate.html#pandas.DataFrame.truncate"], "Title": ["DataFrame.truncate"], "Feature": ["DataFrame.truncate"], "Description": "Truncate a Series or DataFrame before and after some index value.\nThis is a useful shorthand for boolean indexing based on index\nvalues above or below certain thresholds.\nNotes\nIf the index being truncated contains only datetime values,before and after may be specified as strings instead of\nTimestamps.", "Examples": [">>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n...                    'B': ['f', 'g', 'h', 'i', 'j'],\n...                    'C': ['k', 'l', 'm', 'n', 'o']},\n...                   index=[1, 2, 3, 4, 5])\n>>> df\n   A  B  C\n1  a  f  k\n2  b  g  l\n3  c  h  m\n4  d  i  n\n5  e  j  o"], "Parameters": [["before date, str, int", "Truncate all rows before this index value."], ["after date, str, int", "Truncate all rows after this index value."], ["axis {0 or ‘index’, 1 or ‘columns’}, optional", "Axis to truncate. Truncates the index (rows) by default.\nFor Series this parameter is unused and defaults to 0."], ["copy bool, default is True,", "Return a copy of the truncated section. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["type of caller", "The truncated Series or DataFrame."]], "Category": ["Dataframe"], "index": 28}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.backfill.html#pandas.DataFrame.backfill"], "Title": ["DataFrame.backfill"], "Feature": ["DataFrame.backfill"], "Description": "Fill NA/NaN values by using the next valid observation to fill the gap.", "Examples": [], "Parameters": [], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Dataframe"], "index": 29}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html#pandas.DataFrame.bfill"], "Title": ["DataFrame.bfill"], "Feature": ["DataFrame.bfill"], "Description": "Fill NA/NaN values by using the next valid observation to fill the gap.", "Examples": [">>> s = pd.Series([1, None, None, 2])\n>>> s.bfill()\n0    1.0\n1    2.0\n2    2.0\n3    2.0\ndtype: float64\n>>> s.bfill(limit=1)\n0    1.0\n1    NaN\n2    2.0\n3    2.0\ndtype: float64"], "Parameters": [["axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "Axis along which to fill missing values. For Series this parameter is unused and defaults to 0."], ["inplace bool, default False", "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame)."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["limit_area { None , ‘inside’, ‘outside’}, default None", "If limit is specified, consecutive NaNs will be filled with this\nrestriction. None : No fill restriction. ‘inside’: Only fill NaNs surrounded by valid values\n(interpolate). ‘outside’: Only fill NaNs outside valid values (extrapolate)."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible)."]], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Dataframe"], "index": 30}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna"], "Title": ["DataFrame.dropna"], "Feature": ["DataFrame.dropna"], "Description": "Remove missing values.\nSee theUser Guide for more on which values are\nconsidered missing, and how to work with missing data.", "Examples": [">>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n...                             pd.NaT]})\n>>> df\n       name        toy       born\n0    Alfred        NaN        NaT\n1    Batman  Batmobile 1940-04-25\n2  Catwoman   Bullwhip        NaT"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Determine if rows or columns which contain missing values are\nremoved. 0, or ‘index’ : Drop rows which contain missing values. 1, or ‘columns’ : Drop columns which contain missing value. Only a single axis is allowed."], ["how {‘any’, ‘all’}, default ‘any’", "Determine if row or column is removed from DataFrame, when we have\nat least one NA or all NA. ‘any’ : If any NA values are present, drop that row or column. ‘all’ : If all values are NA, drop that row or column."], ["thresh int, optional", "Require that many non-NA values. Cannot be combined with how."], ["subset column label or sequence of labels, optional", "Labels along other axis to consider, e.g. if you are dropping rows\nthese would be a list of columns to include."], ["inplace bool, default False", "Whether to modify the DataFrame rather than creating a new one."], ["ignore_index bool, default False", "If True , the resulting axis will be labeled 0, 1, …, n - 1."]], "Returns": [["DataFrame or None", "DataFrame with NA entries dropped from it or None if inplace=True ."]], "Category": ["Dataframe"], "index": 31}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html#pandas.DataFrame.ffill"], "Title": ["DataFrame.ffill"], "Feature": ["DataFrame.ffill"], "Description": "Fill NA/NaN values by propagating the last valid observation to next valid.", "Examples": [">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n...                    [3, 4, np.nan, 1],\n...                    [np.nan, np.nan, np.nan, np.nan],\n...                    [np.nan, 3, np.nan, 4]],\n...                   columns=list(\"ABCD\"))\n>>> df\n     A    B   C    D\n0  NaN  2.0 NaN  0.0\n1  3.0  4.0 NaN  1.0\n2  NaN  NaN NaN  NaN\n3  NaN  3.0 NaN  4.0"], "Parameters": [["axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "Axis along which to fill missing values. For Series this parameter is unused and defaults to 0."], ["inplace bool, default False", "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame)."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["limit_area { None , ‘inside’, ‘outside’}, default None", "If limit is specified, consecutive NaNs will be filled with this\nrestriction. None : No fill restriction. ‘inside’: Only fill NaNs surrounded by valid values\n(interpolate). ‘outside’: Only fill NaNs outside valid values (extrapolate)."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible)."]], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Dataframe"], "index": 32}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna"], "Title": ["DataFrame.fillna"], "Feature": ["DataFrame.fillna"], "Description": "Fill NA/NaN values using the specified method.", "Examples": [">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n...                    [3, 4, np.nan, 1],\n...                    [np.nan, np.nan, np.nan, np.nan],\n...                    [np.nan, 3, np.nan, 4]],\n...                   columns=list(\"ABCD\"))\n>>> df\n     A    B   C    D\n0  NaN  2.0 NaN  0.0\n1  3.0  4.0 NaN  1.0\n2  NaN  NaN NaN  NaN\n3  NaN  3.0 NaN  4.0"], "Parameters": [["value scalar, dict, Series, or DataFrame", "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame).  Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list."], ["method {‘backfill’, ‘bfill’, ‘ffill’, None}, default None", "Method to use for filling holes in reindexed Series: ffill: propagate last valid observation forward to next valid. backfill / bfill: use next valid observation to fill gap."], ["axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "Axis along which to fill missing values. For Series this parameter is unused and defaults to 0."], ["inplace bool, default False", "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame)."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible)."]], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Dataframe"], "index": 33}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate"], "Title": ["DataFrame.interpolate"], "Feature": ["DataFrame.interpolate"], "Description": "Fill NaN values using an interpolation method.\nPlease note that only method='linear' is supported for\nDataFrame/Series with a MultiIndex.\nNotes\nThe ‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’ and ‘akima’\nmethods are wrappers around the respective SciPy implementations of\nsimilar names. These use the actual numerical values of the index.\nFor more information on their behavior, see theSciPy documentation.", "Examples": [">>> s = pd.Series([0, 1, np.nan, 3])\n>>> s\n0    0.0\n1    1.0\n2    NaN\n3    3.0\ndtype: float64\n>>> s.interpolate()\n0    0.0\n1    1.0\n2    2.0\n3    3.0\ndtype: float64"], "Parameters": [["method str, default ‘linear’", "Interpolation technique to use. One of: ‘linear’: Ignore the index and treat the values as equally\nspaced. This is the only method supported on MultiIndexes. ‘time’: Works on daily and higher resolution data to interpolate\ngiven length of interval. ‘index’, ‘values’: use the actual numerical values of the index. ‘pad’: Fill in NaNs using existing values. ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\n‘barycentric’, ‘polynomial’: Passed to scipy.interpolate.interp1d , whereas ‘spline’ is passed to scipy.interpolate.UnivariateSpline . These methods use the numerical\nvalues of the index.  Both ‘polynomial’ and ‘spline’ require that\nyou also specify an order (int), e.g. df.interpolate(method='polynomial', order=5) . Note that, slinear method in Pandas refers to the Scipy first order spline instead of Pandas first order spline . ‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\nsimilar names. See Notes . ‘from_derivatives’: Refers to scipy.interpolate.BPoly.from_derivatives ."], ["axis {{0 or ‘index’, 1 or ‘columns’, None}}, default None", "Axis to interpolate along. For Series this parameter is unused\nand defaults to 0."], ["limit int, optional", "Maximum number of consecutive NaNs to fill. Must be greater than\n0."], ["inplace bool, default False", "Update the data in place if possible."], ["limit_direction {{‘forward’, ‘backward’, ‘both’}}, Optional", "Consecutive NaNs will be filled in this direction. If limit is specified: If ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’. If ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’. If ‘limit’ is not specified: If ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’ else the default is ‘forward’ raises ValueError if limit_direction is ‘forward’ or ‘both’ and method is ‘backfill’ or ‘bfill’. raises ValueError if limit_direction is ‘backward’ or ‘both’ and method is ‘pad’ or ‘ffill’."], ["If limit is specified:", "If ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’. If ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’."], ["If ‘limit’ is not specified:", "If ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’ else the default is ‘forward’"], ["raises ValueError if limit_direction is ‘forward’ or ‘both’ and", "method is ‘backfill’ or ‘bfill’."], ["raises ValueError if limit_direction is ‘backward’ or ‘both’ and", "method is ‘pad’ or ‘ffill’."], ["limit_area {{ None , ‘inside’, ‘outside’}}, default None", "If limit is specified, consecutive NaNs will be filled with this\nrestriction. None : No fill restriction. ‘inside’: Only fill NaNs surrounded by valid values\n(interpolate). ‘outside’: Only fill NaNs outside valid values (extrapolate)."], ["downcast optional, ‘infer’ or None, defaults to None", "Downcast dtypes if possible."], ["``**kwargs`` optional", "Keyword arguments to pass on to the interpolating function."]], "Returns": [["Series or DataFrame or None", "Returns the same object type as the caller, interpolated at\nsome or all NaN values or None if inplace=True ."]], "Category": ["Dataframe"], "index": 34}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy"], "Title": ["DataFrame.copy"], "Feature": ["DataFrame.copy"], "Description": "Make a copy of this object’s indices and data.\nWhen deep=True(default), a new object will be created with a copy of the calling object’s data and indices. Modifications to the data or indices of the copy will not be reflected in the original object (see notes below).\nWhen deep=False, a new object will be created without copying the calling object’s data or index (only references to the data and index are copied). Any changes to the data of the original will be reflected in the shallow copy (and vice versa).\nNotes\nWhen deep=True, data is copied but actual Python objects will not be copied recursively, only the reference to the object.\nThis is in contrast to copy.deepcopy in the Standard Library,which recursively copies object data (see examples below).\nWhile Index objects are copied when deep=True, the underlying numpy array is not copied for performance reasons. Since Index is immutable, the underlying data can be safely shared and a copy is not needed.\nSince pandas is not thread safe, see the gotchas when copying in a threading environment.\nWhen copy_on_write in pandas config is set toTrue, the copy_on_write config takes effect even when deep=False.\nThis means that any changes to the copied data would make a new copy of the data upon write (and vice versa). Changes made to either the original or copied variable would not be reflected in the counterpart.\nSee Copy_on_Write for more information.", "Examples": [">>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n>>> s\na    1\nb    2\ndtype: int64"], "Parameters": [["deep bool, default True", "Make a deep copy, including a copy of the data and the indices.\nWith deep=False neither the indices nor the data are copied."]], "Returns": [["Series or DataFrame", "Object type matches caller."]], "Category": ["Dataframe"], "index": 35}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna"], "Title": ["DataFrame.isna"], "Feature": ["DataFrame.isna"], "Description": "Detect missing values.\nReturn a boolean same-sized object indicating if the values are NA.\nNA values, such as None ornumpy.NaN, gets mapped to True\nvalues.\nEverything else gets mapped to False values. Characters such as empty\nstrings''or numpy.inf are not considered NA values\n(unless you set pandas.options.mode.use_inf_as_na=True).", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker"], "Parameters": [], "Returns": [["DataFrame", "Mask of bool values for each element in DataFrame that\nindicates whether an element is an NA value."]], "Category": ["Dataframe"], "index": 36}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html#pandas.DataFrame.isnull"], "Title": ["DataFrame.isnull"], "Feature": ["DataFrame.isnull"], "Description": "DataFrame.isnull is an alias for DataFrame.isna.\nDetect missing values.\nReturn a boolean same-sized object indicating if the values are NA.\nNA values, such as None ornumpy.NaN, gets mapped to True\nvalues.\nEverything else gets mapped to False values. Characters such as empty\nstrings''or numpy.inf are not considered NA values\n(unless you set pandas.options.mode.use_inf_as_na=True).", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker"], "Parameters": [], "Returns": [["DataFrame", "Mask of bool values for each element in DataFrame that\nindicates whether an element is an NA value."]], "Category": ["Dataframe"], "index": 37}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html#pandas.DataFrame.notna"], "Title": ["DataFrame.notna"], "Feature": ["DataFrame.notna"], "Description": "Detect existing (non-missing) values.\nReturn a boolean same-sized object indicating if the values are not NA.\nNon-missing values get mapped to True. Characters such as empty\nstrings''or umpy.inf are not considered NA values\n(unless you set pandas.options.mode.use_inf_as_na=True).\nNA values, such as None or numpy.NaN, get mapped to False\nvalues.", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker"], "Parameters": [], "Returns": [["DataFrame", "Mask of bool values for each element in DataFrame that\nindicates whether an element is not an NA value."]], "Category": ["Dataframe"], "index": 38}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html#pandas.DataFrame.notnull"], "Title": ["DataFrame.notnull"], "Feature": ["DataFrame.notnull"], "Description": "DataFrame.notnull is an alias for DataFrame.notna.\nDetect existing (non-missing) values.\nReturn a boolean same-sized object indicating if the values are not NA.\nNon-missing values get mapped to True. Characters such as empty\nstrings''or numpy.inf are not considered NA values\n(unless you set pandas.options.mode.use_inf_as_na=True).\nNA values, such as None or numpy.NaN, get mapped to False\nvalues.\nSee alsoDataFrame.notnullAlias of notna.DataFrame.isnaBoolean inverse of notna.DataFrame.dropnaOmit axes labels with missing values.notnaTop-level notna.", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker"], "Parameters": [], "Returns": [["DataFrame", "Mask of bool values for each element in DataFrame that\nindicates whether an element is not an NA value."]], "Category": ["Dataframe"], "index": 39}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pad.html#pandas.DataFrame.pad"], "Title": ["DataFrame.pad"], "Feature": ["DataFrame.pad"], "Description": "Fill NA/NaN values by propagating the last valid observation to next valid.\nDeprecated since version 2.0:Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.", "Examples": [], "Parameters": [], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Dataframe"], "index": 40}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace"], "Title": ["DataFrame.replace"], "Feature": ["DataFrame.replace"], "Description": "Replace values given into_replacewithvalue.\nValues of the Series/DataFrame are replaced with other values dynamically.\nThis differs from updating with.locor.iloc, which require\nyou to specify a location to update with some value.\nSee alsoSeries.fillnaFill NA values.DataFrame.fillnaFill NA values.Series.whereReplace values based on boolean condition.DataFrame.whereReplace values based on boolean condition.DataFrame.mapApply a function to a Dataframe elementwise.Series.mapMap values of Series according to an input mapping or function.Series.str.replaceSimple string replacement.\nNotes\nRegex substitution is performed under the hood withre.sub. The\nrules for substitution forre.subare the same.Regular expressions will only substitute on strings, meaning you\ncannot provide, for example, a regular expression matching floating\npoint numbers and expect the columns in your frame that have a\nnumeric dtype to be matched. However, if those floating point\nnumbers are strings, then you can do this.This method has a lot of options. You are encouraged to experiment\nand play with this method to gain intuition about how it works.When dict is used as theto_replace value, it is like\nkey(s) in the dict are the to_replace part and\nvalue(s) in the dict are the value parameter.", "Examples": [">>> s = pd.Series([1, 2, 3, 4, 5])\n>>> s.replace(1, 5)\n0    5\n1    2\n2    3\n3    4\n4    5\ndtype: int64"], "Parameters": [["to_replace str, regex, list, dict, Series, int, float, or None", "How to find the values that will be replaced. numeric, str or regex: numeric: numeric values equal to to_replace will be\nreplaced with value str: string exactly matching to_replace will be replaced\nwith value regex: regexs matching to_replace will be replaced with value list of str, regex, or numeric: First, if to_replace and value are both lists, they must be the same length. Second, if regex=True then all of the strings in both lists will be interpreted as regexs otherwise they will match\ndirectly. This doesn’t matter much for value since there\nare only a few possible substitution regexes you can use. str, regex and numeric rules apply as above. dict: Dicts can be used to specify different replacement values\nfor different existing values. For example, {'a': 'b', 'y': 'z'} replaces the value ‘a’ with ‘b’ and\n‘y’ with ‘z’. To use a dict in this way, the optional value parameter should not be given. For a DataFrame a dict can specify that different values\nshould be replaced in different columns. For example, {'a': 1, 'b': 'z'} looks for the value 1 in column ‘a’\nand the value ‘z’ in column ‘b’ and replaces these values\nwith whatever is specified in value . The value parameter\nshould not be None in this case. You can treat this as a\nspecial case of passing two lists except that you are\nspecifying the column to search in. For a DataFrame nested dictionaries, e.g., {'a': {'b': np.nan}} , are read as follows: look in column\n‘a’ for the value ‘b’ and replace it with NaN. The optional value parameter should not be specified to use a nested dict in this\nway. You can nest regular expressions as well. Note that\ncolumn names (the top-level dictionary keys in a nested\ndictionary) cannot be regular expressions. None: This means that the regex argument must be a string,\ncompiled regular expression, or list, dict, ndarray or\nSeries of such elements. If value is also None then\nthis must be a nested dictionary or Series. See the examples section for examples of each of these."], ["value scalar, dict, list, str, regex, default None", "Value to replace any values matching to_replace with.\nFor a DataFrame a dict of values can be used to specify which\nvalue to use for each column (columns not in the dict will not be\nfilled). Regular expressions, strings and lists or dicts of such\nobjects are also allowed."], ["inplace bool, default False", "If True, performs operation inplace and returns None."], ["limit int, default None", "Maximum size gap to forward or backward fill."], ["regex bool or same types as to_replace , default False", "Whether to interpret to_replace and/or value as regular\nexpressions. Alternatively, this could be a regular expression or a\nlist, dict, or array of regular expressions in which case to_replace must be None ."], ["method {‘pad’, ‘ffill’, ‘bfill’}", "The method to use when for replacement, when to_replace is a\nscalar, list or tuple and value is None ."]], "Returns": [["Series/DataFrame", "Object after replacement."]], "Category": ["Dataframe"], "index": 41}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.droplevel.html#pandas.DataFrame.droplevel"], "Title": ["DataFrame.droplevel"], "Feature": ["DataFrame.droplevel"], "Description": "Return Series/DataFrame with requested index / column level(s) removed.", "Examples": [">>> df = pd.DataFrame([\n...     [1, 2, 3, 4],\n...     [5, 6, 7, 8],\n...     [9, 10, 11, 12]\n... ]).set_index([0, 1]).rename_axis(['a', 'b'])"], "Parameters": [["level int, str, or list-like", "If a string is given, must be the name of a level\nIf list-like, elements must be names or positional indexes\nof levels."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Axis along which the level(s) is removed: 0 or ‘index’: remove level(s) in column. 1 or ‘columns’: remove level(s) in row. For Series this parameter is unused and defaults to 0."]], "Returns": [["Series/DataFrame", "Series/DataFrame with requested index / column level(s) removed."]], "Category": ["Dataframe"], "index": 42}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot"], "Title": ["DataFrame.pivot"], "Feature": ["DataFrame.pivot"], "Description": "Return reshaped DataFrame organized by given index / column values.\nReshape data (produce a “pivot” table) based on column values. Uses\nunique values from specified index/columns to form axes of the\nresulting DataFrame. This function does not support data\naggregation, multiple values will result in a MultiIndex in the\ncolumns. See theUser Guide for more on reshaping.\nNotes\nFor finer-tuned control, see hierarchical indexing documentation along\nwith the related stack/unstack methods.\nReference the user guide for more examples.", "Examples": [">>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n...                            'two'],\n...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n...                    'baz': [1, 2, 3, 4, 5, 6],\n...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n>>> df\n    foo   bar  baz  zoo\n0   one   A    1    x\n1   one   B    2    y\n2   one   C    3    z\n3   two   A    4    q\n4   two   B    5    w\n5   two   C    6    t"], "Parameters": [["columns str or object or a list of str", "Column to use to make new frame’s columns."], ["index str or object or a list of str, optional", "Column to use to make new frame’s index. If not given, uses existing index."], ["values str, object or a list of the previous, optional", "Column(s) to use for populating new frame’s values. If not\nspecified, all remaining columns will be used and the result will\nhave hierarchically indexed columns."]], "Returns": [["DataFrame", "Returns reshaped DataFrame."]], "Category": ["Dataframe"], "index": 43}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table"], "Title": ["DataFrame.pivot_table"], "Feature": ["DataFrame.pivot_table"], "Description": "Create a spreadsheet-style pivot table as a DataFrame.\nThe levels in the pivot table will be stored in MultiIndex objects\n(hierarchical indexes) on the index and columns of the result DataFrame.\nNotes\nReference the user guide for more examples.", "Examples": [">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n...                          \"one\", \"one\", \"two\", \"two\"],\n...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n...                          \"small\", \"large\", \"small\", \"small\",\n...                          \"large\"],\n...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n>>> df\n     A    B      C  D  E\n0  foo  one  small  1  2\n1  foo  one  large  2  4\n2  foo  one  large  2  5\n3  foo  two  small  3  5\n4  foo  two  small  3  6\n5  bar  one  large  4  6\n6  bar  one  small  5  8\n7  bar  two  small  6  9\n8  bar  two  large  7  9"], "Parameters": [["values list-like or scalar, optional", "Column or columns to aggregate."], ["index column, Grouper, array, or list of the previous", "Keys to group by on the pivot table index. If a list is passed,\nit can contain any of the other types (except list). If an array is\npassed, it must be the same length as the data and will be used in\nthe same manner as column values."], ["columns column, Grouper, array, or list of the previous", "Keys to group by on the pivot table column. If a list is passed,\nit can contain any of the other types (except list). If an array is\npassed, it must be the same length as the data and will be used in\nthe same manner as column values."], ["aggfunc function, list of functions, dict, default “mean”", "If a list of functions is passed, the resulting pivot table will have\nhierarchical columns whose top level are the function names\n(inferred from the function objects themselves).\nIf a dict is passed, the key is column to aggregate and the value is\nfunction or list of functions. If margin=True , aggfunc will be\nused to calculate the partial aggregates."], ["fill_value scalar, default None", "Value to replace missing values with (in the resulting pivot table,\nafter aggregation)."], ["margins bool, default False", "If margins=True , special All columns and rows\nwill be added with partial group aggregates across the categories\non the rows and columns."], ["dropna bool, default True", "Do not include columns whose entries are all NaN. If True,\nrows with a NaN value in any column will be omitted before\ncomputing margins."], ["margins_name str, default ‘All’", "Name of the row / column that will contain the totals\nwhen margins is True."], ["observed bool, default False", "This only applies if any of the groupers are Categoricals.\nIf True: only show observed values for categorical groupers.\nIf False: show all values for categorical groupers. Deprecated since version 2.2.0: The default value of False is deprecated and will change to True in a future version of pandas."], ["sort bool, default True", "Specifies if the result should be sorted."]], "Returns": [["DataFrame", "An Excel style pivot table."]], "Category": ["Dataframe"], "index": 44}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reorder_levels.html#pandas.DataFrame.reorder_levels"], "Title": ["DataFrame.reorder_levels"], "Feature": ["DataFrame.reorder_levels"], "Description": "Rearrange index levels using input order. May not drop or duplicate levels.", "Examples": [">>> data = {\n...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\n...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\n...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\n... }\n>>> df = pd.DataFrame(data, columns=[\"class\", \"diet\", \"species\"])\n>>> df = df.set_index([\"class\", \"diet\"])\n>>> df\n                                  species\nclass      diet\nMammals    Omnivore                Humans\n           Carnivore                 Dogs\nReptiles   Carnivore               Snakes"], "Parameters": [["order list of int or list of str", "List representing new level order. Reference level by number\n(position) or by key (label)."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Where to reorder levels."]], "Returns": [["DataFrame"]], "Category": ["Dataframe"], "index": 45}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bool.html#pandas.DataFrame.bool"], "Title": ["DataFrame.bool"], "Feature": ["DataFrame.bool"], "Description": "Return the bool of a single element Series or DataFrame.\nbool is deprecated and will be removed in future version of pandas.\nFor Series use pandas.Series.item.\nThis must be a boolean scalar value, either True or False. It will raise a ValueError if the Series or DataFrame does not have exactly 1 element, or that element is not boolean (integer values 0 and 1 will also raise an exception).", "Examples": [">>> pd.Series([True]).bool()  \nTrue\n>>> pd.Series([False]).bool()  \nFalse"], "Parameters": [], "Returns": [["bool", "The value in the Series or DataFrame."]], "Category": ["Dataframe"], "index": 46}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index"], "Title": ["DataFrame.sort_index"], "Feature": ["DataFrame.sort_index"], "Description": "Sort object by labels (along an axis).\nReturns a new DataFrame sorted by label if inplace argument isFalse, otherwise updates the original DataFrame and returns None.", "Examples": [">>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n...                   columns=['A'])\n>>> df.sort_index()\n     A\n1    4\n29   2\n100  1\n150  5\n234  3"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis along which to sort.  The value 0 identifies the rows,\nand 1 identifies the columns."], ["level int or level name or list of ints or list of level names", "If not None, sort on values in specified index level(s)."], ["ascending bool or list-like of bools, default True", "Sort ascending vs. descending. When the index is a MultiIndex the\nsort direction can be controlled for each level individually."], ["inplace bool, default False", "Whether to modify the DataFrame rather than creating a new one."], ["kind {‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. mergesort and stable are the only stable algorithms. For\nDataFrames, this option is only applied when sorting on a single\ncolumn or label."], ["na_position {‘first’, ‘last’}, default ‘last’", "Puts NaNs at the beginning if first ; last puts NaNs at the end.\nNot implemented for MultiIndex."], ["sort_remaining bool, default True", "If True and sorting by level and index is multilevel, sort by other\nlevels too (in order) after sorting by specified level."], ["ignore_index bool, default False", "If True, the resulting axis will be labeled 0, 1, …, n - 1."], ["key callable, optional", "If not None, apply the key function to the index values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized . It should expect an Index and return an Index of the same shape. For MultiIndex\ninputs, the key is applied per level ."]], "Returns": [["DataFrame or None", "The original DataFrame sorted by the labels or None if inplace=True ."]], "Category": ["Dataframe"], "index": 47}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html#pandas.DataFrame.nlargest"], "Title": ["DataFrame.nlargest"], "Feature": ["DataFrame.nlargest"], "Description": "Return the first n rows ordered by columnsin descending order.\nReturn the first n rows with the largest values incolumns, in\ndescending order. The columns that are not specified are returned as\nwell, but not used for ordering.\nThis method is equivalent to df.sort_values(columns,ascending=False).head(n), but more\nperformant.\nNotes\nThis function cannot be used with all column types. For example, when\nspecifying columns with objector category dtypes,TypeErroris\nraised.", "Examples": [">>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n...                                   434000, 434000, 337000, 11300,\n...                                   11300, 11300],\n...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n...                            17036, 182, 38, 311],\n...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n...                   index=[\"Italy\", \"France\", \"Malta\",\n...                          \"Maldives\", \"Brunei\", \"Iceland\",\n...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n>>> df\n          population      GDP alpha-2\nItaly       59000000  1937894      IT\nFrance      65000000  2583560      FR\nMalta         434000    12011      MT\nMaldives      434000     4520      MV\nBrunei        434000    12128      BN\nIceland       337000    17036      IS\nNauru          11300      182      NR\nTuvalu         11300       38      TV\nAnguilla       11300      311      AI"], "Parameters": [["n int", "Number of rows to return."], ["columns label or list of labels", "Column label(s) to order by."], ["keep {‘first’, ‘last’, ‘all’}, default ‘first’", "Where there are duplicate values: first : prioritize the first occurrence(s) last : prioritize the last occurrence(s) all : keep all the ties of the smallest item even if it means\nselecting more than n items."]], "Returns": [["DataFrame", "The first n rows ordered by the given columns in descending\norder."]], "Category": ["Dataframe"], "index": 48}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html#pandas.DataFrame.nsmallest"], "Title": ["DataFrame.nsmallest"], "Feature": ["DataFrame.nsmallest"], "Description": "Return the first n rows ordered by columnsin ascending order.\nReturn the first n rows with the smallest values incolumns, in\nascending order. The columns that are not specified are returned as\nwell, but not used for ordering.\nThis method is equivalent to df.sort_values(columns,ascending=True).head(n), but more\nperformant.\nSee alsoDataFrame.nlargestReturn the first n rows ordered by columnsin descending order.DataFrame.sort_valuesSort DataFrame by the values.DataFrame.headReturn the first n rows without re-ordering.", "Examples": [">>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n...                                   434000, 434000, 337000, 337000,\n...                                   11300, 11300],\n...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n...                            17036, 182, 38, 311],\n...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n...                   index=[\"Italy\", \"France\", \"Malta\",\n...                          \"Maldives\", \"Brunei\", \"Iceland\",\n...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n>>> df\n          population      GDP alpha-2\nItaly       59000000  1937894      IT\nFrance      65000000  2583560      FR\nMalta         434000    12011      MT\nMaldives      434000     4520      MV\nBrunei        434000    12128      BN\nIceland       337000    17036      IS\nNauru         337000      182      NR\nTuvalu         11300       38      TV\nAnguilla       11300      311      AI"], "Parameters": [["n int", "Number of items to retrieve."], ["columns list or str", "Column name or names to order by."], ["keep {‘first’, ‘last’, ‘all’}, default ‘first’", "Where there are duplicate values: first : take the first occurrence. last : take the last occurrence. all : keep all the ties of the largest item even if it means\nselecting more than n items."]], "Returns": [["DataFrame"]], "Category": ["Dataframe"], "index": 49}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swaplevel.html#pandas.DataFrame.swaplevel"], "Title": ["DataFrame.swaplevel"], "Feature": ["DataFrame.swaplevel"], "Description": "Swap levels i and j in aMultiIndex.\nDefault is to swap the two innermost levels of the index.", "Examples": [">>> df = pd.DataFrame(\n...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\n...     index=[\n...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n...         [\"January\", \"February\", \"March\", \"April\"],\n...     ],\n... )\n>>> df\n                                    Grade\nFinal exam  History     January      A\n            Geography   February     B\nCoursework  History     March        A\n            Geography   April        C"], "Parameters": [["i, j int or str", "Levels of the indices to be swapped. Can pass level name as string."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to swap levels on. 0 or ‘index’ for row-wise, 1 or\n‘columns’ for column-wise."]], "Returns": [["DataFrame", "DataFrame with levels swapped in MultiIndex."]], "Category": ["Dataframe"], "index": 50}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"], "Title": ["DataFrame.stack"], "Feature": ["DataFrame.stack"], "Description": "Stack the prescribed level(s) from columns to index.\nReturn a reshaped DataFrame or Series having a multi-level\nindex with one or more new inner-most levels compared to the current\nDataFrame. The new inner-most levels are created by pivoting the\ncolumns of the current dataframe:\nSee alsoDataFrame.unstackUnstack prescribed level(s) from index axis onto column axis.DataFrame.pivotReshape dataframe from long format to wide format.DataFrame.pivot_tableCreate a spreadsheet-style pivot table as a DataFrame.\nNotes\nThe function is named by analogy with a collection of books\nbeing reorganized from being side by side on a horizontal\nposition (the columns of the dataframe) to being stacked\nvertically on top of each other (in the index of the\ndataframe).\nReference the user guide for more examples.", "Examples": [">>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n...                                     index=['cat', 'dog'],\n...                                     columns=['weight', 'height'])"], "Parameters": [["level int, str, list, default -1", "Level(s) to stack from the column axis onto the index\naxis, defined as one index or label, or a list of indices\nor labels."], ["dropna bool, default True", "Whether to drop rows in the resulting Frame/Series with\nmissing values. Stacking a column level onto the index\naxis can create combinations of index and column values\nthat are missing from the original dataframe. See Examples\nsection."], ["sort bool, default True", "Whether to sort the levels of the resulting MultiIndex."], ["future_stack bool, default False", "Whether to use the new implementation that will replace the current\nimplementation in pandas 3.0. When True, dropna and sort have no impact\non the result and must remain unspecified. See pandas 2.1.0 Release\nnotes for more details."]], "Returns": [["DataFrame or Series", "Stacked dataframe or series."]], "Category": ["Dataframe"], "index": 51}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"], "Title": ["DataFrame.unstack"], "Feature": ["DataFrame.unstack"], "Description": "Pivot a level of the (necessarily hierarchical) index labels.\nReturns a DataFrame having a new level of column labels whose inner-most level\nconsists of the pivoted index labels.\nIf the index is not a MultiIndex, the output will be a Series\n(the analogue of stack when the columns are not a MultiIndex).\nNotes\nReference the user guide for more examples.", "Examples": [">>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n...                                    ('two', 'a'), ('two', 'b')])\n>>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n>>> s\none  a   1.0\n     b   2.0\ntwo  a   3.0\n     b   4.0\ndtype: float64"], "Parameters": [["level int, str, or list of these, default -1 (last level)", "Level(s) of index to unstack, can pass level name."], ["fill_value int, str or dict", "Replace NaN with this value if the unstack produces missing values."], ["sort bool, default True", "Sort the level(s) in the resulting MultiIndex columns."]], "Returns": [["Series or DataFrame"]], "Category": ["Dataframe"], "index": 52}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.swapaxes.html#pandas.DataFrame.swapaxes"], "Title": ["DataFrame.swapaxes"], "Feature": ["DataFrame.swapaxes"], "Description": "Interchange axes and swap values axes appropriately.\nPlease use transpose instead.", "Examples": [], "Parameters": [], "Returns": [["same as input"]], "Category": ["Dataframe"], "index": 53}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt"], "Title": ["DataFrame.melt"], "Feature": ["DataFrame.melt"], "Description": "Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\nThis function is useful to massage a DataFrame into a format where one\nor more columns are identifier variables (id_vars), while all other\ncolumns, considered measured variables (value_vars), are “unpivoted” to\nthe row axis, leaving just two non-identifier columns, ‘variable’ and\n‘value’.\nNotes\nReference the user guide for more examples.", "Examples": [">>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n...                    'B': {0: 1, 1: 3, 2: 5},\n...                    'C': {0: 2, 1: 4, 2: 6}})\n>>> df\n   A  B  C\n0  a  1  2\n1  b  3  4\n2  c  5  6"], "Parameters": [["id_vars scalar, tuple, list, or ndarray, optional", "Column(s) to use as identifier variables."], ["value_vars scalar, tuple, list, or ndarray, optional", "Column(s) to unpivot. If not specified, uses all columns that\nare not set as id_vars ."], ["var_name scalar, default None", "Name to use for the ‘variable’ column. If None it uses frame.columns.name or ‘variable’."], ["value_name scalar, default ‘value’", "Name to use for the ‘value’ column, can’t be an existing column label."], ["col_level scalar, optional", "If columns are a MultiIndex then use this level to melt."], ["ignore_index bool, default True", "If True, original index is ignored. If False, the original index is retained.\nIndex labels will be repeated as necessary."]], "Returns": [["DataFrame", "Unpivoted DataFrame."]], "Category": ["Dataframe"], "index": 54}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html#pandas.DataFrame.explode"], "Title": ["DataFrame.explode"], "Feature": ["DataFrame.explode"], "Description": "Transform each element of a list-like to a row, replicating index values.\nNotes\nThis routine will explode list-likes including lists, tuples, sets,\nSeries, and np.ndarray. The result dtype of the subset rows will\nbe object. Scalars will be returned unchanged, and empty list-likes will\nresult in a np.nan for that row. In addition, the ordering of rows in the\noutput will be non-deterministic when exploding sets.\nReference the user guide for more examples.", "Examples": [">>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\n...                    'B': 1,\n...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\n>>> df\n           A  B          C\n0  [0, 1, 2]  1  [a, b, c]\n1        foo  1        NaN\n2         []  1         []\n3     [3, 4]  1     [d, e]"], "Parameters": [["column IndexLabel", "Column(s) to explode.\nFor multiple columns, specify a non-empty list with each element\nbe str or tuple, and all specified columns their list-like data\non same row of the frame must have matching length."], ["ignore_index bool, default False", "If True, the resulting index will be labeled 0, 1, …, n - 1."]], "Returns": [["DataFrame", "Exploded lists to rows of the subset columns;\nindex will be duplicated for these rows."]], "Category": ["Dataframe"], "index": 55}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html#pandas.DataFrame.squeeze"], "Title": ["DataFrame.squeeze"], "Feature": ["DataFrame.squeeze"], "Description": "Squeeze 1 dimensional axis objects into scalars.\nSeries or DataFrames with a single element are squeezed to a scalar.\nDataFrames with a single column or a single row are squeezed to a\nSeries. Otherwise the object is unchanged.\nThis method is most useful when you don’t know if your\nobject is a Series or DataFrame, but you do know it has just a single\ncolumn. In that case you can safely call squeeze to ensure you have a\nSeries.\nSee alsoSeries.ilocInteger-location based indexing for selecting scalars.DataFrame.ilocInteger-location based indexing for selecting Series.Series.to_frameInverse of DataFrame.squeeze for a single-column DataFrame.", "Examples": [">>> primes = pd.Series([2, 3, 5, 7])"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "A specific axis to squeeze. By default, all length-1 axes are\nsqueezed. For Series this parameter is unused and defaults to None ."]], "Returns": [["DataFrame, Series, or scalar", "The projection after squeezing axis or all the axes."]], "Category": ["Dataframe"], "index": 56}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head"], "Title": ["DataFrame.head"], "Feature": ["DataFrame.head"], "Description": "Return the first n rows.\nThis function returns the first n rows for the object based on position. It is useful for quickly testing if your object has the right type of data in it.\nFor negative values ofn, this function returns all rows except the last|n|rows, equivalent todf[:n].\nIf n is larger than the number of rows, this function returns all rows.", "Examples": [">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n>>> df\n      animal\n0  alligator\n1        bee\n2     falcon\n3       lion\n4     monkey\n5     parrot\n6      shark\n7      whale\n8      zebra"], "Parameters": [["n int, default 5", "Number of rows to select."]], "Returns": [["same type as caller", "The first n rows of the caller object."]], "Category": ["Dataframe"], "index": 57}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.T.html#pandas.DataFrame.T"], "Title": ["DataFrame.T"], "Feature": ["DataFrame.T"], "Description": "The transpose of the DataFrame.", "Examples": [">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df\n   col1  col2\n0     1     3\n1     2     4"], "Parameters": [], "Returns": [["DataFrame", "The transposed DataFrame."]], "Category": ["Dataframe"], "index": 58}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose"], "Title": ["DataFrame.transpose"], "Feature": ["DataFrame.transpose"], "Description": "Transpose index and columns.\nReflect the DataFrame over its main diagonal by writing rows as columns\nand vice-versa. The propertyTis an accessor to the method transpose().\nNotes\nTransposing a DataFrame with mixed dtypes will result in a homogeneous\nDataFrame with the objectd type. In such a case, a copy of the data\nis always made.", "Examples": [">>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n>>> df1 = pd.DataFrame(data=d1)\n>>> df1\n   col1  col2\n0     1     3\n1     2     4"], "Parameters": [["*args tuple, optional", "Accepted for compatibility with NumPy."], ["copy bool, default False", "Whether to copy the data after transposing, even for DataFrames\nwith a single dtype. Note that a copy is always required for mixed dtype DataFrames,\nor for DataFrames with any extension types. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["DataFrame", "The transposed DataFrame."]], "Category": ["Dataframe"], "index": 59}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html#pandas.DataFrame.assign"], "Title": ["DataFrame.assign"], "Feature": ["DataFrame.assign"], "Description": "Assign new columns to a DataFrame.\nReturns a new object with all original columns in addition to new ones.\nExisting columns that are re-assigned will be overwritten.\nNotes\nAssigning multiple columns within the sameassignis possible.\nLater items in ‘**kwargs’ may refer to newly created or modified\ncolumns in ‘df’; items are computed and assigned into ‘df’ in order.", "Examples": [">>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n...                   index=['Portland', 'Berkeley'])\n>>> df\n          temp_c\nPortland    17.0\nBerkeley    25.0"], "Parameters": [["**kwargs dict of {str: callable or Series}", "The column names are keywords. If the values are\ncallable, they are computed on the DataFrame and\nassigned to the new columns. The callable must not\nchange input DataFrame (though pandas doesn’t check it).\nIf the values are not callable, (e.g. a Series, scalar, or array),\nthey are simply assigned."]], "Returns": [["DataFrame", "A new DataFrame with the new columns in addition to\nall the existing columns."]], "Category": ["Dataframe"], "index": 60}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html#pandas.DataFrame.compare"], "Title": ["DataFrame.compare"], "Feature": ["DataFrame.compare"], "Description": "Compare to another DataFrame and show the differences.\nNotes\nMatching NaNs will not appear as a difference.\nCan only compare identically-labeled\n(i.e. same shape, identical row and column labels) DataFrames", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n...     },\n...     columns=[\"col1\", \"col2\", \"col3\"],\n... )\n>>> df\n  col1  col2  col3\n0    a   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   3.0\n3    b   NaN   4.0\n4    a   5.0   5.0"], "Parameters": [["other DataFrame", "Object to compare with."], ["align_axis {0 or ‘index’, 1 or ‘columns’}, default 1", "Determine which axis to align the comparison on. 0, or ‘index’ Resulting differences are stacked vertically with rows drawn alternately from self and other. 1, or ‘columns’ Resulting differences are aligned horizontally with columns drawn alternately from self and other."], ["0, or ‘index’ Resulting differences are stacked vertically", "with rows drawn alternately from self and other."], ["1, or ‘columns’ Resulting differences are aligned horizontally", "with columns drawn alternately from self and other."], ["keep_shape bool, default False", "If true, all rows and columns are kept.\nOtherwise, only the ones with different values are kept."], ["keep_equal bool, default False", "If true, the result keeps values that are equal.\nOtherwise, equal values are shown as NaNs."], ["result_names tuple, default (‘self’, ‘other’)", "Set the dataframes names in the comparison."]], "Returns": [["DataFrame", "DataFrame that shows the differences stacked side by side. The resulting index will be a MultiIndex with ‘self’ and ‘other’\nstacked alternately at the inner level."]], "Category": ["Dataframe"], "index": 61}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join"], "Title": ["DataFrame.join"], "Feature": ["DataFrame.join"], "Description": "Join columns of another DataFrame.\nJoin columns with other DataFrame either on index or on a key\ncolumn. Efficiently join multiple DataFrame objects by index at once by\npassing a list.\nSee alsoDataFrame.mergeFor column(s)-on-column(s) operations.\nNotes\nParameterson,lsuffix, andrsuffixare not supported when\npassing a list ofDataFrameobjects.", "Examples": [">>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})"], "Parameters": [["other DataFrame, Series, or a list containing any combination of them", "Index should be similar to one of the columns in this one. If a\nSeries is passed, its name attribute must be set, and that will be\nused as the column name in the resulting joined DataFrame."], ["on str, list of str, or array-like, optional", "Column or index level name(s) in the caller to join on the index\nin other , otherwise joins index-on-index. If multiple\nvalues given, the other DataFrame must have a MultiIndex. Can\npass an array as the join key if it is not already contained in\nthe calling DataFrame. Like an Excel VLOOKUP operation."], ["how {‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘left’", "How to handle the operation of the two objects. left: use calling frame’s index (or column if on is specified) right: use other ’s index. outer: form union of calling frame’s index (or column if on is\nspecified) with other ’s index, and sort it lexicographically. inner: form intersection of calling frame’s index (or column if\non is specified) with other ’s index, preserving the order\nof the calling’s one. cross: creates the cartesian product from both frames, preserves the order\nof the left keys."], ["lsuffix str, default ‘’", "Suffix to use from left frame’s overlapping columns."], ["rsuffix str, default ‘’", "Suffix to use from right frame’s overlapping columns."], ["sort bool, default False", "Order result DataFrame lexicographically by the join key. If False,\nthe order of the join key depends on the join type (how keyword)."], ["validate str, optional", "If specified, checks if join is of specified type. “one_to_one” or “1:1”: check if join keys are unique in both left\nand right datasets. “one_to_many” or “1:m”: check if join keys are unique in left dataset. “many_to_one” or “m:1”: check if join keys are unique in right dataset. “many_to_many” or “m:m”: allowed, but does not result in checks."]], "Returns": [["DataFrame", "A dataframe containing columns from both the caller and other ."]], "Category": ["Dataframe"], "index": 62}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.update.html#pandas.DataFrame.update"], "Title": ["DataFrame.update"], "Feature": ["DataFrame.update"], "Description": "Modify in place using non-NA values from another DataFrame.\nAligns on indices. There is no return value.", "Examples": [">>> df = pd.DataFrame({'A': [1, 2, 3],\n...                    'B': [400, 500, 600]})\n>>> new_df = pd.DataFrame({'B': [4, 5, 6],\n...                        'C': [7, 8, 9]})\n>>> df.update(new_df)\n>>> df\n   A  B\n0  1  4\n1  2  5\n2  3  6"], "Parameters": [["other DataFrame, or object coercible into a DataFrame", "Should have at least one matching index/column label\nwith the original DataFrame. If a Series is passed,\nits name attribute must be set, and that will be\nused as the column name to align with the original DataFrame."], ["join {‘left’}, default ‘left’", "Only left join is implemented, keeping the index and columns of the\noriginal object."], ["overwrite bool, default True", "How to handle non-NA values for overlapping keys: True: overwrite original DataFrame’s values\nwith values from other . False: only update values that are NA in\nthe original DataFrame."], ["filter_func callable(1d-array) -> bool 1d-array, optional", "Can choose to replace values other than NA. Return True for values\nthat should be updated."], ["errors {‘raise’, ‘ignore’}, default ‘ignore’", "If ‘raise’, will raise a ValueError if the DataFrame and other both contain non-NA data in the same place."]], "Returns": [["None", "This method directly changes calling object."]], "Category": ["Dataframe"], "index": 63}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html#pandas.DataFrame.asfreq"], "Title": ["DataFrame.asfreq"], "Feature": ["DataFrame.asfreq"], "Description": "Convert time series to specified frequency.\nReturns the original data conformed to a new index with the specified\nfrequency.\nIf the index of this Series/DataFrame is aPeriodIndex, the new index\nis the result of transforming the original index withPeriodIndex.asfreq(so the original index\nwill map one-to-one to the new index).\nOtherwise, the new index will be equivalent topd.date_range(start,end,freq=freq)where start and end are, respectively, the first and\nlast entries in the original index (see pandas.date_range()). The\nvalues corresponding to any timesteps in the new index which were not present\nin the original index will be null (NaN), unless a method for filling\nsuch unknowns is provided (see the method parameter below).\nTheresample()method is more appropriate if an operation on each group of\ntimesteps (such as an aggregate) is necessary to represent the data at the new\nfrequency.\nNotes\nTo learn more about the frequency strings, please see this link.", "Examples": [">>> index = pd.date_range('1/1/2000', periods=4, freq='min')\n>>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n>>> df = pd.DataFrame({'s': series})\n>>> df\n                       s\n2000-01-01 00:00:00    0.0\n2000-01-01 00:01:00    NaN\n2000-01-01 00:02:00    2.0\n2000-01-01 00:03:00    3.0"], "Parameters": [["freq DateOffset or str", "Frequency DateOffset or string."], ["method {‘backfill’/’bfill’, ‘pad’/’ffill’}, default None", "Method to use for filling holes in reindexed Series (note this\ndoes not fill NaNs that already were present): ‘pad’ / ‘ffill’: propagate last valid observation forward to next\nvalid ‘backfill’ / ‘bfill’: use NEXT valid observation to fill."], ["how {‘start’, ‘end’}, default end", "For PeriodIndex only (see PeriodIndex.asfreq)."], ["normalize bool, default False", "Whether to reset output index to midnight."], ["fill_value scalar, optional", "Value to use for missing values, applied during upsampling (note\nthis does not fill NaNs that already were present)."]], "Returns": [["Series/DataFrame", "Series/DataFrame object reindexed to the specified frequency."]], "Category": ["Dataframe"], "index": 64}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asof.html#pandas.DataFrame.asof"], "Title": ["DataFrame.asof"], "Feature": ["DataFrame.asof"], "Description": "Return the last row(s) without any NaNs before where.\nThe last row (for each element in where, if list) without any\nNaN is taken.\nIn case of aDataFrame, the last row without NaN\nconsidering only the subset of columns (if notNone)\nIf there is no good value, NaN is returned for a Series or\na Series of NaN values for a DataFrame\nNotes\nDates are assumed to be sorted. Raises if this is not the case.", "Examples": [">>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n>>> s\n10    1.0\n20    2.0\n30    NaN\n40    4.0\ndtype: float64"], "Parameters": [["where date or array-like of dates", "Date(s) before which the last row(s) are returned."], ["subset str or array-like of str, default None", "For DataFrame, if not None , only use these columns to\ncheck for NaNs."]], "Returns": [["scalar, Series, or DataFrame", "The return can be: scalar : when self is a Series and where is a scalar Series: when self is a Series and where is an array-like,\nor when self is a DataFrame and where is a scalar DataFrame : when self is a DataFrame and where is an\narray-like"]], "Category": ["Dataframe"], "index": 65}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html#pandas.DataFrame.shift"], "Title": ["DataFrame.shift"], "Feature": ["DataFrame.shift"], "Description": "Shift index by desired number of periods with an optional time freq.\nWhen freq is not passed, shift the index without realigning the data.\nIf freq is passed (in this case, the index must be date or datetime,\nor it will raise aNotImplementedError), the index will be\nincreased using the periods and the freq.freq can be inferred\nwhen specified as “infer” as long as either freq or inferred_freq\nattribute is set in the index.", "Examples": [">>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n...                    \"Col2\": [13, 23, 18, 33, 48],\n...                    \"Col3\": [17, 27, 22, 37, 52]},\n...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n>>> df\n            Col1  Col2  Col3\n2020-01-01    10    13    17\n2020-01-02    20    23    27\n2020-01-03    15    18    22\n2020-01-04    30    33    37\n2020-01-05    45    48    52"], "Parameters": [["periods int or Sequence", "Number of periods to shift. Can be positive or negative.\nIf an iterable of ints, the data will be shifted once by each int.\nThis is equivalent to shifting by one value at a time and\nconcatenating all resulting frames. The resulting columns will have\nthe shift suffixed to their column names. For multiple periods,\naxis must not be 1."], ["freq DateOffset, tseries.offsets, timedelta, or str, optional", "Offset to use from the tseries module or time rule (e.g. ‘EOM’).\nIf freq is specified then the index values are shifted but the\ndata is not realigned. That is, use freq if you would like to\nextend the index when shifting and preserve the original data.\nIf freq is specified as “infer” then it will be inferred from\nthe freq or inferred_freq attributes of the index. If neither of\nthose attributes exist, a ValueError is thrown."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "Shift direction. For Series this parameter is unused and defaults to 0."], ["fill_value object, optional", "The scalar value to use for newly introduced missing values.\nthe default depends on the dtype of self .\nFor numeric data, np.nan is used.\nFor datetime, timedelta, or period data, etc. NaT is used.\nFor extension dtypes, self.dtype.na_value is used."], ["suffix str, optional", "If str and periods is an iterable, this is added after the column\nname and before the shift value for each shifted column name."]], "Returns": [["DataFrame", "Copy of input object, shifted."]], "Category": ["Dataframe"], "index": 66}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.first_valid_index.html#pandas.DataFrame.first_valid_index"], "Title": ["DataFrame.first_valid_index"], "Feature": ["DataFrame.first_valid_index"], "Description": "Return index for first non-NA value or None, if no non-NA value is found.", "Examples": [">>> s = pd.Series([None, 3, 4])\n>>> s.first_valid_index()\n1\n>>> s.last_valid_index()\n2"], "Parameters": [], "Returns": [["type of index"]], "Category": ["Dataframe"], "index": 67}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at"], "Title": ["DataFrame.at"], "Feature": ["DataFrame.at"], "Description": "Access a single value for a row/column label pair.\nSimilar to loc, in that both provide label-based lookups. Use at if you only need to get or set a single value in a DataFrame or Series.", "Examples": [">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n>>> df\n    A   B   C\n4   0   2   3\n5   0   4   1\n6  10  20  30"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 68}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.last_valid_index.html#pandas.DataFrame.last_valid_index"], "Title": ["DataFrame.last_valid_index"], "Feature": ["DataFrame.last_valid_index"], "Description": "Return index for last non-NA value or None, if no non-NA value is found.", "Examples": [">>> s = pd.Series([None, 3, 4])\n>>> s.first_valid_index()\n1\n>>> s.last_valid_index()\n2"], "Parameters": [], "Returns": [["type of index"]], "Category": ["Dataframe"], "index": 69}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html#pandas.DataFrame.resample"], "Title": ["DataFrame.resample"], "Feature": ["DataFrame.resample"], "Description": "Resample time-series data.\nConvenience method for frequency conversion and resampling of time series.\nThe object must have a datetime-like index (DatetimeIndex,PeriodIndex,\norTimedeltaIndex), or the caller must pass the label of a datetime-like\nseries/index to theon/levelkeyword parameter.\nNotes\nSee the user guide for more.\nTo learn more about the offset strings, please see this link.", "Examples": [">>> index = pd.date_range('1/1/2000', periods=9, freq='min')\n>>> series = pd.Series(range(9), index=index)\n>>> series\n2000-01-01 00:00:00    0\n2000-01-01 00:01:00    1\n2000-01-01 00:02:00    2\n2000-01-01 00:03:00    3\n2000-01-01 00:04:00    4\n2000-01-01 00:05:00    5\n2000-01-01 00:06:00    6\n2000-01-01 00:07:00    7\n2000-01-01 00:08:00    8\nFreq: min, dtype: int64"], "Parameters": [["rule DateOffset, Timedelta or str", "The offset string or object representing target conversion."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Which axis to use for up- or down-sampling. For Series this parameter\nis unused and defaults to 0. Must be DatetimeIndex , TimedeltaIndex or PeriodIndex ."], ["closed {‘right’, ‘left’}, default None", "Which side of bin interval is closed. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’."], ["label {‘right’, ‘left’}, default None", "Which bin edge label to label bucket with. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’."], ["convention {‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’", "For PeriodIndex only, controls whether to use the start or\nend of rule ."], ["kind {‘timestamp’, ‘period’}, optional, default None", "Pass ‘timestamp’ to convert the resulting index to a DateTimeIndex or ‘period’ to convert it to a PeriodIndex .\nBy default the input representation is retained. Deprecated since version 2.2.0: Convert index to desired type explicitly instead."], ["on str, optional", "For a DataFrame, column to use instead of index for resampling.\nColumn must be datetime-like."], ["level str or int, optional", "For a MultiIndex, level (name or number) to use for\nresampling. level must be datetime-like."], ["origin Timestamp or str, default ‘start_day’", "The timestamp on which to adjust the grouping. The timezone of origin\nmust match the timezone of the index.\nIf string, must be one of the following: ‘epoch’: origin is 1970-01-01 ‘start’: origin is the first value of the timeseries ‘start_day’: origin is the first day at midnight of the timeseries ‘end’: origin is the last value of the timeseries ‘end_day’: origin is the ceiling midnight of the last day Added in version 1.3.0. Note Only takes effect for Tick-frequencies (i.e. fixed frequencies like\ndays, hours, and minutes, rather than months or quarters)."], ["offset Timedelta or str, default is None", "An offset timedelta added to the origin."], ["group_keys bool, default False", "Whether to include the group keys in the result index when using .apply() on the resampled object. Added in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples)."]], "Returns": [["pandas.api.typing.Resampler", "Resampler object."]], "Category": ["Dataframe"], "index": 70}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_period.html#pandas.DataFrame.to_period"], "Title": ["DataFrame.to_period"], "Feature": ["DataFrame.to_period"], "Description": "Convert DataFrame from DatetimeIndex to PeriodIndex.\nConvert DataFrame from DatetimeIndex to PeriodIndex with desired\nfrequency (inferred from index if not passed).", "Examples": [">>> idx = pd.to_datetime(\n...     [\n...         \"2001-03-31 00:00:00\",\n...         \"2002-05-31 00:00:00\",\n...         \"2003-08-31 00:00:00\",\n...     ]\n... )"], "Parameters": [["freq str, default", "Frequency of the PeriodIndex."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to convert (the index by default)."], ["copy bool, default True", "If False then underlying input data is not copied. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["DataFrame", "The DataFrame has a PeriodIndex."]], "Category": ["Dataframe"], "index": 71}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_timestamp.html#pandas.DataFrame.to_timestamp"], "Title": ["DataFrame.to_timestamp"], "Feature": ["DataFrame.to_timestamp"], "Description": "Cast to DatetimeIndex of timestamps, atbeginningof period.", "Examples": [">>> idx = pd.PeriodIndex(['2023', '2024'], freq='Y')\n>>> d = {'col1': [1, 2], 'col2': [3, 4]}\n>>> df1 = pd.DataFrame(data=d, index=idx)\n>>> df1\n      col1   col2\n2023     1      3\n2024     2      4"], "Parameters": [["freq str, default frequency of PeriodIndex", "Desired frequency."], ["how {‘s’, ‘e’, ‘start’, ‘end’}", "Convention for converting period to timestamp; start of period\nvs. end."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to convert (the index by default)."], ["copy bool, default True", "If False then underlying input data is not copied. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["DataFrame", "The DataFrame has a DatetimeIndex."]], "Category": ["Dataframe"], "index": 72}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_convert.html#pandas.DataFrame.tz_convert"], "Title": ["DataFrame.tz_convert"], "Feature": ["DataFrame.tz_convert"], "Description": "Convert tz-aware axis to target time zone.", "Examples": [">>> s = pd.Series(\n...     [1],\n...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),\n... )\n>>> s.tz_convert('Asia/Shanghai')\n2018-09-15 07:30:00+08:00    1\ndtype: int64"], "Parameters": [["tz str or tzinfo object or None", "Target time zone. Passing None will convert to\nUTC and remove the timezone information."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to convert"], ["level int, str, default None", "If axis is a MultiIndex, convert a specific level. Otherwise\nmust be None."], ["copy bool, default True", "Also make a copy of the underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["Series/DataFrame", "Object with time zone converted axis."]], "Category": ["Dataframe"], "index": 73}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tz_localize.html#pandas.DataFrame.tz_localize"], "Title": ["DataFrame.tz_localize"], "Feature": ["DataFrame.tz_localize"], "Description": "Localize tz-naive index of a Series or DataFrame to target time zone.\nThis operation localizes the Index. To localize the values in a\ntimezone-naive Series, useSeries.dt.tz_localize().", "Examples": [">>> s = pd.Series(\n...     [1],\n...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),\n... )\n>>> s.tz_localize('CET')\n2018-09-15 01:30:00+02:00    1\ndtype: int64"], "Parameters": [["tz str or tzinfo or None", "Time zone to localize. Passing None will remove the\ntime zone information and preserve local time."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to localize"], ["level int, str, default None", "If axis ia a MultiIndex, localize a specific level. Otherwise\nmust be None."], ["copy bool, default True", "Also make a copy of the underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["ambiguous ‘infer’, bool-ndarray, ‘NaT’, default ‘raise’", "When clocks moved backward due to DST, ambiguous times may arise.\nFor example in Central European Time (UTC+01), when going from\n03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n00:30:00 UTC and at 01:30:00 UTC. In such a situation, the ambiguous parameter dictates how ambiguous times should be\nhandled. ‘infer’ will attempt to infer fall dst-transition hours based on\norder bool-ndarray where True signifies a DST time, False designates\na non-DST time (note that this flag is only applicable for\nambiguous times) ‘NaT’ will return NaT where there are ambiguous times ‘raise’ will raise an AmbiguousTimeError if there are ambiguous\ntimes."], ["nonexistent str, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. Valid values are: ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time ‘NaT’ will return NaT where there are nonexistent times timedelta objects will shift nonexistent times by the timedelta ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["Series/DataFrame", "Same type as the input."]], "Category": ["Dataframe"], "index": 74}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html#pandas.DataFrame.iat"], "Title": ["DataFrame.iat"], "Feature": ["DataFrame.iat"], "Description": "Access a single value for a row/column pair by integer position.\nSimilar to iloc, in that both provide integer-based lookups. Use iat if you only need to get or set a single value in a DataFrame or Series.", "Examples": [">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n...                   columns=['A', 'B', 'C'])\n>>> df\n    A   B   C\n0   0   2   3\n1   0   4   1\n2  10  20  30"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 75}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc"], "Title": ["DataFrame.loc"], "Feature": ["DataFrame.loc"], "Description": "Access a group of rows and columns by label(s) or a boolean array.\n.loc[]is primarily label based, but may also be used with a boolean array.\nAllowed inputs are:\nA single label, e.g. 5 or 'a', (note that 5 is interpreted as a label of the index, and never as an integer position along the index).A list or array of labels, e.g.['a','b','c'].A slice object with labels, e.g.'a':'f'.WarningNote that contrary to usual python slices,both the start and the stop are included A boolean array of the same length as the axis being sliced,e.g.[True,False,True].An align able boolean Series. The index of the key will be aligned before masking.An align able Index. The Index of the returned selection will be the input.A call able function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above)\nSee more atSelection by Label.", "Examples": [">>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n...                   index=['cobra', 'viper', 'sidewinder'],\n...                   columns=['max_speed', 'shield'])\n>>> df\n            max_speed  shield\ncobra               1       2\nviper               4       5\nsidewinder          7       8"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 76}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html#pandas.DataFrame.insert"], "Title": ["DataFrame.insert"], "Feature": ["DataFrame.insert"], "Description": "Insert column into DataFrame at specified location.\nRaises a ValueError if column is already contained in the DataFrame,unless allow_duplicates is set to True.", "Examples": [">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df\n   col1  col2\n0     1     3\n1     2     4\n>>> df.insert(1, \"newcol\", [99, 99])\n>>> df\n   col1  newcol  col2\n0     1      99     3\n1     2      99     4\n>>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n>>> df\n   col1  col1  newcol  col2\n0   100     1      99     3\n1   100     2      99     4"], "Parameters": [["loc int", "Insertion index. Must verify 0 <= loc <= len(columns)."], ["column str, number, or hashable object", "Label of the inserted column."], ["value Scalar, Series, or array-like", "Content of the inserted column."], ["allow_duplicates bool, optional, default lib.no_default", "Allow duplicate column labels to be created."]], "Returns": [], "Category": ["Dataframe"], "index": 77}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes"], "Title": ["DataFrame.dtypes"], "Feature": ["DataFrame.dtypes"], "Description": ["Return the dtypes in the DataFrame.\nThis returns a Series with the data type of each column. The result’s index is the original DataFrame’s columns. Columns with mixed types are stored with the object dtype."], "Examples": [">>> df = pd.DataFrame({'float': [1.0],\n...                    'int': [1],\n...                    'datetime': [pd.Timestamp('20180310')],\n...                    'string': ['foo']})\n>>> df.dtypes\nfloat              float64\nint                  int64\ndatetime    datetime64[ns]\nstring              object\ndtype: object"], "Parameters": [], "Returns": [["pandas.Series", "The data type of each column."]], "Category": ["Dataframe"], "index": 78}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html#pandas.DataFrame.items"], "Title": ["DataFrame.items"], "Feature": ["DataFrame.items"], "Description": "Iterate over (column name, Series) pairs.\nIterates over the DataFrame columns, returning a tuple with the column name and the content as a Series.", "Examples": [">>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n...                   'population': [1864, 22000, 80000]},\n...                   index=['panda', 'polar', 'koala'])\n>>> df\n        species   population\npanda   bear      1864\npolar   bear      22000\nkoala   marsupial 80000\n>>> for label, content in df.items():\n...     print(f'label: {label}')\n...     print(f'content: {content}', sep='\\n')\n...\nlabel: species\ncontent:\npanda         bear\npolar         bear\nkoala    marsupial\nName: species, dtype: object\nlabel: population\ncontent:\npanda     1864\npolar    22000\nkoala    80000\nName: population, dtype: int64"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 79}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.keys.html#pandas.DataFrame.keys"], "Title": ["DataFrame.keys"], "Feature": ["DataFrame.keys"], "Description": "Get the ‘info axis’ (see Indexing for more).\nThis is index for Series, columns for DataFrame.", "Examples": [">>> d = pd.DataFrame(data={'A': [1, 2, 3], 'B': [0, 4, 8]},\n...                  index=['a', 'b', 'c'])\n>>> d\n   A  B\na  1  0\nb  2  4\nc  3  8\n>>> d.keys()\nIndex(['A', 'B'], dtype='object')"], "Parameters": [], "Returns": [["Index", "Info axis."]], "Category": ["Dataframe"], "index": 80}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows"], "Title": ["DataFrame.iterrows"], "Feature": ["DataFrame.iterrows"], "Description": "Iterate over DataFrame rows as (index, Series) pairs.", "Examples": [">>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n>>> row = next(df.iterrows())[1]\n>>> row\nint      1.0\nfloat    1.5\nName: 0, dtype: float64\n>>> print(row['int'].dtype)\nfloat64\n>>> print(df['int'].dtype)\nint64"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 81}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples"], "Title": ["DataFrame.itertuples"], "Feature": ["DataFrame.itertuples"], "Description": "Iterate over DataFrame rows as namedtuples.\nNotes\nThe column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore.", "Examples": [">>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n...                   index=['dog', 'hawk'])\n>>> df\n      num_legs  num_wings\ndog          4          0\nhawk         2          2\n>>> for row in df.itertuples():\n...     print(row)\n...\nPandas(Index='dog', num_legs=4, num_wings=0)\nPandas(Index='hawk', num_legs=2, num_wings=2)"], "Parameters": [["index bool, default True", "If True, return the index as the first element of the tuple."], ["name str or None, default “Pandas”", "The name of the returned namedtuples or None to return regular tuples."]], "Returns": [["iterator", "An object to iterate over namedtuples for each row in the DataFrame with the first field possibly being the index and following fields being the column values."]], "Category": ["Dataframe"], "index": 82}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html#pandas.DataFrame.pop"], "Title": ["DataFrame.pop"], "Feature": ["DataFrame.pop"], "Description": "Return item and drop from frame. Raise KeyError if not found.", "Examples": [">>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n...                    ('parrot', 'bird', 24.0),\n...                    ('lion', 'mammal', 80.5),\n...                    ('monkey', 'mammal', np.nan)],\n...                   columns=('name', 'class', 'max_speed'))\n>>> df\n     name   class  max_speed\n0  falcon    bird      389.0\n1  parrot    bird       24.0\n2    lion  mammal       80.5\n3  monkey  mammal        NaN"], "Parameters": [["item label", "Label of column to be popped."]], "Returns": [["Series"]], "Category": ["Dataframe"], "index": 83}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail"], "Title": ["DataFrame.tail"], "Feature": ["DataFrame.tail"], "Description": "Return the last n rows.\nThis function returns last n rows from the object based on position. It is useful for quickly verifying data, for example,after sorting or appending rows.\nFor negative values ofn, this function returns all rows except the first|n|rows, equivalent todf[|n|:].\nIf n is larger than the number of rows, this function returns all rows.", "Examples": [">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n>>> df\n      animal\n0  alligator\n1        bee\n2     falcon\n3       lion\n4     monkey\n5     parrot\n6      shark\n7      whale\n8      zebra"], "Parameters": [["n int, default 5", "Number of rows to select."]], "Returns": [["type of caller", "The last n rows of the caller object."]], "Category": ["Dataframe"], "index": 84}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html#pandas.DataFrame.xs"], "Title": ["DataFrame.xs"], "Feature": ["DataFrame.xs"], "Description": "Return cross-section from the Series/DataFrame.\nThis method takes a key argument to select data at a particular level of a MultiIndex.\nNotes\nx scan not be used to set values.\nMultiIndex Slicers is a generic way to get/set values on any level or levels.\nIt is a superset of xs functionality, seeMultiIndex Slicers.", "Examples": [">>> d = {'num_legs': [4, 4, 2, 2],\n...      'num_wings': [0, 0, 2, 2],\n...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n>>> df = pd.DataFrame(data=d)\n>>> df = df.set_index(['class', 'animal', 'locomotion'])\n>>> df\n                           num_legs  num_wings\nclass  animal  locomotion\nmammal cat     walks              4          0\n       dog     walks              4          0\n       bat     flies              2          2\nbird   penguin walks              2          2"], "Parameters": [["key label or tuple of label", "Label contained in the index, or partially in a MultiIndex."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Axis to retrieve cross-section on."], ["level object, defaults to first n levels (n=1 or len(key))", "In case of a key partially contained in a MultiIndex, indicate which levels are used. Levels can be referred by label or position."], ["drop_level bool, default True", "If False, returns object with same levels as self."]], "Returns": [["Series or DataFrame", "Cross-section from the original Series or DataFrame corresponding to the selected index levels."]], "Category": ["Dataframe"], "index": 85}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.get.html#pandas.DataFrame.get"], "Title": ["DataFrame.get"], "Feature": ["DataFrame.get"], "Description": "Get item from object for given key (ex: DataFrame column).\nReturns default value if not found.", "Examples": [">>> df = pd.DataFrame(\n...     [\n...         [24.3, 75.7, \"high\"],\n...         [31, 87.8, \"high\"],\n...         [22, 71.6, \"medium\"],\n...         [35, 95, \"medium\"],\n...     ],\n...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n... )"], "Parameters": [["key object"]], "Returns": [["same type as items contained in object", ""]], "Category": ["Dataframe"], "index": 86}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html#pandas.DataFrame.isin"], "Title": ["DataFrame.isin"], "Feature": ["DataFrame.isin"], "Description": "Whether each element in the DataFrame is contained in values.", "Examples": [">>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n...                   index=['falcon', 'dog'])\n>>> df\n        num_legs  num_wings\nfalcon         2          2\ndog            4          0"], "Parameters": [["values iterable, Series, DataFrame or dict", "The result will only be true at a location if all the labels match. If values is a Series, that’s the index. If values is a dict, the keys must be the column names,which must match. If values is a DataFrame,then both the index and column labels must match."]], "Returns": [["DataFrame", "DataFrame of booleans showing whether each element in the DataFrame is contained in values."]], "Category": ["Dataframe"], "index": 87}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where"], "Title": ["DataFrame.where"], "Feature": ["DataFrame.where"], "Description": "Replace values where the condition is False.\nNotes\nThe where method is an application of the if-then idiom. For each element in the calling DataFrame, if cond is True the element is used; otherwise the corresponding element from the DataFrame other is used. If the axis of other does not align with axis of condSeries/DataFrame, the misaligned index positions will be filled with\nFalse.\nThe signature forDataFrame.where()differs from numpy.where(). Roughly df1.where(m,df2)is equivalent to np.where(m,df1,df2).\nFor further details and examples see the where documentation in indexing.\nThe dtype of the object takes precedence. The fill value is casted to the object’s dtype, if this can be done loss lessly.", "Examples": [">>> s = pd.Series(range(5))\n>>> s.where(s > 0)\n0    NaN\n1    1.0\n2    2.0\n3    3.0\n4    4.0\ndtype: float64\n>>> s.mask(s > 0)\n0    0.0\n1    NaN\n2    NaN\n3    NaN\n4    NaN\ndtype: float64"], "Parameters": [["cond bool Series/DataFrame, array-like, or callable", "Where cond is True, keep the original value. Where False, replace with corresponding value from other .\nIf cond is callable, it is computed on the Series/DataFrame and should return boolean Series/DataFrame or array. The callable must not change input Series/DataFrame (though pandas doesn’t check it)."], ["other scalar, Series/DataFrame, or callable", "Entries where cond is False are replaced with corresponding value from other .\nIf other is callable, it is computed on the Series/DataFrame and should return scalar or Series/DataFrame. The callable must not change input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding NULL value ( np.nan for numpy dtypes, pd.NA for extension dtypes)."], ["inplace bool, default False", "Whether to perform the operation in place on the data."], ["axis int, default None", "Alignment axis if needed. For Series this parameter is unused and defaults to 0."], ["level int, default None", "Alignment level if needed."]], "Returns": [["Same type as caller or None if inplace=True ."]], "Category": ["Dataframe"], "index": 88}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"], "Title": ["DataFrame.select_dtypes"], "Feature": ["DataFrame.select_dtypes"], "Description": "Return a subset of the DataFrame’s columns based on the column dtypes.\nNotes\nTo select all numeric types, use np.number or 'number'\nTo select strings you must use the object dtype, but note that this will return all object dtype columns. With pd.options.future.infer_string enabled, using\"str\"will work to select all string columns.\nSee the numpy dtype hierarchy\nTo select datetimes, use np.datetime64,'datetime'or'datetime64'\nTo select timedeltas, use np.timedelta64,'timedelta'or'timedelta64'\nTo select Pandas categorical dtypes, use 'category'\nTo select Pandas datetimetz dtypes, use 'datetimetz' or 'datetime64[ns,tz]'", "Examples": [">>> df = pd.DataFrame({'a': [1, 2] * 3,\n...                    'b': [True, False] * 3,\n...                    'c': [1.0, 2.0] * 3})\n>>> df\n        a      b  c\n0       1   True  1.0\n1       2  False  2.0\n2       1   True  1.0\n3       2  False  2.0\n4       1   True  1.0\n5       2  False  2.0"], "Parameters": [["include, exclude scalar or list-like", "A selection of dtypes or strings to be included/excluded. At least\none of these parameters must be supplied."]], "Returns": [["DataFrame", "The subset of the frame including the dtypes in include and\nexcluding the dtypes in exclude ."]], "Category": ["Dataframe"], "index": 89}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mask.html#pandas.DataFrame.mask"], "Title": ["DataFrame.mask"], "Feature": ["DataFrame.mask"], "Description": "Replace values where the condition is True.\nNotes\nThe mask method is an application of the if-then idiom. For each element in the calling DataFrame, if cond is False the element is used; otherwise the corresponding element from the DataFrame other is used. If the axis of other does not align with axis of condSeries/DataFrame, the misaligned index positions will be filled with True.\nThe signature forDataFrame.where()differs from numpy.where(). Roughly df1.where(m,df2)is equivalent to np.where(m,df1,df2).\nFor further details and examples see the mask documentation in indexing.\nThe dtype of the object takes precedence. The fill value is casted to the object’s dtype, if this can be done loss lessly.", "Examples": [">>> s = pd.Series(range(5))\n>>> s.where(s > 0)\n0    NaN\n1    1.0\n2    2.0\n3    3.0\n4    4.0\ndtype: float64\n>>> s.mask(s > 0)\n0    0.0\n1    NaN\n2    NaN\n3    NaN\n4    NaN\ndtype: float64"], "Parameters": [["cond bool Series/DataFrame, array-like, or callable", "Where cond is False, keep the original value. Where\nTrue, replace with corresponding value from other .\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it)."], ["other scalar, Series/DataFrame, or callable", "Entries where cond is True are replaced with\ncorresponding value from other .\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value ( np.nan for numpy dtypes, pd.NA for extension\ndtypes)."], ["inplace bool, default False", "Whether to perform the operation in place on the data."], ["axis int, default None", "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0."], ["level int, default None", "Alignment level if needed."]], "Returns": [["Same type as caller or None if inplace=True ."]], "Category": ["Dataframe"], "index": 90}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add.html#pandas.DataFrame.add"], "Title": ["DataFrame.add"], "Feature": ["DataFrame.add"], "Description": "Get Addition of dataframe and other, element-wise (binary operatoradd).\nEquivalent to dataframe+other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,radd.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 91}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sub.html#pandas.DataFrame.sub"], "Title": ["DataFrame.sub"], "Feature": ["DataFrame.sub"], "Description": "Get Subtraction of dataframe and other, element-wise (binary operatorsub).\nEquivalent todataframe-other, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,rsub.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to\narithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 92}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mul.html#pandas.DataFrame.mul"], "Title": ["DataFrame.mul"], "Feature": ["DataFrame.mul"], "Description": "Get Multiplication of dataframe and other, element-wise (binary operatormul).\nEquivalent todataframe*other, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,rmul.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to\narithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 93}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.div.html#pandas.DataFrame.div"], "Title": ["DataFrame.div"], "Feature": ["DataFrame.div"], "Description": "Get Floating division of dataframe and other, element-wise (binary operatortruediv).\nEquivalent to dataframe/other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,rtruediv.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to\narithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 94}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.truediv.html#pandas.DataFrame.truediv"], "Title": ["DataFrame.truediv"], "Feature": ["DataFrame.truediv"], "Description": "Get Floating division of dataframe and other, element-wise (binary operatortruediv).\nEquivalent todataframe/other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,rtruediv.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 95}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.floordiv.html#pandas.DataFrame.floordiv"], "Title": ["DataFrame.floordiv"], "Feature": ["DataFrame.floordiv"], "Description": "Get Integer division of dataframe and other, element-wise (binary operator floordiv).\nEquivalent to dataframe//other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,rfloordiv.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 96}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mod.html#pandas.DataFrame.mod"], "Title": ["DataFrame.mod"], "Feature": ["DataFrame.mod"], "Description": "Get Modulo of dataframe and other, element-wise (binary operator mod).\nEquivalent to dataframe%other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,rmod.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 97}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pow.html#pandas.DataFrame.pow"], "Title": ["DataFrame.pow"], "Feature": ["DataFrame.pow"], "Description": "Get Exponential power of dataframe and other, element-wise (binary operatorpow).\nEquivalent to dataframe**other, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,rpow.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 98}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dot.html#pandas.DataFrame.dot"], "Title": ["DataFrame.dot"], "Feature": ["DataFrame.dot"], "Description": "Compute the matrix multiplication between the DataFrame and other.\nThis method computes the matrix product between the DataFrame and the values of an other Series, DataFrame or a numpy array.\nIt can also be called usingself@other.\nNotes\nThe dimensions of DataFrame and other must be compatible in order to compute the matrix multiplication. In addition, the column names of\nDataFrame and the index of other must contain the same values, as they will be aligned prior to the multiplication.\nThe dot method for Series computes the inner product, instead of the matrix product here.", "Examples": [">>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n>>> s = pd.Series([1, 1, 2, 1])\n>>> df.dot(s)\n0    -4\n1     5\ndtype: int64"], "Parameters": [["other Series, DataFrame or array-like", "The other object to compute the matrix product with."]], "Returns": [["Series or DataFrame", "If other is a Series, return the matrix product between self and\nother as a Series. If other is a DataFrame or a numpy.array, return\nthe matrix product of self and other in a DataFrame of a np.array."]], "Category": ["Dataframe"], "index": 99}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values"], "Title": ["DataFrame.values"], "Feature": ["DataFrame.values"], "Description": "Return a Numpy representation of the DataFrame.\nWarningWe recommend using DataFrame.to_numpy() instead.\nOnly the values in the DataFrame will be returned, the axes labels will be removed.\nNotes\nThe dtype will be a lower-common-denominator dtype (implicit upcasting); that is to say if the dtypes (even of numeric types) are mixed, the one that accommodates all will be chosen. Use this with care if you are not dealing with the blocks. e.g. If the dtypes are float16 and float32, dtype will be upcast to float32.  If dtypes are int32 and uint8, dtype will be upcast to int32. By numpy.find_common_type() convention, mixing int64 and uint64 will result in a float64 dtype.", "Examples": [">>> df = pd.DataFrame({'age':    [ 3,  29],\n...                    'height': [94, 170],\n...                    'weight': [31, 115]})\n>>> df\n   age  height  weight\n0    3      94      31\n1   29     170     115\n>>> df.dtypes\nage       int64\nheight    int64\nweight    int64\ndtype: object\n>>> df.values\narray([[  3,  94,  31],\n       [ 29, 170, 115]])"], "Parameters": [], "Returns": [["numpy.ndarray", "The values of the DataFrame."]], "Category": ["Dataframe"], "index": 100}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.radd.html#pandas.DataFrame.radd"], "Title": ["DataFrame.radd"], "Feature": ["DataFrame.radd"], "Description": "Get Addition of dataframe and other, element-wise (binary operator radd).\nEquivalent to other+dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,add.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 101}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub"], "Title": ["DataFrame.rsub"], "Feature": ["DataFrame.rsub"], "Description": "Get Subtraction of dataframe and other, element-wise (binary operator rsub).\nEquivalent to other-dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,sub.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 102}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmul.html#pandas.DataFrame.rmul"], "Title": ["DataFrame.rmul"], "Feature": ["DataFrame.rmul"], "Description": "Get Multiplication of dataframe and other, element-wise (binary operator rmul).\nEquivalent to other*dataframe, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,mul.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to\narithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 103}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rdiv.html#pandas.DataFrame.rdiv"], "Title": ["DataFrame.rdiv"], "Feature": ["DataFrame.rdiv"], "Description": "Get Floating division of dataframe and other, element-wise (binary operator rtruediv).\nEquivalent to other/dataframe, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,truediv.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to\narithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 104}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rtruediv.html#pandas.DataFrame.rtruediv"], "Title": ["DataFrame.rtruediv"], "Feature": ["DataFrame.rtruediv"], "Description": "Get Floating division of dataframe and other, element-wise (binary operator rtruediv).\nEquivalent to other/dataframe, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,truediv.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to\narithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 105}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rfloordiv.html#pandas.DataFrame.rfloordiv"], "Title": ["DataFrame.rfloordiv"], "Feature": ["DataFrame.rfloordiv"], "Description": ["Get Integer division of dataframe and other, element-wise (binary operator rfloordiv).\nEquivalent to other // dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, floordiv.\nAmong flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **."], "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 106}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rmod.html#pandas.DataFrame.rmod"], "Title": ["DataFrame.rmod"], "Feature": ["DataFrame.rmod"], "Description": "Get Modulo of dataframe and other, element-wise (binary operator rmod).\nEquivalent to other%dataframe, but with support to substitute a fill_value\nfor missing data in one of the inputs. With reverse version,mod.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 107}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rpow.html#pandas.DataFrame.rpow"], "Title": ["DataFrame.rpow"], "Feature": ["DataFrame.rpow"], "Description": "Get Exponential power of dataframe and other, element-wise (binary operator rpow).\nEquivalent to other**dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version,pow.\nAmong flexible wrappers (add,sub,mul,div,floordiv,mod,pow) to arithmetic operators:+,-,*,/,//,%,**.\nNotes\nMismatched indices will be unioned together.", "Examples": [">>> df = pd.DataFrame({'angles': [0, 3, 4],\n...                    'degrees': [360, 180, 360]},\n...                   index=['circle', 'triangle', 'rectangle'])\n>>> df\n           angles  degrees\ncircle          0      360\ntriangle        3      180\nrectangle       4      360"], "Parameters": [["other scalar, sequence, Series, dict or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Whether to compare by the index (0 or ‘index’) or columns.\n(1 or ‘columns’). For Series input, axis to match Series index on."], ["level int or label", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value float or None, default None", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful DataFrame alignment, with this value before computation.\nIf data in both corresponding DataFrame locations is missing\nthe result will be missing."]], "Returns": [["DataFrame", "Result of the arithmetic operation."]], "Category": ["Dataframe"], "index": 108}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html#pandas.DataFrame.lt"], "Title": ["DataFrame.lt"], "Feature": ["DataFrame.lt"], "Description": "Get Less than of dataframe and other, element-wise (binary operator lt).\nAmong flexible wrappers (eq,ne,le,lt,ge,gt) to comparison operators.\nEquivalent to==,!=,<=,<,>=,>with support to choose axis (rows or columns) and level for comparison.\nNotes\nMismatched indices will be unioned together.NaNvalues are considered different (i.e.NaN!=NaN).", "Examples": [">>> df = pd.DataFrame({'cost': [250, 150, 100],\n...                    'revenue': [100, 250, 300]},\n...                   index=['A', 'B', 'C'])\n>>> df\n   cost  revenue\nA   250      100\nB   150      250\nC   100      300"], "Parameters": [["other scalar, sequence, Series, or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’)."], ["level int or label", "Broadcast across a level, matching Index values on the passed\nMultiIndex level."]], "Returns": [["DataFrame of bool", "Result of the comparison."]], "Category": ["Dataframe"], "index": 109}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html#pandas.DataFrame.gt"], "Title": ["DataFrame.gt"], "Feature": ["DataFrame.gt"], "Description": "Get Greater than of dataframe and other, element-wise (binary operator gt).\nAmong flexible wrappers (eq,ne,le,lt,ge,gt) to comparison operators.\nEquivalent to==,!=,<=,<,>=,>with support to choose axis (rows or columns) and level for comparison.\nNotes\nMismatched indices will be unioned together.NaNvalues are considered different (i.e.NaN!=NaN).", "Examples": [">>> df = pd.DataFrame({'cost': [250, 150, 100],\n...                    'revenue': [100, 250, 300]},\n...                   index=['A', 'B', 'C'])\n>>> df\n   cost  revenue\nA   250      100\nB   150      250\nC   100      300"], "Parameters": [["other scalar, sequence, Series, or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’)."], ["level int or label", "Broadcast across a level, matching Index values on the passed\nMultiIndex level."]], "Returns": [["DataFrame of bool", "Result of the comparison."]], "Category": ["Dataframe"], "index": 110}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.axes.html#pandas.DataFrame.axes"], "Title": ["DataFrame.axes"], "Feature": ["DataFrame.axes"], "Description": "Return a list representing the axes of the DataFrame.\nIt has the row axis labels and column axis labels as the only members.\nThey are returned in that order.", "Examples": [">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df.axes\n[RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\ndtype='object')]"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 111}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.le.html#pandas.DataFrame.le"], "Title": ["DataFrame.le"], "Feature": ["DataFrame.le"], "Description": "Get Less than or equal to of dataframe and other, element-wise (binary operator le).\nAmong flexible wrappers (eq,ne,le,lt,ge,gt) to comparison operators.\nEquivalent to==,!=,<=,<,>=,>with support to choose axis (rows or columns) and level for comparison.\nNotes\nMismatched indices will be unioned together.NaNvalues are considered different (i.e.NaN!=NaN).", "Examples": [">>> df = pd.DataFrame({'cost': [250, 150, 100],\n...                    'revenue': [100, 250, 300]},\n...                   index=['A', 'B', 'C'])\n>>> df\n   cost  revenue\nA   250      100\nB   150      250\nC   100      300"], "Parameters": [["other scalar, sequence, Series, or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’)."], ["level int or label", "Broadcast across a level, matching Index values on the passed\nMultiIndex level."]], "Returns": [["DataFrame of bool", "Result of the comparison."]], "Category": ["Dataframe"], "index": 112}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ge.html#pandas.DataFrame.ge"], "Title": ["DataFrame.ge"], "Feature": ["DataFrame.ge"], "Description": "Get Greater than or equal to of dataframe and other, element-wise (binary operator ge).\nAmong flexible wrappers (eq,ne,le,lt,ge,gt) to comparison operators.\nEquivalent to==,!=,<=,<,>=,>with support to choose axis (rows or columns) and level for comparison.\nNotes\nMismatched indices will be unioned together.NaNvalues are considered different (i.e.NaN!=NaN).", "Examples": [">>> df = pd.DataFrame({'cost': [250, 150, 100],\n...                    'revenue': [100, 250, 300]},\n...                   index=['A', 'B', 'C'])\n>>> df\n   cost  revenue\nA   250      100\nB   150      250\nC   100      300"], "Parameters": [["other scalar, sequence, Series, or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’)."], ["level int or label", "Broadcast across a level, matching Index values on the passed\nMultiIndex level."]], "Returns": [["DataFrame of bool", "Result of the comparison."]], "Category": ["Dataframe"], "index": 113}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ne.html#pandas.DataFrame.ne"], "Title": ["DataFrame.ne"], "Feature": ["DataFrame.ne"], "Description": "Get Not equal to of dataframe and other, element-wise (binary operator ne).\nAmong flexible wrappers (eq,ne,le,lt,ge,gt) to comparison operators.\nEquivalent to==,!=,<=,<,>=,>with support to choose axis (rows or columns) and level for comparison.\nNotes\nMismatched indices will be unioned together.NaNvalues are considered different (i.e.NaN!=NaN).", "Examples": [">>> df = pd.DataFrame({'cost': [250, 150, 100],\n...                    'revenue': [100, 250, 300]},\n...                   index=['A', 'B', 'C'])\n>>> df\n   cost  revenue\nA   250      100\nB   150      250\nC   100      300"], "Parameters": [["other scalar, sequence, Series, or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’)."], ["level int or label", "Broadcast across a level, matching Index values on the passed\nMultiIndex level."]], "Returns": [["DataFrame of bool", "Result of the comparison."]], "Category": ["Dataframe"], "index": 114}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html#pandas.DataFrame.eq"], "Title": ["DataFrame.eq"], "Feature": ["DataFrame.eq"], "Description": "Get Equal to of dataframe and other, element-wise (binary operator eq).\nAmong flexible wrappers (eq,ne,le,lt,ge,gt) to comparison operators.\nEquivalent to==,!=,<=,<,>=,>with support to choose axis (rows or columns) and level for comparison.\nNotes\nMismatched indices will be unioned together.NaNvalues are considered different (i.e.NaN!=NaN).", "Examples": [">>> df = pd.DataFrame({'cost': [250, 150, 100],\n...                    'revenue': [100, 250, 300]},\n...                   index=['A', 'B', 'C'])\n>>> df\n   cost  revenue\nA   250      100\nB   150      250\nC   100      300"], "Parameters": [["other scalar, sequence, Series, or DataFrame", "Any single or multiple element data structure, or list-like object."], ["axis {0 or ‘index’, 1 or ‘columns’}, default ‘columns’", "Whether to compare by the index (0 or ‘index’) or columns\n(1 or ‘columns’)."], ["level int or label", "Broadcast across a level, matching Index values on the passed\nMultiIndex level."]], "Returns": [["DataFrame of bool", "Result of the comparison."]], "Category": ["Dataframe"], "index": 115}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine.html#pandas.DataFrame.combine"], "Title": ["DataFrame.combine"], "Feature": ["DataFrame.combine"], "Description": "Perform column-wise combine with another DataFrame.\nCombines a DataFrame with other DataFrame using func to element-wise combine columns. The row and column indexes of the resulting DataFrame will be the union of the two.", "Examples": [">>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n>>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n>>> df1.combine(df2, take_smaller)\n   A  B\n0  0  3\n1  0  3"], "Parameters": [["other DataFrame", "The DataFrame to merge column-wise."], ["func function", "Function that takes two series as inputs and return a Series or a\nscalar. Used to merge the two dataframes column by columns."], ["fill_value scalar value, default None", "The value to fill NaNs with prior to passing any column to the\nmerge func."], ["overwrite bool, default True", "If True, columns in self that do not exist in other will be\noverwritten with NaNs."]], "Returns": [["DataFrame", "Combination of the provided DataFrames."]], "Category": ["Dataframe"], "index": 116}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first"], "Title": ["DataFrame.combine_first"], "Feature": ["DataFrame.combine_first"], "Description": "Update null elements with value in the same location in other.\nCombine two DataFrame objects by filling null values in one DataFrame with non-null values from other DataFrame. The row and column indexes of the resulting DataFrame will be the union of the two. The resulting dataframe contains the ‘first’ dataframe values and overrides the second one values where both first.loc[index, col] and second.loc[index, col] are not missing values, upon calling first.combine_first(second). See alsoDataFrame.combinePerform series-wise operation on two DataFrames using a given function.", "Examples": [">>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n>>> df1.combine_first(df2)\n     A    B\n0  1.0  3.0\n1  0.0  4.0"], "Parameters": [["other DataFrame", "Provided DataFrame to use to fill null values."]], "Returns": [["DataFrame", "The result of combining the provided DataFrame with the other object."]], "Category": ["Dataframe"], "index": 117}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply"], "Title": ["DataFrame.apply"], "Feature": ["DataFrame.apply"], "Description": "Apply a function along an axis of the DataFrame.\nObjects passed to the function are Series objects whose index is either the DataFrame’s index (axis=0) or the DataFrame’s columns (axis=1). By default (result_type=None), the final return type is inferred from the return type of the applied function. Otherwise,it depends on the result_type argument.\nNotes\nFunctions that mutate the passed object can produce unexpected behavior or errors and are not supported. See Mutating with User Defined Function (UDF) methods for more details.", "Examples": [">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n>>> df\n   A  B\n0  4  9\n1  4  9\n2  4  9"], "Parameters": [["func function", "Function to apply to each column or row."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Axis along which the function is applied: 0 or ‘index’: apply function to each column. 1 or ‘columns’: apply function to each row."], ["raw bool, default False", "Determines if row or column is passed as a Series or ndarray object: False : passes each row or column as a Series to the\nfunction. True : the passed function will receive ndarray objects\ninstead.\nIf you are just applying a NumPy reduction function this will\nachieve much better performance."], ["result_type {‘expand’, ‘reduce’, ‘broadcast’, None}, default None", "These only act when axis=1 (columns): ‘expand’ : list-like results will be turned into columns. ‘reduce’ : returns a Series if possible rather than expanding\nlist-like results. This is the opposite of ‘expand’. ‘broadcast’ : results will be broadcast to the original shape\nof the DataFrame, the original index and columns will be\nretained. The default behaviour (None) depends on the return value of the\napplied function: list-like results will be returned as a Series\nof those. However if the apply function returns a Series these\nare expanded to columns."], ["args tuple", "Positional arguments to pass to func in addition to the\narray/series."], ["by_row False or “compat”, default “compat”", "Only has an effect when func is a listlike or dictlike of funcs\nand the func isn’t a string.\nIf “compat”, will if possible first translate the func into pandas\nmethods (e.g. Series().apply(np.sum) will be translated to Series().sum() ). If that doesn’t work, will try call to apply again with by_row=True and if that fails, will call apply again with by_row=False (backward compatible).\nIf False, the funcs will be passed the whole Series at once. Added in version 2.1.0."], ["engine {‘python’, ‘numba’}, default ‘python’", "Choose between the python (default) engine or the numba engine in apply. The numba engine will attempt to JIT compile the passed function,\nwhich may result in speedups for large DataFrames.\nIt also supports the following engine_kwargs : nopython (compile the function in nopython mode) nogil (release the GIL inside the JIT compiled function) parallel (try to apply the function in parallel over the DataFrame) Note: Due to limitations within numba/how pandas interfaces with numba,\nyou should only use this if raw=True Note: The numba compiler only supports a subset of\nvalid Python/numpy operations. Please read more about the supported python features and supported numpy features in numba to learn what you can or cannot use in the passed function. Added in version 2.2.0."], ["engine_kwargs dict", "Pass keyword arguments to the engine.\nThis is currently only used by the numba engine,\nsee the documentation for the engine argument for more information."], ["**kwargs", "Additional keyword arguments to pass as keywords arguments to func ."]], "Returns": [["Series or DataFrame", "Result of applying func along the given axis of the\nDataFrame."]], "Category": ["Dataframe"], "index": 118}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.map.html#pandas.DataFrame.map"], "Title": ["DataFrame.map"], "Feature": ["DataFrame.map"], "Description": "Apply a function to a Dataframe elementwise.\nThis method applies a function that accepts and returns a scalar to every element of a DataFrame.", "Examples": [">>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n>>> df\n       0      1\n0  1.000  2.120\n1  3.356  4.567"], "Parameters": [["func callable", "Python function, returns a single value from a single value."], ["na_action {None, ‘ignore’}, default None", "If ‘ignore’, propagate NaN values, without passing them to func."], ["**kwargs", "Additional keyword arguments to pass as keywords arguments to func ."]], "Returns": [["DataFrame", "Transformed DataFrame."]], "Category": ["Dataframe"], "index": 119}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap"], "Title": ["DataFrame.applymap"], "Feature": ["DataFrame.applymap"], "Description": "Apply a function to a Dataframe elementwise.\nThis method applies a function that accepts and returns a scalar to every element of a DataFrame.", "Examples": [">>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n>>> df\n       0      1\n0  1.000  2.120\n1  3.356  4.567"], "Parameters": [["func callable", "Python function, returns a single value from a single value."], ["na_action {None, ‘ignore’}, default None", "If ‘ignore’, propagate NaN values, without passing them to func."], ["**kwargs", "Additional keyword arguments to pass as keywords arguments to func ."]], "Returns": [["DataFrame", "Transformed DataFrame."]], "Category": ["Dataframe"], "index": 120}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe"], "Title": ["DataFrame.pipe"], "Feature": ["DataFrame.pipe"], "Description": "Apply chainable functions that expect Series or DataFrames.\nNotes\nUse .pipe when chaining together functions that expect Series, DataFrames or GroupBy objects.", "Examples": [">>> data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n>>> df = pd.DataFrame(data, columns=['Salary', 'Others'])\n>>> df\n   Salary  Others\n0    8000  1000.0\n1    9500     NaN\n2    5000  2000.0"], "Parameters": [["func function", "Function to apply to the Series/DataFrame. args , and kwargs are passed into func .\nAlternatively a (callable, data_keyword) tuple where data_keyword is a string indicating the keyword of callable that expects the Series/DataFrame."], ["*args iterable, optional", "Positional arguments passed into func ."], ["**kwargs mapping, optional", "A dictionary of keyword arguments passed into func ."]], "Returns": [["the return type of func .", ""]], "Category": ["Dataframe"], "index": 121}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html#pandas.DataFrame.ndim"], "Title": ["DataFrame.ndim"], "Feature": ["DataFrame.ndim"], "Description": "Return an int representing the number of axes / array dimensions.\nReturn 1 if Series. Otherwise return 2 if DataFrame.", "Examples": [">>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n>>> s.ndim\n1"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 122}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg"], "Title": ["DataFrame.agg"], "Feature": ["DataFrame.agg"], "Description": "Aggregate using one or more operations over the specified axis.\nNotes\nThe aggregation operations are always performed over an axis, either the index (default) or the column axis. This behavior is different from numpy aggregation functions (mean,median,prod,sum,std,var), where the default is to compute the aggregation of the flattened array, e.g.,numpy.mean(arr_2d)as opposed to numpy.mean(arr_2d,axis=0). agg is an alias for aggregate. Use the alias.\nFunctions that mutate the passed object can produce unexpected behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methods for more details.\nA passed user-defined-function will be passed a Series for evaluation.", "Examples": [">>> df = pd.DataFrame([[1, 2, 3],\n...                    [4, 5, 6],\n...                    [7, 8, 9],\n...                    [np.nan, np.nan, np.nan]],\n...                   columns=['A', 'B', 'C'])"], "Parameters": [["func function, str, list or dict", "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] dict of axis labels -> functions, function names or list of such."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "If 0 or ‘index’: apply function to each column.\nIf 1 or ‘columns’: apply function to each row."], ["*args", "Positional arguments to pass to func ."], ["**kwargs", "Keyword arguments to pass to func ."]], "Returns": [["scalar, Series or DataFrame", "The return can be: scalar : when Series.agg is called with single function Series : when DataFrame.agg is called with a single function DataFrame : when DataFrame.agg is called with several functions"]], "Category": ["Dataframe"], "index": 123}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate"], "Title": ["DataFrame.aggregate"], "Feature": ["DataFrame.aggregate"], "Description": "Aggregate using one or more operations over the specified axis.\nNotes\nThe aggregation operations are always performed over an axis, either the index (default) or the column axis. This behavior is different from numpy aggregation functions (mean,median,prod,sum,std,var), where the default is to compute the aggregation of the flattened array, e.g.,numpy.mean(arr_2d)as opposed to numpy.mean(arr_2d,axis=0). agg is an alias for aggregate. Use the alias.\nFunctions that mutate the passed object can produce unexpected behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methods for more details.\nA passed user-defined-function will be passed a Series for evaluation.", "Examples": [">>> df = pd.DataFrame([[1, 2, 3],\n...                    [4, 5, 6],\n...                    [7, 8, 9],\n...                    [np.nan, np.nan, np.nan]],\n...                   columns=['A', 'B', 'C'])"], "Parameters": [["func function, str, list or dict", "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] dict of axis labels -> functions, function names or list of such."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "If 0 or ‘index’: apply function to each column.\nIf 1 or ‘columns’: apply function to each row."], ["*args", "Positional arguments to pass to func ."], ["**kwargs", "Keyword arguments to pass to func ."]], "Returns": [["scalar, Series or DataFrame", "The return can be: scalar : when Series.agg is called with single function Series : when DataFrame.agg is called with a single function DataFrame : when DataFrame.agg is called with several functions"]], "Category": ["Dataframe"], "index": 124}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform"], "Title": ["DataFrame.transform"], "Feature": ["DataFrame.transform"], "Description": "Call func on self producing a DataFrame with the same axis shape as self.\nNotes\nFunctions that mutate the passed object can produce unexpected behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methods for more details.", "Examples": [">>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n>>> df\n   A  B\n0  0  1\n1  1  2\n2  2  3\n>>> df.transform(lambda x: x + 1)\n   A  B\n0  1  2\n1  2  3\n2  3  4"], "Parameters": [["func function, str, list-like or dict-like", "Function to use for transforming the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply. If func\nis both list-like and dict-like, dict-like behavior takes precedence. Accepted combinations are: function string function name list-like of functions and/or function names, e.g. [np.exp, 'sqrt'] dict-like of axis labels -> functions, function names or list-like of such."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "If 0 or ‘index’: apply function to each column.\nIf 1 or ‘columns’: apply function to each row."], ["*args", "Positional arguments to pass to func ."], ["**kwargs", "Keyword arguments to pass to func ."]], "Returns": [["DataFrame", "A DataFrame that must have the same length as self."]], "Category": ["Dataframe"], "index": 125}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling"], "Title": ["DataFrame.rolling"], "Feature": ["DataFrame.rolling"], "Description": "Provide rolling window calculations.\nNotes\nSee Windowing Operations for further usage details and examples.", "Examples": [">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n>>> df\n     B\n0  0.0\n1  1.0\n2  2.0\n3  NaN\n4  4.0"], "Parameters": [["window int, timedelta, str, offset, or BaseIndexer subclass", "Size of the moving window. If an integer, the fixed number of observations used for\neach window. If a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link . If a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods , center , closed and step will be passed to get_window_bounds ."], ["min_periods int, default None", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan . For a window that is specified by an offset, min_periods will default to 1. For a window that is specified by an integer, min_periods will default\nto the size of the window."], ["center bool, default False", "If False, set the window labels as the right edge of the window index. If True, set the window labels as the center of the window index."], ["win_type str, default None", "If None , all points are evenly weighted. If a string, it must be a valid scipy.signal window function . Certain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature."], ["on str, optional", "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index. Provided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window."], ["axis int or str, default 0", "If 0 or 'index' , roll across the rows. If 1 or 'columns' , roll across the columns. For Series this parameter is unused and defaults to 0. Deprecated since version 2.1.0: The axis keyword is deprecated. For axis=1 ,\ntranspose the DataFrame first instead."], ["closed str, default None", "If 'right' , the first point in the window is excluded from calculations. If 'left' , the last point in the window is excluded from calculations. If 'both' , the no points in the window are excluded from calculations. If 'neither' , the first and last points in the window are excluded\nfrom calculations. Default None ( 'right' )."], ["step int, default None", "Added in version 1.5.0. Evaluate the window at every step result, equivalent to slicing as [::step] . window must be an integer. Using a step argument other\nthan None or 1 will produce a result with a different shape than the input."], ["method str {‘single’, ‘table’}, default ‘single’", "Added in version 1.3.0. Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call."]], "Returns": [["pandas.api.typing.Window or pandas.api.typing.Rolling", "An instance of Window is returned if win_type is passed. Otherwise,\nan instance of Rolling is returned."]], "Category": ["Dataframe"], "index": 126}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding"], "Title": ["DataFrame.expanding"], "Feature": ["DataFrame.expanding"], "Description": "Provide expanding window calculations.\nNotes\nSeeWindowing Operations for further usage details and examples.", "Examples": [">>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n>>> df\n     B\n0  0.0\n1  1.0\n2  2.0\n3  NaN\n4  4.0\nmin_periods\nExpanding sum with 1 vs 3 observations needed to calculate a value.\n>>> df.expanding(1).sum()\n     B\n0  0.0\n1  1.0\n2  3.0\n3  3.0\n4  7.0\n>>> df.expanding(3).sum()\n     B\n0  NaN\n1  NaN\n2  3.0\n3  3.0\n4  7.0"], "Parameters": ["min_periods int, default 1\nMinimum number of observations in window required to have a value; otherwise, result is np.nan.\naxisint or str, default 0\nIf 0 or 'index', roll across the rows.\nIf 1 or 'columns', roll across the columns.\nFor Series this parameter is unused and defaults to 0.\nmethodstr {‘single’, ‘table’}, default ‘single’\nExecute the rolling operation per single column or row ('single') or over the entire object ('table').\nThis argument is only implemented when specifying engine='numba' in the method call."], "Returns": ["pandas.api.typing.Expanding"], "Category": ["Dataframe"], "index": 127}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html#pandas.DataFrame.ewm"], "Title": ["DataFrame.ewm"], "Feature": ["DataFrame.ewm"], "Description": "Provide exponentially weighted (EW) calculations.\nExactly one of com,span,halflife, or alpha must be\nprovided if times is not provided. If times is provided,halflife and one of com,span or alphamay be provided.\nNotes\nSee Windowing Operations for further usage details and examples.", "Examples": [">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n>>> df\n     B\n0  0.0\n1  1.0\n2  2.0\n3  NaN\n4  4.0"], "Parameters": [["com float, optional", "Specify decay in terms of center of mass α = 1 / ( 1 + c o m ) , for c o m ≥ 0 ."], ["span float, optional", "Specify decay in terms of span α = 2 / ( s p a n + 1 ) , for s p a n ≥ 1 ."], ["halflife float, str, timedelta, optional", "Specify decay in terms of half-life α = 1 − exp ⁡ ( − ln ⁡ ( 2 ) / h a l f l i f e ) , for h a l f l i f e > 0 . If times is specified, a timedelta convertible unit over which an\nobservation decays to half its value. Only applicable to mean() ,\nand halflife value will not apply to the other functions."], ["alpha float, optional", "Specify smoothing factor α directly 0 < α ≤ 1 ."], ["min_periods int, default 0", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan ."], ["adjust bool, default True", "Divide by decaying adjustment factor in beginning periods to account\nfor imbalance in relative weightings (viewing EWMA as a moving average). When adjust=True (default), the EW function is calculated using weights w i = ( 1 − α ) i . For example, the EW moving average of the series\n[ x 0 , x 1 , . . . , x t ] would be: y t = x t + ( 1 − α ) x t − 1 + ( 1 − α ) 2 x t − 2 + . . . + ( 1 − α ) t x 0 1 + ( 1 − α ) + ( 1 − α ) 2 + . . . + ( 1 − α ) t When adjust=False , the exponentially weighted function is calculated\nrecursively: y 0 = x 0 y t = ( 1 − α ) y t − 1 + α x t ,"], ["ignore_na bool, default False", "Ignore missing values when calculating weights. When ignore_na=False (default), weights are based on absolute positions.\nFor example, the weights of x 0 and x 2 used in calculating\nthe final weighted average of [ x 0 , None, x 2 ] are ( 1 − α ) 2 and 1 if adjust=True , and ( 1 − α ) 2 and α if adjust=False . When ignore_na=True , weights are based\non relative positions. For example, the weights of x 0 and x 2 used in calculating the final weighted average of\n[ x 0 , None, x 2 ] are 1 − α and 1 if adjust=True , and 1 − α and α if adjust=False ."], ["axis {0, 1}, default 0", "If 0 or 'index' , calculate across the rows. If 1 or 'columns' , calculate across the columns. For Series this parameter is unused and defaults to 0."], ["times np.ndarray, Series, default None", "Only applicable to mean() . Times corresponding to the observations. Must be monotonically increasing and datetime64[ns] dtype. If 1-D array like, a sequence with the same shape as the observations."], ["method str {‘single’, ‘table’}, default ‘single’", "Added in version 1.4.0. Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call. Only applicable to mean()"]], "Returns": [["pandas.api.typing.ExponentialMovingWindow"]], "Category": ["Dataframe"], "index": 128}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html#pandas.DataFrame.abs"], "Title": ["DataFrame.abs"], "Feature": ["DataFrame.abs"], "Description": "Return a Series/DataFrame with absolute numeric value of each element.\nThis function only applies to elements that are all numeric.\nNotes\nFor complex inputs,1.2+1j, the absolute value isa2+b2.", "Examples": [">>> s = pd.Series([-1.10, 2, -3.33, 4])\n>>> s.abs()\n0    1.10\n1    2.00\n2    3.33\n3    4.00\ndtype: float64"], "Parameters": [], "Returns": [["abs", "Series/DataFrame containing the absolute value of each element."]], "Category": ["Dataframe"], "index": 129}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html#pandas.DataFrame.all"], "Title": ["DataFrame.all"], "Feature": ["DataFrame.all"], "Description": "Return whether all elements are True, potentially over an axis.\nReturns True unless there at least one element within a series or along a Dataframe axis that is False or equivalent (e.g. zero or empty).", "Examples": [">>> pd.Series([True, True]).all()\nTrue\n>>> pd.Series([True, False]).all()\nFalse\n>>> pd.Series([], dtype=\"float64\").all()\nTrue\n>>> pd.Series([np.nan]).all()\nTrue\n>>> pd.Series([np.nan]).all(skipna=False)\nTrue"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0. 0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels. 1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index. None : reduce all axes, return a scalar."], ["bool_only bool, default False", "Include only boolean columns. Not implemented for Series."], ["skipna bool, default True", "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be True, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero."], ["**kwargs any, default None", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["Series or DataFrame", "If level is specified, then, DataFrame is returned; otherwise, Series\nis returned."]], "Category": ["Dataframe"], "index": 130}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html#pandas.DataFrame.any"], "Title": ["DataFrame.any"], "Feature": ["DataFrame.any"], "Description": "Return whether any element is True, potentially over an axis.Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent (e.g. non-zero or non-empty).", "Examples": [">>> pd.Series([False, False]).any()\nFalse\n>>> pd.Series([True, False]).any()\nTrue\n>>> pd.Series([], dtype=\"float64\").any()\nFalse\n>>> pd.Series([np.nan]).any()\nFalse\n>>> pd.Series([np.nan]).any(skipna=False)\nTrue"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0. 0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels. 1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index. None : reduce all axes, return a scalar."], ["bool_only bool, default False", "Include only boolean columns. Not implemented for Series."], ["skip na bool, default True", "Exclude NA/null values. If the entire row/column is NA and skip na is\nTrue, then the result will be False, as for an empty row/column.\nIf skip na is False, then NA are treated as True, because these are not\nequal to zero."], ["**kwargs any, default None", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["Series or DataFrame", "If level is specified, then, DataFrame is returned; otherwise, Series\nis returned."]], "Category": ["Dataframe"], "index": 131}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html#pandas.DataFrame.clip"], "Title": ["DataFrame.clip"], "Feature": ["DataFrame.clip"], "Description": "Trim values at input threshold(s).\nAssigns values outside boundary to boundary values. Thresholds can be singular values or array like, and in the latter case the clipping is performed element-wise in the specified axis.", "Examples": [">>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n>>> df = pd.DataFrame(data)\n>>> df\n   col_0  col_1\n0      9     -2\n1     -3     -7\n2      0      6\n3     -1      8\n4      5     -5"], "Parameters": [["lower float or array-like, default None", "Minimum threshold value. All values below this\nthreshold will be set to it. A missing\nthreshold (e.g NA ) will not clip the value."], ["upper float or array-like, default None", "Maximum threshold value. All values above this\nthreshold will be set to it. A missing\nthreshold (e.g NA ) will not clip the value."], ["axis {{0 or ‘index’, 1 or ‘columns’, None}}, default None", "Align object with lower and upper along the given axis.\nFor Series this parameter is unused and defaults to None ."], ["inplace bool, default False", "Whether to perform the operation in place on the data."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted\nfor compatibility with numpy."]], "Returns": [["Series or DataFrame or None", "Same type as calling object with the values outside the\nclip boundaries replaced or None if inplace=True ."]], "Category": ["Dataframe"], "index": 132}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html#pandas.DataFrame.size"], "Title": ["DataFrame.size"], "Feature": ["DataFrame.size"], "Description": "Return an int representing the number of elements in this object.\nReturn the number of rows if Series. Otherwise return the number of rows times number of columns if DataFrame.", "Examples": [">>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n>>> s.size\n3"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 133}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr"], "Title": ["DataFrame.corr"], "Feature": ["DataFrame.corr"], "Description": "Compute pairwise correlation of columns, excluding NA/null values.\nNotes\nPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\nPearson correlation coefficientKendall rank correlation coefficientSpearman’s rank correlation coefficient", "Examples": [">>> def histogram_intersection(a, b):\n...     v = np.minimum(a, b).sum().round(decimals=1)\n...     return v\n>>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n...                   columns=['dogs', 'cats'])\n>>> df.corr(method=histogram_intersection)\n      dogs  cats\ndogs   1.0   0.3\ncats   0.3   1.0"], "Parameters": [["method {‘pearson’, ‘kendall’, ‘spearman’} or callable", "Method of correlation: pearson : standard correlation coefficient kendall : Kendall Tau correlation coefficient spearman : Spearman rank correlation callable: callable with input two 1d ndarrays and returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable’s behavior."], ["callable: callable with input two 1d ndarrays", "and returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable’s behavior."], ["min_periods int, optional", "Minimum number of observations required per pair of columns\nto have a valid result. Currently only available for Pearson\nand Spearman correlation."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: The default value of numeric_only is now False ."]], "Returns": [["DataFrame", "Correlation matrix."]], "Category": ["Dataframe"], "index": 134}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith"], "Title": ["DataFrame.corrwith"], "Feature": ["DataFrame.corrwith"], "Description": "Compute pairwise correlation.\nPairwise correlation is computed between rows or columns of DataFrame with rows or columns of Series or DataFrame. DataFrames are first aligned along both axes before computing the correlations.", "Examples": [">>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n>>> columns = [\"one\", \"two\", \"three\", \"four\"]\n>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n>>> df1.corrwith(df2)\none      1.0\ntwo      1.0\nthree    1.0\nfour     1.0\ndtype: float64"], "Parameters": [["other DataFrame, Series", "Object with which to compute correlations."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\ncolumn-wise."], ["drop bool, default False", "Drop missing indices from result."], ["method {‘pearson’, ‘kendall’, ‘spearman’} or callable", "Method of correlation: pearson : standard correlation coefficient kendall : Kendall Tau correlation coefficient spearman : Spearman rank correlation callable: callable with input two 1d ndarrays and returning a float."], ["callable: callable with input two 1d ndarrays", "and returning a float."], ["numeric_only bool, default False", "Include only float , int or boolean data. "]], "Returns": [["Series", "Pairwise correlations."]], "Category": ["Dataframe"], "index": 135}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html#pandas.DataFrame.count"], "Title": ["DataFrame.count"], "Feature": ["DataFrame.count"], "Description": "Count non-NA cells for each column or row.\nThe valuesNone,NaN,NaT,pandas.NAare considered NA.", "Examples": [">>> df = pd.DataFrame({\"Person\":\n...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n...                    \"Age\": [24., np.nan, 21., 33, 26],\n...                    \"Single\": [False, True, True, True, False]})\n>>> df\n   Person   Age  Single\n0    John  24.0   False\n1    Myla   NaN    True\n2   Lewis  21.0    True\n3    John  33.0    True\n4    Myla  26.0   False"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "If 0 or ‘index’ counts are generated for each column.\nIf 1 or ‘columns’ counts are generated for each row."], ["numeric_only bool, default False", "Include only float , int or boolean data."]], "Returns": [["Series", "For each column/row the number of non-NA/null entries."]], "Category": ["Dataframe"], "index": 136}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cov.html#pandas.DataFrame.cov"], "Title": ["DataFrame.cov"], "Feature": ["DataFrame.cov"], "Description": "Compute pairwise covariance of columns, excluding NA/null values.\nCompute the pairwise covariance among the series of a DataFrame.\nThe returned data frame is the covariance matrix of the columns of the DataFrame.\nBoth NA and null values are automatically excluded from the\ncalculation. (See the note below about bias from missing values.)\nA threshold can be set for the minimum number of observations for each value created. Comparisons with observations below this threshold will be returned asNaN.\nThis method is generally used for the analysis of time series data to understand the relationship between different measures across time.\nNotes\nReturns the covariance matrix of the DataFrame’s time series.\nThe covariance is normalized by N-ddof.\nFor DataFrames that have Series that are missing data (assuming that data is missing at random) the returned covariance matrix will be an unbiased estimate of the variance and covariance between the member Series.\nHowever, for many applications this estimate may not be acceptable because the estimate covariance matrix is not guaranteed to be positive semi-definite. This could lead to estimate correlations having absolute values which are greater than one, and/or a non-invertible\ncovariance matrix. SeeEstimation of covariance matrices for more details.", "Examples": [">>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n...                   columns=['dogs', 'cats'])\n>>> df.cov()\n          dogs      cats\ndogs  0.666667 -1.000000\ncats -1.000000  1.666667"], "Parameters": [["min_periods int, optional", "Minimum number of observations required per pair of columns\nto have a valid result."], ["ddof int, default 1", "Delta degrees of freedom.  The divisor used in calculations\nis N - ddof , where N represents the number of elements.\nThis argument is applicable only when no nan is in the dataframe."], ["numeric_only bool, default False", "Include only float , int or boolean data. "]], "Returns": [["DataFrame", "The covariance matrix of the series of the DataFrame."]], "Category": ["Dataframe"], "index": 137}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummax.html#pandas.DataFrame.cummax"], "Title": ["DataFrame.cummax"], "Feature": ["DataFrame.cummax"], "Description": "Return cumulative maximum over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative maximum.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["Series or DataFrame", "Return cumulative maximum of Series or DataFrame."]], "Category": ["Dataframe"], "index": 138}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cummin.html#pandas.DataFrame.cummin"], "Title": ["DataFrame.cummin"], "Feature": ["DataFrame.cummin"], "Description": "Return cumulative minimum over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nminimum.", "Examples": ["Series\n>>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64\nBy default, NA values are ignored.\n>>> s.cummin()\n0    2.0\n1    NaN\n2    2.0\n3   -1.0\n4   -1.0\ndtype: float64\nTo include NA values in the operation, use skipna=False\n>>> s.cummin(skipna=False)\n0    2.0\n1    NaN\n2    NaN\n3    NaN\n4    NaN\ndtype: float64\nDataFrame\n>>> df = pd.DataFrame([[2.0, 1.0],\n                   [3.0, np.nan],\n                   [1.0, 0.0]],\n                  columns=list('AB'))\ndf\n     A    B\n0  2.0  1.0\n1  3.0  NaN\n2  1.0  0.0\nBy default, iterates over rows and finds the minimum in each column. This is equivalent to axis=None or axis='index'.\n>>> df.cummin()\n     A    B\n0  2.0  1.0\n1  2.0  NaN\n2  1.0  0.0\nTo iterate over columns and find the minimum in each row, use axis=1\n>>> df.cummin(axis=1)\n     A    B\n0  2.0  1.0\n1  3.0  NaN\n2  1.0  0.0"], "Parameters": ["axis\n{0 or ‘index’, 1 or ‘columns’}, default 0\nThe index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\nskipna\nbool, default True\nExclude NA/null values. If an entire row/column is NA, the result will be NA.\n*args, **kwargs\nAdditional keywords have no effect but might be accepted for compatibility with NumPy."], "Returns": ["Series or DataFrame\nReturn cumulative minimum of Series or DataFrame."], "Category": ["Dataframe"], "index": 139}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod"], "Title": ["DataFrame.cumprod"], "Feature": ["DataFrame.cumprod"], "Description": "Return cumulative product over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nproduct.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["Series or DataFrame", "Return cumulative product of Series or DataFrame."]], "Category": ["Dataframe"], "index": 140}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum"], "Title": ["DataFrame.cumsum"], "Feature": ["DataFrame.cumsum"], "Description": "Return cumulative sum over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nsum.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["Series or DataFrame", "Return cumulative sum of Series or DataFrame."]], "Category": ["Dataframe"], "index": 141}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"], "Title": ["DataFrame.describe"], "Feature": ["DataFrame.describe"], "Description": "Generate descriptive statistics.\nDescriptive statistics include those that summarize the central\ntendency, dispersion and shape of a\ndataset’s distribution, excludingNaNvalues.\nAnalyzes both numeric and object series, as well\nas DataFrame column sets of mixed data types. The output\nwill vary depending on what is provided. Refer to the notes\nbelow for more detail.\nBy default the lower percentile is25and the\nupper percentile is75. The50percentile is the\nsame as the median.\nFor object data (e.g. strings or timestamps), the result’s index\nwill include count,unique,top, and freq. The topis the most common value. The freq is the most common value’s\nfrequency. Timestamps also include the first and last items.\nIf multiple object values have the highest count, then the count and top results will be arbitrarily chosen from\namong those with the highest count.\nFor mixed data types provided via aDataFrame, the default is to\nreturn only an analysis of numeric columns. If the dataframe consists\nonly of object and categorical data without any numeric columns, the\ndefault is to return an analysis of both the object and categorical\ncolumns. If include='all' is provided as an option, the result\nwill include a union of attributes of each type.\nThe include and exclude parameters can be used to limit\nwhich columns in a DataFrame are analyzed for the output.\nThe parameters are ignored when analyzing aSeries.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.describe()\ncount    3.0\nmean     2.0\nstd      1.0\nmin      1.0\n25%      1.5\n50%      2.0\n75%      2.5\nmax      3.0\ndtype: float64"], "Parameters": [["percentiles list-like of numbers, optional", "The percentiles to include in the output. All should\nfall between 0 and 1. The default is [.25, .5, .75] , which returns the 25th, 50th, and\n75th percentiles."], ["include ‘all’, list-like of dtypes or None (default), optional", "A white list of data types to include in the result. Ignored\nfor Series . Here are the options: ‘all’ : All columns of the input will be included in the output. A list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit numpy.number . To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of select_dtypes (e.g. df.describe(include=['O']) ). To\nselect pandas categorical columns, use 'category' None (default) : The result will include all numeric columns."], ["exclude list-like of dtypes or None (default), optional,", "A black list of data types to omit from the result. Ignored\nfor Series . Here are the options: A list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit numpy.number . To exclude object columns submit the data\ntype numpy.object . Strings can also be used in the style of select_dtypes (e.g. df.describe(exclude=['O']) ). To\nexclude pandas categorical columns, use 'category' None (default) : The result will exclude nothing."]], "Returns": [["Series or DataFrame", "Summary statistics of the Series or Dataframe provided."]], "Category": ["Dataframe"], "index": 142}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html#pandas.DataFrame.diff"], "Title": ["DataFrame.diff"], "Feature": ["DataFrame.diff"], "Description": "First discrete difference of element.\nCalculates the difference of a DataFrame element compared with another\nelement in the DataFrame (default is element in previous row).\nNotes\nFor boolean dtypes, this use soperator.xor() rather than operator.sub().\nThe result is calculated according to current dtype in DataFrame,\nhowever dtype of the result is always float64.", "Examples": [">>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n...                    'b': [1, 1, 2, 3, 5, 8],\n...                    'c': [1, 4, 9, 16, 25, 36]})\n>>> df\n   a  b   c\n0  1  1   1\n1  2  1   4\n2  3  2   9\n3  4  3  16\n4  5  5  25\n5  6  8  36"], "Parameters": [["periods int, default 1", "Periods to shift for calculating difference, accepts negative\nvalues."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Take difference over rows (0) or columns (1)."]], "Returns": [["DataFrame", "First differences of the Series."]], "Category": ["Dataframe"], "index": 143}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape"], "Title": ["DataFrame.shape"], "Feature": ["DataFrame.shape"], "Description": "Return a tuple representing the dimensionality of the DataFrame.", "Examples": [">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df.shape\n(2, 2)"], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 144}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eval.html#pandas.DataFrame.eval"], "Title": ["DataFrame.eval"], "Feature": ["DataFrame.eval"], "Description": "Evaluate a string describing operations on DataFrame columns.\nOperates on columns only, not specific rows or elements.  This allow seval to run arbitrary code, which can make you vulnerable to code\ninjection if you pass user input to this function.\nNotes\nFor more details see the API documentation for eval().\nFor detailed examples see enhancing performance with eval.", "Examples": [">>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n>>> df\n   A   B\n0  1  10\n1  2   8\n2  3   6\n3  4   4\n4  5   2\n>>> df.eval('A + B')\n0    11\n1    10\n2     9\n3     8\n4     7\ndtype: int64"], "Parameters": [["expr str", "The expression string to evaluate."], ["inplace bool, default False", "If the expression contains an assignment, whether to perform the\noperation inplace and mutate the existing DataFrame. Otherwise,\na new DataFrame is returned."], ["**kwargs", "See the documentation for eval() for complete details\non the keyword arguments accepted by query() ."]], "Returns": [["ndarray, scalar, pandas object, or None", "The result of the evaluation or None if inplace=True ."]], "Category": ["Dataframe"], "index": 145}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html#pandas.DataFrame.kurt"], "Title": ["DataFrame.kurt"], "Feature": ["DataFrame.kurt"], "Description": "Return unbiased kurtosis over requested axis.\nKurtosis obtained using Fisher’s definition of\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.", "Examples": [">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n>>> s\ncat    1\ndog    2\ndog    2\nmouse  3\ndtype: int64\n>>> s.kurt()\n1.5"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar", ""]], "Category": ["Dataframe"], "index": 146}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurtosis.html#pandas.DataFrame.kurtosis"], "Title": ["DataFrame.kurtosis"], "Feature": ["DataFrame.kurtosis"], "Description": "Return unbiased kurtosis over requested axis.\nKurtosis obtained using Fisher’s definition of\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.", "Examples": [">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n>>> s\ncat    1\ndog    2\ndog    2\nmouse  3\ndtype: int64\n>>> s.kurt()\n1.5"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar", ""]], "Category": ["Dataframe"], "index": 147}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html#pandas.DataFrame.max"], "Title": ["DataFrame.max"], "Feature": ["DataFrame.max"], "Description": "Return the maximum of the values over the requested axis.\nIf you want the index of the maximum, use idx max. This is the equivalent of the numpy.ndarray method argmax.", "Examples": [">>> idx = pd.MultiIndex.from_arrays([\n...     ['warm', 'warm', 'cold', 'cold'],\n...     ['dog', 'falcon', 'fish', 'spider']],\n...     names=['blooded', 'animal'])\n>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n>>> s\nblooded  animal\nwarm     dog       4\n         falcon    2\ncold     fish      0\n         spider    8\nName: legs, dtype: int64"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 148}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html#pandas.DataFrame.mean"], "Title": ["DataFrame.mean"], "Feature": ["DataFrame.mean"], "Description": "Return the mean of the values over the requested axis.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.mean()\n2.0"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 149}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html#pandas.DataFrame.median"], "Title": ["DataFrame.median"], "Feature": ["DataFrame.median"], "Description": "Return the median of the values over the requested axis.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.median()\n2.0"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 150}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html#pandas.DataFrame.min"], "Title": ["DataFrame.min"], "Feature": ["DataFrame.min"], "Description": "Return the minimum of the values over the requested axis.\nIf you want the index of the minimum, use idx min. This is the equivalent of the numpy.ndarray method argmin.", "Examples": [">>> idx = pd.MultiIndex.from_arrays([\n...     ['warm', 'warm', 'cold', 'cold'],\n...     ['dog', 'falcon', 'fish', 'spider']],\n...     names=['blooded', 'animal'])\n>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n>>> s\nblooded  animal\nwarm     dog       4\n         falcon    2\ncold     fish      0\n         spider    8\nName: legs, dtype: int64"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 151}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html#pandas.DataFrame.mode"], "Title": ["DataFrame.mode"], "Feature": ["DataFrame.mode"], "Description": "Get the mode(s) of each element along the selected axis.\nThe mode of a set of values is the value that appears most often.\nIt can be multiple values.", "Examples": [">>> df = pd.DataFrame([('bird', 2, 2),\n...                    ('mammal', 4, np.nan),\n...                    ('arthropod', 8, 0),\n...                    ('bird', 2, np.nan)],\n...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n...                   columns=('species', 'legs', 'wings'))\n>>> df\n           species  legs  wings\nfalcon        bird     2    2.0\nhorse       mammal     4    NaN\nspider   arthropod     8    0.0\nostrich       bird     2    NaN"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to iterate over while searching for the mode: 0 or ‘index’ : get mode of each column 1 or ‘columns’ : get mode of each row."], ["numeric_only bool, default False", "If True, only apply to numeric columns."], ["dropna bool, default True", "Don’t consider counts of NaN/NaT."]], "Returns": [["DataFrame", "The modes of each column or row."]], "Category": ["Dataframe"], "index": 152}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html#pandas.DataFrame.pct_change"], "Title": ["DataFrame.pct_change"], "Feature": ["DataFrame.pct_change"], "Description": "Fractional change between the current and a prior element.\nComputes the fractional change from the immediately previous row by\ndefault. This is useful in comparing the fraction of change in a time\nseries of elements.\nNoteDespite the name of this method, it calculates fractional change\n(also known as per unit change or relative change) and not\npercentage change. If you need the percentage change, multiply\nthese values by 100.", "Examples": [">>> s = pd.Series([90, 91, 85])\n>>> s\n0    90\n1    91\n2    85\ndtype: int64"], "Parameters": [["periods int, default 1", "Periods to shift for forming percent change."], ["fill_method {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’", "How to handle NAs before computing percent changes."], ["limit int, default None", "The number of consecutive NAs to fill before stopping."], ["freq DateOffset, timedelta, or str, optional", "Increment to use from time series API (e.g. ‘ME’ or BDay())."], ["**kwargs", "Additional keyword arguments are passed into DataFrame.shift or Series.shift ."]], "Returns": [["Series or DataFrame", "The same type as the calling object."]], "Category": ["Dataframe"], "index": 153}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.prod.html#pandas.DataFrame.prod"], "Title": ["DataFrame.prod"], "Feature": ["DataFrame.prod"], "Description": "Return the product of the values over the requested axis.", "Examples": [">>> pd.Series([], dtype=\"float64\").prod()\n1.0"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 154}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.empty.html#pandas.DataFrame.empty"], "Title": ["DataFrame.empty"], "Feature": ["DataFrame.empty"], "Description": "Indicator whether Series/DataFrame is empty.\nTrue if Series/DataFrame is entirely empty (no items), meaning any of the axes are of length 0.\nNotes\nIf Series/DataFrame contains only NaNs, it is still not considered empty.", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Dataframe"], "index": 155}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.product.html#pandas.DataFrame.product"], "Title": ["DataFrame.product"], "Feature": ["DataFrame.product"], "Description": "Return the product of the values over the requested axis.", "Examples": [">>> pd.Series([], dtype=\"float64\").prod()\n1.0"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 156}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile"], "Title": ["DataFrame.quantile"], "Feature": ["DataFrame.quantile"], "Description": "Return values at the given quantile over requested axis.", "Examples": [">>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n...                   columns=['a', 'b'])\n>>> df.quantile(.1)\na    1.3\nb    3.7\nName: 0.1, dtype: float64\n>>> df.quantile([.1, .5])\n       a     b\n0.1  1.3   3.7\n0.5  2.5  55.0"], "Parameters": [["q float or array-like, default 0.5 (50% quantile)", "Value between 0 <= q <= 1, the quantile(s) to compute."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Equals 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise."], ["numeric_only bool, default False", "Include only float , int or boolean data. Changed in version 2.0.0: The default value of numeric_only is now False ."], ["interpolation {‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data points i and j : linear: i + (j - i) * fraction , where fraction is the\nfractional part of the index surrounded by i and j . lower: i . higher: j . nearest: i or j whichever is nearest. midpoint: ( i + j ) / 2."], ["method {‘single’, ‘table’}, default ‘single’", "Whether to compute quantiles per-column (‘single’) or over all columns\n(‘table’). When ‘table’, the only allowed interpolation methods are\n‘nearest’, ‘lower’, and ‘higher’."]], "Returns": [["Series or DataFrame", "If q is an array, a DataFrame will be returned where the index is q , the columns are the columns of self, and the\nvalues are the quantiles. If q is a float, a Series will be returned where the index is the columns of self and the values are the quantiles."], ["If q is an array, a DataFrame will be returned where the", "index is q , the columns are the columns of self, and the\nvalues are the quantiles."], ["If q is a float, a Series will be returned where the", "index is the columns of self and the values are the quantiles."]], "Category": ["Dataframe"], "index": 157}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rank.html#pandas.DataFrame.rank"], "Title": ["DataFrame.rank"], "Feature": ["DataFrame.rank"], "Description": "Compute numerical data ranks (1 through n) along axis.\nBy default, equal values are assigned a rank that is the average of the\nranks of those values.", "Examples": [">>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n...                                    'spider', 'snake'],\n...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n>>> df\n    Animal  Number_legs\n0      cat          4.0\n1  penguin          2.0\n2      dog          4.0\n3   spider          8.0\n4    snake          NaN"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Index to direct ranking.\nFor Series this parameter is unused and defaults to 0."], ["method {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "How to rank the group of records that have the same value (i.e. ties): average: average rank of the group min: lowest rank in the group max: highest rank in the group first: ranks assigned in order they appear in the array dense: like ‘min’, but rank always increases by 1 between groups."], ["numeric_only bool, default False", "For DataFrame objects, rank only numeric columns if set to True. Changed in version 2.0.0: The default value of numeric_only is now False ."], ["na_option {‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "How to rank NaN values: keep: assign NaN rank to NaN values top: assign lowest rank to NaN values bottom: assign highest rank to NaN values"], ["ascending bool, default True", "Whether or not the elements should be ranked in ascending order."], ["pct bool, default False", "Whether or not to display the returned rankings in percentile\nform."]], "Returns": [["same type as caller", "Return a Series or DataFrame with data ranks as values."]], "Category": ["Dataframe"], "index": 158}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html#pandas.DataFrame.round"], "Title": ["DataFrame.round"], "Feature": ["DataFrame.round"], "Description": "Round a DataFrame to a variable number of decimal places.", "Examples": [">>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n...                   columns=['dogs', 'cats'])\n>>> df\n    dogs  cats\n0  0.21  0.32\n1  0.01  0.67\n2  0.66  0.03\n3  0.21  0.18"], "Parameters": [["decimals int, dict, Series", "Number of decimal places to round each column to. If an int is\ngiven, round each column to the same number of places.\nOtherwise dict and Series round to variable numbers of places.\nColumn names should be in the keys if decimals is a\ndict-like, or in the index if decimals is a Series. Any\ncolumns not included in decimals will be left as is. Elements\nof decimals which are not columns of the input will be\nignored."], ["*args", "Additional keywords have no effect but might be accepted for\ncompatibility with numpy."], ["**kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with numpy."]], "Returns": [["DataFrame", "A DataFrame with the affected columns rounded to the specified\nnumber of decimal places."]], "Category": ["Dataframe"], "index": 159}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sem.html#pandas.DataFrame.sem"], "Title": ["DataFrame.sem"], "Feature": ["DataFrame.sem"], "Description": "Return unbiased standard error of the mean over requested axis.\nNormalized by N-1 by default. This can be changed using the ddof argument", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.sem().round(6)\n0.57735"], "Parameters": [["axis {index (0), columns (1)}", "For Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.sem with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["ddof int, default 1", "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."]], "Returns": [["Series or DataFrame (if level specified)"]], "Category": ["Dataframe"], "index": 160}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html#pandas.DataFrame.skew"], "Title": ["DataFrame.skew"], "Feature": ["DataFrame.skew"], "Description": "Return unbiased skew over requested axis.\nNormalized by N-1.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.skew()\n0.0"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 161}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum"], "Title": ["DataFrame.sum"], "Feature": ["DataFrame.sum"], "Description": "Return the sum of the values over the requested axis.\nThis is equivalent to the method numpy.sum.", "Examples": [">>> idx = pd.MultiIndex.from_arrays([\n...     ['warm', 'warm', 'cold', 'cold'],\n...     ['dog', 'falcon', 'fish', 'spider']],\n...     names=['blooded', 'animal'])\n>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n>>> s\nblooded  animal\nwarm     dog       4\n         falcon    2\ncold     fish      0\n         spider    8\nName: legs, dtype: int64"], "Parameters": [["axis {index (0), columns (1)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.sum with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series or scalar"]], "Category": ["Dataframe"], "index": 162}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html#pandas.DataFrame.std"], "Title": ["DataFrame.std"], "Feature": ["DataFrame.std"], "Description": "Return sample standard deviation over requested axis.\nNormalized by N-1 by default. This can be changed using the ddof argument.\nNotes\nTo have the same behaviour asnumpy.std, use ddof=0(instead of the\ndefault ddof=1)", "Examples": [">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n...                    'age': [21, 25, 62, 43],\n...                    'height': [1.61, 1.87, 1.49, 2.01]}\n...                   ).set_index('person_id')\n>>> df\n           age  height\nperson_id\n0           21    1.61\n1           25    1.87\n2           62    1.49\n3           43    2.01"], "Parameters": [["axis {index (0), columns (1)}", "For Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.std with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["ddof int, default 1", "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."]], "Returns": [["Series or DataFrame (if level specified)"]], "Category": ["Dataframe"], "index": 163}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html#pandas.DataFrame.var"], "Title": ["DataFrame.var"], "Feature": ["DataFrame.var"], "Description": "Return unbiased variance over requested axis.\nNormalized by N-1 by default. This can be changed using the ddof argument.", "Examples": [">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n...                    'age': [21, 25, 62, 43],\n...                    'height': [1.61, 1.87, 1.49, 2.01]}\n...                   ).set_index('person_id')\n>>> df\n           age  height\nperson_id\n0           21    1.61\n1           25    1.87\n2           62    1.49\n3           43    2.01"], "Parameters": [["axis {index (0), columns (1)}", "For Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.var with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["ddof int, default 1", "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."]], "Returns": [["Series or DataFrame (if level specified)"]], "Category": ["Dataframe"], "index": 164}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html#pandas.DataFrame.nunique"], "Title": ["DataFrame.nunique"], "Feature": ["DataFrame.nunique"], "Description": "Count number of distinct elements in specified axis.\nReturn Series with number of distinct elements. Can ignore NaN\nvalues.", "Examples": [">>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n>>> df.nunique()\nA    3\nB    2\ndtype: int64"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for\ncolumn-wise."], ["dropna bool, default True", "Don’t include NaN in the counts."]], "Returns": [["Series"]], "Category": ["Dataframe"], "index": 165}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.apply.html#pandas.core.groupby.SeriesGroupBy.apply"], "Title": ["SeriesGroupBy.apply"], "Feature": ["SeriesGroupBy.apply"], "Description": "Apply functionfuncgroup-wise and combine the results together.\nThe function passed toapplymust take a series as its first\nargument and return a DataFrame, Series or scalar.applywill\nthen take care of combining the results back together into a single\ndataframe or series.applyis therefore a highly flexible\ngrouping method.\nWhileapplyis a very flexible method, its downside is that\nusing it can be quite a bit slower than using more specific methods\nlikeaggortransform. Pandas offers a wide range of method that will\nbe much faster than usingapplyfor their specific purposes, so try to\nuse them before reaching forapply.\nSee alsopipeApply function to the full GroupBy object instead of to each group.aggregateApply aggregate function to the GroupBy object.transformApply function column-by-column to the GroupBy object.Series.applyApply a function to a Series.DataFrame.applyApply a function to each row or column of a DataFrame.\nNotes\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.", "Examples": [">>> s = pd.Series([0, 1, 2], index='a a b'.split())\n>>> g1 = s.groupby(s.index, group_keys=False)\n>>> g2 = s.groupby(s.index, group_keys=True)\n"], "Parameters": [["func callable", "A callable that takes a series as its first argument, and\nreturns a dataframe, a series or a scalar. In addition the\ncallable may take positional and keyword arguments."], ["include_groups bool, default True", "When True, will attempt to apply func to the groupings in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func . Added in version 2.2.0. Deprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas."], ["args, kwargs tuple and dict", "Optional positional and keyword arguments to pass to func ."]], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 168}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ohlc.html#pandas.core.groupby.SeriesGroupBy.ohlc"], "Title": ["SeriesGroupBy.ohlc"], "Feature": ["SeriesGroupBy.ohlc"], "Description": "Compute open, high, low and close values of a group, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex", "Examples": [">>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]\n>>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)\n>>> ser\nSPX     3.4\nCAC     9.0\nSPX     7.2\nCAC     5.2\nSPX     8.8\nCAC     9.4\nSPX     0.1\nCAC     0.5\ndtype: float64\n>>> ser.groupby(level=0).ohlc()\n     open  high  low  close\nCAC   9.0   9.4  0.5    0.5\nSPX   3.4   8.8  0.1    0.1\n"], "Parameters": [], "Returns": [["DataFrame", "Open, high, low and close values within each group."]], "Category": ["Groupby"], "index": 169}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pct_change.html#pandas.core.groupby.SeriesGroupBy.pct_change"], "Title": ["SeriesGroupBy.pct_change"], "Feature": ["SeriesGroupBy.pct_change"], "Description": "Calculate pct_change of each value to previous entry in group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).pct_change()\na         NaN\na    1.000000\nb         NaN\nb    0.333333\ndtype: float64\n"], "Parameters": [], "Returns": [["Series or DataFrame", "Percentage changes within each group."]], "Category": ["Groupby"], "index": 170}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.prod.html#pandas.core.groupby.SeriesGroupBy.prod"], "Title": ["SeriesGroupBy.prod"], "Feature": ["SeriesGroupBy.prod"], "Description": "Compute prod of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).prod()\na    2\nb   12\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."]], "Returns": [["Series or DataFrame", "Computed prod of values within each group."]], "Category": ["Groupby"], "index": 171}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.quantile.html#pandas.core.groupby.SeriesGroupBy.quantile"], "Title": ["SeriesGroupBy.quantile"], "Feature": ["SeriesGroupBy.quantile"], "Description": "Return group values at the given quantile, a la numpy.percentile.\nSee alsoSeries.quantileSimilar method for Series.DataFrame.quantileSimilar method for DataFrame.numpy.percentileNumPy method to compute qth percentile.", "Examples": [">>> df = pd.DataFrame([\n...     ['a', 1], ['a', 2], ['a', 3],\n...     ['b', 1], ['b', 3], ['b', 5]\n... ], columns=['key', 'val'])\n>>> df.groupby('key').quantile()\n    val\nkey\na    2.0\nb    3.0\n"], "Parameters": [["q float or array-like, default 0.5 (50% quantile)", "Value(s) between 0 and 1 providing the quantile(s) to compute."], ["interpolation {‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "Method to use when the desired quantile falls between two points."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Return type determined by caller of GroupBy object."]], "Category": ["Groupby"], "index": 172}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rank.html#pandas.core.groupby.SeriesGroupBy.rank"], "Title": ["SeriesGroupBy.rank"], "Feature": ["SeriesGroupBy.rank"], "Description": "Provide the rank of values within each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"group\": [\"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"b\"],\n...         \"value\": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],\n...     }\n... )\n>>> df\n  group  value\n0     a      2\n1     a      4\n2     a      2\n3     a      3\n4     a      5\n5     b      1\n6     b      2\n7     b      4\n8     b      1\n9     b      5\n>>> for method in ['average', 'min', 'max', 'dense', 'first']:\n...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)\n>>> df\n  group  value  average_rank  min_rank  max_rank  dense_rank  first_rank\n0     a      2           1.5       1.0       2.0         1.0         1.0\n1     a      4           4.0       4.0       4.0         3.0         4.0\n2     a      2           1.5       1.0       2.0         1.0         2.0\n3     a      3           3.0       3.0       3.0         2.0         3.0\n4     a      5           5.0       5.0       5.0         4.0         5.0\n5     b      1           1.5       1.0       2.0         1.0         1.0\n6     b      2           3.0       3.0       3.0         2.0         3.0\n7     b      4           4.0       4.0       4.0         3.0         4.0\n8     b      1           1.5       1.0       2.0         1.0         2.0\n9     b      5           5.0       5.0       5.0         4.0         5.0\n"], "Parameters": [["method {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "average: average rank of group. min: lowest rank in group. max: highest rank in group. first: ranks assigned in order they appear in the array. dense: like ‘min’, but rank always increases by 1 between groups."], ["ascending bool, default True", "False for ranks by high (1) to low (N)."], ["na_option {‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "keep: leave NA values where they are. top: smallest rank if ascending. bottom: smallest rank if descending."], ["pct bool, default False", "Compute percentage rank of data within each group."], ["axis int, default 0", "The axis of the object over which to compute the rank. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."]], "Returns": [["DataFrame with ranking of values within each group", ""]], "Category": ["Groupby"], "index": 173}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.resample.html#pandas.core.groupby.SeriesGroupBy.resample"], "Title": ["SeriesGroupBy.resample"], "Feature": ["SeriesGroupBy.resample"], "Description": "Provide resampling when using a TimeGrouper.\nGiven a grouper, the function resamples it according to a string\n“string” -> “frequency”.\nSee thefrequency aliasesdocumentation for more details.\nSee alsoGrouperSpecify a frequency to resample with when grouping by a key.DatetimeIndex.resampleFrequency conversion and resampling of time series.", "Examples": [">>> idx = pd.date_range('1/1/2000', periods=4, freq='min')\n>>> df = pd.DataFrame(data=4 * [range(2)],\n...                   index=idx,\n...                   columns=['a', 'b'])\n>>> df.iloc[2, 0] = 5\n>>> df\n                    a  b\n2000-01-01 00:00:00  0  1\n2000-01-01 00:01:00  0  1\n2000-01-01 00:02:00  5  1\n2000-01-01 00:03:00  0  1\n"], "Parameters": [["rule str or DateOffset", "The offset string or object representing target grouper conversion."], ["*args", "Possible arguments are how , fill_method , limit , kind and on , and other arguments of TimeGrouper ."], ["include_groups bool, default True", "When True, will attempt to include the groupings in the operation in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func . Added in version 2.2.0. Deprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas."], ["**kwargs", "Possible arguments are how , fill_method , limit , kind and on , and other arguments of TimeGrouper ."]], "Returns": [["pandas.api.typing.DatetimeIndexResamplerGroupby,", ""], ["pandas.api.typing.PeriodIndexResamplerGroupby, or", ""], ["pandas.api.typing.TimedeltaIndexResamplerGroupby", "Return a new groupby object, with type depending on the data\nbeing resampled."]], "Category": ["Groupby"], "index": 174}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html#pandas.core.groupby.SeriesGroupBy.rolling"], "Title": ["SeriesGroupBy.rolling"], "Feature": ["SeriesGroupBy.rolling"], "Description": "Return a rolling grouper, providing rolling functionality per group.\nSee alsoSeries.rollingCalling object with Series data.DataFrame.rollingCalling object with DataFrames.Series.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby.", "Examples": [">>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n...                    'B': [1, 2, 3, 4],\n...                    'C': [0.362, 0.227, 1.267, -0.562]})\n>>> df\n      A  B      C\n0     1  1  0.362\n1     1  2  0.227\n2     2  3  1.267\n3     2  4 -0.562\n"], "Parameters": [["window int, timedelta, str, offset, or BaseIndexer subclass", "Size of the moving window. If an integer, the fixed number of observations used for\neach window. If a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link . If a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods , center , closed and step will be passed to get_window_bounds ."], ["min_periods int, default None", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan . For a window that is specified by an offset, min_periods will default to 1. For a window that is specified by an integer, min_periods will default\nto the size of the window."], ["center bool, default False", "If False, set the window labels as the right edge of the window index. If True, set the window labels as the center of the window index."], ["win_type str, default None", "If None , all points are evenly weighted. If a string, it must be a valid scipy.signal window function . Certain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature."], ["on str, optional", "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index. Provided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window."], ["axis int or str, default 0", "If 0 or 'index' , roll across the rows. If 1 or 'columns' , roll across the columns. For Series this parameter is unused and defaults to 0."], ["closed str, default None", "If 'right' , the first point in the window is excluded from calculations. If 'left' , the last point in the window is excluded from calculations. If 'both' , no points in the window are excluded from calculations. If 'neither' , the first and last points in the window are excluded\nfrom calculations. Default None ( 'right' )."], ["method str {‘single’, ‘table’}, default ‘single’", "Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call."]], "Returns": [["pandas.api.typing.RollingGroupby", "Return a new grouper with our rolling appended."]], "Category": ["Groupby"], "index": 175}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sample.html#pandas.core.groupby.SeriesGroupBy.sample"], "Title": ["SeriesGroupBy.sample"], "Feature": ["SeriesGroupBy.sample"], "Description": "Return a random sample of items from each group.\nYou can userandom_statefor reproducibility.\nSee alsoDataFrame.sampleGenerate random samples from a DataFrame object.numpy.random.choiceGenerate a random sample from a given 1-D numpy array.", "Examples": [">>> df = pd.DataFrame(\n...     {\"a\": [\"red\"] * 2 + [\"blue\"] * 2 + [\"black\"] * 2, \"b\": range(6)}\n... )\n>>> df\n       a  b\n0    red  0\n1    red  1\n2   blue  2\n3   blue  3\n4  black  4\n5  black  5\n"], "Parameters": [["n int, optional", "Number of items to return for each group. Cannot be used with frac and must be no larger than the smallest group unless replace is True. Default is one if frac is None."], ["frac float, optional", "Fraction of items to return. Cannot be used with n ."], ["replace bool, default False", "Allow or disallow sampling of the same row more than once."], ["weights list-like, optional", "Default None results in equal probability weighting.\nIf passed a list-like then values must have the same length as\nthe underlying DataFrame or Series object and will be used as\nsampling probabilities after normalization within each group.\nValues must be non-negative with at least one positive element\nwithin each group."], ["random_state int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given. Changed in version 1.4.0: np.random.Generator objects now accepted"]], "Returns": [["Series or DataFrame", "A new object of same type as caller containing items randomly\nsampled within each group from the caller object."]], "Category": ["Groupby"], "index": 176}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sem.html#pandas.core.groupby.SeriesGroupBy.sem"], "Title": ["SeriesGroupBy.sem"], "Feature": ["SeriesGroupBy.sem"], "Description": "Compute standard error of the mean of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([5, 10, 8, 14], index=lst)\n>>> ser\na     5\na    10\nb     8\nb    14\ndtype: int64\n>>> ser.groupby(level=0).sem()\na    2.5\nb    3.0\ndtype: float64\n"], "Parameters": [["ddof int, default 1", "Degrees of freedom."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Standard error of the mean of values within each group."]], "Category": ["Groupby"], "index": 177}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.shift.html#pandas.core.groupby.SeriesGroupBy.shift"], "Title": ["SeriesGroupBy.shift"], "Feature": ["SeriesGroupBy.shift"], "Description": "Shift each group by periods observations.\nIf freq is passed, the index will be increased using the periods and the freq.\nSee alsoIndex.shiftShift values of Index.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).shift(1)\na    NaN\na    1.0\nb    NaN\nb    3.0\ndtype: float64\n"], "Parameters": [["periods int | Sequence[int], default 1", "Number of periods to shift. If a list of values, shift each group by\neach period."], ["freq str, optional", "Frequency string."], ["axis axis to shift, default 0", "Shift direction. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["fill_value optional", "The scalar value to use for newly introduced missing values. Changed in version 2.1.0: Will raise a ValueError if freq is provided too."], ["suffix str, optional", "A string to add to each shifted column if there are multiple periods.\nIgnored otherwise."]], "Returns": [["Series or DataFrame", "Object shifted within each group."]], "Category": ["Groupby"], "index": 178}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html#pandas.core.groupby.DataFrameGroupBy.apply"], "Title": ["DataFrameGroupBy.apply"], "Feature": ["DataFrameGroupBy.apply"], "Description": "Apply functionfuncgroup-wise and combine the results together.\nThe function passed toapplymust take a dataframe as its first\nargument and return a DataFrame, Series or scalar.applywill\nthen take care of combining the results back together into a single\ndataframe or series.applyis therefore a highly flexible\ngrouping method.\nWhileapplyis a very flexible method, its downside is that\nusing it can be quite a bit slower than using more specific methods\nlikeaggortransform. Pandas offers a wide range of method that will\nbe much faster than usingapplyfor their specific purposes, so try to\nuse them before reaching forapply.\nSee alsopipeApply function to the full GroupBy object instead of to each group.aggregateApply aggregate function to the GroupBy object.transformApply function column-by-column to the GroupBy object.Series.applyApply a function to a Series.DataFrame.applyApply a function to each row or column of a DataFrame.\nNotes\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.", "Examples": [">>> df = pd.DataFrame({'A': 'a a b'.split(),\n...                    'B': [1, 2, 3],\n...                    'C': [4, 6, 5]})\n>>> g1 = df.groupby('A', group_keys=False)\n>>> g2 = df.groupby('A', group_keys=True)\n"], "Parameters": [["func callable", "A callable that takes a dataframe as its first argument, and\nreturns a dataframe, a series or a scalar. In addition the\ncallable may take positional and keyword arguments."], ["include_groups bool, default True", "When True, will attempt to apply func to the groupings in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func . Added in version 2.2.0. Deprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas."], ["args, kwargs tuple and dict", "Optional positional and keyword arguments to pass to func ."]], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 179}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.size.html#pandas.core.groupby.SeriesGroupBy.size"], "Title": ["SeriesGroupBy.size"], "Feature": ["SeriesGroupBy.size"], "Description": "Compute group sizes.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na     1\na     2\nb     3\ndtype: int64\n>>> ser.groupby(level=0).size()\na    2\nb    1\ndtype: int64\n"], "Parameters": [], "Returns": [["DataFrame or Series", "Number of rows in each group as a Series if as_index is True\nor a DataFrame if as_index is False."]], "Category": ["Groupby"], "index": 180}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.skew.html#pandas.core.groupby.SeriesGroupBy.skew"], "Title": ["SeriesGroupBy.skew"], "Feature": ["SeriesGroupBy.skew"], "Description": "Return unbiased skew within groups.\nNormalized by N-1.\nSee alsoSeries.skewReturn unbiased skew over requested axis.", "Examples": [">>> ser = pd.Series([390., 350., 357., np.nan, 22., 20., 30.],\n...                 index=['Falcon', 'Falcon', 'Falcon', 'Falcon',\n...                        'Parrot', 'Parrot', 'Parrot'],\n...                 name=\"Max Speed\")\n>>> ser\nFalcon    390.0\nFalcon    350.0\nFalcon    357.0\nFalcon      NaN\nParrot     22.0\nParrot     20.0\nParrot     30.0\nName: Max Speed, dtype: float64\n>>> ser.groupby(level=0).skew()\nFalcon    1.525174\nParrot    1.457863\nName: Max Speed, dtype: float64\n>>> ser.groupby(level=0).skew(skipna=False)\nFalcon         NaN\nParrot    1.457863\nName: Max Speed, dtype: float64\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "Axis for the function to be applied on.\nThis parameter is only for compatibility with DataFrame and is unused. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 181}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.std.html#pandas.core.groupby.SeriesGroupBy.std"], "Title": ["SeriesGroupBy.std"], "Feature": ["SeriesGroupBy.std"], "Description": "Compute standard deviation of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).std()\na    3.21455\nb    0.57735\ndtype: float64\n"], "Parameters": [["ddof int, default 1", "Degrees of freedom."], ["engine str, default None", "'cython' : Runs the operation through C-extensions from cython. 'numba' : Runs the operation through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba Added in version 1.4.0."], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {{'nopython': True, 'nogil': False, 'parallel': False}} Added in version 1.4.0."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Standard deviation of values within each group."]], "Category": ["Groupby"], "index": 182}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.sum.html#pandas.core.groupby.SeriesGroupBy.sum"], "Title": ["SeriesGroupBy.sum"], "Feature": ["SeriesGroupBy.sum"], "Description": "Compute sum of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).sum()\na    3\nb    7\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."], ["engine str, default None None", "'cython' : Runs rolling apply through C-extensions from cython. 'numba' Runs rolling apply through JIT compiled code from numba. Only available when raw is set to True . None : Defaults to 'cython' or globally setting compute.use_numba"], ["'numba' Runs rolling apply through JIT compiled code from numba.", "Only available when raw is set to True ."], ["engine_kwargs dict, default None None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."], ["For 'numba' engine, the engine can accept nopython , nogil", "and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."]], "Returns": [["Series or DataFrame", "Computed sum of values within each group."]], "Category": ["Groupby"], "index": 183}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.var.html#pandas.core.groupby.SeriesGroupBy.var"], "Title": ["SeriesGroupBy.var"], "Feature": ["SeriesGroupBy.var"], "Description": "Compute variance of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).var()\na    10.333333\nb     0.333333\ndtype: float64\n"], "Parameters": [["ddof int, default 1", "Degrees of freedom."], ["engine str, default None", "'cython' : Runs the operation through C-extensions from cython. 'numba' : Runs the operation through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba Added in version 1.4.0."], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {{'nopython': True, 'nogil': False, 'parallel': False}} Added in version 1.4.0."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Variance of values within each group."]], "Category": ["Groupby"], "index": 184}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.tail.html#pandas.core.groupby.SeriesGroupBy.tail"], "Title": ["SeriesGroupBy.tail"], "Feature": ["SeriesGroupBy.tail"], "Description": "Return last n rows of each group.\nSimilar to.apply(lambdax:x.tail(n)), but it returns a subset of rows\nfrom the original DataFrame with original index and order preserved\n(as_indexflag is ignored).\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n...                   columns=['A', 'B'])\n>>> df.groupby('A').tail(1)\n   A  B\n1  a  2\n3  b  2\n>>> df.groupby('A').tail(-1)\n   A  B\n1  a  2\n3  b  2\n"], "Parameters": [["n int", "If positive: number of entries to include from end of each group.\nIf negative: number of entries to exclude from start of each group."]], "Returns": [["Series or DataFrame", "Subset of original Series or DataFrame as determined by n."]], "Category": ["Groupby"], "index": 185}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.take.html#pandas.core.groupby.SeriesGroupBy.take"], "Title": ["SeriesGroupBy.take"], "Feature": ["SeriesGroupBy.take"], "Description": "Return the elements in the givenpositionalindices in each group.\nThis means that we are not indexing according to actual values in\nthe index attribute of the object. We are indexing according to the\nactual position of the element in the object.\nIf a requested index does not exist for some group, this method will raise.\nTo get similar behavior that ignores indices that don’t exist, seeSeriesGroupBy.nth().\nSee alsoSeries.takeTake elements from a Series along an axis.Series.locSelect a subset of a DataFrame by labels.Series.ilocSelect a subset of a DataFrame by positions.numpy.takeTake elements from an array along an axis.SeriesGroupBy.nthSimilar to take, won’t raise if indices don’t exist.", "Examples": [">>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n...                    ('parrot', 'bird', 24.0),\n...                    ('lion', 'mammal', 80.5),\n...                    ('monkey', 'mammal', np.nan),\n...                    ('rabbit', 'mammal', 15.0)],\n...                   columns=['name', 'class', 'max_speed'],\n...                   index=[4, 3, 2, 1, 0])\n>>> df\n     name   class  max_speed\n4  falcon    bird      389.0\n3  parrot    bird       24.0\n2    lion  mammal       80.5\n1  monkey  mammal        NaN\n0  rabbit  mammal       15.0\n>>> gb = df[\"name\"].groupby([1, 1, 2, 2, 2])\n"], "Parameters": [["indices array-like", "An array of ints indicating which positions to take in each group."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\nFor SeriesGroupBy this parameter is unused and defaults to 0. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["**kwargs", "For compatibility with numpy.take() . Has no effect on the\noutput."]], "Returns": [["Series", "A Series containing the elements taken from each group."]], "Category": ["Groupby"], "index": 186}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.value_counts.html#pandas.core.groupby.SeriesGroupBy.value_counts"], "Title": ["SeriesGroupBy.value_counts"], "Feature": ["SeriesGroupBy.value_counts"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Groupby"], "index": 187}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.boxplot.html#pandas.core.groupby.DataFrameGroupBy.boxplot"], "Title": ["DataFrameGroupBy.boxplot"], "Feature": ["DataFrameGroupBy.boxplot"], "Description": "Make box plots from DataFrameGroupBy data.", "Examples": [">>> import itertools\n>>> tuples = [t for t in itertools.product(range(1000), range(4))]\n>>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n>>> data = np.random.randn(len(index), 4)\n>>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n>>> grouped = df.groupby(level='lvl1')\n>>> grouped.boxplot(rot=45, fontsize=12, figsize=(8, 10))  \n"], "Parameters": [["grouped Grouped DataFrame", ""], ["subplots bool", "False - no subplots will be used True - create a subplot for each group."], ["column column name or list of names, or vector", "Can be any valid input to groupby."], ["fontsize float or str", ""], ["rot label rotation angle", ""], ["grid Setting this to True will show the grid", ""], ["ax Matplotlib axis object, default None", ""], ["figsize A tuple (width, height) in inches", ""], ["layout tuple (optional)", "The layout of the plot: (rows, columns)."], ["sharex bool, default False", "Whether x-axes will be shared among subplots."], ["sharey bool, default True", "Whether y-axes will be shared among subplots."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["**kwargs", "All other plotting keyword arguments to be passed to\nmatplotlib’s boxplot function."]], "Returns": [["dict of key/value = group key/DataFrame.boxplot return value", ""], ["or DataFrame.boxplot return value in case subplots=figures=False", ""]], "Category": ["Groupby"], "index": 188}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.hist.html#pandas.core.groupby.DataFrameGroupBy.hist"], "Title": ["DataFrameGroupBy.hist"], "Feature": ["DataFrameGroupBy.hist"], "Description": "Make a histogram of the DataFrame’s columns.\nAhistogramis a representation of the distribution of data.\nThis function callsmatplotlib.pyplot.hist(), on each series in\nthe DataFrame, resulting in one histogram per column.\nSee alsomatplotlib.pyplot.histPlot a histogram using matplotlib.", "Examples": [">>> data = {'length': [1.5, 0.5, 1.2, 0.9, 3],\n...         'width': [0.7, 0.2, 0.15, 0.2, 1.1]}\n>>> index = ['pig', 'rabbit', 'duck', 'chicken', 'horse']\n>>> df = pd.DataFrame(data, index=index)\n>>> hist = df.hist(bins=3)\n"], "Parameters": [["data DataFrame", "The pandas object holding the data."], ["column str or sequence, optional", "If passed, will be used to limit data to a subset of columns."], ["by object, optional", "If passed, then used to form histograms for separate groups."], ["grid bool, default True", "Whether to show axis grid lines."], ["xlabelsize int, default None", "If specified changes the x-axis label size."], ["xrot float, default None", "Rotation of x axis labels. For example, a value of 90 displays the\nx labels rotated 90 degrees clockwise."], ["ylabelsize int, default None", "If specified changes the y-axis label size."], ["yrot float, default None", "Rotation of y axis labels. For example, a value of 90 displays the\ny labels rotated 90 degrees clockwise."], ["ax Matplotlib axes object, default None", "The axes to plot the histogram on."], ["sharex bool, default True if ax is None else False", "In case subplots=True, share x axis and set some x axis labels to\ninvisible; defaults to True if ax is None otherwise False if an ax\nis passed in.\nNote that passing in both an ax and sharex=True will alter all x axis\nlabels for all subplots in a figure."], ["sharey bool, default False", "In case subplots=True, share y axis and set some y axis labels to\ninvisible."], ["figsize tuple, optional", "The size in inches of the figure to create. Uses the value in matplotlib.rcParams by default."], ["layout tuple, optional", "Tuple of (rows, columns) for the layout of the histograms."], ["bins int or sequence, default 10", "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["legend bool, default False", "Whether to show the legend."], ["**kwargs", "All other plotting keyword arguments to be passed to matplotlib.pyplot.hist() ."]], "Returns": [["matplotlib.AxesSubplot or numpy.ndarray of them", ""]], "Category": ["Groupby"], "index": 189}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.agg.html#pandas.core.groupby.SeriesGroupBy.agg"], "Title": ["SeriesGroupBy.agg"], "Feature": ["SeriesGroupBy.agg"], "Description": "Aggregate using one or more operations over the specified axis.\nSee alsoSeries.groupby.applyApply function func group-wise and combine the results together.Series.groupby.transformTransforms the Series on each group based on the given function.Series.aggregateAggregate using one or more operations over the specified axis.\nNotes\nWhen usingengine='numba', there will be no “fall back” behavior internally.\nThe group data and group index will be passed as numpy arrays to the JITed\nuser defined function, and no alternative execution attempts will be tried.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n"], "Parameters": [["func function, str, list, dict or None", "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] None, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs . The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column. Can also accept a Numba JIT function with engine='numba' specified. Only passing a single function is supported\nwith this engine. If the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use. Deprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\nof pandas. Pass a list of aggregations instead."], ["*args", "Positional arguments to pass to func."], ["engine str, default None", "'cython' : Runs the function through C-extensions from cython. 'numba' : Runs the function through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba"], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function"], ["**kwargs", "If func is None, **kwargs are used to define the output names and\naggregations via Named Aggregation. See func entry. Otherwise, keyword arguments to be passed into func."]], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 190}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.hist.html#pandas.core.groupby.SeriesGroupBy.hist"], "Title": ["SeriesGroupBy.hist"], "Feature": ["SeriesGroupBy.hist"], "Description": null, "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n>>> hist = ser.hist()\n"], "Parameters": [["by object, optional", "If passed, then used to form histograms for separate groups."], ["ax matplotlib axis object", "If not passed, uses gca()."], ["grid bool, default True", "Whether to show axis grid lines."], ["xlabelsize int, default None", "If specified changes the x-axis label size."], ["xrot float, default None", "Rotation of x axis labels."], ["ylabelsize int, default None", "If specified changes the y-axis label size."], ["yrot float, default None", "Rotation of y axis labels."], ["figsize tuple, default None", "Figure size in inches by default."], ["bins int or sequence, default 10", "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["legend bool, default False", "Whether to show the legend."], ["**kwargs", "To be passed to the actual plotting function."]], "Returns": [["matplotlib.AxesSubplot", "A histogram plot."]], "Category": ["Groupby"], "index": 191}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.plot.html#pandas.core.groupby.DataFrameGroupBy.plot"], "Title": ["DataFrameGroupBy.plot"], "Feature": ["DataFrameGroupBy.plot"], "Description": "Make plots of Series or DataFrame.\nUses the backend specified by the\noptionplotting.backend. By default, matplotlib is used.\nNotes\nSee matplotlib documentation online for more on this subjectIfkind= ‘bar’ or ‘barh’, you can specify relative alignments\nfor bar plot layout bypositionkeyword.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center)", "Examples": [">>> ser = pd.Series([1, 2, 3, 3])\n>>> plot = ser.plot(kind='hist', title=\"My plot\")\n"], "Parameters": [["data Series or DataFrame", "The object for which the method is called."], ["x label or position, default None", "Only used if data is a DataFrame."], ["y label, position or list of label, positions, default None", "Allows plotting of one column versus another. Only used if data is a\nDataFrame."], ["kind str", "The kind of plot to produce: ‘line’ : line plot (default) ‘bar’ : vertical bar plot ‘barh’ : horizontal bar plot ‘hist’ : histogram ‘box’ : boxplot ‘kde’ : Kernel Density Estimation plot ‘density’ : same as ‘kde’ ‘area’ : area plot ‘pie’ : pie plot ‘scatter’ : scatter plot (DataFrame only) ‘hexbin’ : hexbin plot (DataFrame only)"], ["ax matplotlib axes object, default None", "An axes of the current figure."], ["subplots bool or sequence of iterables, default False", "Whether to group columns into subplots: False : No subplots will be used True : Make separate subplots for each column. sequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column). Added in version 1.5.0."], ["sharex bool, default True if ax is None else False", "In case subplots=True , share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and sharex=True will alter all x axis labels for all axis in a figure."], ["sharey bool, default False", "In case subplots=True , share y axis and set some y axis labels to invisible."], ["layout tuple, optional", "(rows, columns) for the layout of subplots."], ["figsize a tuple (width, height) in inches", "Size of a figure object."], ["use_index bool, default True", "Use index as ticks for x axis."], ["title str or list", "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot."], ["grid bool, default None (matlab style default)", "Axis grid lines."], ["legend bool or {‘reverse’}", "Place legend on axis subplots."], ["style list or dict", "The matplotlib line style per column."], ["logx bool or ‘sym’, default False", "Use log scaling or symlog scaling on x axis."], ["logy bool or ‘sym’ default False", "Use log scaling or symlog scaling on y axis."], ["loglog bool or ‘sym’, default False", "Use log scaling or symlog scaling on both x and y axes."], ["xticks sequence", "Values to use for the xticks."], ["yticks sequence", "Values to use for the yticks."], ["xlim 2-tuple/list", "Set the x limits of the current axes."], ["ylim 2-tuple/list", "Set the y limits of the current axes."], ["xlabel label, optional", "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots. Changed in version 2.0.0: Now applicable to histograms."], ["ylabel label, optional", "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots. Changed in version 2.0.0: Now applicable to histograms."], ["rot float, default None", "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots)."], ["fontsize float, default None", "Font size for xticks and yticks."], ["colormap str or matplotlib colormap object, default None", "Colormap to select colors from. If string, load colormap with that\nname from matplotlib."], ["colorbar bool, optional", "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots)."], ["position float", "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center)."], ["table bool, Series or DataFrame, default False", "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable."], ["yerr DataFrame, Series, array-like, dict and str", "See Plotting with Error Bars for\ndetail."], ["xerr DataFrame, Series, array-like, dict and str", "Equivalent to yerr."], ["stacked bool, default False in line and bar plots, and True in area plot", "If True, create stacked plot."], ["secondary_y bool or sequence, default False", "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis."], ["mark_right bool, default True", "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend."], ["include_bool bool, default is False", "If True, boolean values can be plotted."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["**kwargs", "Options to pass to matplotlib plotting method."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray of them", "If the backend is not the default matplotlib one, the return value\nwill be the object returned by the backend."]], "Category": ["Groupby"], "index": 192}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.plot.html#pandas.core.groupby.SeriesGroupBy.plot"], "Title": ["SeriesGroupBy.plot"], "Feature": ["SeriesGroupBy.plot"], "Description": "Make plots of Series or DataFrame.\nUses the backend specified by the\noptionplotting.backend. By default, matplotlib is used.\nNotes\nSee matplotlib documentation online for more on this subjectIfkind= ‘bar’ or ‘barh’, you can specify relative alignments\nfor bar plot layout bypositionkeyword.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center)", "Examples": [">>> ser = pd.Series([1, 2, 3, 3])\n>>> plot = ser.plot(kind='hist', title=\"My plot\")\n"], "Parameters": [["data Series or DataFrame", "The object for which the method is called."], ["x label or position, default None", "Only used if data is a DataFrame."], ["y label, position or list of label, positions, default None", "Allows plotting of one column versus another. Only used if data is a\nDataFrame."], ["kind str", "The kind of plot to produce: ‘line’ : line plot (default) ‘bar’ : vertical bar plot ‘barh’ : horizontal bar plot ‘hist’ : histogram ‘box’ : boxplot ‘kde’ : Kernel Density Estimation plot ‘density’ : same as ‘kde’ ‘area’ : area plot ‘pie’ : pie plot ‘scatter’ : scatter plot (DataFrame only) ‘hexbin’ : hexbin plot (DataFrame only)"], ["ax matplotlib axes object, default None", "An axes of the current figure."], ["subplots bool or sequence of iterables, default False", "Whether to group columns into subplots: False : No subplots will be used True : Make separate subplots for each column. sequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column). Added in version 1.5.0."], ["sharex bool, default True if ax is None else False", "In case subplots=True , share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and sharex=True will alter all x axis labels for all axis in a figure."], ["sharey bool, default False", "In case subplots=True , share y axis and set some y axis labels to invisible."], ["layout tuple, optional", "(rows, columns) for the layout of subplots."], ["figsize a tuple (width, height) in inches", "Size of a figure object."], ["use_index bool, default True", "Use index as ticks for x axis."], ["title str or list", "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot."], ["grid bool, default None (matlab style default)", "Axis grid lines."], ["legend bool or {‘reverse’}", "Place legend on axis subplots."], ["style list or dict", "The matplotlib line style per column."], ["logx bool or ‘sym’, default False", "Use log scaling or symlog scaling on x axis."], ["logy bool or ‘sym’ default False", "Use log scaling or symlog scaling on y axis."], ["loglog bool or ‘sym’, default False", "Use log scaling or symlog scaling on both x and y axes."], ["xticks sequence", "Values to use for the xticks."], ["yticks sequence", "Values to use for the yticks."], ["xlim 2-tuple/list", "Set the x limits of the current axes."], ["ylim 2-tuple/list", "Set the y limits of the current axes."], ["xlabel label, optional", "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots. Changed in version 2.0.0: Now applicable to histograms."], ["ylabel label, optional", "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots. Changed in version 2.0.0: Now applicable to histograms."], ["rot float, default None", "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots)."], ["fontsize float, default None", "Font size for xticks and yticks."], ["colormap str or matplotlib colormap object, default None", "Colormap to select colors from. If string, load colormap with that\nname from matplotlib."], ["colorbar bool, optional", "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots)."], ["position float", "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center)."], ["table bool, Series or DataFrame, default False", "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable."], ["yerr DataFrame, Series, array-like, dict and str", "See Plotting with Error Bars for\ndetail."], ["xerr DataFrame, Series, array-like, dict and str", "Equivalent to yerr."], ["stacked bool, default False in line and bar plots, and True in area plot", "If True, create stacked plot."], ["secondary_y bool or sequence, default False", "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis."], ["mark_right bool, default True", "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend."], ["include_bool bool, default is False", "If True, boolean values can be plotted."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["**kwargs", "Options to pass to matplotlib plotting method."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray of them", "If the backend is not the default matplotlib one, the return value\nwill be the object returned by the backend."]], "Category": ["Groupby"], "index": 193}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg"], "Title": ["DataFrameGroupBy.agg"], "Feature": ["DataFrameGroupBy.agg"], "Description": "Aggregate using one or more operations over the specified axis.\nSee alsoDataFrame.groupby.applyApply function func group-wise and combine the results together.DataFrame.groupby.transformTransforms the Series on each group based on the given function.DataFrame.aggregateAggregate using one or more operations over the specified axis.\nNotes\nWhen usingengine='numba', there will be no “fall back” behavior internally.\nThe group data and group index will be passed as numpy arrays to the JITed\nuser defined function, and no alternative execution attempts will be tried.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.", "Examples": [">>> data = {\"A\": [1, 1, 2, 2],\n...         \"B\": [1, 2, 3, 4],\n...         \"C\": [0.362838, 0.227877, 1.267767, -0.562860]}\n>>> df = pd.DataFrame(data)\n>>> df\n   A  B         C\n0  1  1  0.362838\n1  1  2  0.227877\n2  2  3  1.267767\n3  2  4 -0.562860\n"], "Parameters": [["func function, str, list, dict or None", "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] dict of axis labels -> functions, function names or list of such. None, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs . The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column. Can also accept a Numba JIT function with engine='numba' specified. Only passing a single function is supported\nwith this engine. If the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use."], ["*args", "Positional arguments to pass to func."], ["engine str, default None", "'cython' : Runs the function through C-extensions from cython. 'numba' : Runs the function through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba"], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function"], ["**kwargs", "If func is None, **kwargs are used to define the output names and\naggregations via Named Aggregation. See func entry. Otherwise, keyword arguments to be passed into func."]], "Returns": [["DataFrame", ""]], "Category": ["Groupby"], "index": 194}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.aggregate.html#pandas.core.groupby.SeriesGroupBy.aggregate"], "Title": ["SeriesGroupBy.aggregate"], "Feature": ["SeriesGroupBy.aggregate"], "Description": "Aggregate using one or more operations over the specified axis.\nSee alsoSeries.groupby.applyApply function func group-wise and combine the results together.Series.groupby.transformTransforms the Series on each group based on the given function.Series.aggregateAggregate using one or more operations over the specified axis.\nNotes\nWhen usingengine='numba', there will be no “fall back” behavior internally.\nThe group data and group index will be passed as numpy arrays to the JITed\nuser defined function, and no alternative execution attempts will be tried.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n"], "Parameters": [["func function, str, list, dict or None", "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] None, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs . The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column. Can also accept a Numba JIT function with engine='numba' specified. Only passing a single function is supported\nwith this engine. If the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use. Deprecated since version 2.1.0: Passing a dictionary is deprecated and will raise in a future version\nof pandas. Pass a list of aggregations instead."], ["*args", "Positional arguments to pass to func."], ["engine str, default None", "'cython' : Runs the function through C-extensions from cython. 'numba' : Runs the function through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba"], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function"], ["**kwargs", "If func is None, **kwargs are used to define the output names and\naggregations via Named Aggregation. See func entry. Otherwise, keyword arguments to be passed into func."]], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 195}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html#pandas.core.groupby.DataFrameGroupBy.aggregate"], "Title": ["DataFrameGroupBy.aggregate"], "Feature": ["DataFrameGroupBy.aggregate"], "Description": "Aggregate using one or more operations over the specified axis.\nSee alsoDataFrame.groupby.applyApply function func group-wise and combine the results together.DataFrame.groupby.transformTransforms the Series on each group based on the given function.DataFrame.aggregateAggregate using one or more operations over the specified axis.\nNotes\nWhen usingengine='numba', there will be no “fall back” behavior internally.\nThe group data and group index will be passed as numpy arrays to the JITed\nuser defined function, and no alternative execution attempts will be tried.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.", "Examples": [">>> data = {\"A\": [1, 1, 2, 2],\n...         \"B\": [1, 2, 3, 4],\n...         \"C\": [0.362838, 0.227877, 1.267767, -0.562860]}\n>>> df = pd.DataFrame(data)\n>>> df\n   A  B         C\n0  1  1  0.362838\n1  1  2  0.227877\n2  2  3  1.267767\n3  2  4 -0.562860\n"], "Parameters": [["func function, str, list, dict or None", "Function to use for aggregating the data. If a function, must either\nwork when passed a DataFrame or when passed to DataFrame.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] dict of axis labels -> functions, function names or list of such. None, in which case **kwargs are used with Named Aggregation. Here the\noutput has one column for each element in **kwargs . The name of the\ncolumn is keyword, whereas the value determines the aggregation used to compute\nthe values in the column. Can also accept a Numba JIT function with engine='numba' specified. Only passing a single function is supported\nwith this engine. If the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use."], ["*args", "Positional arguments to pass to func."], ["engine str, default None", "'cython' : Runs the function through C-extensions from cython. 'numba' : Runs the function through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba"], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function"], ["**kwargs", "If func is None, **kwargs are used to define the output names and\naggregations via Named Aggregation. See func entry. Otherwise, keyword arguments to be passed into func."]], "Returns": [["DataFrame", ""]], "Category": ["Groupby"], "index": 196}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.transform.html#pandas.core.groupby.SeriesGroupBy.transform"], "Title": ["SeriesGroupBy.transform"], "Feature": ["SeriesGroupBy.transform"], "Description": "Call function producing a same-indexed Series on each group.\nReturns a Series having the same indexes as the original object\nfilled with the transformed values.\nSee alsoSeries.groupby.applyApply functionfuncgroup-wise and combine the results together.Series.groupby.aggregateAggregate using one or more operations over the specified axis.Series.transformCallfuncon self producing a Series with the same axis shape as self.\nNotes\nEach group is endowed the attribute ‘name’ in case you need to know\nwhich group you are working on.\nThe current implementation imposes three requirements on f:\nf must return a value that either has the same shape as the input\nsubframe or can be broadcast to the shape of the input subframe.\nFor example, iffreturns a scalar it will be broadcast to have the\nsame shape as the input subframe.if this is a DataFrame, f must support application column-by-column\nin the subframe. If f also supports application to the entire subframe,\nthen a fast path is used starting from the second chunk.f must not mutate groups. Mutation is not supported and may\nproduce unexpected results. SeeMutating with User Defined Function (UDF) methodsfor more details.\nWhen usingengine='numba', there will be no “fall back” behavior internally.\nThe group data and group index will be passed as numpy arrays to the JITed\nuser defined function, and no alternative execution attempts will be tried.\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.\nChanged in version 2.0.0:When using.transformon a grouped DataFrame and the transformation function\nreturns a DataFrame, pandas now aligns the result’s index\nwith the input’s index. You can call.to_numpy()on the\nresult of the transformation function to avoid alignment.", "Examples": [">>> ser = pd.Series([390.0, 350.0, 30.0, 20.0],\n...                 index=[\"Falcon\", \"Falcon\", \"Parrot\", \"Parrot\"],\n...                 name=\"Max Speed\")\n>>> grouped = ser.groupby([1, 1, 2, 2])\n>>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n    Falcon    0.707107\n    Falcon   -0.707107\n    Parrot    0.707107\n    Parrot   -0.707107\n    Name: Max Speed, dtype: float64\n"], "Parameters": [["f function, str", "Function to apply to each group. See the Notes section below for requirements. Accepted inputs are: String Python function Numba JIT function with engine='numba' specified. Only passing a single function is supported with this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use. If a string is chosen, then it needs to be the name\nof the groupby method you want to use."], ["*args", "Positional arguments to pass to func."], ["engine str, default None", "'cython' : Runs the function through C-extensions from cython. 'numba' : Runs the function through JIT compiled code from numba. None : Defaults to 'cython' or the global setting compute.use_numba"], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function"], ["**kwargs", "Keyword arguments to be passed into func."]], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 197}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html#pandas.core.groupby.DataFrameGroupBy.transform"], "Title": ["DataFrameGroupBy.transform"], "Feature": ["DataFrameGroupBy.transform"], "Description": "Call function producing a same-indexed DataFrame on each group.\nReturns a DataFrame having the same indexes as the original object\nfilled with the transformed values.\nSee alsoDataFrame.groupby.applyApply functionfuncgroup-wise and combine the results together.DataFrame.groupby.aggregateAggregate using one or more operations over the specified axis.DataFrame.transformCallfuncon self producing a DataFrame with the same axis shape as self.\nNotes\nEach group is endowed the attribute ‘name’ in case you need to know\nwhich group you are working on.\nThe current implementation imposes three requirements on f:\nf must return a value that either has the same shape as the input\nsubframe or can be broadcast to the shape of the input subframe.\nFor example, iffreturns a scalar it will be broadcast to have the\nsame shape as the input subframe.if this is a DataFrame, f must support application column-by-column\nin the subframe. If f also supports application to the entire subframe,\nthen a fast path is used starting from the second chunk.f must not mutate groups. Mutation is not supported and may\nproduce unexpected results. SeeMutating with User Defined Function (UDF) methodsfor more details.\nWhen usingengine='numba', there will be no “fall back” behavior internally.\nThe group data and group index will be passed as numpy arrays to the JITed\nuser defined function, and no alternative execution attempts will be tried.\nChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,\nsee the examples below.\nChanged in version 2.0.0:When using.transformon a grouped DataFrame and the transformation function\nreturns a DataFrame, pandas now aligns the result’s index\nwith the input’s index. You can call.to_numpy()on the\nresult of the transformation function to avoid alignment.", "Examples": [">>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n...                           'foo', 'bar'],\n...                    'B' : ['one', 'one', 'two', 'three',\n...                           'two', 'two'],\n...                    'C' : [1, 5, 5, 2, 5, 5],\n...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n>>> grouped = df.groupby('A')[['C', 'D']]\n>>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n        C         D\n0 -1.154701 -0.577350\n1  0.577350  0.000000\n2  0.577350  1.154701\n3 -1.154701 -1.000000\n4  0.577350 -0.577350\n5  0.577350  1.000000\n"], "Parameters": [["f function, str", "Function to apply to each group. See the Notes section below for requirements. Accepted inputs are: String Python function Numba JIT function with engine='numba' specified. Only passing a single function is supported with this engine.\nIf the 'numba' engine is chosen, the function must be\na user defined function with values and index as the\nfirst and second arguments respectively in the function signature.\nEach group’s index will be passed to the user defined function\nand optionally available for use. If a string is chosen, then it needs to be the name\nof the groupby method you want to use."], ["*args", "Positional arguments to pass to func."], ["engine str, default None", "'cython' : Runs the function through C-extensions from cython. 'numba' : Runs the function through JIT compiled code from numba. None : Defaults to 'cython' or the global setting compute.use_numba"], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to the function"], ["**kwargs", "Keyword arguments to be passed into func."]], "Returns": [["DataFrame", ""]], "Category": ["Groupby"], "index": 198}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.pipe.html#pandas.core.groupby.SeriesGroupBy.pipe"], "Title": ["SeriesGroupBy.pipe"], "Feature": ["SeriesGroupBy.pipe"], "Description": "Apply afuncwith arguments to this GroupBy object and return its result.\nUse.pipewhen you want to improve readability by chaining together\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\nInstead of writing\n>>>h=lambdax,arg2,arg3:x+1-arg2*arg3>>>g=lambdax,arg1:x*5/arg1>>>f=lambdax:x**4>>>df=pd.DataFrame([[\"a\",4],[\"b\",5]],columns=[\"group\",\"value\"])>>>h(g(f(df.groupby('group')),arg1=1),arg2=2,arg3=3)Copy to clipboard\nYou can write\n>>>(df.groupby('group')....pipe(f)....pipe(g,arg1=1)....pipe(h,arg2=2,arg3=3))Copy to clipboard\nwhich is much more readable.\nSee alsoSeries.pipeApply a function with arguments to a series.DataFrame.pipeApply a function with arguments to a dataframe.applyApply function to each group instead of to the full GroupBy object.\nNotes\nSee morehere", "Examples": [">>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n>>> df\n   A  B\n0  a  1\n1  b  2\n2  a  3\n3  b  4\n"], "Parameters": [["func callable or tuple of (callable, str)", "Function to apply to this GroupBy object or, alternatively,\na (callable, data_keyword) tuple where data_keyword is a\nstring indicating the keyword of callable that expects the\nGroupBy object."], ["args iterable, optional", "Positional arguments passed into func ."], ["kwargs dict, optional", "A dictionary of keyword arguments passed into func ."]], "Returns": [["the return type of func .", ""]], "Category": ["Groupby"], "index": 199}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pipe.html#pandas.core.groupby.DataFrameGroupBy.pipe"], "Title": ["DataFrameGroupBy.pipe"], "Feature": ["DataFrameGroupBy.pipe"], "Description": "Apply afuncwith arguments to this GroupBy object and return its result.\nUse.pipewhen you want to improve readability by chaining together\nfunctions that expect Series, DataFrames, GroupBy or Resampler objects.\nInstead of writing\n>>>h=lambdax,arg2,arg3:x+1-arg2*arg3>>>g=lambdax,arg1:x*5/arg1>>>f=lambdax:x**4>>>df=pd.DataFrame([[\"a\",4],[\"b\",5]],columns=[\"group\",\"value\"])>>>h(g(f(df.groupby('group')),arg1=1),arg2=2,arg3=3)Copy to clipboard\nYou can write\n>>>(df.groupby('group')....pipe(f)....pipe(g,arg1=1)....pipe(h,arg2=2,arg3=3))Copy to clipboard\nwhich is much more readable.\nSee alsoSeries.pipeApply a function with arguments to a series.DataFrame.pipeApply a function with arguments to a dataframe.applyApply function to each group instead of to the full GroupBy object.\nNotes\nSee morehere", "Examples": [">>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n>>> df\n   A  B\n0  a  1\n1  b  2\n2  a  3\n3  b  4\n"], "Parameters": [["func callable or tuple of (callable, str)", "Function to apply to this GroupBy object or, alternatively,\na (callable, data_keyword) tuple where data_keyword is a\nstring indicating the keyword of callable that expects the\nGroupBy object."], ["args iterable, optional", "Positional arguments passed into func ."], ["kwargs dict, optional", "A dictionary of keyword arguments passed into func ."]], "Returns": [["the return type of func .", ""]], "Category": ["Groupby"], "index": 200}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.groups.html#pandas.core.groupby.DataFrameGroupBy.groups"], "Title": ["DataFrameGroupBy.groups"], "Feature": ["DataFrameGroupBy.groups"], "Description": "Dict {group name -> group labels}.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\ndtype: int64\n>>> ser.groupby(level=0).groups\n{'a': ['a', 'a'], 'b': ['b']}\n"], "Parameters": [], "Returns": [], "Category": ["Groupby"], "index": 201}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html#pandas.core.groupby.DataFrameGroupBy.filter"], "Title": ["DataFrameGroupBy.filter"], "Feature": ["DataFrameGroupBy.filter"], "Description": "Filter elements from groups that don’t satisfy a criterion.\nElements from groups are filtered if they do not satisfy the\nboolean criterion specified by func.\nNotes\nEach subframe is endowed the attribute ‘name’ in case you need to know\nwhich group you are working on.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.", "Examples": [">>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n...                           'foo', 'bar'],\n...                    'B' : [1, 2, 3, 4, 5, 6],\n...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n>>> grouped = df.groupby('A')\n>>> grouped.filter(lambda x: x['B'].mean() > 3.)\n     A  B    C\n1  bar  2  5.0\n3  bar  4  1.0\n5  bar  6  9.0\n"], "Parameters": [["func function", "Criterion to apply to each group. Should return True or False."], ["dropna bool", "Drop groups that do not pass the filter. True by default; if False,\ngroups that evaluate False are filled with NaNs."]], "Returns": [["DataFrame", ""]], "Category": ["Groupby"], "index": 202}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.filter.html#pandas.core.groupby.SeriesGroupBy.filter"], "Title": ["SeriesGroupBy.filter"], "Feature": ["SeriesGroupBy.filter"], "Description": "Filter elements from groups that don’t satisfy a criterion.\nElements from groups are filtered if they do not satisfy the\nboolean criterion specified by func.\nNotes\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.", "Examples": [">>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n...                           'foo', 'bar'],\n...                    'B' : [1, 2, 3, 4, 5, 6],\n...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n>>> grouped = df.groupby('A')\n>>> df.groupby('A').B.filter(lambda x: x.mean() > 3.)\n1    2\n3    4\n5    6\nName: B, dtype: int64\n"], "Parameters": [["func function", "Criterion to apply to each group. Should return True or False."], ["dropna bool", "Drop groups that do not pass the filter. True by default; if False,\ngroups that evaluate False are filled with NaNs."]], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 203}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html#pandas.core.groupby.DataFrameGroupBy.all"], "Title": ["DataFrameGroupBy.all"], "Feature": ["DataFrameGroupBy.all"], "Description": "Return True if all values in the group are truthful, else False.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 0], index=lst)\n>>> ser\na    1\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).all()\na     True\nb    False\ndtype: bool\n"], "Parameters": [["skipna bool, default True", "Flag to ignore nan values during truth testing."]], "Returns": [["Series or DataFrame", "DataFrame or Series of boolean values, where a value is True if all elements\nare True within its respective group, False otherwise."]], "Category": ["Groupby"], "index": 204}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.any.html#pandas.core.groupby.DataFrameGroupBy.any"], "Title": ["DataFrameGroupBy.any"], "Feature": ["DataFrameGroupBy.any"], "Description": "Return True if any value in the group is truthful, else False.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 0], index=lst)\n>>> ser\na    1\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).any()\na     True\nb    False\ndtype: bool\n"], "Parameters": [["skipna bool, default True", "Flag to ignore nan values during truth testing."]], "Returns": [["Series or DataFrame", "DataFrame or Series of boolean values, where a value is True if any element\nis True within its respective group, False otherwise."]], "Category": ["Groupby"], "index": 205}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.bfill.html#pandas.core.groupby.DataFrameGroupBy.bfill"], "Title": ["DataFrameGroupBy.bfill"], "Feature": ["DataFrameGroupBy.bfill"], "Description": "Backward fill the values.\nSee alsoSeries.bfillBackward fill the missing values in the dataset.DataFrame.bfillBackward fill the missing values in the dataset.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.", "Examples": [">>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']\n>>> s = pd.Series([None, 1, None, None, 3], index=index)\n>>> s\nFalcon    NaN\nFalcon    1.0\nParrot    NaN\nParrot    NaN\nParrot    3.0\ndtype: float64\n>>> s.groupby(level=0).bfill()\nFalcon    1.0\nFalcon    1.0\nParrot    3.0\nParrot    3.0\nParrot    3.0\ndtype: float64\n>>> s.groupby(level=0).bfill(limit=1)\nFalcon    1.0\nFalcon    1.0\nParrot    NaN\nParrot    3.0\nParrot    3.0\ndtype: float64\n"], "Parameters": [["limit int, optional", "Limit of how many values to fill."]], "Returns": [["Series or DataFrame", "Object with missing values filled."]], "Category": ["Groupby"], "index": 206}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corr.html#pandas.core.groupby.DataFrameGroupBy.corr"], "Title": ["DataFrameGroupBy.corr"], "Feature": ["DataFrameGroupBy.corr"], "Description": "Compute pairwise correlation of columns, excluding NA/null values.\nSee alsoDataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.Series.corrCompute the correlation between two Series.\nNotes\nPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\nPearson correlation coefficientKendall rank correlation coefficientSpearman’s rank correlation coefficient", "Examples": [">>> def histogram_intersection(a, b):\n...     v = np.minimum(a, b).sum().round(decimals=1)\n...     return v\n>>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n...                   columns=['dogs', 'cats'])\n>>> df.corr(method=histogram_intersection)\n      dogs  cats\ndogs   1.0   0.3\ncats   0.3   1.0\n"], "Parameters": [["method {‘pearson’, ‘kendall’, ‘spearman’} or callable", "Method of correlation: pearson : standard correlation coefficient kendall : Kendall Tau correlation coefficient spearman : Spearman rank correlation callable: callable with input two 1d ndarrays and returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable’s behavior."], ["callable: callable with input two 1d ndarrays", "and returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable’s behavior."], ["min_periods int, optional", "Minimum number of observations required per pair of columns\nto have a valid result. Currently only available for Pearson\nand Spearman correlation."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: The default value of numeric_only is now False ."]], "Returns": [["DataFrame", "Correlation matrix."]], "Category": ["Groupby"], "index": 207}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.corrwith.html#pandas.core.groupby.DataFrameGroupBy.corrwith"], "Title": ["DataFrameGroupBy.corrwith"], "Feature": ["DataFrameGroupBy.corrwith"], "Description": "Compute pairwise correlation.\nPairwise correlation is computed between rows or columns of\nDataFrame with rows or columns of Series or DataFrame. DataFrames\nare first aligned along both axes before computing the\ncorrelations.\nSee alsoDataFrame.corrCompute pairwise correlation of columns.", "Examples": [">>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n>>> columns = [\"one\", \"two\", \"three\", \"four\"]\n>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n>>> df1.corrwith(df2)\none      1.0\ntwo      1.0\nthree    1.0\nfour     1.0\ndtype: float64\n"], "Parameters": [["other DataFrame, Series", "Object with which to compute correlations."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for\ncolumn-wise."], ["drop bool, default False", "Drop missing indices from result."], ["method {‘pearson’, ‘kendall’, ‘spearman’} or callable", "Method of correlation: pearson : standard correlation coefficient kendall : Kendall Tau correlation coefficient spearman : Spearman rank correlation callable: callable with input two 1d ndarrays and returning a float."], ["callable: callable with input two 1d ndarrays", "and returning a float."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: The default value of numeric_only is now False ."]], "Returns": [["Series", "Pairwise correlations."]], "Category": ["Groupby"], "index": 208}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html#pandas.core.groupby.DataFrameGroupBy.count"], "Title": ["DataFrameGroupBy.count"], "Feature": ["DataFrameGroupBy.count"], "Description": "Compute count of group, excluding missing values.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, np.nan], index=lst)\n>>> ser\na    1.0\na    2.0\nb    NaN\ndtype: float64\n>>> ser.groupby(level=0).count()\na    2\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", "Count of values within each group."]], "Category": ["Groupby"], "index": 209}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cov.html#pandas.core.groupby.DataFrameGroupBy.cov"], "Title": ["DataFrameGroupBy.cov"], "Feature": ["DataFrameGroupBy.cov"], "Description": "Compute pairwise covariance of columns, excluding NA/null values.\nCompute the pairwise covariance among the series of a DataFrame.\nThe returned data frame is thecovariance matrixof the columns\nof the DataFrame.\nBoth NA and null values are automatically excluded from the\ncalculation. (See the note below about bias from missing values.)\nA threshold can be set for the minimum number of\nobservations for each value created. Comparisons with observations\nbelow this threshold will be returned asNaN.\nThis method is generally used for the analysis of time series data to\nunderstand the relationship between different measures\nacross time.\nSee alsoSeries.covCompute covariance with another Series.core.window.ewm.ExponentialMovingWindow.covExponential weighted sample covariance.core.window.expanding.Expanding.covExpanding sample covariance.core.window.rolling.Rolling.covRolling sample covariance.\nNotes\nReturns the covariance matrix of the DataFrame’s time series.\nThe covariance is normalized by N-ddof.\nFor DataFrames that have Series that are missing data (assuming that\ndata ismissing at random)\nthe returned covariance matrix will be an unbiased estimate\nof the variance and covariance between the member Series.\nHowever, for many applications this estimate may not be acceptable\nbecause the estimate covariance matrix is not guaranteed to be positive\nsemi-definite. This could lead to estimate correlations having\nabsolute values which are greater than one, and/or a non-invertible\ncovariance matrix. SeeEstimation of covariance matricesfor more details.", "Examples": [">>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n...                   columns=['dogs', 'cats'])\n>>> df.cov()\n          dogs      cats\ndogs  0.666667 -1.000000\ncats -1.000000  1.666667\n"], "Parameters": [["min_periods int, optional", "Minimum number of observations required per pair of columns\nto have a valid result."], ["ddof int, default 1", "Delta degrees of freedom.  The divisor used in calculations\nis N - ddof , where N represents the number of elements.\nThis argument is applicable only when no nan is in the dataframe."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: The default value of numeric_only is now False ."]], "Returns": [["DataFrame", "The covariance matrix of the series of the DataFrame."]], "Category": ["Groupby"], "index": 210}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumcount.html#pandas.core.groupby.DataFrameGroupBy.cumcount"], "Title": ["DataFrameGroupBy.cumcount"], "Feature": ["DataFrameGroupBy.cumcount"], "Description": "Number each item in each group from 0 to the length of that group - 1.\nEssentially this is equivalent to\nself.apply(lambdax:pd.Series(np.arange(len(x)),x.index))Copy to clipboard\nSee alsongroupNumber the groups themselves.", "Examples": [">>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n...                   columns=['A'])\n>>> df\n   A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n>>> df.groupby('A').cumcount()\n0    0\n1    1\n2    2\n3    0\n4    1\n5    3\ndtype: int64\n>>> df.groupby('A').cumcount(ascending=False)\n0    3\n1    2\n2    1\n3    1\n4    0\n5    0\ndtype: int64\n"], "Parameters": [["ascending bool, default True", "If False, number in reverse, from length of group - 1 to 0."]], "Returns": [["Series", "Sequence number of each element within each group."]], "Category": ["Groupby"], "index": 211}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.groups.html#pandas.core.groupby.SeriesGroupBy.groups"], "Title": ["SeriesGroupBy.groups"], "Feature": ["SeriesGroupBy.groups"], "Description": "Dict {group name -> group labels}.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\ndtype: int64\n>>> ser.groupby(level=0).groups\n{'a': ['a', 'a'], 'b': ['b']}\n"], "Parameters": [], "Returns": [], "Category": ["Groupby"], "index": 212}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummax.html#pandas.core.groupby.DataFrameGroupBy.cummax"], "Title": ["DataFrameGroupBy.cummax"], "Feature": ["DataFrameGroupBy.cummax"], "Description": "Cumulative max for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([1, 6, 2, 3, 1, 4], index=lst)\n>>> ser\na    1\na    6\na    2\nb    3\nb    1\nb    4\ndtype: int64\n>>> ser.groupby(level=0).cummax()\na    1\na    6\na    6\nb    3\nb    3\nb    4\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 213}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cummin.html#pandas.core.groupby.DataFrameGroupBy.cummin"], "Title": ["DataFrameGroupBy.cummin"], "Feature": ["DataFrameGroupBy.cummin"], "Description": "Cumulative min for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([1, 6, 2, 3, 0, 4], index=lst)\n>>> ser\na    1\na    6\na    2\nb    3\nb    0\nb    4\ndtype: int64\n>>> ser.groupby(level=0).cummin()\na    1\na    1\na    1\nb    3\nb    0\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 214}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumprod.html#pandas.core.groupby.DataFrameGroupBy.cumprod"], "Title": ["DataFrameGroupBy.cumprod"], "Feature": ["DataFrameGroupBy.cumprod"], "Description": "Cumulative product for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([6, 2, 0], index=lst)\n>>> ser\na    6\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).cumprod()\na    6\na   12\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 215}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.cumsum.html#pandas.core.groupby.DataFrameGroupBy.cumsum"], "Title": ["DataFrameGroupBy.cumsum"], "Feature": ["DataFrameGroupBy.cumsum"], "Description": "Cumulative sum for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([6, 2, 0], index=lst)\n>>> ser\na    6\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).cumsum()\na    6\na    8\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 216}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html#pandas.core.groupby.DataFrameGroupBy.describe"], "Title": ["DataFrameGroupBy.describe"], "Feature": ["DataFrameGroupBy.describe"], "Description": "Generate descriptive statistics.\nDescriptive statistics include those that summarize the central\ntendency, dispersion and shape of a\ndataset’s distribution, excludingNaNvalues.\nAnalyzes both numeric and object series, as well\nasDataFramecolumn sets of mixed data types. The output\nwill vary depending on what is provided. Refer to the notes\nbelow for more detail.\nSee alsoDataFrame.countCount number of non-NA/null observations.DataFrame.maxMaximum of the values in the object.DataFrame.minMinimum of the values in the object.DataFrame.meanMean of the values.DataFrame.stdStandard deviation of the observations.DataFrame.select_dtypesSubset of a DataFrame including/excluding columns based on their dtype.\nNotes\nFor numeric data, the result’s index will includecount,mean,std,min,maxas well as lower,50and\nupper percentiles. By default the lower percentile is25and the\nupper percentile is75. The50percentile is the\nsame as the median.\nFor object data (e.g. strings or timestamps), the result’s index\nwill includecount,unique,top, andfreq. Thetopis the most common value. Thefreqis the most common value’s\nfrequency. Timestamps also include thefirstandlastitems.\nIf multiple object values have the highest count, then thecountandtopresults will be arbitrarily chosen from\namong those with the highest count.\nFor mixed data types provided via aDataFrame, the default is to\nreturn only an analysis of numeric columns. If the dataframe consists\nonly of object and categorical data without any numeric columns, the\ndefault is to return an analysis of both the object and categorical\ncolumns. Ifinclude='all'is provided as an option, the result\nwill include a union of attributes of each type.\nTheincludeandexcludeparameters can be used to limit\nwhich columns in aDataFrameare analyzed for the output.\nThe parameters are ignored when analyzing aSeries.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.describe()\ncount    3.0\nmean     2.0\nstd      1.0\nmin      1.0\n25%      1.5\n50%      2.0\n75%      2.5\nmax      3.0\ndtype: float64\n"], "Parameters": [["percentiles list-like of numbers, optional", "The percentiles to include in the output. All should\nfall between 0 and 1. The default is [.25, .5, .75] , which returns the 25th, 50th, and\n75th percentiles."], ["include ‘all’, list-like of dtypes or None (default), optional", "A white list of data types to include in the result. Ignored\nfor Series . Here are the options: ‘all’ : All columns of the input will be included in the output. A list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit numpy.number . To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of select_dtypes (e.g. df.describe(include=['O']) ). To\nselect pandas categorical columns, use 'category' None (default) : The result will include all numeric columns."], ["exclude list-like of dtypes or None (default), optional,", "A black list of data types to omit from the result. Ignored\nfor Series . Here are the options: A list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit numpy.number . To exclude object columns submit the data\ntype numpy.object . Strings can also be used in the style of select_dtypes (e.g. df.describe(exclude=['O']) ). To\nexclude pandas categorical columns, use 'category' None (default) : The result will exclude nothing."]], "Returns": [["Series or DataFrame", "Summary statistics of the Series or Dataframe provided."]], "Category": ["Groupby"], "index": 217}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html#pandas.core.groupby.DataFrameGroupBy.diff"], "Title": ["DataFrameGroupBy.diff"], "Feature": ["DataFrameGroupBy.diff"], "Description": "First discrete difference of element.\nCalculates the difference of each element compared with another\nelement in the group (default is element in previous row).\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).diff()\na    NaN\na   -5.0\na    6.0\nb    NaN\nb   -1.0\nb    0.0\ndtype: float64\n"], "Parameters": [["periods int, default 1", "Periods to shift for calculating difference, accepts negative values."], ["axis axis to shift, default 0", "Take difference over rows (0) or columns (1). Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."]], "Returns": [["Series or DataFrame", "First differences."]], "Category": ["Groupby"], "index": 218}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ffill.html#pandas.core.groupby.DataFrameGroupBy.ffill"], "Title": ["DataFrameGroupBy.ffill"], "Feature": ["DataFrameGroupBy.ffill"], "Description": "Forward fill the values.\nSee alsoSeries.ffillReturns Series with minimum number of char in object.DataFrame.ffillObject with missing values filled or None if inplace=True.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.", "Examples": [">>> key = [0, 0, 1, 1]\n>>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)\n>>> ser\n0    NaN\n0    2.0\n1    3.0\n1    NaN\ndtype: float64\n>>> ser.groupby(level=0).ffill()\n0    NaN\n0    2.0\n1    3.0\n1    3.0\ndtype: float64\n"], "Parameters": [["limit int, optional", "Limit of how many values to fill."]], "Returns": [["Series or DataFrame", "Object with missing values filled."]], "Category": ["Groupby"], "index": 219}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.fillna.html#pandas.core.groupby.DataFrameGroupBy.fillna"], "Title": ["DataFrameGroupBy.fillna"], "Feature": ["DataFrameGroupBy.fillna"], "Description": "Fill NA/NaN values using the specified method within groups.\nDeprecated since version 2.2.0:This method is deprecated and will be removed in a future version.\nUse theDataFrameGroupBy.ffill()orDataFrameGroupBy.bfill()for forward or backward filling instead. If you want to fill with a\nsingle value, useDataFrame.fillna()instead.\nSee alsoffillForward fill values within a group.bfillBackward fill values within a group.", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"key\": [0, 0, 1, 1, 1],\n...         \"A\": [np.nan, 2, np.nan, 3, np.nan],\n...         \"B\": [2, 3, np.nan, np.nan, np.nan],\n...         \"C\": [np.nan, np.nan, 2, np.nan, np.nan],\n...     }\n... )\n>>> df\n   key    A    B   C\n0    0  NaN  2.0 NaN\n1    0  2.0  3.0 NaN\n2    1  NaN  NaN 2.0\n3    1  3.0  NaN NaN\n4    1  NaN  NaN NaN\n"], "Parameters": [["value scalar, dict, Series, or DataFrame", "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame).  Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list. Users wanting to use the value argument and not method should prefer DataFrame.fillna() as this\nwill produce the same result and be more performant."], ["method {{‘bfill’, ‘ffill’, None}}, default None", "Method to use for filling holes. 'ffill' will propagate\nthe last valid observation forward within a group. 'bfill' will use next valid observation to fill the gap."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Axis along which to fill missing values. When the DataFrameGroupBy axis argument is 0 , using axis=1 here will produce\nthe same results as DataFrame.fillna() . When the DataFrameGroupBy axis argument is 1 , using axis=0 or axis=1 here will produce the same results."], ["inplace bool, default False", "Broken. Do not set to True."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill within a group. In other words,\nif there is a gap with more than this number of consecutive NaNs,\nit will only be partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible)."]], "Returns": [["DataFrame", "Object with missing values filled."]], "Category": ["Groupby"], "index": 220}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html#pandas.core.groupby.DataFrameGroupBy.first"], "Title": ["DataFrameGroupBy.first"], "Feature": ["DataFrameGroupBy.first"], "Description": "Compute the first entry of each column within each group.\nDefaults to skipping NA elements.\nSee alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.lastCompute the last non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.", "Examples": [">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],\n...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))\n>>> df['D'] = pd.to_datetime(df['D'])\n>>> df.groupby(\"A\").first()\n     B  C          D\nA\n1  5.0  1 2000-03-11\n3  6.0  3 2000-03-13\n>>> df.groupby(\"A\").first(min_count=2)\n    B    C          D\nA\n1 NaN  1.0 2000-03-11\n3 NaN  NaN        NaT\n>>> df.groupby(\"A\").first(numeric_only=True)\n     B  C\nA\n1  5.0  1\n3  6.0  3\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA. Added in version 2.2.1."]], "Returns": [["Series or DataFrame", "First values within each group."]], "Category": ["Groupby"], "index": 221}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.head.html#pandas.core.groupby.DataFrameGroupBy.head"], "Title": ["DataFrameGroupBy.head"], "Feature": ["DataFrameGroupBy.head"], "Description": "Return first n rows of each group.\nSimilar to.apply(lambdax:x.head(n)), but it returns a subset of rows\nfrom the original DataFrame with original index and order preserved\n(as_indexflag is ignored).\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n...                   columns=['A', 'B'])\n>>> df.groupby('A').head(1)\n   A  B\n0  1  2\n2  5  6\n>>> df.groupby('A').head(-1)\n   A  B\n0  1  2\n"], "Parameters": [["n int", "If positive: number of entries to include from start of each group.\nIf negative: number of entries to exclude from end of each group."]], "Returns": [["Series or DataFrame", "Subset of original Series or DataFrame as determined by n."]], "Category": ["Groupby"], "index": 222}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.indices.html#pandas.core.groupby.DataFrameGroupBy.indices"], "Title": ["DataFrameGroupBy.indices"], "Feature": ["DataFrameGroupBy.indices"], "Description": "Dict {group name -> group indices}.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\ndtype: int64\n>>> ser.groupby(level=0).indices\n{'a': array([0, 1]), 'b': array([2])}\n"], "Parameters": [], "Returns": [], "Category": ["Groupby"], "index": 223}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmax.html#pandas.core.groupby.DataFrameGroupBy.idxmax"], "Title": ["DataFrameGroupBy.idxmax"], "Feature": ["DataFrameGroupBy.idxmax"], "Description": "Return index of first occurrence of maximum over requested axis.\nNA/null values are excluded.\nSee alsoSeries.idxmaxReturn index of the maximum element.\nNotes\nThis method is the DataFrame version ofndarray.argmax.", "Examples": [">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n...                    'co2_emissions': [37.2, 19.66, 1712]},\n...                   index=['Pork', 'Wheat Products', 'Beef'])\n"], "Parameters": [["axis {{0 or ‘index’, 1 or ‘columns’}}, default None", "The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.\nIf axis is not provided, grouper’s axis is used. Changed in version 2.0.0. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0."]], "Returns": [["Series", "Indexes of maxima along the specified axis."]], "Category": ["Groupby"], "index": 224}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.idxmin.html#pandas.core.groupby.DataFrameGroupBy.idxmin"], "Title": ["DataFrameGroupBy.idxmin"], "Feature": ["DataFrameGroupBy.idxmin"], "Description": "Return index of first occurrence of minimum over requested axis.\nNA/null values are excluded.\nSee alsoSeries.idxminReturn index of the minimum element.\nNotes\nThis method is the DataFrame version ofndarray.argmin.", "Examples": [">>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n...                    'co2_emissions': [37.2, 19.66, 1712]},\n...                   index=['Pork', 'Wheat Products', 'Beef'])\n"], "Parameters": [["axis {{0 or ‘index’, 1 or ‘columns’}}, default None", "The axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.\nIf axis is not provided, grouper’s axis is used. Changed in version 2.0.0. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0."]], "Returns": [["Series", "Indexes of minima along the specified axis."]], "Category": ["Groupby"], "index": 225}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html#pandas.core.groupby.DataFrameGroupBy.last"], "Title": ["DataFrameGroupBy.last"], "Feature": ["DataFrameGroupBy.last"], "Description": "Compute the last entry of each column within each group.\nDefaults to skipping NA elements.\nSee alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.firstCompute the first non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.", "Examples": [">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))\n>>> df.groupby(\"A\").last()\n     B  C\nA\n1  5.0  2\n3  6.0  3\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. If None, will attempt to use\neverything, then use only numeric data."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA. Added in version 2.2.1."]], "Returns": [["Series or DataFrame", "Last of values within each group."]], "Category": ["Groupby"], "index": 226}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html#pandas.core.groupby.DataFrameGroupBy.max"], "Title": ["DataFrameGroupBy.max"], "Feature": ["DataFrameGroupBy.max"], "Description": "Compute max of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).max()\na    2\nb    4\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."], ["engine str, default None None", "'cython' : Runs rolling apply through C-extensions from cython. 'numba' Runs rolling apply through JIT compiled code from numba. Only available when raw is set to True . None : Defaults to 'cython' or globally setting compute.use_numba"], ["'numba' Runs rolling apply through JIT compiled code from numba.", "Only available when raw is set to True ."], ["engine_kwargs dict, default None None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."], ["For 'numba' engine, the engine can accept nopython , nogil", "and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."]], "Returns": [["Series or DataFrame", "Computed max of values within each group."]], "Category": ["Groupby"], "index": 227}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html#pandas.core.groupby.DataFrameGroupBy.mean"], "Title": ["DataFrameGroupBy.mean"], "Feature": ["DataFrameGroupBy.mean"], "Description": "Compute mean of groups, excluding missing values.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n...                    'B': [np.nan, 2, 3, 4, 5],\n...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None and defaults to False ."], ["engine str, default None", "'cython' : Runs the operation through C-extensions from cython. 'numba' : Runs the operation through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba Added in version 1.4.0."], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {{'nopython': True, 'nogil': False, 'parallel': False}} Added in version 1.4.0."]], "Returns": [["pandas.Series or pandas.DataFrame", ""]], "Category": ["Groupby"], "index": 228}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.median.html#pandas.core.groupby.DataFrameGroupBy.median"], "Title": ["DataFrameGroupBy.median"], "Feature": ["DataFrameGroupBy.median"], "Description": "Compute median of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).median()\na    7.0\nb    3.0\ndtype: float64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None and defaults to False."]], "Returns": [["Series or DataFrame", "Median of values within each group."]], "Category": ["Groupby"], "index": 229}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html#pandas.core.groupby.DataFrameGroupBy.min"], "Title": ["DataFrameGroupBy.min"], "Feature": ["DataFrameGroupBy.min"], "Description": "Compute min of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).min()\na    1\nb    3\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."], ["engine str, default None None", "'cython' : Runs rolling apply through C-extensions from cython. 'numba' Runs rolling apply through JIT compiled code from numba. Only available when raw is set to True . None : Defaults to 'cython' or globally setting compute.use_numba"], ["'numba' Runs rolling apply through JIT compiled code from numba.", "Only available when raw is set to True ."], ["engine_kwargs dict, default None None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."], ["For 'numba' engine, the engine can accept nopython , nogil", "and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."]], "Returns": [["Series or DataFrame", "Computed min of values within each group."]], "Category": ["Groupby"], "index": 230}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ngroup.html#pandas.core.groupby.DataFrameGroupBy.ngroup"], "Title": ["DataFrameGroupBy.ngroup"], "Feature": ["DataFrameGroupBy.ngroup"], "Description": "Number each group from 0 to the number of groups - 1.\nThis is the enumerative complement of cumcount.  Note that the\nnumbers given to the groups match the order in which the groups\nwould be seen when iterating over the groupby object, not the\norder they are first observed.\nGroups with missing keys (wherepd.isna()is True) will be labeled withNaNand will be skipped from the count.\nSee alsocumcountNumber the rows in each group.", "Examples": [">>> df = pd.DataFrame({\"color\": [\"red\", None, \"red\", \"blue\", \"blue\", \"red\"]})\n>>> df\n   color\n0    red\n1   None\n2    red\n3   blue\n4   blue\n5    red\n>>> df.groupby(\"color\").ngroup()\n0    1.0\n1    NaN\n2    1.0\n3    0.0\n4    0.0\n5    1.0\ndtype: float64\n>>> df.groupby(\"color\", dropna=False).ngroup()\n0    1\n1    2\n2    1\n3    0\n4    0\n5    1\ndtype: int64\n>>> df.groupby(\"color\", dropna=False).ngroup(ascending=False)\n0    1\n1    0\n2    1\n3    2\n4    2\n5    1\ndtype: int64\n"], "Parameters": [["ascending bool, default True", "If False, number in reverse, from number of group - 1 to 0."]], "Returns": [["Series", "Unique numbers for each group."]], "Category": ["Groupby"], "index": 231}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nth.html#pandas.core.groupby.DataFrameGroupBy.nth"], "Title": ["DataFrameGroupBy.nth"], "Feature": ["DataFrameGroupBy.nth"], "Description": "Take the nth row from each group if n is an int, otherwise a subset of rows.\nCan be either a call or an index. dropna is not available with index notation.\nIndex notation accepts a comma separated list of integers and slices.\nIf dropna, will take the nth non-null row, dropna is either\n‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)\nbefore the groupby.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n>>> g = df.groupby('A')\n>>> g.nth(0)\n   A   B\n0  1 NaN\n2  2 3.0\n>>> g.nth(1)\n   A   B\n1  1 2.0\n4  2 5.0\n>>> g.nth(-1)\n   A   B\n3  1 4.0\n4  2 5.0\n>>> g.nth([0, 1])\n   A   B\n0  1 NaN\n1  1 2.0\n2  2 3.0\n4  2 5.0\n>>> g.nth(slice(None, -1))\n   A   B\n0  1 NaN\n1  1 2.0\n2  2 3.0\n"], "Parameters": [["n int, slice or list of ints and slices", "A single nth value for the row or a list of nth values or slices. Changed in version 1.4.0: Added slice and lists containing slices.\nAdded index notation."], ["dropna {‘any’, ‘all’, None}, default None", "Apply the specified dropna operation before counting which row is\nthe nth row. Only supported if n is an int."]], "Returns": [["Series or DataFrame", "N-th value within each group."]], "Category": ["Groupby"], "index": 232}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html#pandas.core.groupby.DataFrameGroupBy.nunique"], "Title": ["DataFrameGroupBy.nunique"], "Feature": ["DataFrameGroupBy.nunique"], "Description": "Return DataFrame with counts of unique elements in each position.", "Examples": [">>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n...                           'ham', 'ham'],\n...                    'value1': [1, 5, 5, 2, 5, 5],\n...                    'value2': list('abbaxy')})\n>>> df\n     id  value1 value2\n0  spam       1      a\n1   egg       5      b\n2   egg       5      b\n3  spam       2      a\n4   ham       5      x\n5   ham       5      y\n"], "Parameters": [["dropna bool, default True", "Don’t include NaN in the counts."]], "Returns": [["nunique: DataFrame", ""]], "Category": ["Groupby"], "index": 233}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.indices.html#pandas.core.groupby.SeriesGroupBy.indices"], "Title": ["SeriesGroupBy.indices"], "Feature": ["SeriesGroupBy.indices"], "Description": "Dict {group name -> group indices}.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\ndtype: int64\n>>> ser.groupby(level=0).indices\n{'a': array([0, 1]), 'b': array([2])}\n"], "Parameters": [], "Returns": [], "Category": ["Groupby"], "index": 234}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.ohlc.html#pandas.core.groupby.DataFrameGroupBy.ohlc"], "Title": ["DataFrameGroupBy.ohlc"], "Feature": ["DataFrameGroupBy.ohlc"], "Description": "Compute open, high, low and close values of a group, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex", "Examples": [">>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]\n>>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)\n>>> ser\nSPX     3.4\nCAC     9.0\nSPX     7.2\nCAC     5.2\nSPX     8.8\nCAC     9.4\nSPX     0.1\nCAC     0.5\ndtype: float64\n>>> ser.groupby(level=0).ohlc()\n     open  high  low  close\nCAC   9.0   9.4  0.5    0.5\nSPX   3.4   8.8  0.1    0.1\n"], "Parameters": [], "Returns": [["DataFrame", "Open, high, low and close values within each group."]], "Category": ["Groupby"], "index": 235}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.pct_change.html#pandas.core.groupby.DataFrameGroupBy.pct_change"], "Title": ["DataFrameGroupBy.pct_change"], "Feature": ["DataFrameGroupBy.pct_change"], "Description": "Calculate pct_change of each value to previous entry in group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).pct_change()\na         NaN\na    1.000000\nb         NaN\nb    0.333333\ndtype: float64\n"], "Parameters": [], "Returns": [["Series or DataFrame", "Percentage changes within each group."]], "Category": ["Groupby"], "index": 236}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.prod.html#pandas.core.groupby.DataFrameGroupBy.prod"], "Title": ["DataFrameGroupBy.prod"], "Feature": ["DataFrameGroupBy.prod"], "Description": "Compute prod of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).prod()\na    2\nb   12\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."]], "Returns": [["Series or DataFrame", "Computed prod of values within each group."]], "Category": ["Groupby"], "index": 237}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.quantile.html#pandas.core.groupby.DataFrameGroupBy.quantile"], "Title": ["DataFrameGroupBy.quantile"], "Feature": ["DataFrameGroupBy.quantile"], "Description": "Return group values at the given quantile, a la numpy.percentile.\nSee alsoSeries.quantileSimilar method for Series.DataFrame.quantileSimilar method for DataFrame.numpy.percentileNumPy method to compute qth percentile.", "Examples": [">>> df = pd.DataFrame([\n...     ['a', 1], ['a', 2], ['a', 3],\n...     ['b', 1], ['b', 3], ['b', 5]\n... ], columns=['key', 'val'])\n>>> df.groupby('key').quantile()\n    val\nkey\na    2.0\nb    3.0\n"], "Parameters": [["q float or array-like, default 0.5 (50% quantile)", "Value(s) between 0 and 1 providing the quantile(s) to compute."], ["interpolation {‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "Method to use when the desired quantile falls between two points."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Return type determined by caller of GroupBy object."]], "Category": ["Groupby"], "index": 238}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank"], "Title": ["DataFrameGroupBy.rank"], "Feature": ["DataFrameGroupBy.rank"], "Description": "Provide the rank of values within each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"group\": [\"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"b\"],\n...         \"value\": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],\n...     }\n... )\n>>> df\n  group  value\n0     a      2\n1     a      4\n2     a      2\n3     a      3\n4     a      5\n5     b      1\n6     b      2\n7     b      4\n8     b      1\n9     b      5\n>>> for method in ['average', 'min', 'max', 'dense', 'first']:\n...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)\n>>> df\n  group  value  average_rank  min_rank  max_rank  dense_rank  first_rank\n0     a      2           1.5       1.0       2.0         1.0         1.0\n1     a      4           4.0       4.0       4.0         3.0         4.0\n2     a      2           1.5       1.0       2.0         1.0         2.0\n3     a      3           3.0       3.0       3.0         2.0         3.0\n4     a      5           5.0       5.0       5.0         4.0         5.0\n5     b      1           1.5       1.0       2.0         1.0         1.0\n6     b      2           3.0       3.0       3.0         2.0         3.0\n7     b      4           4.0       4.0       4.0         3.0         4.0\n8     b      1           1.5       1.0       2.0         1.0         2.0\n9     b      5           5.0       5.0       5.0         4.0         5.0\n"], "Parameters": [["method {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "average: average rank of group. min: lowest rank in group. max: highest rank in group. first: ranks assigned in order they appear in the array. dense: like ‘min’, but rank always increases by 1 between groups."], ["ascending bool, default True", "False for ranks by high (1) to low (N)."], ["na_option {‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "keep: leave NA values where they are. top: smallest rank if ascending. bottom: smallest rank if descending."], ["pct bool, default False", "Compute percentage rank of data within each group."], ["axis int, default 0", "The axis of the object over which to compute the rank. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."]], "Returns": [["DataFrame with ranking of values within each group", ""]], "Category": ["Groupby"], "index": 239}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.resample.html#pandas.core.groupby.DataFrameGroupBy.resample"], "Title": ["DataFrameGroupBy.resample"], "Feature": ["DataFrameGroupBy.resample"], "Description": "Provide resampling when using a TimeGrouper.\nGiven a grouper, the function resamples it according to a string\n“string” -> “frequency”.\nSee thefrequency aliasesdocumentation for more details.\nSee alsoGrouperSpecify a frequency to resample with when grouping by a key.DatetimeIndex.resampleFrequency conversion and resampling of time series.", "Examples": [">>> idx = pd.date_range('1/1/2000', periods=4, freq='min')\n>>> df = pd.DataFrame(data=4 * [range(2)],\n...                   index=idx,\n...                   columns=['a', 'b'])\n>>> df.iloc[2, 0] = 5\n>>> df\n                    a  b\n2000-01-01 00:00:00  0  1\n2000-01-01 00:01:00  0  1\n2000-01-01 00:02:00  5  1\n2000-01-01 00:03:00  0  1\n"], "Parameters": [["rule str or DateOffset", "The offset string or object representing target grouper conversion."], ["*args", "Possible arguments are how , fill_method , limit , kind and on , and other arguments of TimeGrouper ."], ["include_groups bool, default True", "When True, will attempt to include the groupings in the operation in\nthe case that they are columns of the DataFrame. If this raises a\nTypeError, the result will be computed with the groupings excluded.\nWhen False, the groupings will be excluded when applying func . Added in version 2.2.0. Deprecated since version 2.2.0: Setting include_groups to True is deprecated. Only the value\nFalse will be allowed in a future version of pandas."], ["**kwargs", "Possible arguments are how , fill_method , limit , kind and on , and other arguments of TimeGrouper ."]], "Returns": [["pandas.api.typing.DatetimeIndexResamplerGroupby,", ""], ["pandas.api.typing.PeriodIndexResamplerGroupby, or", ""], ["pandas.api.typing.TimedeltaIndexResamplerGroupby", "Return a new groupby object, with type depending on the data\nbeing resampled."]], "Category": ["Groupby"], "index": 240}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html#pandas.core.groupby.DataFrameGroupBy.rolling"], "Title": ["DataFrameGroupBy.rolling"], "Feature": ["DataFrameGroupBy.rolling"], "Description": "Return a rolling grouper, providing rolling functionality per group.\nSee alsoSeries.rollingCalling object with Series data.DataFrame.rollingCalling object with DataFrames.Series.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby.", "Examples": [">>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n...                    'B': [1, 2, 3, 4],\n...                    'C': [0.362, 0.227, 1.267, -0.562]})\n>>> df\n      A  B      C\n0     1  1  0.362\n1     1  2  0.227\n2     2  3  1.267\n3     2  4 -0.562\n"], "Parameters": [["window int, timedelta, str, offset, or BaseIndexer subclass", "Size of the moving window. If an integer, the fixed number of observations used for\neach window. If a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link . If a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods , center , closed and step will be passed to get_window_bounds ."], ["min_periods int, default None", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan . For a window that is specified by an offset, min_periods will default to 1. For a window that is specified by an integer, min_periods will default\nto the size of the window."], ["center bool, default False", "If False, set the window labels as the right edge of the window index. If True, set the window labels as the center of the window index."], ["win_type str, default None", "If None , all points are evenly weighted. If a string, it must be a valid scipy.signal window function . Certain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature."], ["on str, optional", "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index. Provided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window."], ["axis int or str, default 0", "If 0 or 'index' , roll across the rows. If 1 or 'columns' , roll across the columns. For Series this parameter is unused and defaults to 0."], ["closed str, default None", "If 'right' , the first point in the window is excluded from calculations. If 'left' , the last point in the window is excluded from calculations. If 'both' , no points in the window are excluded from calculations. If 'neither' , the first and last points in the window are excluded\nfrom calculations. Default None ( 'right' )."], ["method str {‘single’, ‘table’}, default ‘single’", "Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call."]], "Returns": [["pandas.api.typing.RollingGroupby", "Return a new grouper with our rolling appended."]], "Category": ["Groupby"], "index": 241}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sample.html#pandas.core.groupby.DataFrameGroupBy.sample"], "Title": ["DataFrameGroupBy.sample"], "Feature": ["DataFrameGroupBy.sample"], "Description": "Return a random sample of items from each group.\nYou can userandom_statefor reproducibility.\nSee alsoDataFrame.sampleGenerate random samples from a DataFrame object.numpy.random.choiceGenerate a random sample from a given 1-D numpy array.", "Examples": [">>> df = pd.DataFrame(\n...     {\"a\": [\"red\"] * 2 + [\"blue\"] * 2 + [\"black\"] * 2, \"b\": range(6)}\n... )\n>>> df\n       a  b\n0    red  0\n1    red  1\n2   blue  2\n3   blue  3\n4  black  4\n5  black  5\n"], "Parameters": [["n int, optional", "Number of items to return for each group. Cannot be used with frac and must be no larger than the smallest group unless replace is True. Default is one if frac is None."], ["frac float, optional", "Fraction of items to return. Cannot be used with n ."], ["replace bool, default False", "Allow or disallow sampling of the same row more than once."], ["weights list-like, optional", "Default None results in equal probability weighting.\nIf passed a list-like then values must have the same length as\nthe underlying DataFrame or Series object and will be used as\nsampling probabilities after normalization within each group.\nValues must be non-negative with at least one positive element\nwithin each group."], ["random_state int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given. Changed in version 1.4.0: np.random.Generator objects now accepted"]], "Returns": [["Series or DataFrame", "A new object of same type as caller containing items randomly\nsampled within each group from the caller object."]], "Category": ["Groupby"], "index": 242}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sem.html#pandas.core.groupby.DataFrameGroupBy.sem"], "Title": ["DataFrameGroupBy.sem"], "Feature": ["DataFrameGroupBy.sem"], "Description": "Compute standard error of the mean of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([5, 10, 8, 14], index=lst)\n>>> ser\na     5\na    10\nb     8\nb    14\ndtype: int64\n>>> ser.groupby(level=0).sem()\na    2.5\nb    3.0\ndtype: float64\n"], "Parameters": [["ddof int, default 1", "Degrees of freedom."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Standard error of the mean of values within each group."]], "Category": ["Groupby"], "index": 243}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.shift.html#pandas.core.groupby.DataFrameGroupBy.shift"], "Title": ["DataFrameGroupBy.shift"], "Feature": ["DataFrameGroupBy.shift"], "Description": "Shift each group by periods observations.\nIf freq is passed, the index will be increased using the periods and the freq.\nSee alsoIndex.shiftShift values of Index.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).shift(1)\na    NaN\na    1.0\nb    NaN\nb    3.0\ndtype: float64\n"], "Parameters": [["periods int | Sequence[int], default 1", "Number of periods to shift. If a list of values, shift each group by\neach period."], ["freq str, optional", "Frequency string."], ["axis axis to shift, default 0", "Shift direction. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["fill_value optional", "The scalar value to use for newly introduced missing values. Changed in version 2.1.0: Will raise a ValueError if freq is provided too."], ["suffix str, optional", "A string to add to each shifted column if there are multiple periods.\nIgnored otherwise."]], "Returns": [["Series or DataFrame", "Object shifted within each group."]], "Category": ["Groupby"], "index": 244}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.get_group.html#pandas.core.groupby.DataFrameGroupBy.get_group"], "Title": ["DataFrameGroupBy.get_group"], "Feature": ["DataFrameGroupBy.get_group"], "Description": "Construct DataFrame from group with provided name.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\ndtype: int64\n>>> ser.groupby(level=0).get_group(\"a\")\na    1\na    2\ndtype: int64\n"], "Parameters": [["name object", "The name of the group to get as a DataFrame."], ["obj DataFrame, default None", "The DataFrame to take the DataFrame out of.  If\nit is None, the object groupby was called on will\nbe used. Deprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\nDo df.iloc[gb.indices.get(name)] instead of gb.get_group(name, obj=df) ."]], "Returns": [["same type as obj", ""]], "Category": ["Groupby"], "index": 245}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html#pandas.core.groupby.DataFrameGroupBy.size"], "Title": ["DataFrameGroupBy.size"], "Feature": ["DataFrameGroupBy.size"], "Description": "Compute group sizes.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na     1\na     2\nb     3\ndtype: int64\n>>> ser.groupby(level=0).size()\na    2\nb    1\ndtype: int64\n"], "Parameters": [], "Returns": [["DataFrame or Series", "Number of rows in each group as a Series if as_index is True\nor a DataFrame if as_index is False."]], "Category": ["Groupby"], "index": 246}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.skew.html#pandas.core.groupby.DataFrameGroupBy.skew"], "Title": ["DataFrameGroupBy.skew"], "Feature": ["DataFrameGroupBy.skew"], "Description": "Return unbiased skew within groups.\nNormalized by N-1.\nSee alsoDataFrame.skewReturn unbiased skew over requested axis.", "Examples": [">>> arrays = [['falcon', 'parrot', 'cockatoo', 'kiwi',\n...            'lion', 'monkey', 'rabbit'],\n...           ['bird', 'bird', 'bird', 'bird',\n...            'mammal', 'mammal', 'mammal']]\n>>> index = pd.MultiIndex.from_arrays(arrays, names=('name', 'class'))\n>>> df = pd.DataFrame({'max_speed': [389.0, 24.0, 70.0, np.nan,\n...                                  80.5, 21.5, 15.0]},\n...                   index=index)\n>>> df\n                max_speed\nname     class\nfalcon   bird        389.0\nparrot   bird         24.0\ncockatoo bird         70.0\nkiwi     bird          NaN\nlion     mammal       80.5\nmonkey   mammal       21.5\nrabbit   mammal       15.0\n>>> gb = df.groupby([\"class\"])\n>>> gb.skew()\n        max_speed\nclass\nbird     1.628296\nmammal   1.669046\n>>> gb.skew(skipna=False)\n        max_speed\nclass\nbird          NaN\nmammal   1.669046\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "Axis for the function to be applied on. Specifying axis=None will apply the aggregation across both axes. Added in version 2.0.0. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["DataFrame", ""]], "Category": ["Groupby"], "index": 247}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.std.html#pandas.core.groupby.DataFrameGroupBy.std"], "Title": ["DataFrameGroupBy.std"], "Feature": ["DataFrameGroupBy.std"], "Description": "Compute standard deviation of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).std()\na    3.21455\nb    0.57735\ndtype: float64\n"], "Parameters": [["ddof int, default 1", "Degrees of freedom."], ["engine str, default None", "'cython' : Runs the operation through C-extensions from cython. 'numba' : Runs the operation through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba Added in version 1.4.0."], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {{'nopython': True, 'nogil': False, 'parallel': False}} Added in version 1.4.0."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Standard deviation of values within each group."]], "Category": ["Groupby"], "index": 248}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html#pandas.core.groupby.DataFrameGroupBy.sum"], "Title": ["DataFrameGroupBy.sum"], "Feature": ["DataFrameGroupBy.sum"], "Description": "Compute sum of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).sum()\na    3\nb    7\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."], ["engine str, default None None", "'cython' : Runs rolling apply through C-extensions from cython. 'numba' Runs rolling apply through JIT compiled code from numba. Only available when raw is set to True . None : Defaults to 'cython' or globally setting compute.use_numba"], ["'numba' Runs rolling apply through JIT compiled code from numba.", "Only available when raw is set to True ."], ["engine_kwargs dict, default None None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."], ["For 'numba' engine, the engine can accept nopython , nogil", "and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."]], "Returns": [["Series or DataFrame", "Computed sum of values within each group."]], "Category": ["Groupby"], "index": 249}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.var.html#pandas.core.groupby.DataFrameGroupBy.var"], "Title": ["DataFrameGroupBy.var"], "Feature": ["DataFrameGroupBy.var"], "Description": "Compute variance of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).var()\na    10.333333\nb     0.333333\ndtype: float64\n"], "Parameters": [["ddof int, default 1", "Degrees of freedom."], ["engine str, default None", "'cython' : Runs the operation through C-extensions from cython. 'numba' : Runs the operation through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba Added in version 1.4.0."], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {{'nopython': True, 'nogil': False, 'parallel': False}} Added in version 1.4.0."], ["numeric_only bool, default False", "Include only float , int or boolean data. Added in version 1.5.0. Changed in version 2.0.0: numeric_only now defaults to False ."]], "Returns": [["Series or DataFrame", "Variance of values within each group."]], "Category": ["Groupby"], "index": 250}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.tail.html#pandas.core.groupby.DataFrameGroupBy.tail"], "Title": ["DataFrameGroupBy.tail"], "Feature": ["DataFrameGroupBy.tail"], "Description": "Return last n rows of each group.\nSimilar to.apply(lambdax:x.tail(n)), but it returns a subset of rows\nfrom the original DataFrame with original index and order preserved\n(as_indexflag is ignored).\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n...                   columns=['A', 'B'])\n>>> df.groupby('A').tail(1)\n   A  B\n1  a  2\n3  b  2\n>>> df.groupby('A').tail(-1)\n   A  B\n1  a  2\n3  b  2\n"], "Parameters": [["n int", "If positive: number of entries to include from end of each group.\nIf negative: number of entries to exclude from start of each group."]], "Returns": [["Series or DataFrame", "Subset of original Series or DataFrame as determined by n."]], "Category": ["Groupby"], "index": 251}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.take.html#pandas.core.groupby.DataFrameGroupBy.take"], "Title": ["DataFrameGroupBy.take"], "Feature": ["DataFrameGroupBy.take"], "Description": "Return the elements in the givenpositionalindices in each group.\nThis means that we are not indexing according to actual values in\nthe index attribute of the object. We are indexing according to the\nactual position of the element in the object.\nIf a requested index does not exist for some group, this method will raise.\nTo get similar behavior that ignores indices that don’t exist, seeDataFrameGroupBy.nth().\nSee alsoDataFrame.takeTake elements from a Series along an axis.DataFrame.locSelect a subset of a DataFrame by labels.DataFrame.ilocSelect a subset of a DataFrame by positions.numpy.takeTake elements from an array along an axis.", "Examples": [">>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n...                    ('parrot', 'bird', 24.0),\n...                    ('lion', 'mammal', 80.5),\n...                    ('monkey', 'mammal', np.nan),\n...                    ('rabbit', 'mammal', 15.0)],\n...                   columns=['name', 'class', 'max_speed'],\n...                   index=[4, 3, 2, 1, 0])\n>>> df\n     name   class  max_speed\n4  falcon    bird      389.0\n3  parrot    bird       24.0\n2    lion  mammal       80.5\n1  monkey  mammal        NaN\n0  rabbit  mammal       15.0\n>>> gb = df.groupby([1, 1, 2, 2, 2])\n"], "Parameters": [["indices array-like", "An array of ints indicating which positions to take."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns. Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."], ["**kwargs", "For compatibility with numpy.take() . Has no effect on the\noutput."]], "Returns": [["DataFrame", "An DataFrame containing the elements taken from each group."]], "Category": ["Groupby"], "index": 252}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.value_counts.html#pandas.core.groupby.DataFrameGroupBy.value_counts"], "Title": ["DataFrameGroupBy.value_counts"], "Feature": ["DataFrameGroupBy.value_counts"], "Description": "Return a Series or DataFrame containing counts of unique rows.\nAdded in version 1.4.0.\nSee alsoSeries.value_countsEquivalent method on Series.DataFrame.value_countsEquivalent method on DataFrame.SeriesGroupBy.value_countsEquivalent method on SeriesGroupBy.\nNotes\nIf the groupby as_index is True then the returned Series will have a\nMultiIndex with one level per input column.If the groupby as_index is False then the returned DataFrame will have an\nadditional column with the value_counts. The column is labelled ‘count’ or\n‘proportion’, depending on thenormalizeparameter.\nBy default, rows that contain any NA values are omitted from\nthe result.\nBy default, the result will be in descending order so that the\nfirst element of each group is the most frequently-occurring row.", "Examples": [">>> df = pd.DataFrame({\n...     'gender': ['male', 'male', 'female', 'male', 'female', 'male'],\n...     'education': ['low', 'medium', 'high', 'low', 'high', 'low'],\n...     'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR']\n... })\n"], "Parameters": [["subset list-like, optional", "Columns to use when counting unique combinations."], ["normalize bool, default False", "Return proportions rather than frequencies."], ["sort bool, default True", "Sort by frequencies."], ["ascending bool, default False", "Sort in ascending order."], ["dropna bool, default True", "Don’t include counts of rows that contain NA values."]], "Returns": [["Series or DataFrame", "Series if the groupby as_index is True, otherwise DataFrame."]], "Category": ["Groupby"], "index": 253}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.all.html#pandas.core.groupby.SeriesGroupBy.all"], "Title": ["SeriesGroupBy.all"], "Feature": ["SeriesGroupBy.all"], "Description": "Return True if all values in the group are truthful, else False.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 0], index=lst)\n>>> ser\na    1\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).all()\na     True\nb    False\ndtype: bool\n"], "Parameters": [["skipna bool, default True", "Flag to ignore nan values during truth testing."]], "Returns": [["Series or DataFrame", "DataFrame or Series of boolean values, where a value is True if all elements\nare True within its respective group, False otherwise."]], "Category": ["Groupby"], "index": 254}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.any.html#pandas.core.groupby.SeriesGroupBy.any"], "Title": ["SeriesGroupBy.any"], "Feature": ["SeriesGroupBy.any"], "Description": "Return True if any value in the group is truthful, else False.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 0], index=lst)\n>>> ser\na    1\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).any()\na     True\nb    False\ndtype: bool\n"], "Parameters": [["skipna bool, default True", "Flag to ignore nan values during truth testing."]], "Returns": [["Series or DataFrame", "DataFrame or Series of boolean values, where a value is True if any element\nis True within its respective group, False otherwise."]], "Category": ["Groupby"], "index": 255}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.get_group.html#pandas.core.groupby.SeriesGroupBy.get_group"], "Title": ["SeriesGroupBy.get_group"], "Feature": ["SeriesGroupBy.get_group"], "Description": "Construct DataFrame from group with provided name.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\ndtype: int64\n>>> ser.groupby(level=0).get_group(\"a\")\na    1\na    2\ndtype: int64\n"], "Parameters": [["name object", "The name of the group to get as a DataFrame."], ["obj DataFrame, default None", "The DataFrame to take the DataFrame out of.  If\nit is None, the object groupby was called on will\nbe used. Deprecated since version 2.1.0: The obj is deprecated and will be removed in a future version.\nDo df.iloc[gb.indices.get(name)] instead of gb.get_group(name, obj=df) ."]], "Returns": [["same type as obj", ""]], "Category": ["Groupby"], "index": 256}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.bfill.html#pandas.core.groupby.SeriesGroupBy.bfill"], "Title": ["SeriesGroupBy.bfill"], "Feature": ["SeriesGroupBy.bfill"], "Description": "Backward fill the values.\nSee alsoSeries.bfillBackward fill the missing values in the dataset.DataFrame.bfillBackward fill the missing values in the dataset.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.", "Examples": [">>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']\n>>> s = pd.Series([None, 1, None, None, 3], index=index)\n>>> s\nFalcon    NaN\nFalcon    1.0\nParrot    NaN\nParrot    NaN\nParrot    3.0\ndtype: float64\n>>> s.groupby(level=0).bfill()\nFalcon    1.0\nFalcon    1.0\nParrot    3.0\nParrot    3.0\nParrot    3.0\ndtype: float64\n>>> s.groupby(level=0).bfill(limit=1)\nFalcon    1.0\nFalcon    1.0\nParrot    NaN\nParrot    3.0\nParrot    3.0\ndtype: float64\n"], "Parameters": [["limit int, optional", "Limit of how many values to fill."]], "Returns": [["Series or DataFrame", "Object with missing values filled."]], "Category": ["Groupby"], "index": 257}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.corr.html#pandas.core.groupby.SeriesGroupBy.corr"], "Title": ["SeriesGroupBy.corr"], "Feature": ["SeriesGroupBy.corr"], "Description": "Compute correlation withotherSeries, excluding missing values.\nThe twoSeriesobjects are not required to be the same length and will be\naligned internally before the correlation function is applied.\nSee alsoDataFrame.corrCompute pairwise correlation between columns.DataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.\nNotes\nPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\nPearson correlation coefficientKendall rank correlation coefficientSpearman’s rank correlation coefficient\nAutomatic data alignment: as with all pandas operations, automatic data alignment is performed for this method.corr()automatically considers values with matching indices.", "Examples": [">>> def histogram_intersection(a, b):\n...     v = np.minimum(a, b).sum().round(decimals=1)\n...     return v\n>>> s1 = pd.Series([.2, .0, .6, .2])\n>>> s2 = pd.Series([.3, .6, .0, .1])\n>>> s1.corr(s2, method=histogram_intersection)\n0.3\n"], "Parameters": [["other Series", "Series with which to compute the correlation."], ["method {‘pearson’, ‘kendall’, ‘spearman’} or callable", "Method used to compute correlation: pearson : Standard correlation coefficient kendall : Kendall Tau correlation coefficient spearman : Spearman rank correlation callable: Callable with input two 1d ndarrays and returning a float. Warning Note that the returned matrix from corr will have 1 along the\ndiagonals and will be symmetric regardless of the callable’s\nbehavior."], ["min_periods int, optional", "Minimum number of observations needed to have a valid result."]], "Returns": [["float", "Correlation with other."]], "Category": ["Groupby"], "index": 258}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.count.html#pandas.core.groupby.SeriesGroupBy.count"], "Title": ["SeriesGroupBy.count"], "Feature": ["SeriesGroupBy.count"], "Description": "Compute count of group, excluding missing values.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([1, 2, np.nan], index=lst)\n>>> ser\na    1.0\na    2.0\nb    NaN\ndtype: float64\n>>> ser.groupby(level=0).count()\na    2\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", "Count of values within each group."]], "Category": ["Groupby"], "index": 259}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cov.html#pandas.core.groupby.SeriesGroupBy.cov"], "Title": ["SeriesGroupBy.cov"], "Feature": ["SeriesGroupBy.cov"], "Description": "Compute covariance with Series, excluding missing values.\nThe twoSeriesobjects are not required to be the same length and\nwill be aligned internally before the covariance is calculated.\nSee alsoDataFrame.covCompute pairwise covariance of columns.", "Examples": [">>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n>>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n>>> s1.cov(s2)\n-0.01685762652715874\n"], "Parameters": [["other Series", "Series with which to compute the covariance."], ["min_periods int, optional", "Minimum number of observations needed to have a valid result."], ["ddof int, default 1", "Delta degrees of freedom.  The divisor used in calculations\nis N - ddof , where N represents the number of elements."]], "Returns": [["float", "Covariance between Series and other normalized by N-1\n(unbiased estimator)."]], "Category": ["Groupby"], "index": 260}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumcount.html#pandas.core.groupby.SeriesGroupBy.cumcount"], "Title": ["SeriesGroupBy.cumcount"], "Feature": ["SeriesGroupBy.cumcount"], "Description": "Number each item in each group from 0 to the length of that group - 1.\nEssentially this is equivalent to\nself.apply(lambdax:pd.Series(np.arange(len(x)),x.index))Copy to clipboard\nSee alsongroupNumber the groups themselves.", "Examples": [">>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n...                   columns=['A'])\n>>> df\n   A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n>>> df.groupby('A').cumcount()\n0    0\n1    1\n2    2\n3    0\n4    1\n5    3\ndtype: int64\n>>> df.groupby('A').cumcount(ascending=False)\n0    3\n1    2\n2    1\n3    1\n4    0\n5    0\ndtype: int64\n"], "Parameters": [["ascending bool, default True", "If False, number in reverse, from length of group - 1 to 0."]], "Returns": [["Series", "Sequence number of each element within each group."]], "Category": ["Groupby"], "index": 261}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummax.html#pandas.core.groupby.SeriesGroupBy.cummax"], "Title": ["SeriesGroupBy.cummax"], "Feature": ["SeriesGroupBy.cummax"], "Description": "Cumulative max for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([1, 6, 2, 3, 1, 4], index=lst)\n>>> ser\na    1\na    6\na    2\nb    3\nb    1\nb    4\ndtype: int64\n>>> ser.groupby(level=0).cummax()\na    1\na    6\na    6\nb    3\nb    3\nb    4\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 262}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cummin.html#pandas.core.groupby.SeriesGroupBy.cummin"], "Title": ["SeriesGroupBy.cummin"], "Feature": ["SeriesGroupBy.cummin"], "Description": "Cumulative min for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([1, 6, 2, 3, 0, 4], index=lst)\n>>> ser\na    1\na    6\na    2\nb    3\nb    0\nb    4\ndtype: int64\n>>> ser.groupby(level=0).cummin()\na    1\na    1\na    1\nb    3\nb    0\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 263}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumprod.html#pandas.core.groupby.SeriesGroupBy.cumprod"], "Title": ["SeriesGroupBy.cumprod"], "Feature": ["SeriesGroupBy.cumprod"], "Description": "Cumulative product for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([6, 2, 0], index=lst)\n>>> ser\na    6\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).cumprod()\na    6\na   12\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 264}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.cumsum.html#pandas.core.groupby.SeriesGroupBy.cumsum"], "Title": ["SeriesGroupBy.cumsum"], "Feature": ["SeriesGroupBy.cumsum"], "Description": "Cumulative sum for each group.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'b']\n>>> ser = pd.Series([6, 2, 0], index=lst)\n>>> ser\na    6\na    2\nb    0\ndtype: int64\n>>> ser.groupby(level=0).cumsum()\na    6\na    8\nb    0\ndtype: int64\n"], "Parameters": [], "Returns": [["Series or DataFrame", ""]], "Category": ["Groupby"], "index": 265}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.describe.html#pandas.core.groupby.SeriesGroupBy.describe"], "Title": ["SeriesGroupBy.describe"], "Feature": ["SeriesGroupBy.describe"], "Description": "Generate descriptive statistics.\nDescriptive statistics include those that summarize the central\ntendency, dispersion and shape of a\ndataset’s distribution, excludingNaNvalues.\nAnalyzes both numeric and object series, as well\nasDataFramecolumn sets of mixed data types. The output\nwill vary depending on what is provided. Refer to the notes\nbelow for more detail.\nSee alsoDataFrame.countCount number of non-NA/null observations.DataFrame.maxMaximum of the values in the object.DataFrame.minMinimum of the values in the object.DataFrame.meanMean of the values.DataFrame.stdStandard deviation of the observations.DataFrame.select_dtypesSubset of a DataFrame including/excluding columns based on their dtype.\nNotes\nFor numeric data, the result’s index will includecount,mean,std,min,maxas well as lower,50and\nupper percentiles. By default the lower percentile is25and the\nupper percentile is75. The50percentile is the\nsame as the median.\nFor object data (e.g. strings or timestamps), the result’s index\nwill includecount,unique,top, andfreq. Thetopis the most common value. Thefreqis the most common value’s\nfrequency. Timestamps also include thefirstandlastitems.\nIf multiple object values have the highest count, then thecountandtopresults will be arbitrarily chosen from\namong those with the highest count.\nFor mixed data types provided via aDataFrame, the default is to\nreturn only an analysis of numeric columns. If the dataframe consists\nonly of object and categorical data without any numeric columns, the\ndefault is to return an analysis of both the object and categorical\ncolumns. Ifinclude='all'is provided as an option, the result\nwill include a union of attributes of each type.\nTheincludeandexcludeparameters can be used to limit\nwhich columns in aDataFrameare analyzed for the output.\nThe parameters are ignored when analyzing aSeries.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.describe()\ncount    3.0\nmean     2.0\nstd      1.0\nmin      1.0\n25%      1.5\n50%      2.0\n75%      2.5\nmax      3.0\ndtype: float64\n"], "Parameters": [["percentiles list-like of numbers, optional", "The percentiles to include in the output. All should\nfall between 0 and 1. The default is [.25, .5, .75] , which returns the 25th, 50th, and\n75th percentiles."], ["include ‘all’, list-like of dtypes or None (default), optional", "A white list of data types to include in the result. Ignored\nfor Series . Here are the options: ‘all’ : All columns of the input will be included in the output. A list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit numpy.number . To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of select_dtypes (e.g. df.describe(include=['O']) ). To\nselect pandas categorical columns, use 'category' None (default) : The result will include all numeric columns."], ["exclude list-like of dtypes or None (default), optional,", "A black list of data types to omit from the result. Ignored\nfor Series . Here are the options: A list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit numpy.number . To exclude object columns submit the data\ntype numpy.object . Strings can also be used in the style of select_dtypes (e.g. df.describe(exclude=['O']) ). To\nexclude pandas categorical columns, use 'category' None (default) : The result will exclude nothing."]], "Returns": [["Series or DataFrame", "Summary statistics of the Series or Dataframe provided."]], "Category": ["Groupby"], "index": 266}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html#pandas.Grouper"], "Title": ["Grouper"], "Feature": ["Grouper"], "Description": "A Grouper allows the user to specify a groupby instruction for an object.\nThis specification will select a column via the key parameter, or if the\nlevel and/or axis parameters are given, a level of the index of the target\nobject.\nIfaxisand/orlevelare passed as keywords to bothGrouperandgroupby, the values passed toGroupertake precedence.", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"Animal\": [\"Falcon\", \"Parrot\", \"Falcon\", \"Falcon\", \"Parrot\"],\n...         \"Speed\": [100, 5, 200, 300, 15],\n...     }\n... )\n>>> df\n   Animal  Speed\n0  Falcon    100\n1  Parrot      5\n2  Falcon    200\n3  Falcon    300\n4  Parrot     15\n>>> df.groupby(pd.Grouper(key=\"Animal\")).mean()\n        Speed\nAnimal\nFalcon  200.0\nParrot   10.0\n"], "Parameters": [["key str, defaults to None", "Groupby key, which selects the grouping column of the target."], ["level name/number, defaults to None", "The level for the target index."], ["freq str / frequency object, defaults to None", "This will groupby the specified frequency if the target selection\n(via key or level) is a datetime-like object. For full specification\nof available frequencies, please see here ."], ["axis str, int, defaults to 0", "Number/name of the axis."], ["sort bool, default to False", "Whether to sort the resulting labels."], ["closed {‘left’ or ‘right’}", "Closed end of interval. Only when freq parameter is passed."], ["label {‘left’ or ‘right’}", "Interval boundary to use for labeling.\nOnly when freq parameter is passed."], ["convention {‘start’, ‘end’, ‘e’, ‘s’}", "If grouper is PeriodIndex and freq parameter is passed."], ["origin Timestamp or str, default ‘start_day’", "The timestamp on which to adjust the grouping. The timezone of origin must\nmatch the timezone of the index.\nIf string, must be one of the following: ‘epoch’: origin is 1970-01-01 ‘start’: origin is the first value of the timeseries ‘start_day’: origin is the first day at midnight of the timeseries ‘end’: origin is the last value of the timeseries ‘end_day’: origin is the ceiling midnight of the last day Added in version 1.3.0."], ["offset Timedelta or str, default is None", "An offset timedelta added to the origin."], ["dropna bool, default True", "If True, and if group keys contain NA values, NA values together with\nrow/column will be dropped. If False, NA values will also be treated as\nthe key in groups."]], "Returns": [["Grouper or pandas.api.typing.TimeGrouper", "A TimeGrouper is returned if freq is not None . Otherwise, a Grouper\nis returned."]], "Category": ["Groupby"], "index": 267}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.diff.html#pandas.core.groupby.SeriesGroupBy.diff"], "Title": ["SeriesGroupBy.diff"], "Feature": ["SeriesGroupBy.diff"], "Description": "First discrete difference of element.\nCalculates the difference of each element compared with another\nelement in the group (default is element in previous row).\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).diff()\na    NaN\na   -5.0\na    6.0\nb    NaN\nb   -1.0\nb    0.0\ndtype: float64\n"], "Parameters": [["periods int, default 1", "Periods to shift for calculating difference, accepts negative values."], ["axis axis to shift, default 0", "Take difference over rows (0) or columns (1). Deprecated since version 2.1.0: For axis=1, operate on the underlying object instead. Otherwise\nthe axis keyword is not necessary."]], "Returns": [["Series or DataFrame", "First differences."]], "Category": ["Groupby"], "index": 268}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ffill.html#pandas.core.groupby.SeriesGroupBy.ffill"], "Title": ["SeriesGroupBy.ffill"], "Feature": ["SeriesGroupBy.ffill"], "Description": "Forward fill the values.\nSee alsoSeries.ffillReturns Series with minimum number of char in object.DataFrame.ffillObject with missing values filled or None if inplace=True.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.", "Examples": [">>> key = [0, 0, 1, 1]\n>>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)\n>>> ser\n0    NaN\n0    2.0\n1    3.0\n1    NaN\ndtype: float64\n>>> ser.groupby(level=0).ffill()\n0    NaN\n0    2.0\n1    3.0\n1    3.0\ndtype: float64\n"], "Parameters": [["limit int, optional", "Limit of how many values to fill."]], "Returns": [["Series or DataFrame", "Object with missing values filled."]], "Category": ["Groupby"], "index": 269}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.fillna.html#pandas.core.groupby.SeriesGroupBy.fillna"], "Title": ["SeriesGroupBy.fillna"], "Feature": ["SeriesGroupBy.fillna"], "Description": "Fill NA/NaN values using the specified method within groups.\nDeprecated since version 2.2.0:This method is deprecated and will be removed in a future version.\nUse theSeriesGroupBy.ffill()orSeriesGroupBy.bfill()for forward or backward filling instead. If you want to fill with a\nsingle value, useSeries.fillna()instead.\nSee alsoffillForward fill values within a group.bfillBackward fill values within a group.", "Examples": [">>> lst = ['cat', 'cat', 'cat', 'mouse', 'mouse']\n>>> ser = pd.Series([1, None, None, 2, None], index=lst)\n>>> ser\ncat    1.0\ncat    NaN\ncat    NaN\nmouse  2.0\nmouse  NaN\ndtype: float64\n>>> ser.groupby(level=0).fillna(0, limit=1)\ncat    1.0\ncat    0.0\ncat    NaN\nmouse  2.0\nmouse  0.0\ndtype: float64\n"], "Parameters": [["value scalar, dict, Series, or DataFrame", "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame).  Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list. Users wanting to use the value argument and not method should prefer Series.fillna() as this\nwill produce the same result and be more performant."], ["method {{‘bfill’, ‘ffill’, None}}, default None", "Method to use for filling holes. 'ffill' will propagate\nthe last valid observation forward within a group. 'bfill' will use next valid observation to fill the gap."], ["axis {0 or ‘index’, 1 or ‘columns’}", "Unused, only for compatibility with DataFrameGroupBy.fillna() ."], ["inplace bool, default False", "Broken. Do not set to True."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill within a group. In other words,\nif there is a gap with more than this number of consecutive NaNs,\nit will only be partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible)."]], "Returns": [["Series", "Object with missing values filled within groups."]], "Category": ["Groupby"], "index": 270}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.first.html#pandas.core.groupby.SeriesGroupBy.first"], "Title": ["SeriesGroupBy.first"], "Feature": ["SeriesGroupBy.first"], "Description": "Compute the first entry of each column within each group.\nDefaults to skipping NA elements.\nSee alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.lastCompute the last non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.", "Examples": [">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],\n...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))\n>>> df['D'] = pd.to_datetime(df['D'])\n>>> df.groupby(\"A\").first()\n     B  C          D\nA\n1  5.0  1 2000-03-11\n3  6.0  3 2000-03-13\n>>> df.groupby(\"A\").first(min_count=2)\n    B    C          D\nA\n1 NaN  1.0 2000-03-11\n3 NaN  NaN        NaT\n>>> df.groupby(\"A\").first(numeric_only=True)\n     B  C\nA\n1  5.0  1\n3  6.0  3\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA. Added in version 2.2.1."]], "Returns": [["Series or DataFrame", "First values within each group."]], "Category": ["Groupby"], "index": 271}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.head.html#pandas.core.groupby.SeriesGroupBy.head"], "Title": ["SeriesGroupBy.head"], "Feature": ["SeriesGroupBy.head"], "Description": "Return first n rows of each group.\nSimilar to.apply(lambdax:x.head(n)), but it returns a subset of rows\nfrom the original DataFrame with original index and order preserved\n(as_indexflag is ignored).\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n...                   columns=['A', 'B'])\n>>> df.groupby('A').head(1)\n   A  B\n0  1  2\n2  5  6\n>>> df.groupby('A').head(-1)\n   A  B\n0  1  2\n"], "Parameters": [["n int", "If positive: number of entries to include from start of each group.\nIf negative: number of entries to exclude from end of each group."]], "Returns": [["Series or DataFrame", "Subset of original Series or DataFrame as determined by n."]], "Category": ["Groupby"], "index": 272}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.last.html#pandas.core.groupby.SeriesGroupBy.last"], "Title": ["SeriesGroupBy.last"], "Feature": ["SeriesGroupBy.last"], "Description": "Compute the last entry of each column within each group.\nDefaults to skipping NA elements.\nSee alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.firstCompute the first non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.", "Examples": [">>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))\n>>> df.groupby(\"A\").last()\n     B  C\nA\n1  5.0  2\n3  6.0  3\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. If None, will attempt to use\neverything, then use only numeric data."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count valid values are present the result will be NA."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA. Added in version 2.2.1."]], "Returns": [["Series or DataFrame", "Last of values within each group."]], "Category": ["Groupby"], "index": 273}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmax.html#pandas.core.groupby.SeriesGroupBy.idxmax"], "Title": ["SeriesGroupBy.idxmax"], "Feature": ["SeriesGroupBy.idxmax"], "Description": "Return the row label of the maximum value.\nIf multiple values equal the maximum, the first row label with that\nvalue is returned.\nSee alsonumpy.argmaxReturn indices of the maximum values along the given axis.DataFrame.idxmaxReturn index of first occurrence of maximum over requested axis.Series.idxminReturn indexlabelof the first occurrence of minimum of values.\nNotes\nThis method is the Series version ofndarray.argmax. This method\nreturns the label of the maximum, whilendarray.argmaxreturns\nthe position. To get the position, useseries.values.argmax().", "Examples": [">>> s = pd.Series(data=[1, None, 4, 3, 4],\n...               index=['A', 'B', 'C', 'D', 'E'])\n>>> s\nA    1.0\nB    NaN\nC    4.0\nD    3.0\nE    4.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["skipna bool, default True", "Exclude NA/null values. If the entire Series is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional arguments and keywords have no effect but might be\naccepted for compatibility with NumPy."]], "Returns": [["Index", "Label of the maximum value."]], "Category": ["Groupby"], "index": 274}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.idxmin.html#pandas.core.groupby.SeriesGroupBy.idxmin"], "Title": ["SeriesGroupBy.idxmin"], "Feature": ["SeriesGroupBy.idxmin"], "Description": "Return the row label of the minimum value.\nIf multiple values equal the minimum, the first row label with that\nvalue is returned.\nSee alsonumpy.argminReturn indices of the minimum values along the given axis.DataFrame.idxminReturn index of first occurrence of minimum over requested axis.Series.idxmaxReturn indexlabelof the first occurrence of maximum of values.\nNotes\nThis method is the Series version ofndarray.argmin. This method\nreturns the label of the minimum, whilendarray.argminreturns\nthe position. To get the position, useseries.values.argmin().", "Examples": [">>> s = pd.Series(data=[1, None, 4, 1],\n...               index=['A', 'B', 'C', 'D'])\n>>> s\nA    1.0\nB    NaN\nC    4.0\nD    1.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["skipna bool, default True", "Exclude NA/null values. If the entire Series is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional arguments and keywords have no effect but might be\naccepted for compatibility with NumPy."]], "Returns": [["Index", "Label of the minimum value."]], "Category": ["Groupby"], "index": 275}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing"], "Title": ["SeriesGroupBy.is_monotonic_increasing"], "Feature": ["SeriesGroupBy.is_monotonic_increasing"], "Description": "Return whether each group’s values are monotonically increasing.", "Examples": [">>> s = pd.Series([2, 1, 3, 4], index=['Falcon', 'Falcon', 'Parrot', 'Parrot'])\n>>> s.groupby(level=0).is_monotonic_increasing\nFalcon    False\nParrot     True\ndtype: bool\n"], "Parameters": [], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 276}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing.html#pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing"], "Title": ["SeriesGroupBy.is_monotonic_decreasing"], "Feature": ["SeriesGroupBy.is_monotonic_decreasing"], "Description": "Return whether each group’s values are monotonically decreasing.", "Examples": [">>> s = pd.Series([2, 1, 3, 4], index=['Falcon', 'Falcon', 'Parrot', 'Parrot'])\n>>> s.groupby(level=0).is_monotonic_decreasing\nFalcon     True\nParrot    False\ndtype: bool\n"], "Parameters": [], "Returns": [["Series", ""]], "Category": ["Groupby"], "index": 277}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.NamedAgg.html#pandas.NamedAgg"], "Title": ["NamedAgg"], "Feature": ["NamedAgg"], "Description": "Helper for column specific aggregation with control over output column names.\nSubclass of typing.NamedTuple.", "Examples": [">>> df = pd.DataFrame({\"key\": [1, 1, 2], \"a\": [-1, 0, 1], 1: [10, 11, 12]})\n>>> agg_a = pd.NamedAgg(column=\"a\", aggfunc=\"min\")\n>>> agg_1 = pd.NamedAgg(column=1, aggfunc=lambda x: np.mean(x))\n>>> df.groupby(\"key\").agg(result_a=agg_a, result_1=agg_1)\n     result_a  result_1\nkey\n1          -1      10.5\n2           1      12.0\n"], "Parameters": [["column Hashable", "Column label in the DataFrame to apply aggfunc."], ["aggfunc function or str", "Function to apply to the provided column. If string, the name of a built-in\npandas function."]], "Returns": [], "Category": ["Groupby"], "index": 278}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.max.html#pandas.core.groupby.SeriesGroupBy.max"], "Title": ["SeriesGroupBy.max"], "Feature": ["SeriesGroupBy.max"], "Description": "Compute max of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).max()\na    2\nb    4\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."], ["engine str, default None None", "'cython' : Runs rolling apply through C-extensions from cython. 'numba' Runs rolling apply through JIT compiled code from numba. Only available when raw is set to True . None : Defaults to 'cython' or globally setting compute.use_numba"], ["'numba' Runs rolling apply through JIT compiled code from numba.", "Only available when raw is set to True ."], ["engine_kwargs dict, default None None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."], ["For 'numba' engine, the engine can accept nopython , nogil", "and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."]], "Returns": [["Series or DataFrame", "Computed max of values within each group."]], "Category": ["Groupby"], "index": 279}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.mean.html#pandas.core.groupby.SeriesGroupBy.mean"], "Title": ["SeriesGroupBy.mean"], "Feature": ["SeriesGroupBy.mean"], "Description": "Compute mean of groups, excluding missing values.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n...                    'B': [np.nan, 2, 3, 4, 5],\n...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None and defaults to False ."], ["engine str, default None", "'cython' : Runs the operation through C-extensions from cython. 'numba' : Runs the operation through JIT compiled code from numba. None : Defaults to 'cython' or globally setting compute.use_numba Added in version 1.4.0."], ["engine_kwargs dict, default None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {{'nopython': True, 'nogil': False, 'parallel': False}} Added in version 1.4.0."]], "Returns": [["pandas.Series or pandas.DataFrame", ""]], "Category": ["Groupby"], "index": 280}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.median.html#pandas.core.groupby.SeriesGroupBy.median"], "Title": ["SeriesGroupBy.median"], "Feature": ["SeriesGroupBy.median"], "Description": "Compute median of groups, excluding missing values.\nFor multiple groupings, the result index will be a MultiIndex", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n>>> ser\na     7\na     2\na     8\nb     4\nb     3\nb     3\ndtype: int64\n>>> ser.groupby(level=0).median()\na    7.0\nb    3.0\ndtype: float64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None and defaults to False."]], "Returns": [["Series or DataFrame", "Median of values within each group."]], "Category": ["Groupby"], "index": 281}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.min.html#pandas.core.groupby.SeriesGroupBy.min"], "Title": ["SeriesGroupBy.min"], "Feature": ["SeriesGroupBy.min"], "Description": "Compute min of group values.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 4], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    4\ndtype: int64\n>>> ser.groupby(level=0).min()\na    1\nb    3\ndtype: int64\n"], "Parameters": [["numeric_only bool, default False", "Include only float, int, boolean columns. Changed in version 2.0.0: numeric_only no longer accepts None ."], ["min_count int, default -1", "The required number of valid values to perform the operation. If fewer\nthan min_count non-NA values are present the result will be NA."], ["engine str, default None None", "'cython' : Runs rolling apply through C-extensions from cython. 'numba' Runs rolling apply through JIT compiled code from numba. Only available when raw is set to True . None : Defaults to 'cython' or globally setting compute.use_numba"], ["'numba' Runs rolling apply through JIT compiled code from numba.", "Only available when raw is set to True ."], ["engine_kwargs dict, default None None", "For 'cython' engine, there are no accepted engine_kwargs For 'numba' engine, the engine can accept nopython , nogil and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."], ["For 'numba' engine, the engine can accept nopython , nogil", "and parallel dictionary keys. The values must either be True or False . The default engine_kwargs for the 'numba' engine is {'nopython': True, 'nogil': False, 'parallel': False} and will be\napplied to both the func and the apply groupby aggregation."]], "Returns": [["Series or DataFrame", "Computed min of values within each group."]], "Category": ["Groupby"], "index": 282}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.ngroup.html#pandas.core.groupby.SeriesGroupBy.ngroup"], "Title": ["SeriesGroupBy.ngroup"], "Feature": ["SeriesGroupBy.ngroup"], "Description": "Number each group from 0 to the number of groups - 1.\nThis is the enumerative complement of cumcount.  Note that the\nnumbers given to the groups match the order in which the groups\nwould be seen when iterating over the groupby object, not the\norder they are first observed.\nGroups with missing keys (wherepd.isna()is True) will be labeled withNaNand will be skipped from the count.\nSee alsocumcountNumber the rows in each group.", "Examples": [">>> df = pd.DataFrame({\"color\": [\"red\", None, \"red\", \"blue\", \"blue\", \"red\"]})\n>>> df\n   color\n0    red\n1   None\n2    red\n3   blue\n4   blue\n5    red\n>>> df.groupby(\"color\").ngroup()\n0    1.0\n1    NaN\n2    1.0\n3    0.0\n4    0.0\n5    1.0\ndtype: float64\n>>> df.groupby(\"color\", dropna=False).ngroup()\n0    1\n1    2\n2    1\n3    0\n4    0\n5    1\ndtype: int64\n>>> df.groupby(\"color\", dropna=False).ngroup(ascending=False)\n0    1\n1    0\n2    1\n3    2\n4    2\n5    1\ndtype: int64\n"], "Parameters": [["ascending bool, default True", "If False, number in reverse, from number of group - 1 to 0."]], "Returns": [["Series", "Unique numbers for each group."]], "Category": ["Groupby"], "index": 283}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nlargest.html#pandas.core.groupby.SeriesGroupBy.nlargest"], "Title": ["SeriesGroupBy.nlargest"], "Feature": ["SeriesGroupBy.nlargest"], "Description": "Return the largestnelements.\nSee alsoSeries.nsmallestGet thensmallest elements.Series.sort_valuesSort Series by values.Series.headReturn the firstnrows.\nNotes\nFaster than.sort_values(ascending=False).head(n)for smallnrelative to the size of theSeriesobject.", "Examples": [">>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n...                         \"Malta\": 434000, \"Maldives\": 434000,\n...                         \"Brunei\": 434000, \"Iceland\": 337000,\n...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n>>> s = pd.Series(countries_population)\n>>> s\nItaly       59000000\nFrance      65000000\nMalta         434000\nMaldives      434000\nBrunei        434000\nIceland       337000\nNauru          11300\nTuvalu         11300\nAnguilla       11300\nMontserrat      5200\ndtype: int64\n"], "Parameters": [["n int, default 5", "Return this many descending sorted values."], ["keep {‘first’, ‘last’, ‘all’}, default ‘first’", "When there are duplicate values that cannot all fit in a\nSeries of n elements: first : return the first n occurrences in order\nof appearance. last : return the last n occurrences in reverse\norder of appearance. all : keep all occurrences. This can result in a Series of\nsize larger than n ."]], "Returns": [["Series", "The n largest values in the Series, sorted in decreasing order."]], "Category": ["Groupby"], "index": 284}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nsmallest.html#pandas.core.groupby.SeriesGroupBy.nsmallest"], "Title": ["SeriesGroupBy.nsmallest"], "Feature": ["SeriesGroupBy.nsmallest"], "Description": "Return the smallestnelements.\nSee alsoSeries.nlargestGet thenlargest elements.Series.sort_valuesSort Series by values.Series.headReturn the firstnrows.\nNotes\nFaster than.sort_values().head(n)for smallnrelative to\nthe size of theSeriesobject.", "Examples": [">>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n...                         \"Brunei\": 434000, \"Malta\": 434000,\n...                         \"Maldives\": 434000, \"Iceland\": 337000,\n...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n>>> s = pd.Series(countries_population)\n>>> s\nItaly       59000000\nFrance      65000000\nBrunei        434000\nMalta         434000\nMaldives      434000\nIceland       337000\nNauru          11300\nTuvalu         11300\nAnguilla       11300\nMontserrat      5200\ndtype: int64\n"], "Parameters": [["n int, default 5", "Return this many ascending sorted values."], ["keep {‘first’, ‘last’, ‘all’}, default ‘first’", "When there are duplicate values that cannot all fit in a\nSeries of n elements: first : return the first n occurrences in order\nof appearance. last : return the last n occurrences in reverse\norder of appearance. all : keep all occurrences. This can result in a Series of\nsize larger than n ."]], "Returns": [["Series", "The n smallest values in the Series, sorted in increasing order."]], "Category": ["Groupby"], "index": 285}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nth.html#pandas.core.groupby.SeriesGroupBy.nth"], "Title": ["SeriesGroupBy.nth"], "Feature": ["SeriesGroupBy.nth"], "Description": "Take the nth row from each group if n is an int, otherwise a subset of rows.\nCan be either a call or an index. dropna is not available with index notation.\nIndex notation accepts a comma separated list of integers and slices.\nIf dropna, will take the nth non-null row, dropna is either\n‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)\nbefore the groupby.\nSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.", "Examples": [">>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n>>> g = df.groupby('A')\n>>> g.nth(0)\n   A   B\n0  1 NaN\n2  2 3.0\n>>> g.nth(1)\n   A   B\n1  1 2.0\n4  2 5.0\n>>> g.nth(-1)\n   A   B\n3  1 4.0\n4  2 5.0\n>>> g.nth([0, 1])\n   A   B\n0  1 NaN\n1  1 2.0\n2  2 3.0\n4  2 5.0\n>>> g.nth(slice(None, -1))\n   A   B\n0  1 NaN\n1  1 2.0\n2  2 3.0\n"], "Parameters": [["n int, slice or list of ints and slices", "A single nth value for the row or a list of nth values or slices. Changed in version 1.4.0: Added slice and lists containing slices.\nAdded index notation."], ["dropna {‘any’, ‘all’, None}, default None", "Apply the specified dropna operation before counting which row is\nthe nth row. Only supported if n is an int."]], "Returns": [["Series or DataFrame", "N-th value within each group."]], "Category": ["Groupby"], "index": 286}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.nunique.html#pandas.core.groupby.SeriesGroupBy.nunique"], "Title": ["SeriesGroupBy.nunique"], "Feature": ["SeriesGroupBy.nunique"], "Description": "Return number of unique elements in the group.", "Examples": [">>> lst = ['a', 'a', 'b', 'b']\n>>> ser = pd.Series([1, 2, 3, 3], index=lst)\n>>> ser\na    1\na    2\nb    3\nb    3\ndtype: int64\n>>> ser.groupby(level=0).nunique()\na    2\nb    1\ndtype: int64\n"], "Parameters": [], "Returns": [["Series", "Number of unique values within each group."]], "Category": ["Groupby"], "index": 287}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.unique.html#pandas.core.groupby.SeriesGroupBy.unique"], "Title": ["SeriesGroupBy.unique"], "Feature": ["SeriesGroupBy.unique"], "Description": "Return unique values for each group.\nIt returns unique values for each of the grouped values. Returned in\norder of appearance. Hash table-based unique, therefore does NOT sort.\nSee alsoSeries.uniqueReturn unique values of Series object.", "Examples": [">>> df = pd.DataFrame([('Chihuahua', 'dog', 6.1),\n...                    ('Beagle', 'dog', 15.2),\n...                    ('Chihuahua', 'dog', 6.9),\n...                    ('Persian', 'cat', 9.2),\n...                    ('Chihuahua', 'dog', 7),\n...                    ('Persian', 'cat', 8.8)],\n...                   columns=['breed', 'animal', 'height_in'])\n>>> df\n       breed     animal   height_in\n0  Chihuahua        dog         6.1\n1     Beagle        dog        15.2\n2  Chihuahua        dog         6.9\n3    Persian        cat         9.2\n4  Chihuahua        dog         7.0\n5    Persian        cat         8.8\n>>> ser = df.groupby('animal')['breed'].unique()\n>>> ser\nanimal\ncat              [Persian]\ndog    [Chihuahua, Beagle]\nName: breed, dtype: object\n"], "Parameters": [], "Returns": [["Series", "Unique values for each of the grouped values."]], "Category": ["Groupby"], "index": 288}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.days_in_month.html#pandas.Timestamp.days_in_month"], "Title": ["Timestamp.days_in_month"], "Feature": ["Timestamp.days_in_month"], "Description": "Return the number of days in the month.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.days_in_month\n31\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 291}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.total_seconds.html#pandas.Timedelta.total_seconds"], "Title": ["Timedelta.total_seconds"], "Feature": ["Timedelta.total_seconds"], "Description": "Total seconds in the duration.", "Examples": [">>> td = pd.Timedelta('1min')\n>>> td\nTimedelta('0 days 00:01:00')\n>>> td.total_seconds()\n60.0\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 292}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.TimedeltaArray.html#pandas.arrays.TimedeltaArray"], "Title": ["arrays.TimedeltaArray"], "Feature": ["arrays.TimedeltaArray"], "Description": "Pandas ExtensionArray for timedelta data.\nWarningTimedeltaArray is currently experimental, and its API may change\nwithout warning. In particular,TimedeltaArray.dtypeis\nexpected to change to be an instance of anExtensionDtypesubclass.\nAttributes\nMethods", "Examples": [">>> pd.arrays.TimedeltaArray._from_sequence(pd.TimedeltaIndex(['1h', '2h']))\n<TimedeltaArray>\n['0 days 01:00:00', '0 days 02:00:00']\nLength: 2, dtype: timedelta64[ns]\n"], "Parameters": [["values array-like", "The timedelta data."], ["dtype numpy.dtype", "Currently, only numpy.dtype(\"timedelta64[ns]\") is accepted."], ["freq Offset, optional", ""], ["copy bool, default False", "Whether to copy the underlying array of data."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 293}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.day.html#pandas.Period.day"], "Title": ["Period.day"], "Feature": ["Period.day"], "Description": "Get day of the month that a Period falls on.\nSee alsoPeriod.dayofweekGet the day of the week.Period.dayofyearGet the day of the year.", "Examples": [">>> p = pd.Period(\"2018-03-11\", freq='h')\n>>> p.day\n11\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 295}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofweek.html#pandas.Period.dayofweek"], "Title": ["Period.dayofweek"], "Feature": ["Period.dayofweek"], "Description": "Day of the week the period lies in, with Monday=0 and Sunday=6.\nIf the period frequency is lower than daily (e.g. hourly), and the\nperiod spans over multiple days, the day at the start of the period is\nused.\nIf the frequency is higher than daily (e.g. monthly), the last day\nof the period is used.\nSee alsoPeriod.day_of_weekDay of the week the period lies in.Period.weekdayAlias of Period.day_of_week.Period.dayDay of the month.Period.dayofyearDay of the year.", "Examples": [">>> per = pd.Period('2017-12-31 22:00', 'h')\n>>> per.day_of_week\n6\n"], "Parameters": [], "Returns": [["int", "Day of the week."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 296}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_week.html#pandas.Period.day_of_week"], "Title": ["Period.day_of_week"], "Feature": ["Period.day_of_week"], "Description": "Day of the week the period lies in, with Monday=0 and Sunday=6.\nIf the period frequency is lower than daily (e.g. hourly), and the\nperiod spans over multiple days, the day at the start of the period is\nused.\nIf the frequency is higher than daily (e.g. monthly), the last day\nof the period is used.\nSee alsoPeriod.day_of_weekDay of the week the period lies in.Period.weekdayAlias of Period.day_of_week.Period.dayDay of the month.Period.dayofyearDay of the year.", "Examples": [">>> per = pd.Period('2017-12-31 22:00', 'h')\n>>> per.day_of_week\n6\n"], "Parameters": [], "Returns": [["int", "Day of the week."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 297}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.dayofyear.html#pandas.Period.dayofyear"], "Title": ["Period.dayofyear"], "Feature": ["Period.dayofyear"], "Description": "Return the day of the year.\nThis attribute returns the day of the year on which the particular\ndate occurs. The return value ranges between 1 to 365 for regular\nyears and 1 to 366 for leap years.\nSee alsoPeriod.dayReturn the day of the month.Period.day_of_weekReturn the day of week.PeriodIndex.day_of_yearReturn the day of year of all indexes.", "Examples": [">>> period = pd.Period(\"2015-10-23\", freq='h')\n>>> period.day_of_year\n296\n>>> period = pd.Period(\"2012-12-31\", freq='D')\n>>> period.day_of_year\n366\n>>> period = pd.Period(\"2013-01-01\", freq='D')\n>>> period.day_of_year\n1\n"], "Parameters": [], "Returns": [["int", "The day of year."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 298}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.day_of_year.html#pandas.Period.day_of_year"], "Title": ["Period.day_of_year"], "Feature": ["Period.day_of_year"], "Description": "Return the day of the year.\nThis attribute returns the day of the year on which the particular\ndate occurs. The return value ranges between 1 to 365 for regular\nyears and 1 to 366 for leap years.\nSee alsoPeriod.dayReturn the day of the month.Period.day_of_weekReturn the day of week.PeriodIndex.day_of_yearReturn the day of year of all indexes.", "Examples": [">>> period = pd.Period(\"2015-10-23\", freq='h')\n>>> period.day_of_year\n296\n>>> period = pd.Period(\"2012-12-31\", freq='D')\n>>> period.day_of_year\n366\n>>> period = pd.Period(\"2013-01-01\", freq='D')\n>>> period.day_of_year\n1\n"], "Parameters": [], "Returns": [["int", "The day of year."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 299}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.days_in_month.html#pandas.Period.days_in_month"], "Title": ["Period.days_in_month"], "Feature": ["Period.days_in_month"], "Description": "Get the total number of days in the month that this period falls on.\nSee alsoPeriod.daysinmonthGets the number of days in the month.DatetimeIndex.daysinmonthGets the number of days in the month.calendar.monthrangeReturns a tuple containing weekday (0-6 ~ Mon-Sun) and number of days (28-31).", "Examples": [">>> p = pd.Period('2018-2-17')\n>>> p.days_in_month\n28\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 300}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.daysinmonth.html#pandas.Period.daysinmonth"], "Title": ["Period.daysinmonth"], "Feature": ["Period.daysinmonth"], "Description": "Get the total number of days of the month that this period falls on.\nSee alsoPeriod.days_in_monthReturn the days of the month.Period.dayofyearReturn the day of the year.", "Examples": [">>> p = pd.Period(\"2018-03-11\", freq='h')\n>>> p.daysinmonth\n31\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 301}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.daysinmonth.html#pandas.Timestamp.daysinmonth"], "Title": ["Timestamp.daysinmonth"], "Feature": ["Timestamp.daysinmonth"], "Description": "Return the number of days in the month.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.days_in_month\n31\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 302}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.end_time.html#pandas.Period.end_time"], "Title": ["Period.end_time"], "Feature": ["Period.end_time"], "Description": "Get the Timestamp for the end of the period.\nSee alsoPeriod.start_timeReturn the start Timestamp.Period.dayofyearReturn the day of year.Period.daysinmonthReturn the days in that month.Period.dayofweekReturn the day of the week.", "Examples": [">>> pd.Period('2020-01', 'D').end_time\nTimestamp('2020-01-01 23:59:59.999999999')\n"], "Parameters": [], "Returns": [["Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 303}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.freq.html#pandas.Period.freq"], "Title": ["Period.freq"], "Feature": ["Period.freq"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 304}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.freqstr.html#pandas.Period.freqstr"], "Title": ["Period.freqstr"], "Feature": ["Period.freqstr"], "Description": "Return a string representation of the frequency.", "Examples": [">>> pd.Period('2020-01', 'D').freqstr\n'D'\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 305}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.hour.html#pandas.Period.hour"], "Title": ["Period.hour"], "Feature": ["Period.hour"], "Description": "Get the hour of the day component of the Period.\nSee alsoPeriod.secondGet the second component of the Period.Period.minuteGet the minute component of the Period.", "Examples": [">>> p = pd.Period(\"2018-03-11 13:03:12.050000\")\n>>> p.hour\n13\n"], "Parameters": [], "Returns": [["int", "The hour as an integer, between 0 and 23."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 306}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.is_leap_year.html#pandas.Period.is_leap_year"], "Title": ["Period.is_leap_year"], "Feature": ["Period.is_leap_year"], "Description": "Return True if the period’s year is in a leap year.", "Examples": [">>> period = pd.Period('2022-01', 'M')\n>>> period.is_leap_year\nFalse\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 307}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.minute.html#pandas.Period.minute"], "Title": ["Period.minute"], "Feature": ["Period.minute"], "Description": "Get minute of the hour component of the Period.\nSee alsoPeriod.hourGet the hour component of the Period.Period.secondGet the second component of the Period.", "Examples": [">>> p = pd.Period(\"2018-03-11 13:03:12.050000\")\n>>> p.minute\n3\n"], "Parameters": [], "Returns": [["int", "The minute as an integer, between 0 and 59."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 308}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.month.html#pandas.Period.month"], "Title": ["Period.month"], "Feature": ["Period.month"], "Description": "Return the month this Period falls on.", "Examples": [">>> period = pd.Period('2022-01', 'M')\n>>> period.month\n1\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 309}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.ordinal.html#pandas.Period.ordinal"], "Title": ["Period.ordinal"], "Feature": ["Period.ordinal"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 310}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.quarter.html#pandas.Period.quarter"], "Title": ["Period.quarter"], "Feature": ["Period.quarter"], "Description": "Return the quarter this Period falls on.", "Examples": [">>> period = pd.Period('2022-04', 'M')\n>>> period.quarter\n2\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 311}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.qyear.html#pandas.Period.qyear"], "Title": ["Period.qyear"], "Feature": ["Period.qyear"], "Description": "Fiscal year the Period lies in according to its starting-quarter.\nTheyearand theqyearof the period will be the same if the fiscal\nand calendar years are the same. When they are not, the fiscal year\ncan be different from the calendar year of the period.\nSee alsoPeriod.yearReturn the calendar year of the period.", "Examples": [">>> per = pd.Period('2018Q1', freq='Q')\n>>> per.qyear\n2018\n>>> per.year\n2018\n"], "Parameters": [], "Returns": [["int", "The fiscal year of the period."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 312}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fold.html#pandas.Timestamp.fold"], "Title": ["Timestamp.fold"], "Feature": ["Timestamp.fold"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 313}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.second.html#pandas.Period.second"], "Title": ["Period.second"], "Feature": ["Period.second"], "Description": "Get the second component of the Period.\nSee alsoPeriod.hourGet the hour component of the Period.Period.minuteGet the minute component of the Period.", "Examples": [">>> p = pd.Period(\"2018-03-11 13:03:12.050000\")\n>>> p.second\n12\n"], "Parameters": [], "Returns": [["int", "The second of the Period (ranges from 0 to 59)."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 314}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.start_time.html#pandas.Period.start_time"], "Title": ["Period.start_time"], "Feature": ["Period.start_time"], "Description": "Get the Timestamp for the start of the period.\nSee alsoPeriod.end_timeReturn the end Timestamp.Period.dayofyearReturn the day of year.Period.daysinmonthReturn the days in that month.Period.dayofweekReturn the day of the week.", "Examples": [">>> period = pd.Period('2012-1-1', freq='D')\n>>> period\nPeriod('2012-01-01', 'D')\n"], "Parameters": [], "Returns": [["Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 315}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.week.html#pandas.Period.week"], "Title": ["Period.week"], "Feature": ["Period.week"], "Description": "Get the week of the year on the given Period.\nSee alsoPeriod.dayofweekGet the day component of the Period.Period.weekdayGet the day component of the Period.", "Examples": [">>> p = pd.Period(\"2018-03-11\", \"h\")\n>>> p.week\n10\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 316}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.weekday.html#pandas.Period.weekday"], "Title": ["Period.weekday"], "Feature": ["Period.weekday"], "Description": "Day of the week the period lies in, with Monday=0 and Sunday=6.\nIf the period frequency is lower than daily (e.g. hourly), and the\nperiod spans over multiple days, the day at the start of the period is\nused.\nIf the frequency is higher than daily (e.g. monthly), the last day\nof the period is used.\nSee alsoPeriod.dayofweekDay of the week the period lies in.Period.weekdayAlias of Period.dayofweek.Period.dayDay of the month.Period.dayofyearDay of the year.", "Examples": [">>> per = pd.Period('2017-12-31 22:00', 'h')\n>>> per.dayofweek\n6\n"], "Parameters": [], "Returns": [["int", "Day of the week."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 317}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.weekofyear.html#pandas.Period.weekofyear"], "Title": ["Period.weekofyear"], "Feature": ["Period.weekofyear"], "Description": "Get the week of the year on the given Period.\nSee alsoPeriod.dayofweekGet the day component of the Period.Period.weekdayGet the day component of the Period.", "Examples": [">>> p = pd.Period(\"2018-03-11\", \"h\")\n>>> p.weekofyear\n10\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 318}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.year.html#pandas.Period.year"], "Title": ["Period.year"], "Feature": ["Period.year"], "Description": "Return the year this Period falls on.", "Examples": [">>> period = pd.Period('2022-01', 'M')\n>>> period.year\n2022\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 319}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.asfreq.html#pandas.Period.asfreq"], "Title": ["Period.asfreq"], "Feature": ["Period.asfreq"], "Description": "Convert Period to desired frequency, at the start or end of the interval.", "Examples": [">>> period = pd.Period('2023-1-1', freq='D')\n>>> period.asfreq('h')\nPeriod('2023-01-01 23:00', 'h')\n"], "Parameters": [["freq str, BaseOffset", "The desired frequency. If passing a str , it needs to be a\nvalid period alias ."], ["how {‘E’, ‘S’, ‘end’, ‘start’}, default ‘end’", "Start or end of the timespan."]], "Returns": [["resampled Period", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 320}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html#pandas.Period.now"], "Title": ["Period.now"], "Feature": ["Period.now"], "Description": "Return the period of now’s date.", "Examples": [">>> pd.Period.now('h')  \nPeriod('2023-06-12 11:00', 'h')\n"], "Parameters": [["freq str, BaseOffset", "Frequency to use for the returned period."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 321}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.strftime.html#pandas.Period.strftime"], "Title": ["Period.strftime"], "Feature": ["Period.strftime"], "Description": "Returns a formatted string representation of thePeriod.\nfmtmust beNoneor a string containing one or several directives.\nWhenNone, the format will be determined from the frequency of the Period.\nThe method recognizes the same directives as thetime.strftime()function of the standard Python distribution, as well as the specific\nadditional directives%f,%F,%q,%l,%u,%n.\n(formatting & docs originally from scikits.timeries).\nNotes", "Examples": [">>> from pandas import Period\n>>> a = Period(freq='Q-JUL', year=2006, quarter=1)\n>>> a.strftime('%F-Q%q')\n'2006-Q1'\n>>> # Output the last month in the quarter of this date\n>>> a.strftime('%b-%Y')\n'Oct-2005'\n>>>\n>>> a = Period(freq='D', year=2001, month=1, day=1)\n>>> a.strftime('%d-%b-%Y')\n'01-Jan-2001'\n>>> a.strftime('%b. %d, %Y was a %A')\n'Jan. 01, 2001 was a Monday'\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 322}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Period.to_timestamp.html#pandas.Period.to_timestamp"], "Title": ["Period.to_timestamp"], "Feature": ["Period.to_timestamp"], "Description": "Return the Timestamp representation of the Period.\nUses the target frequency specified at the part of the period specified\nbyhow, which is eitherStartorFinish.", "Examples": [">>> period = pd.Period('2023-1-1', freq='D')\n>>> timestamp = period.to_timestamp()\n>>> timestamp\nTimestamp('2023-01-01 00:00:00')\n"], "Parameters": [["freq str or DateOffset", "Target frequency. Default is ‘D’ if self.freq is week or\nlonger and ‘S’ otherwise."], ["how str, default ‘S’ (start)", "One of ‘S’, ‘E’. Can be aliased as case insensitive\n‘Start’, ‘Finish’, ‘Begin’, ‘End’."]], "Returns": [["Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 323}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.hour.html#pandas.Timestamp.hour"], "Title": ["Timestamp.hour"], "Feature": ["Timestamp.hour"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 324}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.PeriodArray.html#pandas.arrays.PeriodArray"], "Title": ["arrays.PeriodArray"], "Feature": ["arrays.PeriodArray"], "Description": "Pandas ExtensionArray for storing Period data.\nUsers should usearray()to create new instances.\nAttributes\nMethods\nSee alsoPeriodRepresents a period of time.PeriodIndexImmutable Index for period data.period_rangeCreate a fixed-frequency PeriodArray.arrayConstruct a pandas array.\nNotes\nThere are two components to a PeriodArray\nordinals : integer ndarrayfreq : pd.tseries.offsets.Offset\nThe values are physically stored as a 1-D ndarray of integers. These are\ncalled “ordinals” and represent some kind of offset from a base.\nThefreqindicates the span covered by each element of the array.\nAll elements in the PeriodArray have the samefreq.", "Examples": [">>> pd.arrays.PeriodArray(pd.PeriodIndex(['2023-01-01',\n...                                       '2023-01-02'], freq='D'))\n<PeriodArray>\n['2023-01-01', '2023-01-02']\nLength: 2, dtype: period[D]\n"], "Parameters": [["values Union[PeriodArray, Series[period], ndarray[int], PeriodIndex]", "The data to store. These should be arrays that can be directly\nconverted to ordinals without inference or copy (PeriodArray,\nndarray[int64]), or a box around such an array (Series[period],\nPeriodIndex)."], ["dtype PeriodDtype, optional", "A PeriodDtype instance from which to extract a freq . If both freq and dtype are specified, then the frequencies must match."], ["freq str or DateOffset", "The freq to use for the array. Mostly applicable when values is an ndarray of integers, when freq is required. When values is a PeriodArray (or box around), it’s checked that values.freq matches freq ."], ["copy bool, default False", "Whether to copy the ordinals before storing."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 325}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed.html#pandas.Interval.closed"], "Title": ["Interval.closed"], "Feature": ["Interval.closed"], "Description": "String describing the inclusive side the intervals.\nEitherleft,right,bothorneither.", "Examples": [">>> interval = pd.Interval(left=1, right=2, closed='left')\n>>> interval\nInterval(1, 2, closed='left')\n>>> interval.closed\n'left'\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 328}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_left.html#pandas.Interval.closed_left"], "Title": ["Interval.closed_left"], "Feature": ["Interval.closed_left"], "Description": "Check if the interval is closed on the left side.\nFor the meaning ofclosedandopenseeInterval.\nSee alsoInterval.closed_rightCheck if the interval is closed on the right side.Interval.open_leftBoolean inverse of closed_left.", "Examples": [">>> iv = pd.Interval(0, 5, closed='left')\n>>> iv.closed_left\nTrue\n"], "Parameters": [], "Returns": [["bool", "True if the Interval is closed on the left-side."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 329}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.closed_right.html#pandas.Interval.closed_right"], "Title": ["Interval.closed_right"], "Feature": ["Interval.closed_right"], "Description": "Check if the interval is closed on the right side.\nFor the meaning ofclosedandopenseeInterval.\nSee alsoInterval.closed_leftCheck if the interval is closed on the left side.Interval.open_rightBoolean inverse of closed_right.", "Examples": [">>> iv = pd.Interval(0, 5, closed='both')\n>>> iv.closed_right\nTrue\n"], "Parameters": [], "Returns": [["bool", "True if the Interval is closed on the left-side."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 330}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.is_empty.html#pandas.Interval.is_empty"], "Title": ["Interval.is_empty"], "Feature": ["Interval.is_empty"], "Description": "Indicates if an interval is empty, meaning it contains no points.\nSee alsoInterval.lengthReturn the length of the Interval.", "Examples": [">>> pd.Interval(0, 1, closed='right').is_empty\nFalse\n"], "Parameters": [], "Returns": [["bool or ndarray", "A boolean indicating if a scalar Interval is empty, or a\nboolean ndarray positionally indicating if an Interval in\nan IntervalArray or IntervalIndex is\nempty."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 331}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.left.html#pandas.Interval.left"], "Title": ["Interval.left"], "Feature": ["Interval.left"], "Description": "Left bound for the interval.", "Examples": [">>> interval = pd.Interval(left=1, right=2, closed='left')\n>>> interval\nInterval(1, 2, closed='left')\n>>> interval.left\n1\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 332}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.length.html#pandas.Interval.length"], "Title": ["Interval.length"], "Feature": ["Interval.length"], "Description": "Return the length of the Interval.\nSee alsoInterval.is_emptyIndicates if an interval contains no points.", "Examples": [">>> interval = pd.Interval(left=1, right=2, closed='left')\n>>> interval\nInterval(1, 2, closed='left')\n>>> interval.length\n1\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 333}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.mid.html#pandas.Interval.mid"], "Title": ["Interval.mid"], "Feature": ["Interval.mid"], "Description": "Return the midpoint of the Interval.", "Examples": [">>> iv = pd.Interval(0, 5)\n>>> iv.mid\n2.5\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 334}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_leap_year.html#pandas.Timestamp.is_leap_year"], "Title": ["Timestamp.is_leap_year"], "Feature": ["Timestamp.is_leap_year"], "Description": "Return True if year is a leap year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_leap_year\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 335}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_left.html#pandas.Interval.open_left"], "Title": ["Interval.open_left"], "Feature": ["Interval.open_left"], "Description": "Check if the interval is open on the left side.\nFor the meaning ofclosedandopenseeInterval.\nSee alsoInterval.open_rightCheck if the interval is open on the right side.Interval.closed_leftBoolean inverse of open_left.", "Examples": [">>> iv = pd.Interval(0, 5, closed='neither')\n>>> iv.open_left\nTrue\n"], "Parameters": [], "Returns": [["bool", "True if the Interval is not closed on the left-side."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 336}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.open_right.html#pandas.Interval.open_right"], "Title": ["Interval.open_right"], "Feature": ["Interval.open_right"], "Description": "Check if the interval is open on the right side.\nFor the meaning ofclosedandopenseeInterval.\nSee alsoInterval.open_leftCheck if the interval is open on the left side.Interval.closed_rightBoolean inverse of open_right.", "Examples": [">>> iv = pd.Interval(0, 5, closed='left')\n>>> iv.open_right\nTrue\n"], "Parameters": [], "Returns": [["bool", "True if the Interval is not closed on the left-side."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 337}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.overlaps.html#pandas.Interval.overlaps"], "Title": ["Interval.overlaps"], "Feature": ["Interval.overlaps"], "Description": "Check whether two Interval objects overlap.\nTwo intervals overlap if they share a common point, including closed\nendpoints. Intervals that only have an open endpoint in common do not\noverlap.\nSee alsoIntervalArray.overlapsThe corresponding method for IntervalArray.IntervalIndex.overlapsThe corresponding method for IntervalIndex.", "Examples": [">>> i1 = pd.Interval(0, 2)\n>>> i2 = pd.Interval(1, 3)\n>>> i1.overlaps(i2)\nTrue\n>>> i3 = pd.Interval(4, 5)\n>>> i1.overlaps(i3)\nFalse\n"], "Parameters": [["other Interval", "Interval to check against for an overlap."]], "Returns": [["bool", "True if the two intervals overlap."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 338}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Interval.right.html#pandas.Interval.right"], "Title": ["Interval.right"], "Feature": ["Interval.right"], "Description": "Right bound for the interval.", "Examples": [">>> interval = pd.Interval(left=1, right=2, closed='left')\n>>> interval\nInterval(1, 2, closed='left')\n>>> interval.right\n2\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 339}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntervalArray.html#pandas.arrays.IntervalArray"], "Title": ["arrays.IntervalArray"], "Feature": ["arrays.IntervalArray"], "Description": "Pandas array for interval data that are closed on the same side.\nAttributes\nMethods\nSee alsoIndexThe base pandas Index type.IntervalA bounded slice-like interval; the elements of an IntervalArray.interval_rangeFunction to create a fixed frequency IntervalIndex.cutBin values into discrete Intervals.qcutBin values into equal-sized Intervals based on rank or sample quantiles.\nNotes\nSee theuser guidefor more.", "Examples": [">>> pd.arrays.IntervalArray([pd.Interval(0, 1), pd.Interval(1, 5)])\n<IntervalArray>\n[(0, 1], (1, 5]]\nLength: 2, dtype: interval[int64, right]\n"], "Parameters": [["data array-like (1-dimensional)", "Array-like (ndarray, DateTimeArray , TimeDeltaArray ) containing\nInterval objects from which to build the IntervalArray."], ["closed {‘left’, ‘right’, ‘both’, ‘neither’}, default ‘right’", "Whether the intervals are closed on the left-side, right-side, both or\nneither."], ["dtype dtype or None, default None", "If None, dtype will be inferred."], ["copy bool, default False", "Copy the input data."], ["verify_integrity bool, default True", "Verify that the IntervalArray is valid."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 340}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.IntegerArray.html#pandas.arrays.IntegerArray"], "Title": ["arrays.IntegerArray"], "Feature": ["arrays.IntegerArray"], "Description": "Array of integer (optional missing) values.\nUsespandas.NAas the missing value.\nWarningIntegerArray is currently experimental, and its API or internal\nimplementation may change without warning.\nWe represent an IntegerArray with 2 numpy arrays:\ndata: contains a numpy integer array of the appropriate dtypemask: a boolean array holding a mask on the data, True is missing\nTo construct an IntegerArray from generic array-like input, usepandas.array()with one of the integer dtypes (see examples).\nSeeNullable integer data typefor more.\nAttributes\nMethods", "Examples": [">>> int_array = pd.array([1, None, 3], dtype=pd.Int32Dtype())\n>>> int_array\n<IntegerArray>\n[1, <NA>, 3]\nLength: 3, dtype: Int32\n"], "Parameters": [["values numpy.ndarray", "A 1-d integer-dtype array."], ["mask numpy.ndarray", "A 1-d boolean-dtype array indicating missing values."], ["copy bool, default False", "Whether to copy the values and mask ."]], "Returns": [["IntegerArray", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 342}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_end.html#pandas.Timestamp.is_month_end"], "Title": ["Timestamp.is_month_end"], "Feature": ["Timestamp.is_month_end"], "Description": "Check if the date is the last day of the month.\nSee alsoTimestamp.is_month_startSimilar property indicating month start.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_month_end\nFalse\n"], "Parameters": [], "Returns": [["bool", "True if the date is the last day of the month."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 346}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.FloatingArray.html#pandas.arrays.FloatingArray"], "Title": ["arrays.FloatingArray"], "Feature": ["arrays.FloatingArray"], "Description": "Array of floating (optional missing) values.\nWarningFloatingArray is currently experimental, and its API or internal\nimplementation may change without warning. Especially the behaviour\nregarding NaN (distinct from NA missing values) is subject to change.\nWe represent a FloatingArray with 2 numpy arrays:\ndata: contains a numpy float array of the appropriate dtypemask: a boolean array holding a mask on the data, True is missing\nTo construct an FloatingArray from generic array-like input, usepandas.array()with one of the float dtypes (see examples).\nSeeNullable integer data typefor more.\nAttributes\nMethods", "Examples": [">>> pd.array([0.1, None, 0.3], dtype=pd.Float32Dtype())\n<FloatingArray>\n[0.1, <NA>, 0.3]\nLength: 3, dtype: Float32\n"], "Parameters": [["values numpy.ndarray", "A 1-d float-dtype array."], ["mask numpy.ndarray", "A 1-d boolean-dtype array indicating missing values."], ["copy bool, default False", "Whether to copy the values and mask ."]], "Returns": [["FloatingArray", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 352}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.categories.html#pandas.CategoricalDtype.categories"], "Title": ["CategoricalDtype.categories"], "Feature": ["CategoricalDtype.categories"], "Description": "AnIndexcontaining the unique categories allowed.", "Examples": [">>> cat_type = pd.CategoricalDtype(categories=['a', 'b'], ordered=True)\n>>> cat_type.categories\nIndex(['a', 'b'], dtype='object')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 356}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_month_start.html#pandas.Timestamp.is_month_start"], "Title": ["Timestamp.is_month_start"], "Feature": ["Timestamp.is_month_start"], "Description": "Check if the date is the first day of the month.\nSee alsoTimestamp.is_month_endSimilar property indicating the last day of the month.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_month_start\nFalse\n"], "Parameters": [], "Returns": [["bool", "True if the date is the first day of the month."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 357}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.ordered.html#pandas.CategoricalDtype.ordered"], "Title": ["CategoricalDtype.ordered"], "Feature": ["CategoricalDtype.ordered"], "Description": "Whether the categories have an ordered relationship.", "Examples": [">>> cat_type = pd.CategoricalDtype(categories=['a', 'b'], ordered=True)\n>>> cat_type.ordered\nTrue\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 358}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Categorical.from_codes.html#pandas.Categorical.from_codes"], "Title": ["Categorical.from_codes"], "Feature": ["Categorical.from_codes"], "Description": "Make a Categorical type from codes and categories or dtype.\nThis constructor is useful if you already have codes and\ncategories/dtype and so do not need the (computation intensive)\nfactorization step, which is usually done on the constructor.\nIf your data does not follow this convention, please use the normal\nconstructor.", "Examples": [">>> dtype = pd.CategoricalDtype(['a', 'b'], ordered=True)\n>>> pd.Categorical.from_codes(codes=[0, 1, 0, 1], dtype=dtype)\n['a', 'b', 'a', 'b']\nCategories (2, object): ['a' < 'b']\n"], "Parameters": [["codes array-like of int", "An integer array, where each integer points to a category in\ncategories or dtype.categories, or else is -1 for NaN."], ["categories index-like, optional", "The categories for the categorical. Items need to be unique.\nIf the categories are not given here, then they must be provided\nin dtype ."], ["ordered bool, optional", "Whether or not this categorical is treated as an ordered\ncategorical. If not given here or in dtype , the resulting\ncategorical will be unordered."], ["dtype CategoricalDtype or “category”, optional", "If CategoricalDtype , cannot be used together with categories or ordered ."], ["validate bool, default True", "If True, validate that the codes are valid for the dtype.\nIf False, don’t validate that the codes are valid. Be careful about skipping\nvalidation, as invalid codes can lead to severe problems, such as segfaults. Added in version 2.1.0."]], "Returns": [["Categorical", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 360}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Categorical.dtype.html#pandas.Categorical.dtype"], "Title": ["Categorical.dtype"], "Feature": ["Categorical.dtype"], "Description": "TheCategoricalDtypefor this instance.", "Examples": [">>> cat = pd.Categorical(['a', 'b'], ordered=True)\n>>> cat\n['a', 'b']\nCategories (2, object): ['a' < 'b']\n>>> cat.dtype\nCategoricalDtype(categories=['a', 'b'], ordered=True, categories_dtype=object)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 361}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html#pandas.Categorical.categories"], "Title": ["Categorical.categories"], "Feature": ["Categorical.categories"], "Description": "The categories of this categorical.\nSetting assigns new values to each category (effectively a rename of\neach individual category).\nThe assigned value has to be a list-like object. All items must be\nunique and the number of items in the new categories must be the same\nas the number of items in the old categories.\nSee alsorename_categoriesRename categories.reorder_categoriesReorder categories.add_categoriesAdd new categories.remove_categoriesRemove the specified categories.remove_unused_categoriesRemove categories which are not used.set_categoriesSet the categories to the specified ones.", "Examples": [">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n>>> ser.cat.categories\nIndex(['a', 'b', 'c'], dtype='object')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 362}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Categorical.ordered.html#pandas.Categorical.ordered"], "Title": ["Categorical.ordered"], "Feature": ["Categorical.ordered"], "Description": "Whether the categories have an ordered relationship.", "Examples": [">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n>>> ser.cat.ordered\nFalse\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 363}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Categorical.codes.html#pandas.Categorical.codes"], "Title": ["Categorical.codes"], "Feature": ["Categorical.codes"], "Description": "The category codes of this categorical index.\nCodes are an array of integers which are the positions of the actual\nvalues in the categories array.\nThere is no setter, use the other categorical methods and the normal item\nsetter to change values in the categorical.", "Examples": [">>> cat = pd.Categorical(['a', 'b'], ordered=True)\n>>> cat.codes\narray([0, 1], dtype=int8)\n"], "Parameters": [], "Returns": [["ndarray[int]", "A non-writable view of the codes array."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 364}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.SparseArray.html#pandas.arrays.SparseArray"], "Title": ["arrays.SparseArray"], "Feature": ["arrays.SparseArray"], "Description": "An ExtensionArray for storing sparse data.\nAttributes\nMethods", "Examples": [">>> from pandas.arrays import SparseArray\n>>> arr = SparseArray([0, 0, 1, 2])\n>>> arr\n[0, 0, 1, 2]\nFill: 0\nIntIndex\nIndices: array([2, 3], dtype=int32)\n"], "Parameters": [["data array-like or scalar", "A dense array of values to store in the SparseArray. This may contain fill_value ."], ["sparse_index SparseIndex, optional", ""], ["fill_value scalar, optional", "Elements in data that are fill_value are not stored in the\nSparseArray. For memory savings, this should be the most common value\nin data . By default, fill_value depends on the dtype of data : data.dtype na_value float np.nan int 0 bool False datetime64 pd.NaT timedelta64 pd.NaT The fill value is potentially specified in three ways. In order of\nprecedence, these are The fill_value argument dtype.fill_value if fill_value is None and dtype is\na SparseDtype data.dtype.fill_value if fill_value is None and dtype is not a SparseDtype and data is a SparseArray ."], ["kind str", "Can be ‘integer’ or ‘block’, default is ‘integer’.\nThe type of storage for sparse locations. ‘block’: Stores a block and block_length for each\ncontiguous span of sparse values. This is best when\nsparse data tends to be clumped together, with large\nregions of fill-value values between sparse values. ‘integer’: uses an integer to store the location of\neach sparse value."], ["dtype np.dtype or SparseDtype, optional", "The dtype to use for the SparseArray. For numpy dtypes, this\ndetermines the dtype of self.sp_values . For SparseDtype,\nthis determines self.sp_values and self.fill_value ."], ["copy bool, default False", "Whether to explicitly copy the incoming data array."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 366}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_end.html#pandas.Timestamp.is_quarter_end"], "Title": ["Timestamp.is_quarter_end"], "Feature": ["Timestamp.is_quarter_end"], "Description": "Check if date is last day of the quarter.\nSee alsoTimestamp.is_quarter_startSimilar property indicating the quarter start.Timestamp.quarterReturn the quarter of the date.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_quarter_end\nFalse\n"], "Parameters": [], "Returns": [["bool", "True if date is last day of the quarter."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 368}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.StringArray.html#pandas.arrays.StringArray"], "Title": ["arrays.StringArray"], "Feature": ["arrays.StringArray"], "Description": "Extension array for string data.\nWarningStringArray is considered experimental. The implementation and\nparts of the API may change without warning.\nAttributes\nMethods\nSee alsopandas.array()The recommended function for creating a StringArray.Series.strThe string methods are available on Series backed by a StringArray.\nNotes\nStringArray returns a BooleanArray for comparison methods.", "Examples": [">>> pd.array(['This is', 'some text', None, 'data.'], dtype=\"string\")\n<StringArray>\n['This is', 'some text', <NA>, 'data.']\nLength: 4, dtype: string\n"], "Parameters": [["values array-like", "The array of data. Warning Currently, this expects an object-dtype ndarray\nwhere the elements are Python strings\nor nan-likes ( None , np.nan , NA ).\nThis may change without warning in the future. Use pandas.array() with dtype=\"string\" for a stable way of\ncreating a StringArray from any sequence. Changed in version 1.5.0: StringArray now accepts array-likes containing\nnan-likes( None , np.nan ) for the values parameter\nin addition to strings and pandas.NA"], ["copy bool, default False", "Whether to copy the array of data."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 369}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.ArrowStringArray.html#pandas.arrays.ArrowStringArray"], "Title": ["arrays.ArrowStringArray"], "Feature": ["arrays.ArrowStringArray"], "Description": "Extension array for string data in apyarrow.ChunkedArray.\nWarningArrowStringArray is considered experimental. The implementation and\nparts of the API may change without warning.\nAttributes\nMethods\nSee alsopandas.array()The recommended function for creating a ArrowStringArray.Series.strThe string methods are available on Series backed by a ArrowStringArray.\nNotes\nArrowStringArray returns a BooleanArray for comparison methods.", "Examples": [">>> pd.array(['This is', 'some text', None, 'data.'], dtype=\"string[pyarrow]\")\n<ArrowStringArray>\n['This is', 'some text', <NA>, 'data.']\nLength: 4, dtype: string\n"], "Parameters": [["values pyarrow.Array or pyarrow.ChunkedArray", "The array of data."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 370}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.BooleanArray.html#pandas.arrays.BooleanArray"], "Title": ["arrays.BooleanArray"], "Feature": ["arrays.BooleanArray"], "Description": "Array of boolean (True/False) data with missing values.\nThis is a pandas Extension array for boolean data, under the hood\nrepresented by 2 numpy arrays: a boolean array with the data and\na boolean array with the mask (True indicating missing).\nBooleanArray implements Kleene logic (sometimes called three-value\nlogic) for logical operations. SeeKleene logical operationsfor more.\nTo construct an BooleanArray from generic array-like input, usepandas.array()specifyingdtype=\"boolean\"(see examples\nbelow).\nWarningBooleanArray is considered experimental. The implementation and\nparts of the API may change without warning.\nAttributes\nMethods", "Examples": [">>> pd.array([True, False, None], dtype=\"boolean\")\n<BooleanArray>\n[True, False, <NA>]\nLength: 3, dtype: boolean\n"], "Parameters": [["values numpy.ndarray", "A 1-d boolean-dtype array with the data."], ["mask numpy.ndarray", "A 1-d boolean-dtype array indicating missing values (True\nindicates missing)."], ["copy bool, default False", "Whether to copy the values and mask arrays."]], "Returns": [["BooleanArray", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 372}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.union_categoricals.html#pandas.api.types.union_categoricals"], "Title": ["api.types.union_categoricals"], "Feature": ["api.types.union_categoricals"], "Description": "Combine list-like of Categorical-like, unioning categories.\nAll categories must have the same dtype.\nNotes\nTo learn more about categories, seelink", "Examples": [">>> a = pd.Categorical([\"b\", \"c\"])\n>>> b = pd.Categorical([\"a\", \"b\"])\n>>> pd.api.types.union_categoricals([a, b])\n['b', 'c', 'a', 'b']\nCategories (3, object): ['b', 'c', 'a']\n"], "Parameters": [["to_union list-like", "Categorical, CategoricalIndex, or Series with dtype=’category’."], ["sort_categories bool, default False", "If true, resulting categories will be lexsorted, otherwise\nthey will be ordered as they appear in the data."], ["ignore_order bool, default False", "If true, the ordered attribute of the Categoricals will be ignored.\nResults in an unordered categorical."]], "Returns": [["Categorical", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 374}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.infer_dtype.html#pandas.api.types.infer_dtype"], "Title": ["api.types.infer_dtype"], "Feature": ["api.types.infer_dtype"], "Description": "Return a string label of the type of a scalar or list-like of values.\nNotes\n‘mixed’ is the catchall for anything that is not otherwise\nspecialized‘mixed-integer-float’ are floats and integers‘mixed-integer’ are integers mixed with non-integers‘unknown-array’ is the catchall for something thatisan array (has\na dtype attribute), but has a dtype unknown to pandas (e.g. external\nextension array)", "Examples": [">>> from pandas.api.types import infer_dtype\n>>> infer_dtype(['foo', 'bar'])\n'string'\n"], "Parameters": [["value scalar, list, ndarray, or pandas type", ""], ["skipna bool, default True", "Ignore NaN values when inferring the type."]], "Returns": [["str", "Describing the common type of the input data."], ["Results can include:", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 375}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.pandas_dtype.html#pandas.api.types.pandas_dtype"], "Title": ["api.types.pandas_dtype"], "Feature": ["api.types.pandas_dtype"], "Description": "Convert input into a pandas only dtype object or a numpy dtype object.", "Examples": [">>> pd.api.types.pandas_dtype(int)\ndtype('int64')\n"], "Parameters": [["dtype object to be converted", ""]], "Returns": [["np.dtype or a pandas dtype", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 376}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_any_real_numeric_dtype.html#pandas.api.types.is_any_real_numeric_dtype"], "Title": ["api.types.is_any_real_numeric_dtype"], "Feature": ["api.types.is_any_real_numeric_dtype"], "Description": "Check whether the provided array or dtype is of a real number dtype.", "Examples": [">>> from pandas.api.types import is_any_real_numeric_dtype\n>>> is_any_real_numeric_dtype(int)\nTrue\n>>> is_any_real_numeric_dtype(float)\nTrue\n>>> is_any_real_numeric_dtype(object)\nFalse\n>>> is_any_real_numeric_dtype(str)\nFalse\n>>> is_any_real_numeric_dtype(complex(1, 2))\nFalse\n>>> is_any_real_numeric_dtype(bool)\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of a real number dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 377}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool_dtype.html#pandas.api.types.is_bool_dtype"], "Title": ["api.types.is_bool_dtype"], "Feature": ["api.types.is_bool_dtype"], "Description": "Check whether the provided array or dtype is of a boolean dtype.\nNotes\nAn ExtensionArray is considered boolean when the_is_booleanattribute is set to True.", "Examples": [">>> from pandas.api.types import is_bool_dtype\n>>> is_bool_dtype(str)\nFalse\n>>> is_bool_dtype(int)\nFalse\n>>> is_bool_dtype(bool)\nTrue\n>>> is_bool_dtype(np.bool_)\nTrue\n>>> is_bool_dtype(np.array(['a', 'b']))\nFalse\n>>> is_bool_dtype(pd.Series([1, 2]))\nFalse\n>>> is_bool_dtype(np.array([True, False]))\nTrue\n>>> is_bool_dtype(pd.Categorical([True, False]))\nTrue\n>>> is_bool_dtype(pd.arrays.SparseArray([True, False]))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of a boolean dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 378}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_quarter_start.html#pandas.Timestamp.is_quarter_start"], "Title": ["Timestamp.is_quarter_start"], "Feature": ["Timestamp.is_quarter_start"], "Description": "Check if the date is the first day of the quarter.\nSee alsoTimestamp.is_quarter_endSimilar property indicating the quarter end.Timestamp.quarterReturn the quarter of the date.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_quarter_start\nFalse\n"], "Parameters": [], "Returns": [["bool", "True if date is first day of the quarter."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 379}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_categorical_dtype.html#pandas.api.types.is_categorical_dtype"], "Title": ["api.types.is_categorical_dtype"], "Feature": ["api.types.is_categorical_dtype"], "Description": "Check whether an array-like or dtype is of the Categorical dtype.\nDeprecated since version 2.2.0:Use isinstance(dtype, pd.CategoricalDtype) instead.", "Examples": [">>> from pandas.api.types import is_categorical_dtype\n>>> from pandas import CategoricalDtype\n>>> is_categorical_dtype(object)\nFalse\n>>> is_categorical_dtype(CategoricalDtype())\nTrue\n>>> is_categorical_dtype([1, 2, 3])\nFalse\n>>> is_categorical_dtype(pd.Categorical([1, 2, 3]))\nTrue\n>>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of the Categorical dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 380}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex_dtype.html#pandas.api.types.is_complex_dtype"], "Title": ["api.types.is_complex_dtype"], "Feature": ["api.types.is_complex_dtype"], "Description": "Check whether the provided array or dtype is of a complex dtype.", "Examples": [">>> from pandas.api.types import is_complex_dtype\n>>> is_complex_dtype(str)\nFalse\n>>> is_complex_dtype(int)\nFalse\n>>> is_complex_dtype(np.complex128)\nTrue\n>>> is_complex_dtype(np.array(['a', 'b']))\nFalse\n>>> is_complex_dtype(pd.Series([1, 2]))\nFalse\n>>> is_complex_dtype(np.array([1 + 1j, 5]))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of a complex dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 381}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_any_dtype.html#pandas.api.types.is_datetime64_any_dtype"], "Title": ["api.types.is_datetime64_any_dtype"], "Feature": ["api.types.is_datetime64_any_dtype"], "Description": "Check whether the provided array or dtype is of the datetime64 dtype.", "Examples": [">>> from pandas.api.types import is_datetime64_any_dtype\n>>> from pandas.core.dtypes.dtypes import DatetimeTZDtype\n>>> is_datetime64_any_dtype(str)\nFalse\n>>> is_datetime64_any_dtype(int)\nFalse\n>>> is_datetime64_any_dtype(np.datetime64)  # can be tz-naive\nTrue\n>>> is_datetime64_any_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\nTrue\n>>> is_datetime64_any_dtype(np.array(['a', 'b']))\nFalse\n>>> is_datetime64_any_dtype(np.array([1, 2]))\nFalse\n>>> is_datetime64_any_dtype(np.array([], dtype=\"datetime64[ns]\"))\nTrue\n>>> is_datetime64_any_dtype(pd.DatetimeIndex([1, 2, 3], dtype=\"datetime64[ns]\"))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["bool", "Whether or not the array or dtype is of the datetime64 dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 382}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_dtype.html#pandas.api.types.is_datetime64_dtype"], "Title": ["api.types.is_datetime64_dtype"], "Feature": ["api.types.is_datetime64_dtype"], "Description": "Check whether an array-like or dtype is of the datetime64 dtype.", "Examples": [">>> from pandas.api.types import is_datetime64_dtype\n>>> is_datetime64_dtype(object)\nFalse\n>>> is_datetime64_dtype(np.datetime64)\nTrue\n>>> is_datetime64_dtype(np.array([], dtype=int))\nFalse\n>>> is_datetime64_dtype(np.array([], dtype=np.datetime64))\nTrue\n>>> is_datetime64_dtype([1, 2, 3])\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of the datetime64 dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 383}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64_ns_dtype.html#pandas.api.types.is_datetime64_ns_dtype"], "Title": ["api.types.is_datetime64_ns_dtype"], "Feature": ["api.types.is_datetime64_ns_dtype"], "Description": "Check whether the provided array or dtype is of the datetime64[ns] dtype.", "Examples": [">>> from pandas.api.types import is_datetime64_ns_dtype\n>>> from pandas.core.dtypes.dtypes import DatetimeTZDtype\n>>> is_datetime64_ns_dtype(str)\nFalse\n>>> is_datetime64_ns_dtype(int)\nFalse\n>>> is_datetime64_ns_dtype(np.datetime64)  # no unit\nFalse\n>>> is_datetime64_ns_dtype(DatetimeTZDtype(\"ns\", \"US/Eastern\"))\nTrue\n>>> is_datetime64_ns_dtype(np.array(['a', 'b']))\nFalse\n>>> is_datetime64_ns_dtype(np.array([1, 2]))\nFalse\n>>> is_datetime64_ns_dtype(np.array([], dtype=\"datetime64\"))  # no unit\nFalse\n>>> is_datetime64_ns_dtype(np.array([], dtype=\"datetime64[ps]\"))  # wrong unit\nFalse\n>>> is_datetime64_ns_dtype(pd.DatetimeIndex([1, 2, 3], dtype=\"datetime64[ns]\"))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["bool", "Whether or not the array or dtype is of the datetime64[ns] dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 384}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_datetime64tz_dtype.html#pandas.api.types.is_datetime64tz_dtype"], "Title": ["api.types.is_datetime64tz_dtype"], "Feature": ["api.types.is_datetime64tz_dtype"], "Description": "Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\nDeprecated since version 2.1.0:Use isinstance(dtype, pd.DatetimeTZDtype) instead.", "Examples": [">>> from pandas.api.types import is_datetime64tz_dtype\n>>> is_datetime64tz_dtype(object)\nFalse\n>>> is_datetime64tz_dtype([1, 2, 3])\nFalse\n>>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive\nFalse\n>>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of a DatetimeTZDtype dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 385}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_extension_array_dtype.html#pandas.api.types.is_extension_array_dtype"], "Title": ["api.types.is_extension_array_dtype"], "Feature": ["api.types.is_extension_array_dtype"], "Description": "Check if an object is a pandas extension array type.\nSee theUse Guidefor more.\nNotes\nThis checks whether an object implements the pandas extension\narray interface. In pandas, this includes:\nCategoricalSparseIntervalPeriodDatetimeArrayTimedeltaArray\nThird-party libraries may implement arrays or types satisfying\nthis interface as well.", "Examples": [">>> from pandas.api.types import is_extension_array_dtype\n>>> arr = pd.Categorical(['a', 'b'])\n>>> is_extension_array_dtype(arr)\nTrue\n>>> is_extension_array_dtype(arr.dtype)\nTrue\n"], "Parameters": [["arr_or_dtype object", "For array-like input, the .dtype attribute will\nbe extracted."]], "Returns": [["bool", "Whether the arr_or_dtype is an extension array type."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 386}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float_dtype.html#pandas.api.types.is_float_dtype"], "Title": ["api.types.is_float_dtype"], "Feature": ["api.types.is_float_dtype"], "Description": "Check whether the provided array or dtype is of a float dtype.", "Examples": [">>> from pandas.api.types import is_float_dtype\n>>> is_float_dtype(str)\nFalse\n>>> is_float_dtype(int)\nFalse\n>>> is_float_dtype(float)\nTrue\n>>> is_float_dtype(np.array(['a', 'b']))\nFalse\n>>> is_float_dtype(pd.Series([1, 2]))\nFalse\n>>> is_float_dtype(pd.Index([1, 2.]))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of a float dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 387}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_int64_dtype.html#pandas.api.types.is_int64_dtype"], "Title": ["api.types.is_int64_dtype"], "Feature": ["api.types.is_int64_dtype"], "Description": "Check whether the provided array or dtype is of the int64 dtype.\nDeprecated since version 2.1.0:is_int64_dtype is deprecated and will be removed in a future\nversion. Use dtype == np.int64 instead.\nNotes\nDepending on system architecture, the return value ofis_int64_dtype(\nint)will be True if the OS uses 64-bit integers and False if the OS\nuses 32-bit integers.", "Examples": [">>> from pandas.api.types import is_int64_dtype\n>>> is_int64_dtype(str)  \nFalse\n>>> is_int64_dtype(np.int32)  \nFalse\n>>> is_int64_dtype(np.int64)  \nTrue\n>>> is_int64_dtype('int8')  \nFalse\n>>> is_int64_dtype('Int8')  \nFalse\n>>> is_int64_dtype(pd.Int64Dtype)  \nTrue\n>>> is_int64_dtype(float)  \nFalse\n>>> is_int64_dtype(np.uint64)  # unsigned  \nFalse\n>>> is_int64_dtype(np.array(['a', 'b']))  \nFalse\n>>> is_int64_dtype(np.array([1, 2], dtype=np.int64))  \nTrue\n>>> is_int64_dtype(pd.Index([1, 2.]))  # float  \nFalse\n>>> is_int64_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned  \nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of the int64 dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 388}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer_dtype.html#pandas.api.types.is_integer_dtype"], "Title": ["api.types.is_integer_dtype"], "Feature": ["api.types.is_integer_dtype"], "Description": "Check whether the provided array or dtype is of an integer dtype.\nUnlike inis_any_int_dtype, timedelta64 instances will return False.\nThe nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\nas integer by this function.", "Examples": [">>> from pandas.api.types import is_integer_dtype\n>>> is_integer_dtype(str)\nFalse\n>>> is_integer_dtype(int)\nTrue\n>>> is_integer_dtype(float)\nFalse\n>>> is_integer_dtype(np.uint64)\nTrue\n>>> is_integer_dtype('int8')\nTrue\n>>> is_integer_dtype('Int8')\nTrue\n>>> is_integer_dtype(pd.Int8Dtype)\nTrue\n>>> is_integer_dtype(np.datetime64)\nFalse\n>>> is_integer_dtype(np.timedelta64)\nFalse\n>>> is_integer_dtype(np.array(['a', 'b']))\nFalse\n>>> is_integer_dtype(pd.Series([1, 2]))\nTrue\n>>> is_integer_dtype(np.array([], dtype=np.timedelta64))\nFalse\n>>> is_integer_dtype(pd.Index([1, 2.]))  # float\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of an integer dtype and\nnot an instance of timedelta64."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 389}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_end.html#pandas.Timestamp.is_year_end"], "Title": ["Timestamp.is_year_end"], "Feature": ["Timestamp.is_year_end"], "Description": "Return True if date is last day of the year.\nSee alsoTimestamp.is_year_startSimilar property indicating the start of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_year_end\nFalse\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 390}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval_dtype.html#pandas.api.types.is_interval_dtype"], "Title": ["api.types.is_interval_dtype"], "Feature": ["api.types.is_interval_dtype"], "Description": "Check whether an array-like or dtype is of the Interval dtype.\nDeprecated since version 2.2.0:Use isinstance(dtype, pd.IntervalDtype) instead.", "Examples": [">>> from pandas.core.dtypes.common import is_interval_dtype\n>>> is_interval_dtype(object)\nFalse\n>>> is_interval_dtype(pd.IntervalDtype())\nTrue\n>>> is_interval_dtype([1, 2, 3])\nFalse\n>>>\n>>> interval = pd.Interval(1, 2, closed=\"right\")\n>>> is_interval_dtype(interval)\nFalse\n>>> is_interval_dtype(pd.IntervalIndex([interval]))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of the Interval dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 391}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html#pandas.api.types.is_numeric_dtype"], "Title": ["api.types.is_numeric_dtype"], "Feature": ["api.types.is_numeric_dtype"], "Description": "Check whether the provided array or dtype is of a numeric dtype.", "Examples": [">>> from pandas.api.types import is_numeric_dtype\n>>> is_numeric_dtype(str)\nFalse\n>>> is_numeric_dtype(int)\nTrue\n>>> is_numeric_dtype(float)\nTrue\n>>> is_numeric_dtype(np.uint64)\nTrue\n>>> is_numeric_dtype(np.datetime64)\nFalse\n>>> is_numeric_dtype(np.timedelta64)\nFalse\n>>> is_numeric_dtype(np.array(['a', 'b']))\nFalse\n>>> is_numeric_dtype(pd.Series([1, 2]))\nTrue\n>>> is_numeric_dtype(pd.Index([1, 2.]))\nTrue\n>>> is_numeric_dtype(np.array([], dtype=np.timedelta64))\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of a numeric dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 392}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_object_dtype.html#pandas.api.types.is_object_dtype"], "Title": ["api.types.is_object_dtype"], "Feature": ["api.types.is_object_dtype"], "Description": "Check whether an array-like or dtype is of the object dtype.", "Examples": [">>> from pandas.api.types import is_object_dtype\n>>> is_object_dtype(object)\nTrue\n>>> is_object_dtype(int)\nFalse\n>>> is_object_dtype(np.array([], dtype=object))\nTrue\n>>> is_object_dtype(np.array([], dtype=int))\nFalse\n>>> is_object_dtype([1, 2, 3])\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of the object dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 393}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_period_dtype.html#pandas.api.types.is_period_dtype"], "Title": ["api.types.is_period_dtype"], "Feature": ["api.types.is_period_dtype"], "Description": "Check whether an array-like or dtype is of the Period dtype.\nDeprecated since version 2.2.0:Use isinstance(dtype, pd.Period) instead.", "Examples": [">>> from pandas.core.dtypes.common import is_period_dtype\n>>> is_period_dtype(object)\nFalse\n>>> is_period_dtype(pd.PeriodDtype(freq=\"D\"))\nTrue\n>>> is_period_dtype([1, 2, 3])\nFalse\n>>> is_period_dtype(pd.Period(\"2017-01-01\"))\nFalse\n>>> is_period_dtype(pd.PeriodIndex([], freq=\"Y\"))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of the Period dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 394}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_signed_integer_dtype.html#pandas.api.types.is_signed_integer_dtype"], "Title": ["api.types.is_signed_integer_dtype"], "Feature": ["api.types.is_signed_integer_dtype"], "Description": "Check whether the provided array or dtype is of a signed integer dtype.\nUnlike inis_any_int_dtype, timedelta64 instances will return False.\nThe nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\nas integer by this function.", "Examples": [">>> from pandas.core.dtypes.common import is_signed_integer_dtype\n>>> is_signed_integer_dtype(str)\nFalse\n>>> is_signed_integer_dtype(int)\nTrue\n>>> is_signed_integer_dtype(float)\nFalse\n>>> is_signed_integer_dtype(np.uint64)  # unsigned\nFalse\n>>> is_signed_integer_dtype('int8')\nTrue\n>>> is_signed_integer_dtype('Int8')\nTrue\n>>> is_signed_integer_dtype(pd.Int8Dtype)\nTrue\n>>> is_signed_integer_dtype(np.datetime64)\nFalse\n>>> is_signed_integer_dtype(np.timedelta64)\nFalse\n>>> is_signed_integer_dtype(np.array(['a', 'b']))\nFalse\n>>> is_signed_integer_dtype(pd.Series([1, 2]))\nTrue\n>>> is_signed_integer_dtype(np.array([], dtype=np.timedelta64))\nFalse\n>>> is_signed_integer_dtype(pd.Index([1, 2.]))  # float\nFalse\n>>> is_signed_integer_dtype(np.array([1, 2], dtype=np.uint32))  # unsigned\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of a signed integer dtype\nand not an instance of timedelta64."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 395}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_string_dtype.html#pandas.api.types.is_string_dtype"], "Title": ["api.types.is_string_dtype"], "Feature": ["api.types.is_string_dtype"], "Description": "Check whether the provided array or dtype is of the string dtype.\nIf an array is passed with an object dtype, the elements must be\ninferred as strings.", "Examples": [">>> from pandas.api.types import is_string_dtype\n>>> is_string_dtype(str)\nTrue\n>>> is_string_dtype(object)\nTrue\n>>> is_string_dtype(int)\nFalse\n>>> is_string_dtype(np.array(['a', 'b']))\nTrue\n>>> is_string_dtype(pd.Series([1, 2]))\nFalse\n>>> is_string_dtype(pd.Series([1, 2], dtype=object))\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of the string dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 396}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_dtype.html#pandas.api.types.is_timedelta64_dtype"], "Title": ["api.types.is_timedelta64_dtype"], "Feature": ["api.types.is_timedelta64_dtype"], "Description": "Check whether an array-like or dtype is of the timedelta64 dtype.", "Examples": [">>> from pandas.core.dtypes.common import is_timedelta64_dtype\n>>> is_timedelta64_dtype(object)\nFalse\n>>> is_timedelta64_dtype(np.timedelta64)\nTrue\n>>> is_timedelta64_dtype([1, 2, 3])\nFalse\n>>> is_timedelta64_dtype(pd.Series([], dtype=\"timedelta64[ns]\"))\nTrue\n>>> is_timedelta64_dtype('0 days')\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array-like or dtype to check."]], "Returns": [["boolean", "Whether or not the array-like or dtype is of the timedelta64 dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 397}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_timedelta64_ns_dtype.html#pandas.api.types.is_timedelta64_ns_dtype"], "Title": ["api.types.is_timedelta64_ns_dtype"], "Feature": ["api.types.is_timedelta64_ns_dtype"], "Description": "Check whether the provided array or dtype is of the timedelta64[ns] dtype.\nThis is a very specific dtype, so generic ones likenp.timedelta64will return False if passed into this function.", "Examples": [">>> from pandas.core.dtypes.common import is_timedelta64_ns_dtype\n>>> is_timedelta64_ns_dtype(np.dtype('m8[ns]'))\nTrue\n>>> is_timedelta64_ns_dtype(np.dtype('m8[ps]'))  # Wrong frequency\nFalse\n>>> is_timedelta64_ns_dtype(np.array([1, 2], dtype='m8[ns]'))\nTrue\n>>> is_timedelta64_ns_dtype(np.array([1, 2], dtype=np.timedelta64))\nFalse\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of the timedelta64[ns] dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 398}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_unsigned_integer_dtype.html#pandas.api.types.is_unsigned_integer_dtype"], "Title": ["api.types.is_unsigned_integer_dtype"], "Feature": ["api.types.is_unsigned_integer_dtype"], "Description": "Check whether the provided array or dtype is of an unsigned integer dtype.\nThe nullable Integer dtypes (e.g. pandas.UInt64Dtype) are also\nconsidered as integer by this function.", "Examples": [">>> from pandas.api.types import is_unsigned_integer_dtype\n>>> is_unsigned_integer_dtype(str)\nFalse\n>>> is_unsigned_integer_dtype(int)  # signed\nFalse\n>>> is_unsigned_integer_dtype(float)\nFalse\n>>> is_unsigned_integer_dtype(np.uint64)\nTrue\n>>> is_unsigned_integer_dtype('uint8')\nTrue\n>>> is_unsigned_integer_dtype('UInt8')\nTrue\n>>> is_unsigned_integer_dtype(pd.UInt8Dtype)\nTrue\n>>> is_unsigned_integer_dtype(np.array(['a', 'b']))\nFalse\n>>> is_unsigned_integer_dtype(pd.Series([1, 2]))  # signed\nFalse\n>>> is_unsigned_integer_dtype(pd.Index([1, 2.]))  # float\nFalse\n>>> is_unsigned_integer_dtype(np.array([1, 2], dtype=np.uint32))\nTrue\n"], "Parameters": [["arr_or_dtype array-like or dtype", "The array or dtype to check."]], "Returns": [["boolean", "Whether or not the array or dtype is of an unsigned integer dtype."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 399}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_sparse.html#pandas.api.types.is_sparse"], "Title": ["api.types.is_sparse"], "Feature": ["api.types.is_sparse"], "Description": "Check whether an array-like is a 1-D pandas sparse array.\nDeprecated since version 2.1.0:Use isinstance(dtype, pd.SparseDtype) instead.\nCheck that the one-dimensional array-like is a pandas sparse array.\nReturns True if it is a pandas sparse array, not another type of\nsparse array.", "Examples": [">>> from pandas.api.types import is_sparse\n>>> is_sparse(pd.arrays.SparseArray([0, 0, 1, 0]))\nTrue\n>>> is_sparse(pd.Series(pd.arrays.SparseArray([0, 0, 1, 0])))\nTrue\n"], "Parameters": [["arr array-like", "Array-like to check."]], "Returns": [["bool", "Whether or not the array-like is a pandas sparse array."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 400}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.is_year_start.html#pandas.Timestamp.is_year_start"], "Title": ["Timestamp.is_year_start"], "Feature": ["Timestamp.is_year_start"], "Description": "Return True if date is first day of the year.\nSee alsoTimestamp.is_year_endSimilar property indicating the end of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.is_year_start\nFalse\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 402}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_dict_like.html#pandas.api.types.is_dict_like"], "Title": ["api.types.is_dict_like"], "Feature": ["api.types.is_dict_like"], "Description": "Check if the object is dict-like.", "Examples": [">>> from pandas.api.types import is_dict_like\n>>> is_dict_like({1: 2})\nTrue\n>>> is_dict_like([1, 2, 3])\nFalse\n>>> is_dict_like(dict)\nFalse\n>>> is_dict_like(dict())\nTrue\n"], "Parameters": [["obj The object to check", ""]], "Returns": [["bool", "Whether obj has dict-like properties."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 403}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_file_like.html#pandas.api.types.is_file_like"], "Title": ["api.types.is_file_like"], "Feature": ["api.types.is_file_like"], "Description": "Check if the object is a file-like object.\nFor objects to be considered file-like, they must\nbe an iterator AND have either areadand/orwritemethod as an attribute.\nNote: file-like objects must be iterable, but\niterable objects need not be file-like.", "Examples": [">>> import io\n>>> from pandas.api.types import is_file_like\n>>> buffer = io.StringIO(\"data\")\n>>> is_file_like(buffer)\nTrue\n>>> is_file_like([1, 2, 3])\nFalse\n"], "Parameters": [["obj The object to check", ""]], "Returns": [["bool", "Whether obj has file-like properties."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 404}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_list_like.html#pandas.api.types.is_list_like"], "Title": ["api.types.is_list_like"], "Feature": ["api.types.is_list_like"], "Description": "Check if the object is list-like.\nObjects that are considered list-like are for example Python\nlists, tuples, sets, NumPy arrays, and Pandas Series.\nStrings and datetime objects, however, are not considered list-like.", "Examples": [">>> import datetime\n>>> from pandas.api.types import is_list_like\n>>> is_list_like([1, 2, 3])\nTrue\n>>> is_list_like({1, 2, 3})\nTrue\n>>> is_list_like(datetime.datetime(2017, 1, 1))\nFalse\n>>> is_list_like(\"foo\")\nFalse\n>>> is_list_like(1)\nFalse\n>>> is_list_like(np.array([2]))\nTrue\n>>> is_list_like(np.array(2))\nFalse\n"], "Parameters": [["obj object", "Object to check."], ["allow_sets bool, default True", "If this parameter is False, sets will not be considered list-like."]], "Returns": [["bool", "Whether obj has list-like properties."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 405}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_named_tuple.html#pandas.api.types.is_named_tuple"], "Title": ["api.types.is_named_tuple"], "Feature": ["api.types.is_named_tuple"], "Description": "Check if the object is a named tuple.", "Examples": [">>> from collections import namedtuple\n>>> from pandas.api.types import is_named_tuple\n>>> Point = namedtuple(\"Point\", [\"x\", \"y\"])\n>>> p = Point(1, 2)\n>>>\n>>> is_named_tuple(p)\nTrue\n>>> is_named_tuple((1, 2))\nFalse\n"], "Parameters": [["obj The object to check", ""]], "Returns": [["bool", "Whether obj is a named tuple."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 406}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_iterator.html#pandas.api.types.is_iterator"], "Title": ["api.types.is_iterator"], "Feature": ["api.types.is_iterator"], "Description": "Check if the object is an iterator.\nThis is intended for generators, not list-like objects.", "Examples": [">>> import datetime\n>>> from pandas.api.types import is_iterator\n>>> is_iterator((x for x in []))\nTrue\n>>> is_iterator([1, 2, 3])\nFalse\n>>> is_iterator(datetime.datetime(2017, 1, 1))\nFalse\n>>> is_iterator(\"foo\")\nFalse\n>>> is_iterator(1)\nFalse\n"], "Parameters": [["obj The object to check", ""]], "Returns": [["is_iter bool", "Whether obj is an iterator."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 407}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_bool.html#pandas.api.types.is_bool"], "Title": ["api.types.is_bool"], "Feature": ["api.types.is_bool"], "Description": "Return True if given object is boolean.", "Examples": [">>> pd.api.types.is_bool(True)\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 408}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_complex.html#pandas.api.types.is_complex"], "Title": ["api.types.is_complex"], "Feature": ["api.types.is_complex"], "Description": "Return True if given object is complex.", "Examples": [">>> pd.api.types.is_complex(1 + 1j)\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 409}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_float.html#pandas.api.types.is_float"], "Title": ["api.types.is_float"], "Feature": ["api.types.is_float"], "Description": "Return True if given object is float.", "Examples": [">>> pd.api.types.is_float(1.0)\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 410}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_hashable.html#pandas.api.types.is_hashable"], "Title": ["api.types.is_hashable"], "Feature": ["api.types.is_hashable"], "Description": "Return True if hash(obj) will succeed, False otherwise.\nSome types will pass a test against collections.abc.Hashable but fail when\nthey are actually hashed with hash().\nDistinguish between these and other types by trying the call to hash() and\nseeing if they raise TypeError.", "Examples": [">>> import collections\n>>> from pandas.api.types import is_hashable\n>>> a = ([],)\n>>> isinstance(a, collections.abc.Hashable)\nTrue\n>>> is_hashable(a)\nFalse\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 411}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_integer.html#pandas.api.types.is_integer"], "Title": ["api.types.is_integer"], "Feature": ["api.types.is_integer"], "Description": "Return True if given object is integer.", "Examples": [">>> pd.api.types.is_integer(1)\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 412}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.max.html#pandas.Timestamp.max"], "Title": ["Timestamp.max"], "Feature": ["Timestamp.max"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 413}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_interval.html#pandas.api.types.is_interval"], "Title": ["api.types.is_interval"], "Feature": ["api.types.is_interval"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 414}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_number.html#pandas.api.types.is_number"], "Title": ["api.types.is_number"], "Feature": ["api.types.is_number"], "Description": "Check if the object is a number.\nReturns True when the object is a number, and False if is not.\nSee alsoapi.types.is_integerChecks a subgroup of numbers.", "Examples": [">>> from pandas.api.types import is_number\n>>> is_number(1)\nTrue\n>>> is_number(7.15)\nTrue\n"], "Parameters": [["obj any type", "The object to check if is a number."]], "Returns": [["bool", "Whether obj is a number or not."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 415}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re.html#pandas.api.types.is_re"], "Title": ["api.types.is_re"], "Feature": ["api.types.is_re"], "Description": "Check if the object is a regex pattern instance.", "Examples": [">>> from pandas.api.types import is_re\n>>> import re\n>>> is_re(re.compile(\".*\"))\nTrue\n>>> is_re(\"foo\")\nFalse\n"], "Parameters": [["obj The object to check", ""]], "Returns": [["bool", "Whether obj is a regex pattern."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 416}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_re_compilable.html#pandas.api.types.is_re_compilable"], "Title": ["api.types.is_re_compilable"], "Feature": ["api.types.is_re_compilable"], "Description": "Check if the object can be compiled into a regex pattern instance.", "Examples": [">>> from pandas.api.types import is_re_compilable\n>>> is_re_compilable(\".*\")\nTrue\n>>> is_re_compilable(1)\nFalse\n"], "Parameters": [["obj The object to check", ""]], "Returns": [["bool", "Whether obj can be compiled as a regex pattern."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 417}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_scalar.html#pandas.api.types.is_scalar"], "Title": ["api.types.is_scalar"], "Feature": ["api.types.is_scalar"], "Description": "Return True if given object is scalar.", "Examples": [">>> import datetime\n>>> dt = datetime.datetime(2018, 10, 3)\n>>> pd.api.types.is_scalar(dt)\nTrue\n"], "Parameters": [["val object", "This includes: numpy array scalar (e.g. np.int64) Python builtin numerics Python builtin byte arrays and strings None datetime.datetime datetime.timedelta Period decimal.Decimal Interval DateOffset Fraction Number."]], "Returns": [["bool", "Return True if given object is scalar."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 418}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.microsecond.html#pandas.Timestamp.microsecond"], "Title": ["Timestamp.microsecond"], "Feature": ["Timestamp.microsecond"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 419}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.min.html#pandas.Timestamp.min"], "Title": ["Timestamp.min"], "Feature": ["Timestamp.min"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 420}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.minute.html#pandas.Timestamp.minute"], "Title": ["Timestamp.minute"], "Feature": ["Timestamp.minute"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 421}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.month.html#pandas.Timestamp.month"], "Title": ["Timestamp.month"], "Feature": ["Timestamp.month"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 422}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.nanosecond.html#pandas.Timestamp.nanosecond"], "Title": ["Timestamp.nanosecond"], "Feature": ["Timestamp.nanosecond"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 423}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.quarter.html#pandas.Timestamp.quarter"], "Title": ["Timestamp.quarter"], "Feature": ["Timestamp.quarter"], "Description": "Return the quarter of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.quarter\n1\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 424}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.resolution.html#pandas.Timestamp.resolution"], "Title": ["Timestamp.resolution"], "Feature": ["Timestamp.resolution"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 425}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.second.html#pandas.Timestamp.second"], "Title": ["Timestamp.second"], "Feature": ["Timestamp.second"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 426}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz.html#pandas.Timestamp.tz"], "Title": ["Timestamp.tz"], "Feature": ["Timestamp.tz"], "Description": "Alias for tzinfo.", "Examples": [">>> ts = pd.Timestamp(1584226800, unit='s', tz='Europe/Stockholm')\n>>> ts.tz\n<DstTzInfo 'Europe/Stockholm' CET+1:00:00 STD>\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 428}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tzinfo.html#pandas.Timestamp.tzinfo"], "Title": ["Timestamp.tzinfo"], "Feature": ["Timestamp.tzinfo"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 429}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.unit.html#pandas.Timestamp.unit"], "Title": ["Timestamp.unit"], "Feature": ["Timestamp.unit"], "Description": "The abbreviation associated with self._creso.", "Examples": [">>> pd.Timestamp(\"2020-01-01 12:34:56\").unit\n's'\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 430}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.value.html#pandas.Timestamp.value"], "Title": ["Timestamp.value"], "Feature": ["Timestamp.value"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 431}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.week.html#pandas.Timestamp.week"], "Title": ["Timestamp.week"], "Feature": ["Timestamp.week"], "Description": "Return the week number of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.week\n11\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 432}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekofyear.html#pandas.Timestamp.weekofyear"], "Title": ["Timestamp.weekofyear"], "Feature": ["Timestamp.weekofyear"], "Description": "Return the week number of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.week\n11\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 433}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.year.html#pandas.Timestamp.year"], "Title": ["Timestamp.year"], "Feature": ["Timestamp.year"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 434}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.as_unit.html#pandas.Timestamp.as_unit"], "Title": ["Timestamp.as_unit"], "Feature": ["Timestamp.as_unit"], "Description": "Convert the underlying int64 representaton to the given unit.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 00:00:00.01')\n>>> ts\nTimestamp('2023-01-01 00:00:00.010000')\n>>> ts.unit\n'ms'\n>>> ts = ts.as_unit('s')\n>>> ts\nTimestamp('2023-01-01 00:00:00')\n>>> ts.unit\n's'\n"], "Parameters": [["unit {“ns”, “us”, “ms”, “s”}", ""], ["round_ok bool, default True", "If False and the conversion requires rounding, raise."]], "Returns": [["Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 435}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.astimezone.html#pandas.Timestamp.astimezone"], "Title": ["Timestamp.astimezone"], "Feature": ["Timestamp.astimezone"], "Description": "Convert timezone-aware Timestamp to another time zone.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651', tz='UTC')\n>>> ts\nTimestamp('2020-03-14 15:32:52.192548651+0000', tz='UTC')\n"], "Parameters": [["tz str, pytz.timezone, dateutil.tz.tzfile or None", "Time zone for time which Timestamp will be converted to.\nNone will remove timezone holding UTC time."]], "Returns": [["converted Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 436}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ceil.html#pandas.Timestamp.ceil"], "Title": ["Timestamp.ceil"], "Feature": ["Timestamp.ceil"], "Description": "Return a new Timestamp ceiled to this resolution.\nNotes\nIf the Timestamp has a timezone, ceiling will take place relative to the\nlocal (“wall”) time and re-localized to the same timezone. When ceiling\nnear daylight savings time, usenonexistentandambiguousto\ncontrol the re-localization behavior.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n"], "Parameters": [["freq str", "Frequency string indicating the ceiling resolution."], ["ambiguous bool or {‘raise’, ‘NaT’}, default ‘raise’", "The behavior is as follows: bool contains flags to determine if time is dst or not (note\nthat this flag is only applicable for ambiguous fall dst dates). ‘NaT’ will return NaT for an ambiguous time. ‘raise’ will raise an AmbiguousTimeError for an ambiguous time."], ["nonexistent {‘raise’, ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta}, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time. ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time. ‘NaT’ will return NaT where there are nonexistent times. timedelta objects will shift nonexistent times by the timedelta. ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 437}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.asm8.html#pandas.Timestamp.asm8"], "Title": ["Timestamp.asm8"], "Feature": ["Timestamp.asm8"], "Description": "Return numpy datetime64 format in nanoseconds.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14, 15)\n>>> ts.asm8\nnumpy.datetime64('2020-03-14T15:00:00.000000')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 438}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.combine.html#pandas.Timestamp.combine"], "Title": ["Timestamp.combine"], "Feature": ["Timestamp.combine"], "Description": "Combine date, time into datetime with same date and time fields.", "Examples": [">>> from datetime import date, time\n>>> pd.Timestamp.combine(date(2020, 3, 14), time(15, 30, 15))\nTimestamp('2020-03-14 15:30:15')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 439}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.ctime.html#pandas.Timestamp.ctime"], "Title": ["Timestamp.ctime"], "Feature": ["Timestamp.ctime"], "Description": "Return ctime() style string.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00.00')\n>>> ts\nTimestamp('2023-01-01 10:00:00')\n>>> ts.ctime()\n'Sun Jan  1 10:00:00 2023'\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 440}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.date.html#pandas.Timestamp.date"], "Title": ["Timestamp.date"], "Feature": ["Timestamp.date"], "Description": "Return date object with same year, month and day.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00.00')\n>>> ts\nTimestamp('2023-01-01 10:00:00')\n>>> ts.date()\ndatetime.date(2023, 1, 1)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 441}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_name.html#pandas.Timestamp.day_name"], "Title": ["Timestamp.day_name"], "Feature": ["Timestamp.day_name"], "Description": "Return the day name of the Timestamp with specified locale.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n>>> ts.day_name()\n'Saturday'\n"], "Parameters": [["locale str, default None (English locale)", "Locale determining the language in which to return the day name."]], "Returns": [["str", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 442}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dst.html#pandas.Timestamp.dst"], "Title": ["Timestamp.dst"], "Feature": ["Timestamp.dst"], "Description": "Return the daylight saving time (DST) adjustment.", "Examples": [">>> ts = pd.Timestamp('2000-06-01 00:00:00', tz='Europe/Brussels')\n>>> ts\nTimestamp('2000-06-01 00:00:00+0200', tz='Europe/Brussels')\n>>> ts.dst()\ndatetime.timedelta(seconds=3600)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 443}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.floor.html#pandas.Timestamp.floor"], "Title": ["Timestamp.floor"], "Feature": ["Timestamp.floor"], "Description": "Return a new Timestamp floored to this resolution.\nNotes\nIf the Timestamp has a timezone, flooring will take place relative to the\nlocal (“wall”) time and re-localized to the same timezone. When flooring\nnear daylight savings time, usenonexistentandambiguousto\ncontrol the re-localization behavior.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n"], "Parameters": [["freq str", "Frequency string indicating the flooring resolution."], ["ambiguous bool or {‘raise’, ‘NaT’}, default ‘raise’", "The behavior is as follows: bool contains flags to determine if time is dst or not (note\nthat this flag is only applicable for ambiguous fall dst dates). ‘NaT’ will return NaT for an ambiguous time. ‘raise’ will raise an AmbiguousTimeError for an ambiguous time."], ["nonexistent {‘raise’, ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta}, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time. ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time. ‘NaT’ will return NaT where there are nonexistent times. timedelta objects will shift nonexistent times by the timedelta. ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 444}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromordinal.html#pandas.Timestamp.fromordinal"], "Title": ["Timestamp.fromordinal"], "Feature": ["Timestamp.fromordinal"], "Description": "Construct a timestamp from a a proleptic Gregorian ordinal.\nNotes\nBy definition there cannot be any tz info on the ordinal itself.", "Examples": [">>> pd.Timestamp.fromordinal(737425)\nTimestamp('2020-01-01 00:00:00')\n"], "Parameters": [["ordinal int", "Date corresponding to a proleptic Gregorian ordinal."], ["tz str, pytz.timezone, dateutil.tz.tzfile or None", "Time zone for the Timestamp."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 445}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.fromtimestamp.html#pandas.Timestamp.fromtimestamp"], "Title": ["Timestamp.fromtimestamp"], "Feature": ["Timestamp.fromtimestamp"], "Description": "Transform timestamp[, tz] to tz’s local time from POSIX timestamp.", "Examples": [">>> pd.Timestamp.fromtimestamp(1584199972)  \nTimestamp('2020-03-14 15:32:52')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 446}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isocalendar.html#pandas.Timestamp.isocalendar"], "Title": ["Timestamp.isocalendar"], "Feature": ["Timestamp.isocalendar"], "Description": "Return a named tuple containing ISO year, week number, and weekday.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00')\n>>> ts\nTimestamp('2023-01-01 10:00:00')\n>>> ts.isocalendar()\ndatetime.IsoCalendarDate(year=2022, week=52, weekday=7)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 447}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoformat.html#pandas.Timestamp.isoformat"], "Title": ["Timestamp.isoformat"], "Feature": ["Timestamp.isoformat"], "Description": "Return the time formatted according to ISO 8601.\nThe full format looks like ‘YYYY-MM-DD HH:MM:SS.mmmmmmnnn’.\nBy default, the fractional part is omitted if self.microsecond == 0\nand self.nanosecond == 0.\nIf self.tzinfo is not None, the UTC offset is also attached, giving\ngiving a full format of ‘YYYY-MM-DD HH:MM:SS.mmmmmmnnn+HH:MM’.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n>>> ts.isoformat()\n'2020-03-14T15:32:52.192548651'\n>>> ts.isoformat(timespec='microseconds')\n'2020-03-14T15:32:52.192548'\n"], "Parameters": [["sep str, default ‘T’", "String used as the separator between the date and time."], ["timespec str, default ‘auto’", "Specifies the number of additional terms of the time to include.\nThe valid values are ‘auto’, ‘hours’, ‘minutes’, ‘seconds’,\n‘milliseconds’, ‘microseconds’, and ‘nanoseconds’."]], "Returns": [["str", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 448}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day.html#pandas.Timestamp.day"], "Title": ["Timestamp.day"], "Feature": ["Timestamp.day"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 449}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.isoweekday.html#pandas.Timestamp.isoweekday"], "Title": ["Timestamp.isoweekday"], "Feature": ["Timestamp.isoweekday"], "Description": "Return the day of the week represented by the date.\nMonday == 1 … Sunday == 7.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00')\n>>> ts\nTimestamp('2023-01-01 10:00:00')\n>>> ts.isoweekday()\n7\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 450}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.month_name.html#pandas.Timestamp.month_name"], "Title": ["Timestamp.month_name"], "Feature": ["Timestamp.month_name"], "Description": "Return the month name of the Timestamp with specified locale.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n>>> ts.month_name()\n'March'\n"], "Parameters": [["locale str, default None (English locale)", "Locale determining the language in which to return the month name."]], "Returns": [["str", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 451}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.normalize.html#pandas.Timestamp.normalize"], "Title": ["Timestamp.normalize"], "Feature": ["Timestamp.normalize"], "Description": "Normalize Timestamp to midnight, preserving tz information.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14, 15, 30)\n>>> ts.normalize()\nTimestamp('2020-03-14 00:00:00')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 452}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.now.html#pandas.Timestamp.now"], "Title": ["Timestamp.now"], "Feature": ["Timestamp.now"], "Description": "Return new Timestamp object representing current time local to tz.", "Examples": [">>> pd.Timestamp.now()  \nTimestamp('2020-11-16 22:06:16.378782')\n"], "Parameters": [["tz str or timezone object, default None", "Timezone to localize to."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 453}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.replace.html#pandas.Timestamp.replace"], "Title": ["Timestamp.replace"], "Feature": ["Timestamp.replace"], "Description": "Implements datetime.replace, handles nanoseconds.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651', tz='UTC')\n>>> ts\nTimestamp('2020-03-14 15:32:52.192548651+0000', tz='UTC')\n"], "Parameters": [["year int, optional", ""], ["month int, optional", ""], ["day int, optional", ""], ["hour int, optional", ""], ["minute int, optional", ""], ["second int, optional", ""], ["microsecond int, optional", ""], ["nanosecond int, optional", ""], ["tzinfo tz-convertible, optional", ""], ["fold int, optional", ""]], "Returns": [["Timestamp with fields replaced", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 454}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.round.html#pandas.Timestamp.round"], "Title": ["Timestamp.round"], "Feature": ["Timestamp.round"], "Description": "Round the Timestamp to the specified resolution.\nNotes\nIf the Timestamp has a timezone, rounding will take place relative to the\nlocal (“wall”) time and re-localized to the same timezone. When rounding\nnear daylight savings time, usenonexistentandambiguousto\ncontrol the re-localization behavior.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n"], "Parameters": [["freq str", "Frequency string indicating the rounding resolution."], ["ambiguous bool or {‘raise’, ‘NaT’}, default ‘raise’", "The behavior is as follows: bool contains flags to determine if time is dst or not (note\nthat this flag is only applicable for ambiguous fall dst dates). ‘NaT’ will return NaT for an ambiguous time. ‘raise’ will raise an AmbiguousTimeError for an ambiguous time."], ["nonexistent {‘raise’, ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta}, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time. ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time. ‘NaT’ will return NaT where there are nonexistent times. timedelta objects will shift nonexistent times by the timedelta. ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["a new Timestamp rounded to the given resolution of freq", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 455}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strftime.html#pandas.Timestamp.strftime"], "Title": ["Timestamp.strftime"], "Feature": ["Timestamp.strftime"], "Description": "Return a formatted string of the Timestamp.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n>>> ts.strftime('%Y-%m-%d %X')\n'2020-03-14 15:32:52'\n"], "Parameters": [["format str", "Format string to convert Timestamp to string.\nSee strftime documentation for more information on the format string: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior ."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 456}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.strptime.html#pandas.Timestamp.strptime"], "Title": ["Timestamp.strptime"], "Feature": ["Timestamp.strptime"], "Description": "Function is not implemented. Use pd.to_datetime().", "Examples": [">>> pd.Timestamp.strptime(\"2023-01-01\", \"%d/%m/%y\")\nTraceback (most recent call last):\nNotImplementedError\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 457}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.time.html#pandas.Timestamp.time"], "Title": ["Timestamp.time"], "Feature": ["Timestamp.time"], "Description": "Return time object with same time but with tzinfo=None.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00')\n>>> ts\nTimestamp('2023-01-01 10:00:00')\n>>> ts.time()\ndatetime.time(10, 0)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 458}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timestamp.html#pandas.Timestamp.timestamp"], "Title": ["Timestamp.timestamp"], "Feature": ["Timestamp.timestamp"], "Description": "Return POSIX timestamp as float.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548')\n>>> ts.timestamp()\n1584199972.192548\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 459}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dayofweek.html#pandas.Timestamp.dayofweek"], "Title": ["Timestamp.dayofweek"], "Feature": ["Timestamp.dayofweek"], "Description": "Return day of the week.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.day_of_week\n5\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 460}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetuple.html#pandas.Timestamp.timetuple"], "Title": ["Timestamp.timetuple"], "Feature": ["Timestamp.timetuple"], "Description": "Return time tuple, compatible with time.localtime().", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00')\n>>> ts\nTimestamp('2023-01-01 10:00:00')\n>>> ts.timetuple()\ntime.struct_time(tm_year=2023, tm_mon=1, tm_mday=1,\ntm_hour=10, tm_min=0, tm_sec=0, tm_wday=6, tm_yday=1, tm_isdst=-1)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 461}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.timetz.html#pandas.Timestamp.timetz"], "Title": ["Timestamp.timetz"], "Feature": ["Timestamp.timetz"], "Description": "Return time object with same time and tzinfo.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00', tz='Europe/Brussels')\n>>> ts\nTimestamp('2023-01-01 10:00:00+0100', tz='Europe/Brussels')\n>>> ts.timetz()\ndatetime.time(10, 0, tzinfo=<DstTzInfo 'Europe/Brussels' CET+1:00:00 STD>)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 462}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_datetime64.html#pandas.Timestamp.to_datetime64"], "Title": ["Timestamp.to_datetime64"], "Feature": ["Timestamp.to_datetime64"], "Description": "Return a numpy.datetime64 object with same precision.", "Examples": [">>> ts = pd.Timestamp(year=2023, month=1, day=1,\n...                   hour=10, second=15)\n>>> ts\nTimestamp('2023-01-01 10:00:15')\n>>> ts.to_datetime64()\nnumpy.datetime64('2023-01-01T10:00:15.000000')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 463}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_julian_date.html#pandas.Timestamp.to_julian_date"], "Title": ["Timestamp.to_julian_date"], "Feature": ["Timestamp.to_julian_date"], "Description": "Convert TimeStamp to a Julian Date.\n0 Julian date is noon January 1, 4713 BC.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52')\n>>> ts.to_julian_date()\n2458923.147824074\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 465}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_period.html#pandas.Timestamp.to_period"], "Title": ["Timestamp.to_period"], "Feature": ["Timestamp.to_period"], "Description": "Return an period of which this timestamp is an observation.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n>>> # Year end frequency\n>>> ts.to_period(freq='Y')\nPeriod('2020', 'Y-DEC')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 466}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.to_pydatetime.html#pandas.Timestamp.to_pydatetime"], "Title": ["Timestamp.to_pydatetime"], "Feature": ["Timestamp.to_pydatetime"], "Description": "Convert a Timestamp object to a native Python datetime object.\nIf warn=True, issue a warning if nanoseconds is nonzero.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548')\n>>> ts.to_pydatetime()\ndatetime.datetime(2020, 3, 14, 15, 32, 52, 192548)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 467}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.today.html#pandas.Timestamp.today"], "Title": ["Timestamp.today"], "Feature": ["Timestamp.today"], "Description": "Return the current time in the local timezone.\nThis differs from datetime.today() in that it can be localized to a\npassed timezone.", "Examples": [">>> pd.Timestamp.today()    \nTimestamp('2020-11-16 22:37:39.969883')\n"], "Parameters": [["tz str or timezone object, default None", "Timezone to localize to."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 468}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.toordinal.html#pandas.Timestamp.toordinal"], "Title": ["Timestamp.toordinal"], "Feature": ["Timestamp.toordinal"], "Description": "Return proleptic Gregorian ordinal. January 1 of year 1 is day 1.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:50')\n>>> ts\nTimestamp('2023-01-01 10:00:50')\n>>> ts.toordinal()\n738521\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 469}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_convert.html#pandas.Timestamp.tz_convert"], "Title": ["Timestamp.tz_convert"], "Feature": ["Timestamp.tz_convert"], "Description": "Convert timezone-aware Timestamp to another time zone.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651', tz='UTC')\n>>> ts\nTimestamp('2020-03-14 15:32:52.192548651+0000', tz='UTC')\n"], "Parameters": [["tz str, pytz.timezone, dateutil.tz.tzfile or None", "Time zone for time which Timestamp will be converted to.\nNone will remove timezone holding UTC time."]], "Returns": [["converted Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 470}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_week.html#pandas.Timestamp.day_of_week"], "Title": ["Timestamp.day_of_week"], "Feature": ["Timestamp.day_of_week"], "Description": "Return day of the week.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.day_of_week\n5\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 471}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tz_localize.html#pandas.Timestamp.tz_localize"], "Title": ["Timestamp.tz_localize"], "Feature": ["Timestamp.tz_localize"], "Description": "Localize the Timestamp to a timezone.\nConvert naive Timestamp to local time zone or remove\ntimezone from timezone-aware Timestamp.", "Examples": [">>> ts = pd.Timestamp('2020-03-14T15:32:52.192548651')\n>>> ts\nTimestamp('2020-03-14 15:32:52.192548651')\n"], "Parameters": [["tz str, pytz.timezone, dateutil.tz.tzfile or None", "Time zone for time which Timestamp will be converted to.\nNone will remove timezone holding local time."], ["ambiguous bool, ‘NaT’, default ‘raise’", "When clocks moved backward due to DST, ambiguous times may arise.\nFor example in Central European Time (UTC+01), when going from\n03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n00:30:00 UTC and at 01:30:00 UTC. In such a situation, the ambiguous parameter dictates how ambiguous times should be\nhandled. The behavior is as follows: bool contains flags to determine if time is dst or not (note\nthat this flag is only applicable for ambiguous fall dst dates). ‘NaT’ will return NaT for an ambiguous time. ‘raise’ will raise an AmbiguousTimeError for an ambiguous time."], ["nonexistent ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. The behavior is as follows: ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time. ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time. ‘NaT’ will return NaT where there are nonexistent times. timedelta objects will shift nonexistent times by the timedelta. ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["localized Timestamp", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 472}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.tzname.html#pandas.Timestamp.tzname"], "Title": ["Timestamp.tzname"], "Feature": ["Timestamp.tzname"], "Description": "Return time zone name.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00', tz='Europe/Brussels')\n>>> ts\nTimestamp('2023-01-01 10:00:00+0100', tz='Europe/Brussels')\n>>> ts.tzname()\n'CET'\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 473}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcfromtimestamp.html#pandas.Timestamp.utcfromtimestamp"], "Title": ["Timestamp.utcfromtimestamp"], "Feature": ["Timestamp.utcfromtimestamp"], "Description": "Construct a timezone-aware UTC datetime from a POSIX timestamp.\nNotes\nTimestamp.utcfromtimestamp behavior differs from datetime.utcfromtimestamp\nin returning a timezone-aware object.", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 474}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcnow.html#pandas.Timestamp.utcnow"], "Title": ["Timestamp.utcnow"], "Feature": ["Timestamp.utcnow"], "Description": "Return a new Timestamp representing UTC day and time.", "Examples": [">>> pd.Timestamp.utcnow()   \nTimestamp('2020-11-16 22:50:18.092888+0000', tz='UTC')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 475}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utcoffset.html#pandas.Timestamp.utcoffset"], "Title": ["Timestamp.utcoffset"], "Feature": ["Timestamp.utcoffset"], "Description": "Return utc offset.", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00', tz='Europe/Brussels')\n>>> ts\nTimestamp('2023-01-01 10:00:00+0100', tz='Europe/Brussels')\n>>> ts.utcoffset()\ndatetime.timedelta(seconds=3600)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 476}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.utctimetuple.html#pandas.Timestamp.utctimetuple"], "Title": ["Timestamp.utctimetuple"], "Feature": ["Timestamp.utctimetuple"], "Description": "Return UTC time tuple, compatible with time.localtime().", "Examples": [">>> ts = pd.Timestamp('2023-01-01 10:00:00', tz='Europe/Brussels')\n>>> ts\nTimestamp('2023-01-01 10:00:00+0100', tz='Europe/Brussels')\n>>> ts.utctimetuple()\ntime.struct_time(tm_year=2023, tm_mon=1, tm_mday=1, tm_hour=9,\ntm_min=0, tm_sec=0, tm_wday=6, tm_yday=1, tm_isdst=0)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 477}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.weekday.html#pandas.Timestamp.weekday"], "Title": ["Timestamp.weekday"], "Feature": ["Timestamp.weekday"], "Description": "Return the day of the week represented by the date.\nMonday == 0 … Sunday == 6.", "Examples": [">>> ts = pd.Timestamp('2023-01-01')\n>>> ts\nTimestamp('2023-01-01  00:00:00')\n>>> ts.weekday()\n6\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 478}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.arrays.DatetimeArray.html#pandas.arrays.DatetimeArray"], "Title": ["arrays.DatetimeArray"], "Feature": ["arrays.DatetimeArray"], "Description": "Pandas ExtensionArray for tz-naive or tz-aware datetime data.\nWarningDatetimeArray is currently experimental, and its API may change\nwithout warning. In particular,DatetimeArray.dtypeis\nexpected to change to always be an instance of anExtensionDtypesubclass.\nAttributes\nMethods", "Examples": [">>> pd.arrays.DatetimeArray._from_sequence(\n...    pd.DatetimeIndex(['2023-01-01', '2023-01-02'], freq='D'))\n<DatetimeArray>\n['2023-01-01 00:00:00', '2023-01-02 00:00:00']\nLength: 2, dtype: datetime64[ns]\n"], "Parameters": [["values Series, Index, DatetimeArray, ndarray", "The datetime data. For DatetimeArray values (or a Series or Index boxing one), dtype and freq will be extracted from values ."], ["dtype numpy.dtype or DatetimeTZDtype", "Note that the only NumPy dtype allowed is ‘datetime64[ns]’."], ["freq str or Offset, optional", "The frequency."], ["copy bool, default False", "Whether to copy the underlying array of values."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 479}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.dayofyear.html#pandas.Timestamp.dayofyear"], "Title": ["Timestamp.dayofyear"], "Feature": ["Timestamp.dayofyear"], "Description": "Return the day of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.day_of_year\n74\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 482}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.asm8.html#pandas.Timedelta.asm8"], "Title": ["Timedelta.asm8"], "Feature": ["Timedelta.asm8"], "Description": "Return a numpy timedelta64 array scalar view.\nProvides access to the array scalar view (i.e. a combination of the\nvalue and the units) associated with the numpy.timedelta64().view(),\nincluding a 64-bit integer representation of the timedelta in\nnanoseconds (Python int compatible).", "Examples": [">>> td = pd.Timedelta('1 days 2 min 3 us 42 ns')\n>>> td.asm8\nnumpy.timedelta64(86520000003042,'ns')\n"], "Parameters": [], "Returns": [["numpy timedelta64 array scalar view", "Array scalar view of the timedelta in nanoseconds."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 483}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.components.html#pandas.Timedelta.components"], "Title": ["Timedelta.components"], "Feature": ["Timedelta.components"], "Description": "Return a components namedtuple-like.", "Examples": [">>> td = pd.Timedelta('2 day 4 min 3 us 42 ns')\n>>> td.components\nComponents(days=2, hours=0, minutes=4, seconds=0, milliseconds=0,\n    microseconds=3, nanoseconds=42)\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 484}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.days.html#pandas.Timedelta.days"], "Title": ["Timedelta.days"], "Feature": ["Timedelta.days"], "Description": "Returns the days of the timedelta.", "Examples": [">>> td = pd.Timedelta(1, \"d\")\n>>> td.days\n1\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 485}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.max.html#pandas.Timedelta.max"], "Title": ["Timedelta.max"], "Feature": ["Timedelta.max"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 486}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.microseconds.html#pandas.Timedelta.microseconds"], "Title": ["Timedelta.microseconds"], "Feature": ["Timedelta.microseconds"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 487}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.min.html#pandas.Timedelta.min"], "Title": ["Timedelta.min"], "Feature": ["Timedelta.min"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 488}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.nanoseconds.html#pandas.Timedelta.nanoseconds"], "Title": ["Timedelta.nanoseconds"], "Feature": ["Timedelta.nanoseconds"], "Description": "Return the number of nanoseconds (n), where 0 <= n < 1 microsecond.\nSee alsoTimedelta.componentsReturn all attributes with assigned values (i.e. days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds).", "Examples": [">>> td = pd.Timedelta('1 days 2 min 3 us 42 ns')\n"], "Parameters": [], "Returns": [["int", "Number of nanoseconds."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 489}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.resolution.html#pandas.Timedelta.resolution"], "Title": ["Timedelta.resolution"], "Feature": ["Timedelta.resolution"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 490}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.seconds.html#pandas.Timedelta.seconds"], "Title": ["Timedelta.seconds"], "Feature": ["Timedelta.seconds"], "Description": "Return the total hours, minutes, and seconds of the timedelta as seconds.\nTimedelta.seconds = hours * 3600 + minutes * 60 + seconds.\nSee alsoTimedelta.componentsReturn all attributes with assigned values (i.e. days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds).Timedelta.total_secondsExpress the Timedelta as total number of seconds.", "Examples": [">>> td = pd.Timedelta('1 days 2 min 3 us 42 ns')\n>>> td.seconds\n120\n"], "Parameters": [], "Returns": [["int", "Number of seconds."]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 491}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.unit.html#pandas.Timedelta.unit"], "Title": ["Timedelta.unit"], "Feature": ["Timedelta.unit"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 492}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.day_of_year.html#pandas.Timestamp.day_of_year"], "Title": ["Timestamp.day_of_year"], "Feature": ["Timestamp.day_of_year"], "Description": "Return the day of the year.", "Examples": [">>> ts = pd.Timestamp(2020, 3, 14)\n>>> ts.day_of_year\n74\n"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 493}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.value.html#pandas.Timedelta.value"], "Title": ["Timedelta.value"], "Feature": ["Timedelta.value"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 494}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.view.html#pandas.Timedelta.view"], "Title": ["Timedelta.view"], "Feature": ["Timedelta.view"], "Description": "Array view compatibility.", "Examples": [">>> td = pd.Timedelta('3D')\n>>> td\nTimedelta('3 days 00:00:00')\n>>> td.view(int)\n259200000000000\n"], "Parameters": [["dtype str or dtype", "The dtype to view the underlying data as."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 495}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.as_unit.html#pandas.Timedelta.as_unit"], "Title": ["Timedelta.as_unit"], "Feature": ["Timedelta.as_unit"], "Description": "Convert the underlying int64 representation to the given unit.", "Examples": [">>> td = pd.Timedelta('1001ms')\n>>> td\nTimedelta('0 days 00:00:01.001000')\n>>> td.as_unit('s')\nTimedelta('0 days 00:00:01')\n"], "Parameters": [["unit {“ns”, “us”, “ms”, “s”}", ""], ["round_ok bool, default True", "If False and the conversion requires rounding, raise."]], "Returns": [["Timedelta", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 496}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.ceil.html#pandas.Timedelta.ceil"], "Title": ["Timedelta.ceil"], "Feature": ["Timedelta.ceil"], "Description": "Return a new Timedelta ceiled to this resolution.", "Examples": [">>> td = pd.Timedelta('1001ms')\n>>> td\nTimedelta('0 days 00:00:01.001000')\n>>> td.ceil('s')\nTimedelta('0 days 00:00:02')\n"], "Parameters": [["freq str", "Frequency string indicating the ceiling resolution.\nIt uses the same units as class constructor Timedelta ."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 497}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.floor.html#pandas.Timedelta.floor"], "Title": ["Timedelta.floor"], "Feature": ["Timedelta.floor"], "Description": "Return a new Timedelta floored to this resolution.", "Examples": [">>> td = pd.Timedelta('1001ms')\n>>> td\nTimedelta('0 days 00:00:01.001000')\n>>> td.floor('s')\nTimedelta('0 days 00:00:01')\n"], "Parameters": [["freq str", "Frequency string indicating the flooring resolution.\nIt uses the same units as class constructor Timedelta ."]], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 498}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.isoformat.html#pandas.Timedelta.isoformat"], "Title": ["Timedelta.isoformat"], "Feature": ["Timedelta.isoformat"], "Description": "Format the Timedelta as ISO 8601 Duration.\nP[n]Y[n]M[n]DT[n]H[n]M[n]S, where the[n]s are replaced by the\nvalues. Seehttps://en.wikipedia.org/wiki/ISO_8601#Durations.\nSee alsoTimestamp.isoformatFunction is used to convert the given Timestamp object into the ISO format.\nNotes\nThe longest component is days, whose value may be larger than\n365.\nEvery component is always included, even if its value is 0.\nPandas uses nanosecond precision, so up to 9 decimal places may\nbe included in the seconds component.\nTrailing 0’s are removed from the seconds component after the decimal.\nWe do not 0 pad components, so it’s…T5H…, not…T05H…", "Examples": [">>> td = pd.Timedelta(days=6, minutes=50, seconds=3,\n...                   milliseconds=10, microseconds=10, nanoseconds=12)\n"], "Parameters": [], "Returns": [["str", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 499}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.round.html#pandas.Timedelta.round"], "Title": ["Timedelta.round"], "Feature": ["Timedelta.round"], "Description": "Round the Timedelta to the specified resolution.", "Examples": [">>> td = pd.Timedelta('1001ms')\n>>> td\nTimedelta('0 days 00:00:01.001000')\n>>> td.round('s')\nTimedelta('0 days 00:00:01')\n"], "Parameters": [["freq str", "Frequency string indicating the rounding resolution.\nIt uses the same units as class constructor Timedelta ."]], "Returns": [["a new Timedelta rounded to the given resolution of freq", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 500}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_pytimedelta.html#pandas.Timedelta.to_pytimedelta"], "Title": ["Timedelta.to_pytimedelta"], "Feature": ["Timedelta.to_pytimedelta"], "Description": "Convert a pandas Timedelta object into a pythondatetime.timedeltaobject.\nTimedelta objects are internally saved as numpy datetime64[ns] dtype.\nUse to_pytimedelta() to convert to object dtype.\nSee alsoto_timedeltaConvert argument to Timedelta type.\nNotes\nAny nanosecond resolution will be lost.", "Examples": [">>> td = pd.Timedelta('3D')\n>>> td\nTimedelta('3 days 00:00:00')\n>>> td.to_pytimedelta()\ndatetime.timedelta(days=3)\n"], "Parameters": [], "Returns": [["datetime.timedelta or numpy.array of datetime.timedelta", ""]], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 501}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.to_timedelta64.html#pandas.Timedelta.to_timedelta64"], "Title": ["Timedelta.to_timedelta64"], "Feature": ["Timedelta.to_timedelta64"], "Description": "Return a numpy.timedelta64 object with ‘ns’ precision.", "Examples": [">>> td = pd.Timedelta('3D')\n>>> td\nTimedelta('3 days 00:00:00')\n>>> td.to_timedelta64()\nnumpy.timedelta64(259200000000000,'ns')\n"], "Parameters": [], "Returns": [], "Category": ["Pandas-Arrays-Scalars-And-Data-Types"], "index": 502}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.index.html#pandas.Series.index"], "Title": ["Series.index"], "Feature": ["Series.index"], "Description": "The index (axis labels) of the Series.\nThe index of a Series is used to label and identify each element of the\nunderlying data. The index can be thought of as an immutable ordered set\n(technically a multi-set, as it may contain duplicate labels), and is\nused to index and align data in pandas.\nSee alsoSeries.reindexConform Series to new index.IndexThe base pandas index type.\nNotes\nFor more information on pandas indexing, see theindexing user guide.", "Examples": [">>> cities = ['Kolkata', 'Chicago', 'Toronto', 'Lisbon']\n>>> populations = [14.85, 2.71, 2.93, 0.51]\n>>> city_series = pd.Series(populations, index=cities)\n>>> city_series.index\nIndex(['Kolkata', 'Chicago', 'Toronto', 'Lisbon'], dtype='object')\n"], "Parameters": [], "Returns": [["Index", "The index labels of the Series."]], "Category": ["Series"], "index": 504}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html#pandas.Series.memory_usage"], "Title": ["Series.memory_usage"], "Feature": ["Series.memory_usage"], "Description": "Return the memory usage of the Series.\nThe memory usage can optionally include the contribution of\nthe index and of elements ofobjectdtype.\nSee alsonumpy.ndarray.nbytesTotal bytes consumed by the elements of the array.DataFrame.memory_usageBytes consumed by a DataFrame.", "Examples": [">>> s = pd.Series(range(3))\n>>> s.memory_usage()\n152\n"], "Parameters": [["index bool, default True", "Specifies whether to include the memory usage of the Series index."], ["deep bool, default False", "If True, introspect the data deeply by interrogating object dtypes for system-level memory consumption, and include\nit in the returned value."]], "Returns": [["int", "Bytes of memory consumed."]], "Category": ["Series"], "index": 505}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html#pandas.Series.prod"], "Title": ["Series.prod"], "Feature": ["Series.prod"], "Description": "Return the product of the values over the requested axis.\nSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.", "Examples": [">>> pd.Series([], dtype=\"float64\").prod()\n1.0\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis). Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 506}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html#pandas.Series.quantile"], "Title": ["Series.quantile"], "Feature": ["Series.quantile"], "Description": "Return value at the given quantile.\nSee alsocore.window.Rolling.quantileCalculate the rolling quantile.numpy.percentileReturns the q-th percentile(s) of the array elements.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s.quantile(.5)\n2.5\n>>> s.quantile([.25, .5, .75])\n0.25    1.75\n0.50    2.50\n0.75    3.25\ndtype: float64\n"], "Parameters": [["q float or array-like, default 0.5 (50% quantile)", "The quantile(s) to compute, which can lie in range: 0 <= q <= 1."], ["interpolation {‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}", "This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data points i and j : linear: i + (j - i) * (x-i)/(j-i) , where (x-i)/(j-i) is\nthe fractional part of the index surrounded by i > j . lower: i . higher: j . nearest: i or j whichever is nearest. midpoint: ( i + j ) / 2."]], "Returns": [["float or Series", "If q is an array, a Series will be returned where the\nindex is q and the values are the quantiles, otherwise\na float will be returned."]], "Category": ["Series"], "index": 507}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rank.html#pandas.Series.rank"], "Title": ["Series.rank"], "Feature": ["Series.rank"], "Description": "Compute numerical data ranks (1 through n) along axis.\nBy default, equal values are assigned a rank that is the average of the\nranks of those values.\nSee alsocore.groupby.DataFrameGroupBy.rankRank of values within each group.core.groupby.SeriesGroupBy.rankRank of values within each group.", "Examples": [">>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n...                                    'spider', 'snake'],\n...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n>>> df\n    Animal  Number_legs\n0      cat          4.0\n1  penguin          2.0\n2      dog          4.0\n3   spider          8.0\n4    snake          NaN\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Index to direct ranking.\nFor Series this parameter is unused and defaults to 0."], ["method {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’", "How to rank the group of records that have the same value (i.e. ties): average: average rank of the group min: lowest rank in the group max: highest rank in the group first: ranks assigned in order they appear in the array dense: like ‘min’, but rank always increases by 1 between groups."], ["numeric_only bool, default False", "For DataFrame objects, rank only numeric columns if set to True. Changed in version 2.0.0: The default value of numeric_only is now False ."], ["na_option {‘keep’, ‘top’, ‘bottom’}, default ‘keep’", "How to rank NaN values: keep: assign NaN rank to NaN values top: assign lowest rank to NaN values bottom: assign highest rank to NaN values"], ["ascending bool, default True", "Whether or not the elements should be ranked in ascending order."], ["pct bool, default False", "Whether or not to display the returned rankings in percentile\nform."]], "Returns": [["same type as caller", "Return a Series or DataFrame with data ranks as values."]], "Category": ["Series"], "index": 508}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sem.html#pandas.Series.sem"], "Title": ["Series.sem"], "Feature": ["Series.sem"], "Description": "Return unbiased standard error of the mean over requested axis.\nNormalized by N-1 by default. This can be changed using the ddof argument", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.sem().round(6)\n0.57735\n"], "Parameters": [["axis {index (0)}", "For Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.sem with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["ddof int, default 1", "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."]], "Returns": [["scalar or Series (if level specified)", ""]], "Category": ["Series"], "index": 509}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.skew.html#pandas.Series.skew"], "Title": ["Series.skew"], "Feature": ["Series.skew"], "Description": "Return unbiased skew over requested axis.\nNormalized by N-1.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.skew()\n0.0\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 510}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html#pandas.Series.std"], "Title": ["Series.std"], "Feature": ["Series.std"], "Description": "Return sample standard deviation over requested axis.\nNormalized by N-1 by default. This can be changed using the ddof argument.\nNotes\nTo have the same behaviour asnumpy.std, useddof=0(instead of the\ndefaultddof=1)", "Examples": [">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n...                    'age': [21, 25, 62, 43],\n...                    'height': [1.61, 1.87, 1.49, 2.01]}\n...                   ).set_index('person_id')\n>>> df\n           age  height\nperson_id\n0           21    1.61\n1           25    1.87\n2           62    1.49\n3           43    2.01\n"], "Parameters": [["axis {index (0)}", "For Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.std with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["ddof int, default 1", "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."]], "Returns": [["scalar or Series (if level specified)", ""]], "Category": ["Series"], "index": 511}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sum.html#pandas.Series.sum"], "Title": ["Series.sum"], "Feature": ["Series.sum"], "Description": "Return the sum of the values over the requested axis.\nThis is equivalent to the methodnumpy.sum.\nSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.", "Examples": [">>> idx = pd.MultiIndex.from_arrays([\n...     ['warm', 'warm', 'cold', 'cold'],\n...     ['dog', 'falcon', 'fish', 'spider']],\n...     names=['blooded', 'animal'])\n>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n>>> s\nblooded  animal\nwarm     dog       4\n         falcon    2\ncold     fish      0\n         spider    8\nName: legs, dtype: int64\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.sum with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis). Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 512}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html#pandas.Series.var"], "Title": ["Series.var"], "Feature": ["Series.var"], "Description": "Return unbiased variance over requested axis.\nNormalized by N-1 by default. This can be changed using the ddof argument.", "Examples": [">>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n...                    'age': [21, 25, 62, 43],\n...                    'height': [1.61, 1.87, 1.49, 2.01]}\n...                   ).set_index('person_id')\n>>> df\n           age  height\nperson_id\n0           21    1.61\n1           25    1.87\n2           62    1.49\n3           43    2.01\n"], "Parameters": [["axis {index (0)}", "For Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.var with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis)."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["ddof int, default 1", "Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."]], "Returns": [["scalar or Series (if level specified)", ""]], "Category": ["Series"], "index": 513}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.kurtosis.html#pandas.Series.kurtosis"], "Title": ["Series.kurtosis"], "Feature": ["Series.kurtosis"], "Description": "Return unbiased kurtosis over requested axis.\nKurtosis obtained using Fisher’s definition of\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.", "Examples": [">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n>>> s\ncat    1\ndog    2\ndog    2\nmouse  3\ndtype: int64\n>>> s.kurt()\n1.5\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 514}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html#pandas.Series.unique"], "Title": ["Series.unique"], "Feature": ["Series.unique"], "Description": "Return unique values of Series object.\nUniques are returned in order of appearance. Hash table-based unique,\ntherefore does NOT sort.\nSee alsoSeries.drop_duplicatesReturn Series with duplicate values removed.uniqueTop-level unique method for any 1-d array-like object.Index.uniqueReturn Index with unique values from an Index object.\nNotes\nReturns the unique values as a NumPy array. In case of an\nextension-array backed Series, a newExtensionArrayof that type with just\nthe unique values is returned. This includes", "Examples": [">>> pd.Series([2, 1, 3, 3], name='A').unique()\narray([2, 1, 3])\n"], "Parameters": [], "Returns": [["ndarray or ExtensionArray", "The unique values returned as a NumPy array. See Notes."]], "Category": ["Series"], "index": 515}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.hasnans.html#pandas.Series.hasnans"], "Title": ["Series.hasnans"], "Feature": ["Series.hasnans"], "Description": "Return True if there are any NaNs.\nEnables various performance speedups.", "Examples": [">>> s = pd.Series([1, 2, 3, None])\n>>> s\n0    1.0\n1    2.0\n2    3.0\n3    NaN\ndtype: float64\n>>> s.hasnans\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Series"], "index": 516}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html#pandas.Series.nunique"], "Title": ["Series.nunique"], "Feature": ["Series.nunique"], "Description": "Return number of unique elements in the object.\nExcludes NA values by default.\nSee alsoDataFrame.nuniqueMethod nunique for DataFrame.Series.countCount non-NA/null observations in the Series.", "Examples": [">>> s = pd.Series([1, 3, 5, 7, 7])\n>>> s\n0    1\n1    3\n2    5\n3    7\n4    7\ndtype: int64\n"], "Parameters": [["dropna bool, default True", "Don’t include NaN in the count."]], "Returns": [["int", ""]], "Category": ["Series"], "index": 517}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html#pandas.Series.is_unique"], "Title": ["Series.is_unique"], "Feature": ["Series.is_unique"], "Description": "Return boolean if values in the object are unique.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.is_unique\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Series"], "index": 518}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_increasing.html#pandas.Series.is_monotonic_increasing"], "Title": ["Series.is_monotonic_increasing"], "Feature": ["Series.is_monotonic_increasing"], "Description": "Return boolean if values in the object are monotonically increasing.", "Examples": [">>> s = pd.Series([1, 2, 2])\n>>> s.is_monotonic_increasing\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Series"], "index": 519}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.is_monotonic_decreasing.html#pandas.Series.is_monotonic_decreasing"], "Title": ["Series.is_monotonic_decreasing"], "Feature": ["Series.is_monotonic_decreasing"], "Description": "Return boolean if values in the object are monotonically decreasing.", "Examples": [">>> s = pd.Series([3, 2, 2, 1])\n>>> s.is_monotonic_decreasing\nTrue\n"], "Parameters": [], "Returns": [["bool", ""]], "Category": ["Series"], "index": 520}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html#pandas.Series.value_counts"], "Title": ["Series.value_counts"], "Feature": ["Series.value_counts"], "Description": "Return a Series containing counts of unique values.\nThe resulting object will be in descending order so that the\nfirst element is the most frequently-occurring element.\nExcludes NA values by default.\nSee alsoSeries.countNumber of non-NA elements in a Series.DataFrame.countNumber of non-NA elements in a DataFrame.DataFrame.value_countsEquivalent method on DataFrames.", "Examples": [">>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n>>> index.value_counts()\n3.0    2\n1.0    1\n2.0    1\n4.0    1\nName: count, dtype: int64\n"], "Parameters": [["normalize bool, default False", "If True then the object returned will contain the relative\nfrequencies of the unique values."], ["sort bool, default True", "Sort by frequencies when True. Preserve the order of the data when False."], ["ascending bool, default False", "Sort in ascending order."], ["bins int, optional", "Rather than count values, group them into half-open bins,\na convenience for pd.cut , only works with numeric data."], ["dropna bool, default True", "Don’t include counts of NaN."]], "Returns": [["Series", ""]], "Category": ["Series"], "index": 521}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.align.html#pandas.Series.align"], "Title": ["Series.align"], "Feature": ["Series.align"], "Description": "Align two objects on their axes with the specified join method.\nJoin method is specified for each axis Index.", "Examples": [">>> df = pd.DataFrame(\n...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n... )\n>>> other = pd.DataFrame(\n...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n...     columns=[\"A\", \"B\", \"C\", \"D\"],\n...     index=[2, 3, 4],\n... )\n>>> df\n   D  B  E  A\n1  1  2  3  4\n2  6  7  8  9\n>>> other\n    A    B    C    D\n2   10   20   30   40\n3   60   70   80   90\n4  600  700  800  900\n"], "Parameters": [["other DataFrame or Series", ""], ["join {‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’", "Type of alignment to be performed. left: use only keys from left frame, preserve key order. right: use only keys from right frame, preserve key order. outer: use union of keys from both frames, sort keys lexicographically. inner: use intersection of keys from both frames,\npreserve the order of the left keys."], ["axis allowed axis of the other object, default None", "Align on index (0), columns (1), or both (None)."], ["level int or level name, default None", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["copy bool, default True", "Always returns new objects. If copy=False and no reindexing is\nrequired then original objects are returned. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["fill_value scalar, default np.nan", "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value."], ["method {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None", "Method to use for filling holes in reindexed Series: pad / ffill: propagate last valid observation forward to next valid. backfill / bfill: use NEXT valid observation to fill gap. Deprecated since version 2.1."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None. Deprecated since version 2.1."], ["fill_axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0", "Filling axis, method and limit. Deprecated since version 2.1."], ["broadcast_axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None", "Broadcast values along this axis, if aligning two objects of\ndifferent dimensions. Deprecated since version 2.1."]], "Returns": [["tuple of (Series/DataFrame, type of other)", "Aligned objects."]], "Category": ["Series"], "index": 522}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.case_when.html#pandas.Series.case_when"], "Title": ["Series.case_when"], "Feature": ["Series.case_when"], "Description": "Replace values where the conditions are True.\nSee alsoSeries.maskReplace values where the condition is True.", "Examples": [">>> c = pd.Series([6, 7, 8, 9], name='c')\n>>> a = pd.Series([0, 0, 1, 2])\n>>> b = pd.Series([0, 3, 4, 5])\n"], "Parameters": [["caselist A list of tuples of conditions and expected replacements", "Takes the form: (condition0, replacement0) , (condition1, replacement1) , … . condition should be a 1-D boolean array-like object\nor a callable. If condition is a callable,\nit is computed on the Series\nand should return a boolean Series or array.\nThe callable must not change the input Series\n(though pandas doesn`t check it). replacement should be a\n1-D array-like object, a scalar or a callable.\nIf replacement is a callable, it is computed on the Series\nand should return a scalar or Series. The callable\nmust not change the input Series\n(though pandas doesn`t check it). Added in version 2.2.0."]], "Returns": [["Series", ""]], "Category": ["Series"], "index": 523}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.drop.html#pandas.Series.drop"], "Title": ["Series.drop"], "Feature": ["Series.drop"], "Description": "Return Series with specified index labels removed.\nRemove elements of a Series based on specifying the index labels.\nWhen using a multi-index, labels on different levels can be removed\nby specifying the level.\nSee alsoSeries.reindexReturn only specified index labels of Series.Series.dropnaReturn series without null values.Series.drop_duplicatesReturn Series with duplicate values removed.DataFrame.dropDrop specified labels from rows or columns.", "Examples": [">>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n>>> s\nA  0\nB  1\nC  2\ndtype: int64\n"], "Parameters": [["labels single label or list-like", "Index labels to drop."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["index single label or list-like", "Redundant for application on Series, but ‘index’ can be used instead\nof ‘labels’."], ["columns single label or list-like", "No change is made to the Series; use ‘index’ or ‘labels’ instead."], ["level int or level name, optional", "For MultiIndex, level for which the labels will be removed."], ["inplace bool, default False", "If True, do operation inplace and return None."], ["errors {‘ignore’, ‘raise’}, default ‘raise’", "If ‘ignore’, suppress error and only existing labels are dropped."]], "Returns": [["Series or None", "Series with specified index labels removed or None if inplace=True ."]], "Category": ["Series"], "index": 524}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.droplevel.html#pandas.Series.droplevel"], "Title": ["Series.droplevel"], "Feature": ["Series.droplevel"], "Description": "Return Series/DataFrame with requested index / column level(s) removed.", "Examples": [">>> df = pd.DataFrame([\n...     [1, 2, 3, 4],\n...     [5, 6, 7, 8],\n...     [9, 10, 11, 12]\n... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n"], "Parameters": [["level int, str, or list-like", "If a string is given, must be the name of a level\nIf list-like, elements must be names or positional indexes\nof levels."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Axis along which the level(s) is removed: 0 or ‘index’: remove level(s) in column. 1 or ‘columns’: remove level(s) in row. For Series this parameter is unused and defaults to 0."]], "Returns": [["Series/DataFrame", "Series/DataFrame with requested index / column level(s) removed."]], "Category": ["Series"], "index": 525}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.drop_duplicates.html#pandas.Series.drop_duplicates"], "Title": ["Series.drop_duplicates"], "Feature": ["Series.drop_duplicates"], "Description": "Return Series with duplicate values removed.\nSee alsoIndex.drop_duplicatesEquivalent method on Index.DataFrame.drop_duplicatesEquivalent method on DataFrame.Series.duplicatedRelated method on Series, indicating duplicate Series values.Series.uniqueReturn unique values as an array.", "Examples": [">>> s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama', 'hippo'],\n...               name='animal')\n>>> s\n0     llama\n1       cow\n2     llama\n3    beetle\n4     llama\n5     hippo\nName: animal, dtype: object\n"], "Parameters": [["keep {‘first’, ‘last’, False }, default ‘first’", "Method to handle dropping duplicates: ‘first’ : Drop duplicates except for the first occurrence. ‘last’ : Drop duplicates except for the last occurrence. False : Drop all duplicates."], ["inplace bool, default False", "If True , performs operation inplace and returns None."], ["ignore_index bool, default False", "If True , the resulting axis will be labeled 0, 1, …, n - 1. Added in version 2.0.0."]], "Returns": [["Series or None", "Series with duplicates dropped or None if inplace=True ."]], "Category": ["Series"], "index": 526}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.empty.html#pandas.Series.empty"], "Title": ["Series.empty"], "Feature": ["Series.empty"], "Description": "Indicator whether Series/DataFrame is empty.\nTrue if Series/DataFrame is entirely empty (no items), meaning any of the\naxes are of length 0.\nSee alsoSeries.dropnaReturn series without null values.DataFrame.dropnaReturn DataFrame with labels on given axis omitted where (all or any) data are missing.\nNotes\nIf Series/DataFrame contains only NaNs, it is still not considered empty. See\nthe example below.", "Examples": [">>> df_empty = pd.DataFrame({'A' : []})\n>>> df_empty\nEmpty DataFrame\nColumns: [A]\nIndex: []\n>>> df_empty.empty\nTrue\n"], "Parameters": [], "Returns": [["bool", "If Series/DataFrame is empty, return True, if not return False."]], "Category": ["Series"], "index": 527}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html#pandas.Series.duplicated"], "Title": ["Series.duplicated"], "Feature": ["Series.duplicated"], "Description": "Indicate duplicate Series values.\nDuplicated values are indicated asTruevalues in the resulting\nSeries. Either all duplicates, all except the first or all except the\nlast occurrence of duplicates can be indicated.\nSee alsoIndex.duplicatedEquivalent method on pandas.Index.DataFrame.duplicatedEquivalent method on pandas.DataFrame.Series.drop_duplicatesRemove duplicate values from Series.", "Examples": [">>> animals = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama'])\n>>> animals.duplicated()\n0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool\n"], "Parameters": [["keep {‘first’, ‘last’, False}, default ‘first’", "Method to handle dropping duplicates: ‘first’ : Mark duplicates as True except for the first\noccurrence. ‘last’ : Mark duplicates as True except for the last\noccurrence. False : Mark all duplicates as True ."]], "Returns": [["Series[bool]", "Series indicating whether each value has occurred in the\npreceding values."]], "Category": ["Series"], "index": 528}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.equals.html#pandas.Series.equals"], "Title": ["Series.equals"], "Feature": ["Series.equals"], "Description": "Test whether two objects contain the same elements.\nThis function allows two Series or DataFrames to be compared against\neach other to see if they have the same shape and elements. NaNs in\nthe same location are considered equal.\nThe row/column index do not need to have the same type, as long\nas the values are considered equal. Corresponding columns and\nindex must be of the same dtype.\nSee alsoSeries.eqCompare two Series objects of the same length and return a Series where each element is True if the element in each Series is equal, False otherwise.DataFrame.eqCompare two DataFrame objects of the same shape and return a DataFrame where each element is True if the respective element in each DataFrame is equal, False otherwise.testing.assert_series_equalRaises an AssertionError if left and right are not equal. Provides an easy interface to ignore inequality in dtypes, indexes and precision among others.testing.assert_frame_equalLike assert_series_equal, but targets DataFrames.numpy.array_equalReturn True if two arrays have the same shape and elements, False otherwise.", "Examples": [">>> df = pd.DataFrame({1: [10], 2: [20]})\n>>> df\n    1   2\n0  10  20\n"], "Parameters": [["other Series or DataFrame", "The other Series or DataFrame to be compared with the first."]], "Returns": [["bool", "True if all elements are the same in both objects, False\notherwise."]], "Category": ["Series"], "index": 529}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.first.html#pandas.Series.first"], "Title": ["Series.first"], "Feature": ["Series.first"], "Description": "Select initial periods of time series data based on a date offset.\nDeprecated since version 2.1:first()is deprecated and will be removed in a future version.\nPlease create a mask and filter using.locinstead.\nFor a DataFrame with a sorted DatetimeIndex, this function can\nselect the first few rows based on a date offset.\nSee alsolastSelect final periods of time series based on a date offset.at_timeSelect values at a particular time of the day.between_timeSelect values between particular times of the day.", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n            A\n2018-04-09  1\n2018-04-11  2\n2018-04-13  3\n2018-04-15  4\n"], "Parameters": [["offset str, DateOffset or dateutil.relativedelta", "The offset length of the data that will be selected. For instance,\n‘1ME’ will display all the rows having their index within the first month."]], "Returns": [["Series or DataFrame", "A subset of the caller."]], "Category": ["Series"], "index": 530}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.head.html#pandas.Series.head"], "Title": ["Series.head"], "Feature": ["Series.head"], "Description": "Return the firstnrows.\nThis function returns the firstnrows for the object based\non position. It is useful for quickly testing if your object\nhas the right type of data in it.\nFor negative values ofn, this function returns all rows except\nthe last|n|rows, equivalent todf[:n].\nIf n is larger than the number of rows, this function returns all rows.\nSee alsoDataFrame.tailReturns the lastnrows.", "Examples": [">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n>>> df\n      animal\n0  alligator\n1        bee\n2     falcon\n3       lion\n4     monkey\n5     parrot\n6      shark\n7      whale\n8      zebra\n"], "Parameters": [["n int, default 5", "Number of rows to select."]], "Returns": [["same type as caller", "The first n rows of the caller object."]], "Category": ["Series"], "index": 531}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html#pandas.Series.idxmax"], "Title": ["Series.idxmax"], "Feature": ["Series.idxmax"], "Description": "Return the row label of the maximum value.\nIf multiple values equal the maximum, the first row label with that\nvalue is returned.\nSee alsonumpy.argmaxReturn indices of the maximum values along the given axis.DataFrame.idxmaxReturn index of first occurrence of maximum over requested axis.Series.idxminReturn indexlabelof the first occurrence of minimum of values.\nNotes\nThis method is the Series version ofndarray.argmax. This method\nreturns the label of the maximum, whilendarray.argmaxreturns\nthe position. To get the position, useseries.values.argmax().", "Examples": [">>> s = pd.Series(data=[1, None, 4, 3, 4],\n...               index=['A', 'B', 'C', 'D', 'E'])\n>>> s\nA    1.0\nB    NaN\nC    4.0\nD    3.0\nE    4.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["skipna bool, default True", "Exclude NA/null values. If the entire Series is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional arguments and keywords have no effect but might be\naccepted for compatibility with NumPy."]], "Returns": [["Index", "Label of the maximum value."]], "Category": ["Series"], "index": 532}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmin.html#pandas.Series.idxmin"], "Title": ["Series.idxmin"], "Feature": ["Series.idxmin"], "Description": "Return the row label of the minimum value.\nIf multiple values equal the minimum, the first row label with that\nvalue is returned.\nSee alsonumpy.argminReturn indices of the minimum values along the given axis.DataFrame.idxminReturn index of first occurrence of minimum over requested axis.Series.idxmaxReturn indexlabelof the first occurrence of maximum of values.\nNotes\nThis method is the Series version ofndarray.argmin. This method\nreturns the label of the minimum, whilendarray.argminreturns\nthe position. To get the position, useseries.values.argmin().", "Examples": [">>> s = pd.Series(data=[1, None, 4, 1],\n...               index=['A', 'B', 'C', 'D'])\n>>> s\nA    1.0\nB    NaN\nC    4.0\nD    1.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["skipna bool, default True", "Exclude NA/null values. If the entire Series is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional arguments and keywords have no effect but might be\naccepted for compatibility with NumPy."]], "Returns": [["Index", "Label of the minimum value."]], "Category": ["Series"], "index": 533}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html#pandas.Series.isin"], "Title": ["Series.isin"], "Feature": ["Series.isin"], "Description": "Whether elements in Series are contained invalues.\nReturn a boolean Series showing whether each element in the Series\nmatches an element in the passed sequence ofvaluesexactly.\nSee alsoDataFrame.isinEquivalent method on DataFrame.", "Examples": [">>> s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama',\n...                'hippo'], name='animal')\n>>> s.isin(['cow', 'llama'])\n0     True\n1     True\n2     True\n3    False\n4     True\n5    False\nName: animal, dtype: bool\n"], "Parameters": [["values set or list-like", "The sequence of values to test. Passing in a single string will\nraise a TypeError . Instead, turn a single string into a\nlist of one element."]], "Returns": [["Series", "Series of booleans indicating if each element is in values."]], "Category": ["Series"], "index": 534}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.last.html#pandas.Series.last"], "Title": ["Series.last"], "Feature": ["Series.last"], "Description": "Select final periods of time series data based on a date offset.\nDeprecated since version 2.1:last()is deprecated and will be removed in a future version.\nPlease create a mask and filter using.locinstead.\nFor a DataFrame with a sorted DatetimeIndex, this function\nselects the last few rows based on a date offset.\nSee alsofirstSelect initial periods of time series based on a date offset.at_timeSelect values at a particular time of the day.between_timeSelect values between particular times of the day.\nNotes\nDeprecated since version 2.1.0:Please create a mask and filter using.locinstead", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n            A\n2018-04-09  1\n2018-04-11  2\n2018-04-13  3\n2018-04-15  4\n"], "Parameters": [["offset str, DateOffset, dateutil.relativedelta", "The offset length of the data that will be selected. For instance,\n‘3D’ will display all the rows having their index within the last 3 days."]], "Returns": [["Series or DataFrame", "A subset of the caller."]], "Category": ["Series"], "index": 535}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex.html#pandas.Series.reindex"], "Title": ["Series.reindex"], "Feature": ["Series.reindex"], "Description": "Conform Series to new index with optional filling logic.\nPlaces NA/NaN in locations having no value in the previous index. A new object\nis produced unless the new index is equivalent to the current one andcopy=False.\nSee alsoDataFrame.set_indexSet row labels.DataFrame.reset_indexRemove row labels or move them to new columns.DataFrame.reindex_likeChange to same indices as other DataFrame.", "Examples": [">>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n>>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n...                   index=index)\n>>> df\n           http_status  response_time\nFirefox            200           0.04\nChrome             200           0.02\nSafari             404           0.07\nIE10               404           0.08\nKonqueror          301           1.00\n"], "Parameters": [["index array-like, optional", "New labels for the index. Preferably an Index object to avoid\nduplicating data."], ["axis int or str, optional", "Unused."], ["method {None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index. None (default): don’t fill gaps pad / ffill: Propagate last valid observation forward to next\nvalid. backfill / bfill: Use next valid observation to fill gap. nearest: Use nearest valid observations to fill gap."], ["copy bool, default True", "Return a new object, even if the passed indexes are the same. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value scalar, default np.nan", "Value to use for missing values. Defaults to NaN, but can be any\n“compatible” value."], ["limit int, default None", "Maximum number of consecutive elements to forward or backward fill."], ["tolerance optional", "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations most\nsatisfy the equation abs(index[indexer] - target) <= tolerance . Tolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type."]], "Returns": [["Series with changed index.", ""]], "Category": ["Series"], "index": 536}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.reindex_like.html#pandas.Series.reindex_like"], "Title": ["Series.reindex_like"], "Feature": ["Series.reindex_like"], "Description": "Return an object with matching indices as other object.\nConform the object to the same index on all axes. Optional\nfilling logic, placing NaN in locations having no value\nin the previous index. A new object is produced unless the\nnew index is equivalent to the current one and copy=False.\nSee alsoDataFrame.set_indexSet row labels.DataFrame.reset_indexRemove row labels or move them to new columns.DataFrame.reindexChange to new indices or expand indices.\nNotes\nSame as calling.reindex(index=other.index,columns=other.columns,...).", "Examples": [">>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n...                     [31, 87.8, 'high'],\n...                     [22, 71.6, 'medium'],\n...                     [35, 95, 'medium']],\n...                    columns=['temp_celsius', 'temp_fahrenheit',\n...                             'windspeed'],\n...                    index=pd.date_range(start='2014-02-12',\n...                                        end='2014-02-15', freq='D'))\n"], "Parameters": [["other Object of the same data type", "Its row and column indices are used to define the new indices\nof this object."], ["method {None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}", "Method to use for filling holes in reindexed DataFrame.\nPlease note: this is only applicable to DataFrames/Series with a\nmonotonically increasing/decreasing index. None (default): don’t fill gaps pad / ffill: propagate last valid observation forward to next\nvalid backfill / bfill: use next valid observation to fill gap nearest: use nearest valid observations to fill gap."], ["copy bool, default True", "Return a new object, even if the passed indexes are the same. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["limit int, default None", "Maximum number of consecutive labels to fill for inexact matches."], ["tolerance optional", "Maximum distance between original and new labels for inexact\nmatches. The values of the index at the matching locations must\nsatisfy the equation abs(index[indexer] - target) <= tolerance . Tolerance may be a scalar value, which applies the same tolerance\nto all values, or list-like, which applies variable tolerance per\nelement. List-like includes list, tuple, array, Series, and must be\nthe same size as the index and its dtype must exactly match the\nindex’s type."]], "Returns": [["Series or DataFrame", "Same type as caller, but with changed indices on each axis."]], "Category": ["Series"], "index": 537}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dtypes.html#pandas.Series.dtypes"], "Title": ["Series.dtypes"], "Feature": ["Series.dtypes"], "Description": "Return the dtype object of the underlying data.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.dtypes\ndtype('int64')\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 538}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rename.html#pandas.Series.rename"], "Title": ["Series.rename"], "Feature": ["Series.rename"], "Description": "Alter Series index labels or name.\nFunction / dict values must be unique (1-to-1). Labels not contained in\na dict / Series will be left as-is. Extra labels listed don’t throw an\nerror.\nAlternatively, changeSeries.namewith a scalar value.\nSee theuser guidefor more.\nSee alsoDataFrame.renameCorresponding DataFrame method.Series.rename_axisSet the name of the axis.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s\n0    1\n1    2\n2    3\ndtype: int64\n>>> s.rename(\"my_name\")  # scalar, changes Series.name\n0    1\n1    2\n2    3\nName: my_name, dtype: int64\n>>> s.rename(lambda x: x ** 2)  # function, changes labels\n0    1\n1    2\n4    3\ndtype: int64\n>>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n0    1\n3    2\n5    3\ndtype: int64\n"], "Parameters": [["index scalar, hashable sequence, dict-like or function optional", "Functions or dict-like are transformations to apply to\nthe index.\nScalar or hashable sequence-like will alter the Series.name attribute."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["copy bool, default True", "Also copy underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["inplace bool, default False", "Whether to return a new Series. If True the value of copy is ignored."], ["level int or level name, default None", "In case of MultiIndex, only rename labels in the specified level."], ["errors {‘ignore’, ‘raise’}, default ‘ignore’", "If ‘raise’, raise KeyError when a dict-like mapper or index contains labels that are not present in the index being transformed.\nIf ‘ignore’, existing keys will be renamed and extra keys will be ignored."]], "Returns": [["Series or None", "Series with index labels or name altered or None if inplace=True ."]], "Category": ["Series"], "index": 539}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rename_axis.html#pandas.Series.rename_axis"], "Title": ["Series.rename_axis"], "Feature": ["Series.rename_axis"], "Description": "Set the name of the axis for the index or columns.\nSee alsoSeries.renameAlter Series index labels or name.DataFrame.renameAlter DataFrame index labels or name.Index.renameSet new names on index.\nNotes\nDataFrame.rename_axissupports two calling conventions\n(index=index_mapper,columns=columns_mapper,...)(mapper,axis={'index','columns'},...)\nThe first calling convention will only modify the names of\nthe index and/or the names of the Index object that is the columns.\nIn this case, the parametercopyis ignored.\nThe second calling convention will modify the names of the\ncorresponding index if mapper is a list or a scalar.\nHowever, if mapper is dict-like or a function, it will use the\ndeprecated behavior of modifying the axislabels.\nWehighlyrecommend using keyword arguments to clarify your\nintent.", "Examples": [">>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n>>> s\n0       dog\n1       cat\n2    monkey\ndtype: object\n>>> s.rename_axis(\"animal\")\nanimal\n0    dog\n1    cat\n2    monkey\ndtype: object\n"], "Parameters": [["mapper scalar, list-like, optional", "Value to set the axis name attribute."], ["index, columns scalar, list-like, dict-like or function, optional", "A scalar, list-like, dict-like or functions transformations to\napply to that axis’ values.\nNote that the columns parameter is not allowed if the\nobject is a Series. This parameter only apply for DataFrame\ntype objects. Use either mapper and axis to\nspecify the axis to target with mapper , or index and/or columns ."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to rename. For Series this parameter is unused and defaults to 0."], ["copy bool, default None", "Also copy underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["inplace bool, default False", "Modifies the object directly, instead of creating a new Series\nor DataFrame."]], "Returns": [["Series, DataFrame, or None", "The same type as the caller or None if inplace=True ."]], "Category": ["Series"], "index": 540}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.reset_index.html#pandas.Series.reset_index"], "Title": ["Series.reset_index"], "Feature": ["Series.reset_index"], "Description": "Generate a new DataFrame or Series with the index reset.\nThis is useful when the index needs to be treated as a column, or\nwhen the index is meaningless and needs to be reset to the default\nbefore another operation.\nSee alsoDataFrame.reset_indexAnalogous function for DataFrame.", "Examples": [">>> s = pd.Series([1, 2, 3, 4], name='foo',\n...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n"], "Parameters": [["level int, str, tuple, or list, default optional", "For a Series with a MultiIndex, only remove the specified levels\nfrom the index. Removes all levels by default."], ["drop bool, default False", "Just reset the index, without inserting it as a column in\nthe new DataFrame."], ["name object, optional", "The name to use for the column containing the original Series\nvalues. Uses self.name by default. This argument is ignored\nwhen drop is True."], ["inplace bool, default False", "Modify the Series in place (do not create a new object)."], ["allow_duplicates bool, default False", "Allow duplicate column labels to be created. Added in version 1.5.0."]], "Returns": [["Series or DataFrame or None", "When drop is False (the default), a DataFrame is returned.\nThe newly created columns will come first in the DataFrame,\nfollowed by the original Series values.\nWhen drop is True, a Series is returned.\nIn either case, if inplace=True , no value is returned."]], "Category": ["Series"], "index": 541}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sample.html#pandas.Series.sample"], "Title": ["Series.sample"], "Feature": ["Series.sample"], "Description": "Return a random sample of items from an axis of object.\nYou can userandom_statefor reproducibility.\nSee alsoDataFrameGroupBy.sampleGenerates random samples from each group of a DataFrame object.SeriesGroupBy.sampleGenerates random samples from each group of a Series object.numpy.random.choiceGenerates a random sample from a given 1-D numpy array.\nNotes\nIffrac> 1,replacementshould be set toTrue.", "Examples": [">>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n...                    'num_wings': [2, 0, 0, 0],\n...                    'num_specimen_seen': [10, 2, 1, 8]},\n...                   index=['falcon', 'dog', 'spider', 'fish'])\n>>> df\n        num_legs  num_wings  num_specimen_seen\nfalcon         2          2                 10\ndog            4          0                  2\nspider         8          0                  1\nfish           0          0                  8\n"], "Parameters": [["n int, optional", "Number of items from axis to return. Cannot be used with frac .\nDefault = 1 if frac = None."], ["frac float, optional", "Fraction of axis items to return. Cannot be used with n ."], ["replace bool, default False", "Allow or disallow sampling of the same row more than once."], ["weights str or ndarray-like, optional", "Default ‘None’ results in equal probability weighting.\nIf passed a Series, will align with target object on index. Index\nvalues in weights not found in sampled object will be ignored and\nindex values in sampled object not in weights will be assigned\nweights of zero.\nIf called on a DataFrame, will accept the name of a column\nwhen axis = 0.\nUnless weights are a Series, weights must be same length as axis\nbeing sampled.\nIf weights do not sum to 1, they will be normalized to sum to 1.\nMissing values in the weights column will be treated as zero.\nInfinite values not allowed."], ["random_state int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional", "If int, array-like, or BitGenerator, seed for random number generator.\nIf np.random.RandomState or np.random.Generator, use as given. Changed in version 1.4.0: np.random.Generator objects now accepted"], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "Axis to sample. Accepts axis number or name. Default is stat axis\nfor given data type. For Series this parameter is unused and defaults to None ."], ["ignore_index bool, default False", "If True, the resulting index will be labeled 0, 1, …, n - 1. Added in version 1.3.0."]], "Returns": [["Series or DataFrame", "A new object of same type as caller containing n items randomly\nsampled from the caller object."]], "Category": ["Series"], "index": 542}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html#pandas.Series.set_axis"], "Title": ["Series.set_axis"], "Feature": ["Series.set_axis"], "Description": "Assign desired index to given axis.\nIndexes for row labels can be changed by assigning\na list-like or Index.\nSee alsoSeries.rename_axisAlter the name of the index.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s\n0    1\n1    2\n2    3\ndtype: int64\n"], "Parameters": [["labels list-like, Index", "The values for the new index."], ["axis {0 or ‘index’}, default 0", "The axis to update. The value 0 identifies the rows. For Series this parameter is unused and defaults to 0."], ["copy bool, default True", "Whether to make a copy of the underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["Series", "An object of type Series."]], "Category": ["Series"], "index": 543}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.take.html#pandas.Series.take"], "Title": ["Series.take"], "Feature": ["Series.take"], "Description": "Return the elements in the givenpositionalindices along an axis.\nThis means that we are not indexing according to actual values in\nthe index attribute of the object. We are indexing according to the\nactual position of the element in the object.\nSee alsoDataFrame.locSelect a subset of a DataFrame by labels.DataFrame.ilocSelect a subset of a DataFrame by positions.numpy.takeTake elements from an array along an axis.", "Examples": [">>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n...                    ('parrot', 'bird', 24.0),\n...                    ('lion', 'mammal', 80.5),\n...                    ('monkey', 'mammal', np.nan)],\n...                   columns=['name', 'class', 'max_speed'],\n...                   index=[0, 2, 3, 1])\n>>> df\n     name   class  max_speed\n0  falcon    bird      389.0\n2  parrot    bird       24.0\n3    lion  mammal       80.5\n1  monkey  mammal        NaN\n"], "Parameters": [["indices array-like", "An array of ints indicating which positions to take."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "The axis on which to select elements. 0 means that we are\nselecting rows, 1 means that we are selecting columns.\nFor Series this parameter is unused and defaults to 0."], ["**kwargs", "For compatibility with numpy.take() . Has no effect on the\noutput."]], "Returns": [["same type as caller", "An array-like containing the elements taken from the object."]], "Category": ["Series"], "index": 544}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.tail.html#pandas.Series.tail"], "Title": ["Series.tail"], "Feature": ["Series.tail"], "Description": "Return the lastnrows.\nThis function returns lastnrows from the object based on\nposition. It is useful for quickly verifying data, for example,\nafter sorting or appending rows.\nFor negative values ofn, this function returns all rows except\nthe first|n|rows, equivalent todf[|n|:].\nIf n is larger than the number of rows, this function returns all rows.\nSee alsoDataFrame.headThe firstnrows of the caller object.", "Examples": [">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n>>> df\n      animal\n0  alligator\n1        bee\n2     falcon\n3       lion\n4     monkey\n5     parrot\n6      shark\n7      whale\n8      zebra\n"], "Parameters": [["n int, default 5", "Number of rows to select."]], "Returns": [["type of caller", "The last n rows of the caller object."]], "Category": ["Series"], "index": 545}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.truncate.html#pandas.Series.truncate"], "Title": ["Series.truncate"], "Feature": ["Series.truncate"], "Description": "Truncate a Series or DataFrame before and after some index value.\nThis is a useful shorthand for boolean indexing based on index\nvalues above or below certain thresholds.\nSee alsoDataFrame.locSelect a subset of a DataFrame by label.DataFrame.ilocSelect a subset of a DataFrame by position.\nNotes\nIf the index being truncated contains only datetime values,beforeandaftermay be specified as strings instead of\nTimestamps.", "Examples": [">>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n...                    'B': ['f', 'g', 'h', 'i', 'j'],\n...                    'C': ['k', 'l', 'm', 'n', 'o']},\n...                   index=[1, 2, 3, 4, 5])\n>>> df\n   A  B  C\n1  a  f  k\n2  b  g  l\n3  c  h  m\n4  d  i  n\n5  e  j  o\n"], "Parameters": [["before date, str, int", "Truncate all rows before this index value."], ["after date, str, int", "Truncate all rows after this index value."], ["axis {0 or ‘index’, 1 or ‘columns’}, optional", "Axis to truncate. Truncates the index (rows) by default.\nFor Series this parameter is unused and defaults to 0."], ["copy bool, default is True,", "Return a copy of the truncated section. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["type of caller", "The truncated Series or DataFrame."]], "Category": ["Series"], "index": 546}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.where.html#pandas.Series.where"], "Title": ["Series.where"], "Feature": ["Series.where"], "Description": "Replace values where the condition is False.\nSee alsoDataFrame.mask()Return an object of same shape as self.\nNotes\nThe where method is an application of the if-then idiom. For each\nelement in the calling DataFrame, ifcondisTruethe\nelement is used; otherwise the corresponding element from the DataFrameotheris used. If the axis ofotherdoes not align with axis ofcondSeries/DataFrame, the misaligned index positions will be filled with\nFalse.\nThe signature forDataFrame.where()differs fromnumpy.where(). Roughlydf1.where(m,df2)is equivalent tonp.where(m,df1,df2).\nFor further details and examples see thewheredocumentation inindexing.\nThe dtype of the object takes precedence. The fill value is casted to\nthe object’s dtype, if this can be done losslessly.", "Examples": [">>> s = pd.Series(range(5))\n>>> s.where(s > 0)\n0    NaN\n1    1.0\n2    2.0\n3    3.0\n4    4.0\ndtype: float64\n>>> s.mask(s > 0)\n0    0.0\n1    NaN\n2    NaN\n3    NaN\n4    NaN\ndtype: float64\n"], "Parameters": [["cond bool Series/DataFrame, array-like, or callable", "Where cond is True, keep the original value. Where\nFalse, replace with corresponding value from other .\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it)."], ["other scalar, Series/DataFrame, or callable", "Entries where cond is False are replaced with\ncorresponding value from other .\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value ( np.nan for numpy dtypes, pd.NA for extension\ndtypes)."], ["inplace bool, default False", "Whether to perform the operation in place on the data."], ["axis int, default None", "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0."], ["level int, default None", "Alignment level if needed."]], "Returns": [["Same type as caller or None if inplace=True .", ""]], "Category": ["Series"], "index": 547}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.mask.html#pandas.Series.mask"], "Title": ["Series.mask"], "Feature": ["Series.mask"], "Description": "Replace values where the condition is True.\nSee alsoDataFrame.where()Return an object of same shape as self.\nNotes\nThe mask method is an application of the if-then idiom. For each\nelement in the calling DataFrame, ifcondisFalsethe\nelement is used; otherwise the corresponding element from the DataFrameotheris used. If the axis ofotherdoes not align with axis ofcondSeries/DataFrame, the misaligned index positions will be filled with\nTrue.\nThe signature forDataFrame.where()differs fromnumpy.where(). Roughlydf1.where(m,df2)is equivalent tonp.where(m,df1,df2).\nFor further details and examples see themaskdocumentation inindexing.\nThe dtype of the object takes precedence. The fill value is casted to\nthe object’s dtype, if this can be done losslessly.", "Examples": [">>> s = pd.Series(range(5))\n>>> s.where(s > 0)\n0    NaN\n1    1.0\n2    2.0\n3    3.0\n4    4.0\ndtype: float64\n>>> s.mask(s > 0)\n0    0.0\n1    NaN\n2    NaN\n3    NaN\n4    NaN\ndtype: float64\n"], "Parameters": [["cond bool Series/DataFrame, array-like, or callable", "Where cond is False, keep the original value. Where\nTrue, replace with corresponding value from other .\nIf cond is callable, it is computed on the Series/DataFrame and\nshould return boolean Series/DataFrame or array. The callable must\nnot change input Series/DataFrame (though pandas doesn’t check it)."], ["other scalar, Series/DataFrame, or callable", "Entries where cond is True are replaced with\ncorresponding value from other .\nIf other is callable, it is computed on the Series/DataFrame and\nshould return scalar or Series/DataFrame. The callable must not\nchange input Series/DataFrame (though pandas doesn’t check it).\nIf not specified, entries will be filled with the corresponding\nNULL value ( np.nan for numpy dtypes, pd.NA for extension\ndtypes)."], ["inplace bool, default False", "Whether to perform the operation in place on the data."], ["axis int, default None", "Alignment axis if needed. For Series this parameter is\nunused and defaults to 0."], ["level int, default None", "Alignment level if needed."]], "Returns": [["Same type as caller or None if inplace=True .", ""]], "Category": ["Series"], "index": 548}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.name.html#pandas.Series.name"], "Title": ["Series.name"], "Feature": ["Series.name"], "Description": "Return the name of the Series.\nThe name of a Series becomes its index or column name if it is used\nto form a DataFrame. It is also used whenever displaying the Series\nusing the interpreter.\nSee alsoSeries.renameSets the Series name when given a scalar input.Index.nameCorresponding Index property.", "Examples": [">>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\n>>> s\n0    1\n1    2\n2    3\nName: Numbers, dtype: int64\n>>> s.name = \"Integers\"\n>>> s\n0    1\n1    2\n2    3\nName: Integers, dtype: int64\n"], "Parameters": [], "Returns": [["label (hashable object)", "The name of the Series, also the column name if part of a DataFrame."]], "Category": ["Series"], "index": 549}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.add_prefix.html#pandas.Series.add_prefix"], "Title": ["Series.add_prefix"], "Feature": ["Series.add_prefix"], "Description": "Prefix labels with stringprefix.\nFor Series, the row labels are prefixed.\nFor DataFrame, the column labels are prefixed.\nSee alsoSeries.add_suffixSuffix row labels with stringsuffix.DataFrame.add_suffixSuffix column labels with stringsuffix.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s\n0    1\n1    2\n2    3\n3    4\ndtype: int64\n"], "Parameters": [["prefix str", "The string to add before each label."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "Axis to add prefix on Added in version 2.0.0."]], "Returns": [["Series or DataFrame", "New Series or DataFrame with updated labels."]], "Category": ["Series"], "index": 550}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.add_suffix.html#pandas.Series.add_suffix"], "Title": ["Series.add_suffix"], "Feature": ["Series.add_suffix"], "Description": "Suffix labels with stringsuffix.\nFor Series, the row labels are suffixed.\nFor DataFrame, the column labels are suffixed.\nSee alsoSeries.add_prefixPrefix row labels with stringprefix.DataFrame.add_prefixPrefix column labels with stringprefix.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s\n0    1\n1    2\n2    3\n3    4\ndtype: int64\n"], "Parameters": [["suffix str", "The string to add after each label."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "Axis to add suffix on Added in version 2.0.0."]], "Returns": [["Series or DataFrame", "New Series or DataFrame with updated labels."]], "Category": ["Series"], "index": 551}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.filter.html#pandas.Series.filter"], "Title": ["Series.filter"], "Feature": ["Series.filter"], "Description": "Subset the dataframe rows or columns according to the specified index labels.\nNote that this routine does not filter a dataframe on its\ncontents. The filter is applied to the labels of the index.\nSee alsoDataFrame.locAccess a group of rows and columns by label(s) or a boolean array.\nNotes\nTheitems,like, andregexparameters are\nenforced to be mutually exclusive.\naxisdefaults to the info axis that is used when indexing\nwith[].", "Examples": [">>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n...                   index=['mouse', 'rabbit'],\n...                   columns=['one', 'two', 'three'])\n>>> df\n        one  two  three\nmouse     1    2      3\nrabbit    4    5      6\n"], "Parameters": [["items list-like", "Keep labels from axis which are in items."], ["like str", "Keep labels from axis for which “like in label == True”."], ["regex str (regular expression)", "Keep labels from axis for which re.search(regex, label) == True."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "The axis to filter on, expressed either as an index (int)\nor axis name (str). By default this is the info axis, ‘columns’ for\nDataFrame. For Series this parameter is unused and defaults to None ."]], "Returns": [["same type as input object", ""]], "Category": ["Series"], "index": 552}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.backfill.html#pandas.Series.backfill"], "Title": ["Series.backfill"], "Feature": ["Series.backfill"], "Description": "Fill NA/NaN values by using the next valid observation to fill the gap.\nDeprecated since version 2.0:Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.", "Examples": [], "Parameters": [], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Series"], "index": 553}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.bfill.html#pandas.Series.bfill"], "Title": ["Series.bfill"], "Feature": ["Series.bfill"], "Description": "Fill NA/NaN values by using the next valid observation to fill the gap.", "Examples": [">>> s = pd.Series([1, None, None, 2])\n>>> s.bfill()\n0    1.0\n1    2.0\n2    2.0\n3    2.0\ndtype: float64\n>>> s.bfill(limit=1)\n0    1.0\n1    NaN\n2    2.0\n3    2.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "Axis along which to fill missing values. For Series this parameter is unused and defaults to 0."], ["inplace bool, default False", "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame)."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["limit_area { None , ‘inside’, ‘outside’}, default None", "If limit is specified, consecutive NaNs will be filled with this\nrestriction. None : No fill restriction. ‘inside’: Only fill NaNs surrounded by valid values\n(interpolate). ‘outside’: Only fill NaNs outside valid values (extrapolate). Added in version 2.2.0."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible). Deprecated since version 2.2.0."]], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Series"], "index": 554}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dropna.html#pandas.Series.dropna"], "Title": ["Series.dropna"], "Feature": ["Series.dropna"], "Description": "Return a new Series with missing values removed.\nSee theUser Guidefor more on which values are\nconsidered missing, and how to work with missing data.\nSee alsoSeries.isnaIndicate missing values.Series.notnaIndicate existing (non-missing) values.Series.fillnaReplace missing values.DataFrame.dropnaDrop rows or columns which contain NA values.Index.dropnaDrop missing indices.", "Examples": [">>> ser = pd.Series([1., 2., np.nan])\n>>> ser\n0    1.0\n1    2.0\n2    NaN\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["inplace bool, default False", "If True, do operation inplace and return None."], ["how str, optional", "Not in use. Kept for compatibility."], ["ignore_index bool, default False", "If True , the resulting axis will be labeled 0, 1, …, n - 1. Added in version 2.0.0."]], "Returns": [["Series or None", "Series with NA entries dropped from it or None if inplace=True ."]], "Category": ["Series"], "index": 555}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.ffill.html#pandas.Series.ffill"], "Title": ["Series.ffill"], "Feature": ["Series.ffill"], "Description": "Fill NA/NaN values by propagating the last valid observation to next valid.", "Examples": [">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n...                    [3, 4, np.nan, 1],\n...                    [np.nan, np.nan, np.nan, np.nan],\n...                    [np.nan, 3, np.nan, 4]],\n...                   columns=list(\"ABCD\"))\n>>> df\n     A    B   C    D\n0  NaN  2.0 NaN  0.0\n1  3.0  4.0 NaN  1.0\n2  NaN  NaN NaN  NaN\n3  NaN  3.0 NaN  4.0\n"], "Parameters": [["axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "Axis along which to fill missing values. For Series this parameter is unused and defaults to 0."], ["inplace bool, default False", "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame)."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["limit_area { None , ‘inside’, ‘outside’}, default None", "If limit is specified, consecutive NaNs will be filled with this\nrestriction. None : No fill restriction. ‘inside’: Only fill NaNs surrounded by valid values\n(interpolate). ‘outside’: Only fill NaNs outside valid values (extrapolate). Added in version 2.2.0."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible). Deprecated since version 2.2.0."]], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Series"], "index": 556}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html#pandas.Series.fillna"], "Title": ["Series.fillna"], "Feature": ["Series.fillna"], "Description": "Fill NA/NaN values using the specified method.\nSee alsoffillFill values by propagating the last valid observation to next valid.bfillFill values by using the next valid observation to fill the gap.interpolateFill NaN values using interpolation.reindexConform object to new index.asfreqConvert TimeSeries to specified frequency.", "Examples": [">>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n...                    [3, 4, np.nan, 1],\n...                    [np.nan, np.nan, np.nan, np.nan],\n...                    [np.nan, 3, np.nan, 4]],\n...                   columns=list(\"ABCD\"))\n>>> df\n     A    B   C    D\n0  NaN  2.0 NaN  0.0\n1  3.0  4.0 NaN  1.0\n2  NaN  NaN NaN  NaN\n3  NaN  3.0 NaN  4.0\n"], "Parameters": [["value scalar, dict, Series, or DataFrame", "Value to use to fill holes (e.g. 0), alternately a\ndict/Series/DataFrame of values specifying which value to use for\neach index (for a Series) or column (for a DataFrame).  Values not\nin the dict/Series/DataFrame will not be filled. This value cannot\nbe a list."], ["method {‘backfill’, ‘bfill’, ‘ffill’, None}, default None", "Method to use for filling holes in reindexed Series: ffill: propagate last valid observation forward to next valid. backfill / bfill: use next valid observation to fill gap. Deprecated since version 2.1.0: Use ffill or bfill instead."], ["axis {0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame", "Axis along which to fill missing values. For Series this parameter is unused and defaults to 0."], ["inplace bool, default False", "If True, fill in-place. Note: this will modify any\nother views on this object (e.g., a no-copy slice for a column in a\nDataFrame)."], ["limit int, default None", "If method is specified, this is the maximum number of consecutive\nNaN values to forward/backward fill. In other words, if there is\na gap with more than this number of consecutive NaNs, it will only\nbe partially filled. If method is not specified, this is the\nmaximum number of entries along the entire axis where NaNs will be\nfilled. Must be greater than 0 if not None."], ["downcast dict, default is None", "A dict of item->dtype of what to downcast if possible,\nor the string ‘infer’ which will try to downcast to an appropriate\nequal type (e.g. float64 to int64 if possible). Deprecated since version 2.2.0."]], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Series"], "index": 557}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate"], "Title": ["Series.interpolate"], "Feature": ["Series.interpolate"], "Description": "Fill NaN values using an interpolation method.\nPlease note that onlymethod='linear'is supported for\nDataFrame/Series with a MultiIndex.\nSee alsofillnaFill missing values using different methods.scipy.interpolate.Akima1DInterpolatorPiecewise cubic polynomials (Akima interpolator).scipy.interpolate.BPoly.from_derivativesPiecewise polynomial in the Bernstein basis.scipy.interpolate.interp1dInterpolate a 1-D function.scipy.interpolate.KroghInterpolatorInterpolate polynomial (Krogh interpolator).scipy.interpolate.PchipInterpolatorPCHIP 1-d monotonic cubic interpolation.scipy.interpolate.CubicSplineCubic spline data interpolator.\nNotes\nThe ‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’ and ‘akima’\nmethods are wrappers around the respective SciPy implementations of\nsimilar names. These use the actual numerical values of the index.\nFor more information on their behavior, see theSciPy documentation.", "Examples": [">>> s = pd.Series([0, 1, np.nan, 3])\n>>> s\n0    0.0\n1    1.0\n2    NaN\n3    3.0\ndtype: float64\n>>> s.interpolate()\n0    0.0\n1    1.0\n2    2.0\n3    3.0\ndtype: float64\n"], "Parameters": [["method str, default ‘linear’", "Interpolation technique to use. One of: ‘linear’: Ignore the index and treat the values as equally\nspaced. This is the only method supported on MultiIndexes. ‘time’: Works on daily and higher resolution data to interpolate\ngiven length of interval. ‘index’, ‘values’: use the actual numerical values of the index. ‘pad’: Fill in NaNs using existing values. ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,\n‘barycentric’, ‘polynomial’: Passed to scipy.interpolate.interp1d , whereas ‘spline’ is passed to scipy.interpolate.UnivariateSpline . These methods use the numerical\nvalues of the index.  Both ‘polynomial’ and ‘spline’ require that\nyou also specify an order (int), e.g. df.interpolate(method='polynomial', order=5) . Note that, slinear method in Pandas refers to the Scipy first order spline instead of Pandas first order spline . ‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,\n‘cubicspline’: Wrappers around the SciPy interpolation methods of\nsimilar names. See Notes . ‘from_derivatives’: Refers to scipy.interpolate.BPoly.from_derivatives ."], ["axis {{0 or ‘index’, 1 or ‘columns’, None}}, default None", "Axis to interpolate along. For Series this parameter is unused\nand defaults to 0."], ["limit int, optional", "Maximum number of consecutive NaNs to fill. Must be greater than\n0."], ["inplace bool, default False", "Update the data in place if possible."], ["limit_direction {{‘forward’, ‘backward’, ‘both’}}, Optional", "Consecutive NaNs will be filled in this direction. If limit is specified: If ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’. If ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’. If ‘limit’ is not specified: If ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’ else the default is ‘forward’ raises ValueError if limit_direction is ‘forward’ or ‘both’ and method is ‘backfill’ or ‘bfill’. raises ValueError if limit_direction is ‘backward’ or ‘both’ and method is ‘pad’ or ‘ffill’."], ["If limit is specified:", "If ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’. If ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be\n‘backwards’."], ["If ‘limit’ is not specified:", "If ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’ else the default is ‘forward’"], ["raises ValueError if limit_direction is ‘forward’ or ‘both’ and", "method is ‘backfill’ or ‘bfill’."], ["raises ValueError if limit_direction is ‘backward’ or ‘both’ and", "method is ‘pad’ or ‘ffill’."], ["limit_area {{ None , ‘inside’, ‘outside’}}, default None", "If limit is specified, consecutive NaNs will be filled with this\nrestriction. None : No fill restriction. ‘inside’: Only fill NaNs surrounded by valid values\n(interpolate). ‘outside’: Only fill NaNs outside valid values (extrapolate)."], ["downcast optional, ‘infer’ or None, defaults to None", "Downcast dtypes if possible. Deprecated since version 2.1.0."], ["``**kwargs`` optional", "Keyword arguments to pass on to the interpolating function."]], "Returns": [["Series or DataFrame or None", "Returns the same object type as the caller, interpolated at\nsome or all NaN values or None if inplace=True ."]], "Category": ["Series"], "index": 558}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.isna.html#pandas.Series.isna"], "Title": ["Series.isna"], "Feature": ["Series.isna"], "Description": "Detect missing values.\nReturn a boolean same-sized object indicating if the values are NA.\nNA values, such as None ornumpy.NaN, gets mapped to True\nvalues.\nEverything else gets mapped to False values. Characters such as empty\nstrings''ornumpy.infare not considered NA values\n(unless you setpandas.options.mode.use_inf_as_na=True).\nSee alsoSeries.isnullAlias of isna.Series.notnaBoolean inverse of isna.Series.dropnaOmit axes labels with missing values.isnaTop-level isna.", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker\n"], "Parameters": [], "Returns": [["Series", "Mask of bool values for each element in Series that\nindicates whether an element is an NA value."]], "Category": ["Series"], "index": 559}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.flags.html#pandas.Series.flags"], "Title": ["Series.flags"], "Feature": ["Series.flags"], "Description": "Get the properties associated with this pandas object.\nThe available flags are\nFlags.allows_duplicate_labels\nSee alsoFlagsFlags that apply to pandas objects.DataFrame.attrsGlobal metadata applying to this dataset.\nNotes\n“Flags” differ from “metadata”. Flags reflect properties of the\npandas object (the Series or DataFrame). Metadata refer to properties\nof the dataset, and should be stored inDataFrame.attrs.", "Examples": [">>> df = pd.DataFrame({\"A\": [1, 2]})\n>>> df.flags\n<Flags(allows_duplicate_labels=True)>\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 560}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.isnull.html#pandas.Series.isnull"], "Title": ["Series.isnull"], "Feature": ["Series.isnull"], "Description": "Series.isnull is an alias for Series.isna.\nDetect missing values.\nReturn a boolean same-sized object indicating if the values are NA.\nNA values, such as None ornumpy.NaN, gets mapped to True\nvalues.\nEverything else gets mapped to False values. Characters such as empty\nstrings''ornumpy.infare not considered NA values\n(unless you setpandas.options.mode.use_inf_as_na=True).\nSee alsoSeries.isnullAlias of isna.Series.notnaBoolean inverse of isna.Series.dropnaOmit axes labels with missing values.isnaTop-level isna.", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker\n"], "Parameters": [], "Returns": [["Series", "Mask of bool values for each element in Series that\nindicates whether an element is an NA value."]], "Category": ["Series"], "index": 561}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.notna.html#pandas.Series.notna"], "Title": ["Series.notna"], "Feature": ["Series.notna"], "Description": "Detect existing (non-missing) values.\nReturn a boolean same-sized object indicating if the values are not NA.\nNon-missing values get mapped to True. Characters such as empty\nstrings''ornumpy.infare not considered NA values\n(unless you setpandas.options.mode.use_inf_as_na=True).\nNA values, such as None ornumpy.NaN, get mapped to False\nvalues.\nSee alsoSeries.notnullAlias of notna.Series.isnaBoolean inverse of notna.Series.dropnaOmit axes labels with missing values.notnaTop-level notna.", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker\n"], "Parameters": [], "Returns": [["Series", "Mask of bool values for each element in Series that\nindicates whether an element is not an NA value."]], "Category": ["Series"], "index": 562}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.notnull.html#pandas.Series.notnull"], "Title": ["Series.notnull"], "Feature": ["Series.notnull"], "Description": "Series.notnull is an alias for Series.notna.\nDetect existing (non-missing) values.\nReturn a boolean same-sized object indicating if the values are not NA.\nNon-missing values get mapped to True. Characters such as empty\nstrings''ornumpy.infare not considered NA values\n(unless you setpandas.options.mode.use_inf_as_na=True).\nNA values, such as None ornumpy.NaN, get mapped to False\nvalues.\nSee alsoSeries.notnullAlias of notna.Series.isnaBoolean inverse of notna.Series.dropnaOmit axes labels with missing values.notnaTop-level notna.", "Examples": [">>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n...                              pd.Timestamp('1940-04-25')],\n...                        name=['Alfred', 'Batman', ''],\n...                        toy=[None, 'Batmobile', 'Joker']))\n>>> df\n   age       born    name        toy\n0  5.0        NaT  Alfred       None\n1  6.0 1939-05-27  Batman  Batmobile\n2  NaN 1940-04-25              Joker\n"], "Parameters": [], "Returns": [["Series", "Mask of bool values for each element in Series that\nindicates whether an element is not an NA value."]], "Category": ["Series"], "index": 563}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.pad.html#pandas.Series.pad"], "Title": ["Series.pad"], "Feature": ["Series.pad"], "Description": "Fill NA/NaN values by propagating the last valid observation to next valid.\nDeprecated since version 2.0:Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.", "Examples": [], "Parameters": [], "Returns": [["Series/DataFrame or None", "Object with missing values filled or None if inplace=True ."]], "Category": ["Series"], "index": 564}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html#pandas.Series.replace"], "Title": ["Series.replace"], "Feature": ["Series.replace"], "Description": "Replace values given into_replacewithvalue.\nValues of the Series/DataFrame are replaced with other values dynamically.\nThis differs from updating with.locor.iloc, which require\nyou to specify a location to update with some value.\nSee alsoSeries.fillnaFill NA values.DataFrame.fillnaFill NA values.Series.whereReplace values based on boolean condition.DataFrame.whereReplace values based on boolean condition.DataFrame.mapApply a function to a Dataframe elementwise.Series.mapMap values of Series according to an input mapping or function.Series.str.replaceSimple string replacement.\nNotes\nRegex substitution is performed under the hood withre.sub. The\nrules for substitution forre.subare the same.Regular expressions will only substitute on strings, meaning you\ncannot provide, for example, a regular expression matching floating\npoint numbers and expect the columns in your frame that have a\nnumeric dtype to be matched. However, if those floating point\nnumbersarestrings, then you can do this.This method hasa lotof options. You are encouraged to experiment\nand play with this method to gain intuition about how it works.When dict is used as theto_replacevalue, it is like\nkey(s) in the dict are the to_replace part and\nvalue(s) in the dict are the value parameter.", "Examples": [">>> s = pd.Series([1, 2, 3, 4, 5])\n>>> s.replace(1, 5)\n0    5\n1    2\n2    3\n3    4\n4    5\ndtype: int64\n"], "Parameters": [["to_replace str, regex, list, dict, Series, int, float, or None", "How to find the values that will be replaced. numeric, str or regex: numeric: numeric values equal to to_replace will be\nreplaced with value str: string exactly matching to_replace will be replaced\nwith value regex: regexs matching to_replace will be replaced with value list of str, regex, or numeric: First, if to_replace and value are both lists, they must be the same length. Second, if regex=True then all of the strings in both lists will be interpreted as regexs otherwise they will match\ndirectly. This doesn’t matter much for value since there\nare only a few possible substitution regexes you can use. str, regex and numeric rules apply as above. dict: Dicts can be used to specify different replacement values\nfor different existing values. For example, {'a': 'b', 'y': 'z'} replaces the value ‘a’ with ‘b’ and\n‘y’ with ‘z’. To use a dict in this way, the optional value parameter should not be given. For a DataFrame a dict can specify that different values\nshould be replaced in different columns. For example, {'a': 1, 'b': 'z'} looks for the value 1 in column ‘a’\nand the value ‘z’ in column ‘b’ and replaces these values\nwith whatever is specified in value . The value parameter\nshould not be None in this case. You can treat this as a\nspecial case of passing two lists except that you are\nspecifying the column to search in. For a DataFrame nested dictionaries, e.g., {'a': {'b': np.nan}} , are read as follows: look in column\n‘a’ for the value ‘b’ and replace it with NaN. The optional value parameter should not be specified to use a nested dict in this\nway. You can nest regular expressions as well. Note that\ncolumn names (the top-level dictionary keys in a nested\ndictionary) cannot be regular expressions. None: This means that the regex argument must be a string,\ncompiled regular expression, or list, dict, ndarray or\nSeries of such elements. If value is also None then\nthis must be a nested dictionary or Series. See the examples section for examples of each of these."], ["value scalar, dict, list, str, regex, default None", "Value to replace any values matching to_replace with.\nFor a DataFrame a dict of values can be used to specify which\nvalue to use for each column (columns not in the dict will not be\nfilled). Regular expressions, strings and lists or dicts of such\nobjects are also allowed."], ["inplace bool, default False", "If True, performs operation inplace and returns None."], ["limit int, default None", "Maximum size gap to forward or backward fill. Deprecated since version 2.1.0."], ["regex bool or same types as to_replace , default False", "Whether to interpret to_replace and/or value as regular\nexpressions. Alternatively, this could be a regular expression or a\nlist, dict, or array of regular expressions in which case to_replace must be None ."], ["method {‘pad’, ‘ffill’, ‘bfill’}", "The method to use when for replacement, when to_replace is a\nscalar, list or tuple and value is None . Deprecated since version 2.1.0."]], "Returns": [["Series/DataFrame", "Object after replacement."]], "Category": ["Series"], "index": 565}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.argsort.html#pandas.Series.argsort"], "Title": ["Series.argsort"], "Feature": ["Series.argsort"], "Description": "Return the integer indices that would sort the Series values.\nOverride ndarray.argsort. Argsorts the value, omitting NA/null values,\nand places the result in the same locations as the non-NA values.\nSee alsonumpy.ndarray.argsortReturns the indices that would sort this array.", "Examples": [">>> s = pd.Series([3, 2, 1])\n>>> s.argsort()\n0    2\n1    1\n2    0\ndtype: int64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["kind {‘mergesort’, ‘quicksort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "Choice of sorting algorithm. See numpy.sort() for more\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms."], ["order None", "Has no effect but is accepted for compatibility with numpy."], ["stable None", "Has no effect but is accepted for compatibility with numpy."]], "Returns": [["Series[np.intp]", "Positions of values within the sort order with -1 indicating\nnan values."]], "Category": ["Series"], "index": 566}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.argmin.html#pandas.Series.argmin"], "Title": ["Series.argmin"], "Feature": ["Series.argmin"], "Description": "Return int position of the smallest value in the Series.\nIf the minimum is achieved in multiple locations,\nthe first row position is returned.\nSee alsoSeries.argminReturn position of the minimum value.Series.argmaxReturn position of the maximum value.numpy.ndarray.argminEquivalent method for numpy arrays.Series.idxmaxReturn index label of the maximum values.Series.idxminReturn index label of the minimum values.", "Examples": [">>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n>>> s\nCorn Flakes              100.0\nAlmond Delight           110.0\nCinnamon Toast Crunch    120.0\nCocoa Puff               110.0\ndtype: float64\n"], "Parameters": [["axis {None}", "Unused. Parameter needed for compatibility with DataFrame."], ["skipna bool, default True", "Exclude NA/null values when showing the result."], ["*args, **kwargs", "Additional arguments and keywords for compatibility with NumPy."]], "Returns": [["int", "Row position of the minimum value."]], "Category": ["Series"], "index": 567}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.argmax.html#pandas.Series.argmax"], "Title": ["Series.argmax"], "Feature": ["Series.argmax"], "Description": "Return int position of the largest value in the Series.\nIf the maximum is achieved in multiple locations,\nthe first row position is returned.\nSee alsoSeries.argmaxReturn position of the maximum value.Series.argminReturn position of the minimum value.numpy.ndarray.argmaxEquivalent method for numpy arrays.Series.idxmaxReturn index label of the maximum values.Series.idxminReturn index label of the minimum values.", "Examples": [">>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n>>> s\nCorn Flakes              100.0\nAlmond Delight           110.0\nCinnamon Toast Crunch    120.0\nCocoa Puff               110.0\ndtype: float64\n"], "Parameters": [["axis {None}", "Unused. Parameter needed for compatibility with DataFrame."], ["skipna bool, default True", "Exclude NA/null values when showing the result."], ["*args, **kwargs", "Additional arguments and keywords for compatibility with NumPy."]], "Returns": [["int", "Row position of the maximum value."]], "Category": ["Series"], "index": 568}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.reorder_levels.html#pandas.Series.reorder_levels"], "Title": ["Series.reorder_levels"], "Feature": ["Series.reorder_levels"], "Description": "Rearrange index levels using input order.\nMay not drop or duplicate levels.", "Examples": [">>> arrays = [np.array([\"dog\", \"dog\", \"cat\", \"cat\", \"bird\", \"bird\"]),\n...           np.array([\"white\", \"black\", \"white\", \"black\", \"white\", \"black\"])]\n>>> s = pd.Series([1, 2, 3, 3, 5, 2], index=arrays)\n>>> s\ndog   white    1\n      black    2\ncat   white    3\n      black    3\nbird  white    5\n      black    2\ndtype: int64\n>>> s.reorder_levels([1, 0])\nwhite  dog     1\nblack  dog     2\nwhite  cat     3\nblack  cat     3\nwhite  bird    5\nblack  bird    2\ndtype: int64\n"], "Parameters": [["order list of int representing new level order", "Reference level by number or key."]], "Returns": [["type of caller (new object)", ""]], "Category": ["Series"], "index": 569}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html#pandas.Series.sort_values"], "Title": ["Series.sort_values"], "Feature": ["Series.sort_values"], "Description": "Sort by the values.\nSort a Series in ascending or descending order by some\ncriterion.\nSee alsoSeries.sort_indexSort by the Series indices.DataFrame.sort_valuesSort DataFrame by the values along either axis.DataFrame.sort_indexSort DataFrame by indices.", "Examples": [">>> s = pd.Series([np.nan, 1, 3, 10, 5])\n>>> s\n0     NaN\n1     1.0\n2     3.0\n3     10.0\n4     5.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["ascending bool or list of bools, default True", "If True, sort values in ascending order, otherwise descending."], ["inplace bool, default False", "If True, perform operation in-place."], ["kind {‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. ‘mergesort’ and ‘stable’ are the only stable  algorithms."], ["na_position {‘first’ or ‘last’}, default ‘last’", "Argument ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at\nthe end."], ["ignore_index bool, default False", "If True, the resulting axis will be labeled 0, 1, …, n - 1."], ["key callable, optional", "If not None, apply the key function to the series values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized . It should expect a Series and return an array-like."]], "Returns": [["Series or None", "Series ordered by values or None if inplace=True ."]], "Category": ["Series"], "index": 570}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.set_flags.html#pandas.Series.set_flags"], "Title": ["Series.set_flags"], "Feature": ["Series.set_flags"], "Description": "Return a new object with updated flags.\nSee alsoDataFrame.attrsGlobal metadata applying to this dataset.DataFrame.flagsGlobal flags applying to this object.\nNotes\nThis method returns a new object that’s a view on the same data\nas the input. Mutating the input or the output values will be reflected\nin the other.\nThis method is intended to be used in method chains.\n“Flags” differ from “metadata”. Flags reflect properties of the\npandas object (the Series or DataFrame). Metadata refer to properties\nof the dataset, and should be stored inDataFrame.attrs.", "Examples": [">>> df = pd.DataFrame({\"A\": [1, 2]})\n>>> df.flags.allows_duplicate_labels\nTrue\n>>> df2 = df.set_flags(allows_duplicate_labels=False)\n>>> df2.flags.allows_duplicate_labels\nFalse\n"], "Parameters": [["copy bool, default False", "Specify if a copy of the object should be made. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["allows_duplicate_labels bool, optional", "Whether the returned object allows duplicate labels."]], "Returns": [["Series or DataFrame", "The same type as the caller."]], "Category": ["Series"], "index": 571}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html#pandas.Series.sort_index"], "Title": ["Series.sort_index"], "Feature": ["Series.sort_index"], "Description": "Sort Series by index labels.\nReturns a new Series sorted by label ifinplaceargument isFalse, otherwise updates the original series and returns None.\nSee alsoDataFrame.sort_indexSort DataFrame by the index.DataFrame.sort_valuesSort DataFrame by the value.Series.sort_valuesSort Series by the value.", "Examples": [">>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n>>> s.sort_index()\n1    c\n2    b\n3    a\n4    d\ndtype: object\n"], "Parameters": [["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["level int, optional", "If not None, sort on values in specified index level(s)."], ["ascending bool or list-like of bools, default True", "Sort ascending vs. descending. When the index is a MultiIndex the\nsort direction can be controlled for each level individually."], ["inplace bool, default False", "If True, perform operation in-place."], ["kind {‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’", "Choice of sorting algorithm. See also numpy.sort() for more\ninformation. ‘mergesort’ and ‘stable’ are the only stable algorithms. For\nDataFrames, this option is only applied when sorting on a single\ncolumn or label."], ["na_position {‘first’, ‘last’}, default ‘last’", "If ‘first’ puts NaNs at the beginning, ‘last’ puts NaNs at the end.\nNot implemented for MultiIndex."], ["sort_remaining bool, default True", "If True and sorting by level and index is multilevel, sort by other\nlevels too (in order) after sorting by specified level."], ["ignore_index bool, default False", "If True, the resulting axis will be labeled 0, 1, …, n - 1."], ["key callable, optional", "If not None, apply the key function to the index values\nbefore sorting. This is similar to the key argument in the\nbuiltin sorted() function, with the notable difference that\nthis key function should be vectorized . It should expect an Index and return an Index of the same shape."]], "Returns": [["Series or None", "The original Series sorted by the labels or None if inplace=True ."]], "Category": ["Series"], "index": 572}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.swaplevel.html#pandas.Series.swaplevel"], "Title": ["Series.swaplevel"], "Feature": ["Series.swaplevel"], "Description": "Swap levels i and j in aMultiIndex.\nDefault is to swap the two innermost levels of the index.", "Examples": [">>> s = pd.Series(\n...     [\"A\", \"B\", \"A\", \"C\"],\n...     index=[\n...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n...         [\"January\", \"February\", \"March\", \"April\"],\n...     ],\n... )\n>>> s\nFinal exam  History     January      A\n            Geography   February     B\nCoursework  History     March        A\n            Geography   April        C\ndtype: object\n"], "Parameters": [["i, j int or str", "Levels of the indices to be swapped. Can pass level name as string."], ["copy bool, default True", "Whether to copy underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["Series", "Series with levels swapped in MultiIndex."]], "Category": ["Series"], "index": 573}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.unstack.html#pandas.Series.unstack"], "Title": ["Series.unstack"], "Feature": ["Series.unstack"], "Description": "Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.\nNotes\nReferencethe user guidefor more examples.", "Examples": [">>> s = pd.Series([1, 2, 3, 4],\n...               index=pd.MultiIndex.from_product([['one', 'two'],\n...                                                 ['a', 'b']]))\n>>> s\none  a    1\n     b    2\ntwo  a    3\n     b    4\ndtype: int64\n"], "Parameters": [["level int, str, or list of these, default last level", "Level(s) to unstack, can pass level name."], ["fill_value scalar value, default None", "Value to use when replacing NaN values."], ["sort bool, default True", "Sort the level(s) in the resulting MultiIndex columns."]], "Returns": [["DataFrame", "Unstacked Series."]], "Category": ["Series"], "index": 574}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.explode.html#pandas.Series.explode"], "Title": ["Series.explode"], "Feature": ["Series.explode"], "Description": "Transform each element of a list-like to a row.\nSee alsoSeries.str.splitSplit string values on specified separator.Series.unstackUnstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.DataFrame.meltUnpivot a DataFrame from wide format to long format.DataFrame.explodeExplode a DataFrame from list-like columns to long format.\nNotes\nThis routine will explode list-likes including lists, tuples, sets,\nSeries, and np.ndarray. The result dtype of the subset rows will\nbe object. Scalars will be returned unchanged, and empty list-likes will\nresult in a np.nan for that row. In addition, the ordering of elements in\nthe output will be non-deterministic when exploding sets.\nReferencethe user guidefor more examples.", "Examples": [">>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])\n>>> s\n0    [1, 2, 3]\n1          foo\n2           []\n3       [3, 4]\ndtype: object\n"], "Parameters": [["ignore_index bool, default False", "If True, the resulting index will be labeled 0, 1, …, n - 1."]], "Returns": [["Series", "Exploded lists to rows; index will be duplicated for these rows."]], "Category": ["Series"], "index": 575}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.searchsorted.html#pandas.Series.searchsorted"], "Title": ["Series.searchsorted"], "Feature": ["Series.searchsorted"], "Description": "Find indices where elements should be inserted to maintain order.\nFind the indices into a sorted Seriesselfsuch that, if the\ncorresponding elements invaluewere inserted before the indices,\nthe order ofselfwould be preserved.\nNoteThe Seriesmustbe monotonically sorted, otherwise\nwrong locations will likely be returned. Pandas doesnotcheck this for you.\nSee alsosort_valuesSort by the values along either axis.numpy.searchsortedSimilar method from NumPy.\nNotes\nBinary search is used to find the required insertion points.", "Examples": [">>> ser = pd.Series([1, 2, 3])\n>>> ser\n0    1\n1    2\n2    3\ndtype: int64\n"], "Parameters": [["value array-like or scalar", "Values to insert into self ."], ["side {‘left’, ‘right’}, optional", "If ‘left’, the index of the first suitable location found is given.\nIf ‘right’, return the last such index.  If there is no suitable\nindex, return either 0 or N (where N is the length of self )."], ["sorter 1-D array-like, optional", "Optional array of integer indices that sort self into ascending\norder. They are typically the result of np.argsort ."]], "Returns": [["int or array of int", "A scalar or array of insertion points with the\nsame shape as value ."]], "Category": ["Series"], "index": 576}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.ravel.html#pandas.Series.ravel"], "Title": ["Series.ravel"], "Feature": ["Series.ravel"], "Description": "Return the flattened underlying data as an ndarray or ExtensionArray.\nDeprecated since version 2.2.0:Series.ravel is deprecated. The underlying array is already 1D, so\nravel is not necessary.  Useto_numpy()for conversion to a numpy\narray instead.\nSee alsonumpy.ndarray.ravelReturn a flattened array.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.ravel()  \narray([1, 2, 3])\n"], "Parameters": [], "Returns": [["numpy.ndarray or ExtensionArray", "Flattened data of the Series."]], "Category": ["Series"], "index": 577}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.repeat.html#pandas.Series.repeat"], "Title": ["Series.repeat"], "Feature": ["Series.repeat"], "Description": "Repeat elements of a Series.\nReturns a new Series where each element of the current Series\nis repeated consecutively a given number of times.\nSee alsoIndex.repeatEquivalent function for Index.numpy.repeatSimilar method fornumpy.ndarray.", "Examples": [">>> s = pd.Series(['a', 'b', 'c'])\n>>> s\n0    a\n1    b\n2    c\ndtype: object\n>>> s.repeat(2)\n0    a\n0    a\n1    b\n1    b\n2    c\n2    c\ndtype: object\n>>> s.repeat([1, 2, 3])\n0    a\n1    b\n1    b\n2    c\n2    c\n2    c\ndtype: object\n"], "Parameters": [["repeats int or array of ints", "The number of repetitions for each element. This should be a\nnon-negative integer. Repeating 0 times will return an empty\nSeries."], ["axis None", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "Newly created Series with repeated elements."]], "Category": ["Series"], "index": 578}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.squeeze.html#pandas.Series.squeeze"], "Title": ["Series.squeeze"], "Feature": ["Series.squeeze"], "Description": "Squeeze 1 dimensional axis objects into scalars.\nSeries or DataFrames with a single element are squeezed to a scalar.\nDataFrames with a single column or a single row are squeezed to a\nSeries. Otherwise the object is unchanged.\nThis method is most useful when you don’t know if your\nobject is a Series or DataFrame, but you do know it has just a single\ncolumn. In that case you can safely callsqueezeto ensure you have a\nSeries.\nSee alsoSeries.ilocInteger-location based indexing for selecting scalars.DataFrame.ilocInteger-location based indexing for selecting Series.Series.to_frameInverse of DataFrame.squeeze for a single-column DataFrame.", "Examples": [">>> primes = pd.Series([2, 3, 5, 7])\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "A specific axis to squeeze. By default, all length-1 axes are\nsqueezed. For Series this parameter is unused and defaults to None ."]], "Returns": [["DataFrame, Series, or scalar", "The projection after squeezing axis or all the axes."]], "Category": ["Series"], "index": 579}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.view.html#pandas.Series.view"], "Title": ["Series.view"], "Feature": ["Series.view"], "Description": "Create a new view of the Series.\nDeprecated since version 2.2.0:Series.viewis deprecated and will be removed in a future version.\nUseSeries.astype()as an alternative to change the dtype.\nThis function will return a new Series with a view of the same\nunderlying values in memory, optionally reinterpreted with a new data\ntype. The new data type must preserve the same size in bytes as to not\ncause index misalignment.\nSee alsonumpy.ndarray.viewEquivalent numpy function to create a new view of the same data in memory.\nNotes\nSeries are instantiated withdtype=float64by default. Whilenumpy.ndarray.view()will return a view with the same data type as\nthe original array,Series.view()(without specified dtype)\nwill try usingfloat64and may fail if the original data type size\nin bytes is not the same.", "Examples": [], "Parameters": [["dtype data type", "Data type object or one of their string representations."]], "Returns": [["Series", "A new Series object as a view of the same data in memory."]], "Category": ["Series"], "index": 580}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.compare.html#pandas.Series.compare"], "Title": ["Series.compare"], "Feature": ["Series.compare"], "Description": "Compare to another Series and show the differences.\nSee alsoDataFrame.compareCompare with another DataFrame and show differences.\nNotes\nMatching NaNs will not appear as a difference.", "Examples": [">>> s1 = pd.Series([\"a\", \"b\", \"c\", \"d\", \"e\"])\n>>> s2 = pd.Series([\"a\", \"a\", \"c\", \"b\", \"e\"])\n"], "Parameters": [["other Series", "Object to compare with."], ["align_axis {0 or ‘index’, 1 or ‘columns’}, default 1", "Determine which axis to align the comparison on. 0, or ‘index’ Resulting differences are stacked vertically with rows drawn alternately from self and other. 1, or ‘columns’ Resulting differences are aligned horizontally with columns drawn alternately from self and other."], ["0, or ‘index’ Resulting differences are stacked vertically", "with rows drawn alternately from self and other."], ["1, or ‘columns’ Resulting differences are aligned horizontally", "with columns drawn alternately from self and other."], ["keep_shape bool, default False", "If true, all rows and columns are kept.\nOtherwise, only the ones with different values are kept."], ["keep_equal bool, default False", "If true, the result keeps values that are equal.\nOtherwise, equal values are shown as NaNs."], ["result_names tuple, default (‘self’, ‘other’)", "Set the dataframes names in the comparison. Added in version 1.5.0."]], "Returns": [["Series or DataFrame", "If axis is 0 or ‘index’ the result will be a Series.\nThe resulting index will be a MultiIndex with ‘self’ and ‘other’\nstacked alternately at the inner level. If axis is 1 or ‘columns’ the result will be a DataFrame.\nIt will have two columns namely ‘self’ and ‘other’."]], "Category": ["Series"], "index": 581}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html#pandas.Series.astype"], "Title": ["Series.astype"], "Feature": ["Series.astype"], "Description": "Cast a pandas object to a specified dtypedtype.\nSee alsoto_datetimeConvert argument to datetime.to_timedeltaConvert argument to timedelta.to_numericConvert argument to a numeric type.numpy.ndarray.astypeCast a numpy array to a specified type.\nNotes\nChanged in version 2.0.0:Usingastypeto convert from timezone-naive dtype to\ntimezone-aware dtype will raise an exception.\nUseSeries.dt.tz_localize()instead.", "Examples": [">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n>>> df = pd.DataFrame(data=d)\n>>> df.dtypes\ncol1    int64\ncol2    int64\ndtype: object\n"], "Parameters": [["dtype str, data type, Series or Mapping of column name -> data type", "Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\ncast entire pandas object to the same type. Alternatively, use a\nmapping, e.g. {col: dtype, …}, where col is a column label and dtype is\na numpy.dtype or Python type to cast one or more of the DataFrame’s\ncolumns to column-specific types."], ["copy bool, default True", "Return a copy when copy=True (be very careful setting copy=False as changes to values then may propagate to other\npandas objects). Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["errors {‘raise’, ‘ignore’}, default ‘raise’", "Control raising of exceptions on invalid data for provided dtype. raise : allow exceptions to be raised ignore : suppress exceptions. On error return original object."]], "Returns": [["same type as caller", ""]], "Category": ["Series"], "index": 582}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.update.html#pandas.Series.update"], "Title": ["Series.update"], "Feature": ["Series.update"], "Description": "Modify Series in place using values from passed Series.\nUses non-NA values from passed Series to make updates. Aligns\non index.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.update(pd.Series([4, 5, 6]))\n>>> s\n0    4\n1    5\n2    6\ndtype: int64\n"], "Parameters": [["other Series, or object coercible into Series", ""]], "Returns": [], "Category": ["Series"], "index": 583}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.asfreq.html#pandas.Series.asfreq"], "Title": ["Series.asfreq"], "Feature": ["Series.asfreq"], "Description": "Convert time series to specified frequency.\nReturns the original data conformed to a new index with the specified\nfrequency.\nIf the index of this Series/DataFrame is aPeriodIndex, the new index\nis the result of transforming the original index withPeriodIndex.asfreq(so the original index\nwill map one-to-one to the new index).\nOtherwise, the new index will be equivalent topd.date_range(start,end,freq=freq)wherestartandendare, respectively, the first and\nlast entries in the original index (seepandas.date_range()). The\nvalues corresponding to any timesteps in the new index which were not present\nin the original index will be null (NaN), unless a method for filling\nsuch unknowns is provided (see themethodparameter below).\nTheresample()method is more appropriate if an operation on each group of\ntimesteps (such as an aggregate) is necessary to represent the data at the new\nfrequency.\nSee alsoreindexConform DataFrame to new index with optional filling logic.\nNotes\nTo learn more about the frequency strings, please seethis link.", "Examples": [">>> index = pd.date_range('1/1/2000', periods=4, freq='min')\n>>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n>>> df = pd.DataFrame({'s': series})\n>>> df\n                       s\n2000-01-01 00:00:00    0.0\n2000-01-01 00:01:00    NaN\n2000-01-01 00:02:00    2.0\n2000-01-01 00:03:00    3.0\n"], "Parameters": [["freq DateOffset or str", "Frequency DateOffset or string."], ["method {‘backfill’/’bfill’, ‘pad’/’ffill’}, default None", "Method to use for filling holes in reindexed Series (note this\ndoes not fill NaNs that already were present): ‘pad’ / ‘ffill’: propagate last valid observation forward to next\nvalid ‘backfill’ / ‘bfill’: use NEXT valid observation to fill."], ["how {‘start’, ‘end’}, default end", "For PeriodIndex only (see PeriodIndex.asfreq)."], ["normalize bool, default False", "Whether to reset output index to midnight."], ["fill_value scalar, optional", "Value to use for missing values, applied during upsampling (note\nthis does not fill NaNs that already were present)."]], "Returns": [["Series/DataFrame", "Series/DataFrame object reindexed to the specified frequency."]], "Category": ["Series"], "index": 584}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.asof.html#pandas.Series.asof"], "Title": ["Series.asof"], "Feature": ["Series.asof"], "Description": "Return the last row(s) without any NaNs beforewhere.\nThe last row (for each element inwhere, if list) without any\nNaN is taken.\nIn case of aDataFrame, the last row without NaN\nconsidering only the subset of columns (if notNone)\nIf there is no good value, NaN is returned for a Series or\na Series of NaN values for a DataFrame\nSee alsomerge_asofPerform an asof merge. Similar to left join.\nNotes\nDates are assumed to be sorted. Raises if this is not the case.", "Examples": [">>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n>>> s\n10    1.0\n20    2.0\n30    NaN\n40    4.0\ndtype: float64\n"], "Parameters": [["where date or array-like of dates", "Date(s) before which the last row(s) are returned."], ["subset str or array-like of str, default None", "For DataFrame, if not None , only use these columns to\ncheck for NaNs."]], "Returns": [["scalar, Series, or DataFrame", "The return can be: scalar : when self is a Series and where is a scalar Series: when self is a Series and where is an array-like,\nor when self is a DataFrame and where is a scalar DataFrame : when self is a DataFrame and where is an\narray-like"]], "Category": ["Series"], "index": 585}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.shift.html#pandas.Series.shift"], "Title": ["Series.shift"], "Feature": ["Series.shift"], "Description": "Shift index by desired number of periods with an optional timefreq.\nWhenfreqis not passed, shift the index without realigning the data.\nIffreqis passed (in this case, the index must be date or datetime,\nor it will raise aNotImplementedError), the index will be\nincreased using the periods and thefreq.freqcan be inferred\nwhen specified as “infer” as long as either freq or inferred_freq\nattribute is set in the index.\nSee alsoIndex.shiftShift values of Index.DatetimeIndex.shiftShift values of DatetimeIndex.PeriodIndex.shiftShift values of PeriodIndex.", "Examples": [">>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n...                    \"Col2\": [13, 23, 18, 33, 48],\n...                    \"Col3\": [17, 27, 22, 37, 52]},\n...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n>>> df\n            Col1  Col2  Col3\n2020-01-01    10    13    17\n2020-01-02    20    23    27\n2020-01-03    15    18    22\n2020-01-04    30    33    37\n2020-01-05    45    48    52\n"], "Parameters": [["periods int or Sequence", "Number of periods to shift. Can be positive or negative.\nIf an iterable of ints, the data will be shifted once by each int.\nThis is equivalent to shifting by one value at a time and\nconcatenating all resulting frames. The resulting columns will have\nthe shift suffixed to their column names. For multiple periods,\naxis must not be 1."], ["freq DateOffset, tseries.offsets, timedelta, or str, optional", "Offset to use from the tseries module or time rule (e.g. ‘EOM’).\nIf freq is specified then the index values are shifted but the\ndata is not realigned. That is, use freq if you would like to\nextend the index when shifting and preserve the original data.\nIf freq is specified as “infer” then it will be inferred from\nthe freq or inferred_freq attributes of the index. If neither of\nthose attributes exist, a ValueError is thrown."], ["axis {0 or ‘index’, 1 or ‘columns’, None}, default None", "Shift direction. For Series this parameter is unused and defaults to 0."], ["fill_value object, optional", "The scalar value to use for newly introduced missing values.\nthe default depends on the dtype of self .\nFor numeric data, np.nan is used.\nFor datetime, timedelta, or period data, etc. NaT is used.\nFor extension dtypes, self.dtype.na_value is used."], ["suffix str, optional", "If str and periods is an iterable, this is added after the column\nname and before the shift value for each shifted column name."]], "Returns": [["Series/DataFrame", "Copy of input object, shifted."]], "Category": ["Series"], "index": 586}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.first_valid_index.html#pandas.Series.first_valid_index"], "Title": ["Series.first_valid_index"], "Feature": ["Series.first_valid_index"], "Description": "Return index for first non-NA value or None, if no non-NA value is found.", "Examples": [">>> s = pd.Series([None, 3, 4])\n>>> s.first_valid_index()\n1\n>>> s.last_valid_index()\n2\n"], "Parameters": [], "Returns": [["type of index", ""]], "Category": ["Series"], "index": 587}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.last_valid_index.html#pandas.Series.last_valid_index"], "Title": ["Series.last_valid_index"], "Feature": ["Series.last_valid_index"], "Description": "Return index for last non-NA value or None, if no non-NA value is found.", "Examples": [">>> s = pd.Series([None, 3, 4])\n>>> s.first_valid_index()\n1\n>>> s.last_valid_index()\n2\n"], "Parameters": [], "Returns": [["type of index", ""]], "Category": ["Series"], "index": 588}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.resample.html#pandas.Series.resample"], "Title": ["Series.resample"], "Feature": ["Series.resample"], "Description": "Resample time-series data.\nConvenience method for frequency conversion and resampling of time series.\nThe object must have a datetime-like index (DatetimeIndex,PeriodIndex,\norTimedeltaIndex), or the caller must pass the label of a datetime-like\nseries/index to theon/levelkeyword parameter.\nSee alsoSeries.resampleResample a Series.DataFrame.resampleResample a DataFrame.groupbyGroup Series/DataFrame by mapping, function, label, or list of labels.asfreqReindex a Series/DataFrame with the given frequency without grouping.\nNotes\nSee theuser guidefor more.\nTo learn more about the offset strings, please seethis link.", "Examples": [">>> index = pd.date_range('1/1/2000', periods=9, freq='min')\n>>> series = pd.Series(range(9), index=index)\n>>> series\n2000-01-01 00:00:00    0\n2000-01-01 00:01:00    1\n2000-01-01 00:02:00    2\n2000-01-01 00:03:00    3\n2000-01-01 00:04:00    4\n2000-01-01 00:05:00    5\n2000-01-01 00:06:00    6\n2000-01-01 00:07:00    7\n2000-01-01 00:08:00    8\nFreq: min, dtype: int64\n"], "Parameters": [["rule DateOffset, Timedelta or str", "The offset string or object representing target conversion."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Which axis to use for up- or down-sampling. For Series this parameter\nis unused and defaults to 0. Must be DatetimeIndex , TimedeltaIndex or PeriodIndex . Deprecated since version 2.0.0: Use frame.T.resample(…) instead."], ["closed {‘right’, ‘left’}, default None", "Which side of bin interval is closed. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’."], ["label {‘right’, ‘left’}, default None", "Which bin edge label to label bucket with. The default is ‘left’\nfor all frequency offsets except for ‘ME’, ‘YE’, ‘QE’, ‘BME’,\n‘BA’, ‘BQE’, and ‘W’ which all have a default of ‘right’."], ["convention {‘start’, ‘end’, ‘s’, ‘e’}, default ‘start’", "For PeriodIndex only, controls whether to use the start or\nend of rule ."], ["kind {‘timestamp’, ‘period’}, optional, default None", "Pass ‘timestamp’ to convert the resulting index to a DateTimeIndex or ‘period’ to convert it to a PeriodIndex .\nBy default the input representation is retained. Deprecated since version 2.2.0: Convert index to desired type explicitly instead."], ["on str, optional", "For a DataFrame, column to use instead of index for resampling.\nColumn must be datetime-like."], ["level str or int, optional", "For a MultiIndex, level (name or number) to use for\nresampling. level must be datetime-like."], ["origin Timestamp or str, default ‘start_day’", "The timestamp on which to adjust the grouping. The timezone of origin\nmust match the timezone of the index.\nIf string, must be one of the following: ‘epoch’: origin is 1970-01-01 ‘start’: origin is the first value of the timeseries ‘start_day’: origin is the first day at midnight of the timeseries ‘end’: origin is the last value of the timeseries ‘end_day’: origin is the ceiling midnight of the last day Added in version 1.3.0. Note Only takes effect for Tick-frequencies (i.e. fixed frequencies like\ndays, hours, and minutes, rather than months or quarters)."], ["offset Timedelta or str, default is None", "An offset timedelta added to the origin."], ["group_keys bool, default False", "Whether to include the group keys in the result index when using .apply() on the resampled object. Added in version 1.5.0: Not specifying group_keys will retain values-dependent behavior\nfrom pandas 1.4 and earlier (see pandas 1.5.0 Release notes for examples). Changed in version 2.0.0: group_keys now defaults to False ."]], "Returns": [["pandas.api.typing.Resampler", "Resampler object."]], "Category": ["Series"], "index": 589}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_convert.html#pandas.Series.tz_convert"], "Title": ["Series.tz_convert"], "Feature": ["Series.tz_convert"], "Description": "Convert tz-aware axis to target time zone.", "Examples": [">>> s = pd.Series(\n...     [1],\n...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),\n... )\n>>> s.tz_convert('Asia/Shanghai')\n2018-09-15 07:30:00+08:00    1\ndtype: int64\n"], "Parameters": [["tz str or tzinfo object or None", "Target time zone. Passing None will convert to\nUTC and remove the timezone information."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to convert"], ["level int, str, default None", "If axis is a MultiIndex, convert a specific level. Otherwise\nmust be None."], ["copy bool, default True", "Also make a copy of the underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["Series/DataFrame", "Object with time zone converted axis."]], "Category": ["Series"], "index": 590}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.tz_localize.html#pandas.Series.tz_localize"], "Title": ["Series.tz_localize"], "Feature": ["Series.tz_localize"], "Description": "Localize tz-naive index of a Series or DataFrame to target time zone.\nThis operation localizes the Index. To localize the values in a\ntimezone-naive Series, useSeries.dt.tz_localize().", "Examples": [">>> s = pd.Series(\n...     [1],\n...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),\n... )\n>>> s.tz_localize('CET')\n2018-09-15 01:30:00+02:00    1\ndtype: int64\n"], "Parameters": [["tz str or tzinfo or None", "Time zone to localize. Passing None will remove the\ntime zone information and preserve local time."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The axis to localize"], ["level int, str, default None", "If axis ia a MultiIndex, localize a specific level. Otherwise\nmust be None."], ["copy bool, default True", "Also make a copy of the underlying data. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"], ["ambiguous ‘infer’, bool-ndarray, ‘NaT’, default ‘raise’", "When clocks moved backward due to DST, ambiguous times may arise.\nFor example in Central European Time (UTC+01), when going from\n03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n00:30:00 UTC and at 01:30:00 UTC. In such a situation, the ambiguous parameter dictates how ambiguous times should be\nhandled. ‘infer’ will attempt to infer fall dst-transition hours based on\norder bool-ndarray where True signifies a DST time, False designates\na non-DST time (note that this flag is only applicable for\nambiguous times) ‘NaT’ will return NaT where there are ambiguous times ‘raise’ will raise an AmbiguousTimeError if there are ambiguous\ntimes."], ["nonexistent str, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. Valid values are: ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time ‘NaT’ will return NaT where there are nonexistent times timedelta objects will shift nonexistent times by the timedelta ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["Series/DataFrame", "Same type as the input."]], "Category": ["Series"], "index": 591}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.at_time.html#pandas.Series.at_time"], "Title": ["Series.at_time"], "Feature": ["Series.at_time"], "Description": "Select values at particular time of day (e.g., 9:30AM).\nSee alsobetween_timeSelect values between particular times of the day.firstSelect initial periods of time series based on a date offset.lastSelect final periods of time series based on a date offset.DatetimeIndex.indexer_at_timeGet just the index locations for values at particular time of the day.", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='12h')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n                     A\n2018-04-09 00:00:00  1\n2018-04-09 12:00:00  2\n2018-04-10 00:00:00  3\n2018-04-10 12:00:00  4\n"], "Parameters": [["time datetime.time or str", "The values to select."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "For Series this parameter is unused and defaults to 0."]], "Returns": [["Series or DataFrame", ""]], "Category": ["Series"], "index": 592}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.convert_dtypes.html#pandas.Series.convert_dtypes"], "Title": ["Series.convert_dtypes"], "Feature": ["Series.convert_dtypes"], "Description": "Convert columns to the best possible dtypes using dtypes supportingpd.NA.\nSee alsoinfer_objectsInfer dtypes of objects.to_datetimeConvert argument to datetime.to_timedeltaConvert argument to timedelta.to_numericConvert argument to a numeric type.\nNotes\nBy default,convert_dtypeswill attempt to convert a Series (or each\nSeries in a DataFrame) to dtypes that supportpd.NA. By using the optionsconvert_string,convert_integer,convert_booleanandconvert_floating, it is possible to turn off individual conversions\ntoStringDtype, the integer extension types,BooleanDtypeor floating extension types, respectively.\nFor object-dtyped columns, ifinfer_objectsisTrue, use the inference\nrules as during normal Series/DataFrame construction.  Then, if possible,\nconvert toStringDtype,BooleanDtypeor an appropriate integer\nor floating extension type, otherwise leave asobject.\nIf the dtype is integer, convert to an appropriate integer extension type.\nIf the dtype is numeric, and consists of all integers, convert to an\nappropriate integer extension type. Otherwise, convert to an\nappropriate floating extension type.\nIn the future, as new dtypes are added that supportpd.NA, the results\nof this method will change to support those new dtypes.", "Examples": [">>> df = pd.DataFrame(\n...     {\n...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n...     }\n... )\n"], "Parameters": [["infer_objects bool, default True", "Whether object dtypes should be converted to the best possible types."], ["convert_string bool, default True", "Whether object dtypes should be converted to StringDtype() ."], ["convert_integer bool, default True", "Whether, if possible, conversion can be done to integer extension types."], ["convert_boolean bool, defaults True", "Whether object dtypes should be converted to BooleanDtypes() ."], ["convert_floating bool, defaults True", "Whether, if possible, conversion can be done to floating extension types.\nIf convert_integer is also True, preference will be give to integer\ndtypes if the floats can be faithfully casted to integers."], ["dtype_backend {‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’", "Back-end data type applied to the resultant DataFrame (still experimental). Behaviour is as follows: \"numpy_nullable\" : returns nullable-dtype-backed DataFrame (default). \"pyarrow\" : returns pyarrow-backed nullable ArrowDtype DataFrame. Added in version 2.0."]], "Returns": [["Series or DataFrame", "Copy of input object with new dtype."]], "Category": ["Series"], "index": 593}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.between_time.html#pandas.Series.between_time"], "Title": ["Series.between_time"], "Feature": ["Series.between_time"], "Description": "Select values between particular times of the day (e.g., 9:00-9:30 AM).\nBy settingstart_timeto be later thanend_time,\nyou can get the times that arenotbetween the two times.\nSee alsoat_timeSelect values at a particular time of the day.firstSelect initial periods of time series based on a date offset.lastSelect final periods of time series based on a date offset.DatetimeIndex.indexer_between_timeGet just the index locations for values between particular times of the day.", "Examples": [">>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n>>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n>>> ts\n                     A\n2018-04-09 00:00:00  1\n2018-04-10 00:20:00  2\n2018-04-11 00:40:00  3\n2018-04-12 01:00:00  4\n"], "Parameters": [["start_time datetime.time or str", "Initial time as a time filter limit."], ["end_time datetime.time or str", "End time as a time filter limit."], ["inclusive {“both”, “neither”, “left”, “right”}, default “both”", "Include boundaries; whether to set each bound as closed or open."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Determine range time on index or columns value.\nFor Series this parameter is unused and defaults to 0."]], "Returns": [["Series or DataFrame", "Data from the original object filtered to the specified dates range."]], "Category": ["Series"], "index": 594}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html#pandas.Series.str"], "Title": ["Series.str"], "Feature": ["Series.str"], "Description": "Vectorized string functions for Series and Index.\nNAs stay NA unless handled otherwise by a particular method.\nPatterned after Python’s string methods, with some inspiration from\nR’s stringr package.", "Examples": [">>> s = pd.Series([\"A_Str_Series\"])\n>>> s\n0    A_Str_Series\ndtype: object\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 595}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.html#pandas.Series.cat"], "Title": ["Series.cat"], "Feature": ["Series.cat"], "Description": "Accessor object for categorical properties of the Series values.", "Examples": [">>> s = pd.Series(list(\"abbccc\")).astype(\"category\")\n>>> s\n0    a\n1    b\n2    b\n3    c\n4    c\n5    c\ndtype: category\nCategories (3, object): ['a', 'b', 'c']\n"], "Parameters": [["data Series or CategoricalIndex", ""]], "Returns": [], "Category": ["Series"], "index": 596}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html#pandas.Series.dt"], "Title": ["Series.dt"], "Feature": ["Series.dt"], "Description": "Accessor object for datetimelike properties of the Series values.", "Examples": [">>> seconds_series = pd.Series(pd.date_range(\"2000-01-01\", periods=3, freq=\"s\"))\n>>> seconds_series\n0   2000-01-01 00:00:00\n1   2000-01-01 00:00:01\n2   2000-01-01 00:00:02\ndtype: datetime64[ns]\n>>> seconds_series.dt.second\n0    0\n1    1\n2    2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 597}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.html#pandas.Series.sparse"], "Title": ["Series.sparse"], "Feature": ["Series.sparse"], "Description": "Accessor for SparseSparse from other sparse matrix data types.", "Examples": [">>> ser = pd.Series([0, 0, 2, 2, 2], dtype=\"Sparse[int]\")\n>>> ser.sparse.density\n0.6\n>>> ser.sparse.sp_values\narray([2, 2, 2])\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 598}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sparse.html#pandas.DataFrame.sparse"], "Title": ["DataFrame.sparse"], "Feature": ["DataFrame.sparse"], "Description": "DataFrame accessor for sparse data.", "Examples": [">>> df = pd.DataFrame({\"a\": [1, 2, 0, 0],\n...                   \"b\": [3, 0, 0, 4]}, dtype=\"Sparse[int]\")\n>>> df.sparse.density\n0.5\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 599}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Index.str.html#pandas.Index.str"], "Title": ["Index.str"], "Feature": ["Index.str"], "Description": "Vectorized string functions for Series and Index.\nNAs stay NA unless handled otherwise by a particular method.\nPatterned after Python’s string methods, with some inspiration from\nR’s stringr package.", "Examples": [">>> s = pd.Series([\"A_Str_Series\"])\n>>> s\n0    A_Str_Series\ndtype: object\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 600}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html#pandas.Series.dt.date"], "Title": ["Series.dt.date"], "Feature": ["Series.dt.date"], "Description": "Returns numpy array of pythondatetime.dateobjects.\nNamely, the date part of Timestamps without time and\ntimezone information.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.date\n0    2020-01-01\n1    2020-02-01\ndtype: object\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 601}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.time.html#pandas.Series.dt.time"], "Title": ["Series.dt.time"], "Feature": ["Series.dt.time"], "Description": "Returns numpy array ofdatetime.timeobjects.\nThe time part of the Timestamps.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.time\n0    10:00:00\n1    11:00:00\ndtype: object\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 602}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.timetz.html#pandas.Series.dt.timetz"], "Title": ["Series.dt.timetz"], "Feature": ["Series.dt.timetz"], "Description": "Returns numpy array ofdatetime.timeobjects with timezones.\nThe time part of the Timestamps.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.timetz\n0    10:00:00+00:00\n1    11:00:00+00:00\ndtype: object\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 603}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.infer_objects.html#pandas.Series.infer_objects"], "Title": ["Series.infer_objects"], "Feature": ["Series.infer_objects"], "Description": "Attempt to infer better dtypes for object columns.\nAttempts soft conversion of object-dtyped\ncolumns, leaving non-object and unconvertible\ncolumns unchanged. The inference rules are the\nsame as during normal Series/DataFrame construction.\nSee alsoto_datetimeConvert argument to datetime.to_timedeltaConvert argument to timedelta.to_numericConvert argument to numeric type.convert_dtypesConvert argument to best possible dtype.", "Examples": [">>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n>>> df = df.iloc[1:]\n>>> df\n   A\n1  1\n2  2\n3  3\n"], "Parameters": [["copy bool, default True", "Whether to make a copy for non-object or non-inferable columns\nor Series. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["same type as input object", ""]], "Category": ["Series"], "index": 604}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html#pandas.Series.dt.year"], "Title": ["Series.dt.year"], "Feature": ["Series.dt.year"], "Description": "The year of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"YE\")\n... )\n>>> datetime_series\n0   2000-12-31\n1   2001-12-31\n2   2002-12-31\ndtype: datetime64[ns]\n>>> datetime_series.dt.year\n0    2000\n1    2001\n2    2002\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 605}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html#pandas.Series.dt.month"], "Title": ["Series.dt.month"], "Feature": ["Series.dt.month"], "Description": "The month as January=1, December=12.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"ME\")\n... )\n>>> datetime_series\n0   2000-01-31\n1   2000-02-29\n2   2000-03-31\ndtype: datetime64[ns]\n>>> datetime_series.dt.month\n0    1\n1    2\n2    3\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 606}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day.html#pandas.Series.dt.day"], "Title": ["Series.dt.day"], "Feature": ["Series.dt.day"], "Description": "The day of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"D\")\n... )\n>>> datetime_series\n0   2000-01-01\n1   2000-01-02\n2   2000-01-03\ndtype: datetime64[ns]\n>>> datetime_series.dt.day\n0    1\n1    2\n2    3\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 607}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.hour.html#pandas.Series.dt.hour"], "Title": ["Series.dt.hour"], "Feature": ["Series.dt.hour"], "Description": "The hours of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"h\")\n... )\n>>> datetime_series\n0   2000-01-01 00:00:00\n1   2000-01-01 01:00:00\n2   2000-01-01 02:00:00\ndtype: datetime64[ns]\n>>> datetime_series.dt.hour\n0    0\n1    1\n2    2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 608}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.minute.html#pandas.Series.dt.minute"], "Title": ["Series.dt.minute"], "Feature": ["Series.dt.minute"], "Description": "The minutes of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"min\")\n... )\n>>> datetime_series\n0   2000-01-01 00:00:00\n1   2000-01-01 00:01:00\n2   2000-01-01 00:02:00\ndtype: datetime64[ns]\n>>> datetime_series.dt.minute\n0    0\n1    1\n2    2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 609}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.second.html#pandas.Series.dt.second"], "Title": ["Series.dt.second"], "Feature": ["Series.dt.second"], "Description": "The seconds of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"s\")\n... )\n>>> datetime_series\n0   2000-01-01 00:00:00\n1   2000-01-01 00:00:01\n2   2000-01-01 00:00:02\ndtype: datetime64[ns]\n>>> datetime_series.dt.second\n0    0\n1    1\n2    2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 610}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microsecond.html#pandas.Series.dt.microsecond"], "Title": ["Series.dt.microsecond"], "Feature": ["Series.dt.microsecond"], "Description": "The microseconds of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"us\")\n... )\n>>> datetime_series\n0   2000-01-01 00:00:00.000000\n1   2000-01-01 00:00:00.000001\n2   2000-01-01 00:00:00.000002\ndtype: datetime64[ns]\n>>> datetime_series.dt.microsecond\n0       0\n1       1\n2       2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 611}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanosecond.html#pandas.Series.dt.nanosecond"], "Title": ["Series.dt.nanosecond"], "Feature": ["Series.dt.nanosecond"], "Description": "The nanoseconds of the datetime.", "Examples": [">>> datetime_series = pd.Series(\n...     pd.date_range(\"2000-01-01\", periods=3, freq=\"ns\")\n... )\n>>> datetime_series\n0   2000-01-01 00:00:00.000000000\n1   2000-01-01 00:00:00.000000001\n2   2000-01-01 00:00:00.000000002\ndtype: datetime64[ns]\n>>> datetime_series.dt.nanosecond\n0       0\n1       1\n2       2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 612}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofweek.html#pandas.Series.dt.dayofweek"], "Title": ["Series.dt.dayofweek"], "Feature": ["Series.dt.dayofweek"], "Description": "The day of the week with Monday=0, Sunday=6.\nReturn the day of the week. It is assumed the week starts on\nMonday, which is denoted by 0 and ends on Sunday which is denoted\nby 6. This method is available on both Series with datetime\nvalues (using thedtaccessor) or DatetimeIndex.\nSee alsoSeries.dt.dayofweekAlias.Series.dt.weekdayAlias.Series.dt.day_nameReturns the name of the day of the week.", "Examples": [">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n>>> s.dt.dayofweek\n2016-12-31    5\n2017-01-01    6\n2017-01-02    0\n2017-01-03    1\n2017-01-04    2\n2017-01-05    3\n2017-01-06    4\n2017-01-07    5\n2017-01-08    6\nFreq: D, dtype: int32\n"], "Parameters": [], "Returns": [["Series or Index", "Containing integers indicating the day number."]], "Category": ["Series"], "index": 613}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_week.html#pandas.Series.dt.day_of_week"], "Title": ["Series.dt.day_of_week"], "Feature": ["Series.dt.day_of_week"], "Description": "The day of the week with Monday=0, Sunday=6.\nReturn the day of the week. It is assumed the week starts on\nMonday, which is denoted by 0 and ends on Sunday which is denoted\nby 6. This method is available on both Series with datetime\nvalues (using thedtaccessor) or DatetimeIndex.\nSee alsoSeries.dt.dayofweekAlias.Series.dt.weekdayAlias.Series.dt.day_nameReturns the name of the day of the week.", "Examples": [">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n>>> s.dt.dayofweek\n2016-12-31    5\n2017-01-01    6\n2017-01-02    0\n2017-01-03    1\n2017-01-04    2\n2017-01-05    3\n2017-01-06    4\n2017-01-07    5\n2017-01-08    6\nFreq: D, dtype: int32\n"], "Parameters": [], "Returns": [["Series or Index", "Containing integers indicating the day number."]], "Category": ["Series"], "index": 614}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.array.html#pandas.Series.array"], "Title": ["Series.array"], "Feature": ["Series.array"], "Description": "The ExtensionArray of the data backing this Series or Index.\nSee alsoIndex.to_numpySimilar method that always returns a NumPy array.Series.to_numpySimilar method that always returns a NumPy array.\nNotes\nThis table lays out the different array types for each extension\ndtype within pandas.\nFor any 3rd-party extension types, the array type will be an\nExtensionArray.\nFor all remaining dtypes.arraywill be aarrays.NumpyExtensionArraywrapping the actual ndarray\nstored within. If you absolutely need a NumPy array (possibly with\ncopying / coercing data), then useSeries.to_numpy()instead.", "Examples": [">>> pd.Series([1, 2, 3]).array\n<NumpyExtensionArray>\n[1, 2, 3]\nLength: 3, dtype: int64\n"], "Parameters": [], "Returns": [["ExtensionArray", "An ExtensionArray of the values stored within. For extension\ntypes, this is the actual array. For NumPy native types, this\nis a thin (no copy) wrapper around numpy.ndarray . .array differs from .values , which may require converting\nthe data to a different form."]], "Category": ["Series"], "index": 615}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.copy.html#pandas.Series.copy"], "Title": ["Series.copy"], "Feature": ["Series.copy"], "Description": "Make a copy of this object’s indices and data.\nWhendeep=True(default), a new object will be created with a\ncopy of the calling object’s data and indices. Modifications to\nthe data or indices of the copy will not be reflected in the\noriginal object (see notes below).\nWhendeep=False, a new object will be created without copying\nthe calling object’s data or index (only references to the data\nand index are copied). Any changes to the data of the original\nwill be reflected in the shallow copy (and vice versa).\nNoteThedeep=Falsebehaviour as described above will change\nin pandas 3.0.Copy-on-Writewill be enabled by default, which means that the “shallow” copy\nis that is returned withdeep=Falsewill still avoid making\nan eager copy, but changes to the data of the original willnolonger be reflected in the shallow copy (or vice versa). Instead,\nit makes use of a lazy (deferred) copy mechanism that will copy\nthe data only when any changes to the original or shallow copy is\nmade.You can already get the future behavior and improvements through\nenabling copy on writepd.options.mode.copy_on_write=True\nNotes\nWhendeep=True, data is copied but actual Python objects\nwill not be copied recursively, only the reference to the object.\nThis is in contrast tocopy.deepcopyin the Standard Library,\nwhich recursively copies object data (see examples below).\nWhileIndexobjects are copied whendeep=True, the underlying\nnumpy array is not copied for performance reasons. SinceIndexis\nimmutable, the underlying data can be safely shared and a copy\nis not needed.\nSince pandas is not thread safe, see thegotchaswhen copying in a threading\nenvironment.\nWhencopy_on_writein pandas config is set toTrue, thecopy_on_writeconfig takes effect even whendeep=False.\nThis means that any changes to the copied data would make a new copy\nof the data upon write (and vice versa). Changes made to either the\noriginal or copied variable would not be reflected in the counterpart.\nSeeCopy_on_Writefor more information.", "Examples": [">>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n>>> s\na    1\nb    2\ndtype: int64\n"], "Parameters": [["deep bool, default True", "Make a deep copy, including a copy of the data and the indices.\nWith deep=False neither the indices nor the data are copied."]], "Returns": [["Series or DataFrame", "Object type matches caller."]], "Category": ["Series"], "index": 616}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html#pandas.Series.dt.weekday"], "Title": ["Series.dt.weekday"], "Feature": ["Series.dt.weekday"], "Description": "The day of the week with Monday=0, Sunday=6.\nReturn the day of the week. It is assumed the week starts on\nMonday, which is denoted by 0 and ends on Sunday which is denoted\nby 6. This method is available on both Series with datetime\nvalues (using thedtaccessor) or DatetimeIndex.\nSee alsoSeries.dt.dayofweekAlias.Series.dt.weekdayAlias.Series.dt.day_nameReturns the name of the day of the week.", "Examples": [">>> s = pd.date_range('2016-12-31', '2017-01-08', freq='D').to_series()\n>>> s.dt.dayofweek\n2016-12-31    5\n2017-01-01    6\n2017-01-02    0\n2017-01-03    1\n2017-01-04    2\n2017-01-05    3\n2017-01-06    4\n2017-01-07    5\n2017-01-08    6\nFreq: D, dtype: int32\n"], "Parameters": [], "Returns": [["Series or Index", "Containing integers indicating the day number."]], "Category": ["Series"], "index": 617}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofyear.html#pandas.Series.dt.dayofyear"], "Title": ["Series.dt.dayofyear"], "Feature": ["Series.dt.dayofyear"], "Description": "The ordinal day of the year.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.dayofyear\n0    1\n1   32\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 618}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_of_year.html#pandas.Series.dt.day_of_year"], "Title": ["Series.dt.day_of_year"], "Feature": ["Series.dt.day_of_year"], "Description": "The ordinal day of the year.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.dayofyear\n0    1\n1   32\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 619}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days_in_month.html#pandas.Series.dt.days_in_month"], "Title": ["Series.dt.days_in_month"], "Feature": ["Series.dt.days_in_month"], "Description": "The number of days in the month.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.daysinmonth\n0    31\n1    29\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 620}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.quarter.html#pandas.Series.dt.quarter"], "Title": ["Series.dt.quarter"], "Feature": ["Series.dt.quarter"], "Description": "The quarter of the date.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"4/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-04-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.quarter\n0    1\n1    2\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 621}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_start.html#pandas.Series.dt.is_month_start"], "Title": ["Series.dt.is_month_start"], "Feature": ["Series.dt.is_month_start"], "Description": "Indicates whether the date is the first day of the month.\nSee alsois_month_startReturn a boolean indicating whether the date is the first day of the month.is_month_endReturn a boolean indicating whether the date is the last day of the month.", "Examples": [">>> s = pd.Series(pd.date_range(\"2018-02-27\", periods=3))\n>>> s\n0   2018-02-27\n1   2018-02-28\n2   2018-03-01\ndtype: datetime64[ns]\n>>> s.dt.is_month_start\n0    False\n1    False\n2    True\ndtype: bool\n>>> s.dt.is_month_end\n0    False\n1    True\n2    False\ndtype: bool\n"], "Parameters": [], "Returns": [["Series or array", "For Series, returns a Series with boolean values.\nFor DatetimeIndex, returns a boolean array."]], "Category": ["Series"], "index": 622}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_month_end.html#pandas.Series.dt.is_month_end"], "Title": ["Series.dt.is_month_end"], "Feature": ["Series.dt.is_month_end"], "Description": "Indicates whether the date is the last day of the month.\nSee alsois_month_startReturn a boolean indicating whether the date is the first day of the month.is_month_endReturn a boolean indicating whether the date is the last day of the month.", "Examples": [">>> s = pd.Series(pd.date_range(\"2018-02-27\", periods=3))\n>>> s\n0   2018-02-27\n1   2018-02-28\n2   2018-03-01\ndtype: datetime64[ns]\n>>> s.dt.is_month_start\n0    False\n1    False\n2    True\ndtype: bool\n>>> s.dt.is_month_end\n0    False\n1    True\n2    False\ndtype: bool\n"], "Parameters": [], "Returns": [["Series or array", "For Series, returns a Series with boolean values.\nFor DatetimeIndex, returns a boolean array."]], "Category": ["Series"], "index": 623}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_start.html#pandas.Series.dt.is_quarter_start"], "Title": ["Series.dt.is_quarter_start"], "Feature": ["Series.dt.is_quarter_start"], "Description": "Indicator for whether the date is the first day of a quarter.\nSee alsoquarterReturn the quarter of the date.is_quarter_endSimilar property for indicating the quarter end.", "Examples": [">>> df = pd.DataFrame({'dates': pd.date_range(\"2017-03-30\",\n...                   periods=4)})\n>>> df.assign(quarter=df.dates.dt.quarter,\n...           is_quarter_start=df.dates.dt.is_quarter_start)\n       dates  quarter  is_quarter_start\n0 2017-03-30        1             False\n1 2017-03-31        1             False\n2 2017-04-01        2              True\n3 2017-04-02        2             False\n"], "Parameters": [], "Returns": [["is_quarter_start Series or DatetimeIndex", "The same type as the original data with boolean values. Series will\nhave the same name and index. DatetimeIndex will have the same\nname."]], "Category": ["Series"], "index": 624}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_quarter_end.html#pandas.Series.dt.is_quarter_end"], "Title": ["Series.dt.is_quarter_end"], "Feature": ["Series.dt.is_quarter_end"], "Description": "Indicator for whether the date is the last day of a quarter.\nSee alsoquarterReturn the quarter of the date.is_quarter_startSimilar property indicating the quarter start.", "Examples": [">>> df = pd.DataFrame({'dates': pd.date_range(\"2017-03-30\",\n...                    periods=4)})\n>>> df.assign(quarter=df.dates.dt.quarter,\n...           is_quarter_end=df.dates.dt.is_quarter_end)\n       dates  quarter    is_quarter_end\n0 2017-03-30        1             False\n1 2017-03-31        1              True\n2 2017-04-01        2             False\n3 2017-04-02        2             False\n"], "Parameters": [], "Returns": [["is_quarter_end Series or DatetimeIndex", "The same type as the original data with boolean values. Series will\nhave the same name and index. DatetimeIndex will have the same\nname."]], "Category": ["Series"], "index": 625}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_start.html#pandas.Series.dt.is_year_start"], "Title": ["Series.dt.is_year_start"], "Feature": ["Series.dt.is_year_start"], "Description": "Indicate whether the date is the first day of a year.\nSee alsois_year_endSimilar property indicating the last day of the year.", "Examples": [">>> dates = pd.Series(pd.date_range(\"2017-12-30\", periods=3))\n>>> dates\n0   2017-12-30\n1   2017-12-31\n2   2018-01-01\ndtype: datetime64[ns]\n"], "Parameters": [], "Returns": [["Series or DatetimeIndex", "The same type as the original data with boolean values. Series will\nhave the same name and index. DatetimeIndex will have the same\nname."]], "Category": ["Series"], "index": 626}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.bool.html#pandas.Series.bool"], "Title": ["Series.bool"], "Feature": ["Series.bool"], "Description": "Return the bool of a single element Series or DataFrame.\nDeprecated since version 2.1.0:bool is deprecated and will be removed in future version of pandas.\nForSeriesusepandas.Series.item.\nThis must be a boolean scalar value, either True or False. It will raise a\nValueError if the Series or DataFrame does not have exactly 1 element, or that\nelement is not boolean (integer values 0 and 1 will also raise an exception).\nSee alsoSeries.astypeChange the data type of a Series, including to boolean.DataFrame.astypeChange the data type of a DataFrame, including to boolean.numpy.bool_NumPy boolean data type, used by pandas for boolean values.", "Examples": [">>> pd.Series([True]).bool()  \nTrue\n>>> pd.Series([False]).bool()  \nFalse\n"], "Parameters": [], "Returns": [["bool", "The value in the Series or DataFrame."]], "Category": ["Series"], "index": 627}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_year_end.html#pandas.Series.dt.is_year_end"], "Title": ["Series.dt.is_year_end"], "Feature": ["Series.dt.is_year_end"], "Description": "Indicate whether the date is the last day of the year.\nSee alsois_year_startSimilar property indicating the start of the year.", "Examples": [">>> dates = pd.Series(pd.date_range(\"2017-12-30\", periods=3))\n>>> dates\n0   2017-12-30\n1   2017-12-31\n2   2018-01-01\ndtype: datetime64[ns]\n"], "Parameters": [], "Returns": [["Series or DatetimeIndex", "The same type as the original data with boolean values. Series will\nhave the same name and index. DatetimeIndex will have the same\nname."]], "Category": ["Series"], "index": 628}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.is_leap_year.html#pandas.Series.dt.is_leap_year"], "Title": ["Series.dt.is_leap_year"], "Feature": ["Series.dt.is_leap_year"], "Description": "Boolean indicator if the date belongs to a leap year.\nA leap year is a year, which has 366 days (instead of 365) including\n29th of February as an intercalary day.\nLeap years are years which are multiples of four with the exception\nof years divisible by 100 but not by 400.", "Examples": [">>> idx = pd.date_range(\"2012-01-01\", \"2015-01-01\", freq=\"YE\")\n>>> idx\nDatetimeIndex(['2012-12-31', '2013-12-31', '2014-12-31'],\n              dtype='datetime64[ns]', freq='YE-DEC')\n>>> idx.is_leap_year\narray([ True, False, False])\n"], "Parameters": [], "Returns": [["Series or ndarray", "Booleans indicating if dates belong to a leap year."]], "Category": ["Series"], "index": 629}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.daysinmonth.html#pandas.Series.dt.daysinmonth"], "Title": ["Series.dt.daysinmonth"], "Feature": ["Series.dt.daysinmonth"], "Description": "The number of days in the month.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.daysinmonth\n0    31\n1    29\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 630}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz.html#pandas.Series.dt.tz"], "Title": ["Series.dt.tz"], "Feature": ["Series.dt.tz"], "Description": "Return the timezone.", "Examples": [">>> s = pd.Series([\"1/1/2020 10:00:00+00:00\", \"2/1/2020 11:00:00+00:00\"])\n>>> s = pd.to_datetime(s)\n>>> s\n0   2020-01-01 10:00:00+00:00\n1   2020-02-01 11:00:00+00:00\ndtype: datetime64[ns, UTC]\n>>> s.dt.tz\ndatetime.timezone.utc\n"], "Parameters": [], "Returns": [["datetime.tzinfo, pytz.tzinfo.BaseTZInfo, dateutil.tz.tz.tzfile, or None", "Returns None when the array is tz-naive."]], "Category": ["Series"], "index": 631}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.freq.html#pandas.Series.dt.freq"], "Title": ["Series.dt.freq"], "Feature": ["Series.dt.freq"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 632}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.unit.html#pandas.Series.dt.unit"], "Title": ["Series.dt.unit"], "Feature": ["Series.dt.unit"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 633}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.isocalendar.html#pandas.Series.dt.isocalendar"], "Title": ["Series.dt.isocalendar"], "Feature": ["Series.dt.isocalendar"], "Description": "Calculate year, week, and day according to the ISO 8601 standard.\nSee alsoTimestamp.isocalendarFunction return a 3-tuple containing ISO year, week number, and weekday for the given Timestamp object.datetime.date.isocalendarReturn a named tuple object with three components: year, week and weekday.", "Examples": [">>> ser = pd.to_datetime(pd.Series([\"2010-01-01\", pd.NaT]))\n>>> ser.dt.isocalendar()\n   year  week  day\n0  2009    53     5\n1  <NA>  <NA>  <NA>\n>>> ser.dt.isocalendar().week\n0      53\n1    <NA>\nName: week, dtype: UInt32\n"], "Parameters": [], "Returns": [["DataFrame", "With columns year, week and day."]], "Category": ["Series"], "index": 634}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html#pandas.Series.dt.to_period"], "Title": ["Series.dt.to_period"], "Feature": ["Series.dt.to_period"], "Description": "Cast to PeriodArray/PeriodIndex at a particular frequency.\nConverts DatetimeArray/Index to PeriodArray/PeriodIndex.\nSee alsoPeriodIndexImmutable ndarray holding ordinal values.DatetimeIndex.to_pydatetimeReturn DatetimeIndex as object.", "Examples": [">>> df = pd.DataFrame({\"y\": [1, 2, 3]},\n...                   index=pd.to_datetime([\"2000-03-31 00:00:00\",\n...                                         \"2000-05-31 00:00:00\",\n...                                         \"2000-08-31 00:00:00\"]))\n>>> df.index.to_period(\"M\")\nPeriodIndex(['2000-03', '2000-05', '2000-08'],\n            dtype='period[M]')\n"], "Parameters": [["freq str or Period, optional", "One of pandas’ period aliases or an Period object. Will be inferred by default."]], "Returns": [["PeriodArray/PeriodIndex", ""]], "Category": ["Series"], "index": 635}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pydatetime.html#pandas.Series.dt.to_pydatetime"], "Title": ["Series.dt.to_pydatetime"], "Feature": ["Series.dt.to_pydatetime"], "Description": "Return the data as an array ofdatetime.datetimeobjects.\nDeprecated since version 2.1.0:The current behavior of dt.to_pydatetime is deprecated.\nIn a future version this will return a Series containing python\ndatetime objects instead of a ndarray.\nTimezone information is retained if present.\nWarningPython’s datetime uses microsecond resolution, which is lower than\npandas (nanosecond). The values are truncated.\nSee alsodatetime.datetimeStandard library value for a datetime.", "Examples": [">>> s = pd.Series(pd.date_range('20180310', periods=2))\n>>> s\n0   2018-03-10\n1   2018-03-11\ndtype: datetime64[ns]\n"], "Parameters": [], "Returns": [["numpy.ndarray", "Object dtype array containing native Python datetime objects."]], "Category": ["Series"], "index": 636}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_localize.html#pandas.Series.dt.tz_localize"], "Title": ["Series.dt.tz_localize"], "Feature": ["Series.dt.tz_localize"], "Description": "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index.\nThis method takes a time zone (tz) naive Datetime Array/Index object\nand makes this time zone aware. It does not move the time to another\ntime zone.\nThis method can also be used to do the inverse – to create a time\nzone unaware object from an aware object. To that end, passtz=None.\nSee alsoDatetimeIndex.tz_convertConvert tz-aware DatetimeIndex from one time zone to another.", "Examples": [">>> tz_naive = pd.date_range('2018-03-01 09:00', periods=3)\n>>> tz_naive\nDatetimeIndex(['2018-03-01 09:00:00', '2018-03-02 09:00:00',\n               '2018-03-03 09:00:00'],\n              dtype='datetime64[ns]', freq='D')\n"], "Parameters": [["tz str, pytz.timezone, dateutil.tz.tzfile, datetime.tzinfo or None", "Time zone to convert timestamps to. Passing None will\nremove the time zone information preserving local time."], ["ambiguous ‘infer’, ‘NaT’, bool array, default ‘raise’", "When clocks moved backward due to DST, ambiguous times may arise.\nFor example in Central European Time (UTC+01), when going from\n03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n00:30:00 UTC and at 01:30:00 UTC. In such a situation, the ambiguous parameter dictates how ambiguous times should be\nhandled. ‘infer’ will attempt to infer fall dst-transition hours based on\norder bool-ndarray where True signifies a DST time, False signifies a\nnon-DST time (note that this flag is only applicable for\nambiguous times) ‘NaT’ will return NaT where there are ambiguous times ‘raise’ will raise an AmbiguousTimeError if there are ambiguous\ntimes."], ["nonexistent ‘shift_forward’, ‘shift_backward, ‘NaT’, timedelta, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time ‘NaT’ will return NaT where there are nonexistent times timedelta objects will shift nonexistent times by the timedelta ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["Same type as self", "Array/Index converted to the specified time zone."]], "Category": ["Series"], "index": 637}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html#pandas.Series.to_numpy"], "Title": ["Series.to_numpy"], "Feature": ["Series.to_numpy"], "Description": "A NumPy ndarray representing the values in this Series or Index.\nSee alsoSeries.arrayGet the actual data stored within.Index.arrayGet the actual data stored within.DataFrame.to_numpySimilar method for DataFrame.\nNotes\nThe returned array will be the same up to equality (values equal\ninselfwill be equal in the returned array; likewise for values\nthat are not equal). Whenselfcontains an ExtensionArray, the\ndtype may be different. For example, for a category-dtype Series,to_numpy()will return a NumPy array and the categorical dtype\nwill be lost.\nFor NumPy dtypes, this will be a reference to the actual data stored\nin this Series or Index (assumingcopy=False). Modifying the result\nin place will modify the data stored in the Series or Index (not that\nwe recommend doing that).\nFor extension types,to_numpy()mayrequire copying data and\ncoercing the result to a NumPy type (possibly object), which may be\nexpensive. When you need a no-copy reference to the underlying data,Series.arrayshould be used instead.\nThis table lays out the different dtypes and default return types ofto_numpy()for various dtypes within pandas.", "Examples": [">>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n>>> ser.to_numpy()\narray(['a', 'b', 'a'], dtype=object)\n"], "Parameters": [["dtype str or numpy.dtype, optional", "The dtype to pass to numpy.asarray() ."], ["copy bool, default False", "Whether to ensure that the returned value is not a view on\nanother array. Note that copy=False does not ensure that to_numpy() is no-copy. Rather, copy=True ensure that\na copy is made, even if not strictly necessary."], ["na_value Any, optional", "The value to use for missing values. The default value depends\non dtype and the type of the array."], ["**kwargs", "Additional keywords passed through to the to_numpy method\nof the underlying array (for extension arrays)."]], "Returns": [["numpy.ndarray", ""]], "Category": ["Series"], "index": 638}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.tz_convert.html#pandas.Series.dt.tz_convert"], "Title": ["Series.dt.tz_convert"], "Feature": ["Series.dt.tz_convert"], "Description": "Convert tz-aware Datetime Array/Index from one time zone to another.\nSee alsoDatetimeIndex.tzA timezone that has a variable offset from UTC.DatetimeIndex.tz_localizeLocalize tz-naive DatetimeIndex to a given time zone, or remove timezone from a tz-aware DatetimeIndex.", "Examples": [">>> dti = pd.date_range(start='2014-08-01 09:00',\n...                     freq='h', periods=3, tz='Europe/Berlin')\n"], "Parameters": [["tz str, pytz.timezone, dateutil.tz.tzfile, datetime.tzinfo or None", "Time zone for time. Corresponding timestamps would be converted\nto this time zone of the Datetime Array/Index. A tz of None will\nconvert to UTC and remove the timezone information."]], "Returns": [["Array or Index", ""]], "Category": ["Series"], "index": 639}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.normalize.html#pandas.Series.dt.normalize"], "Title": ["Series.dt.normalize"], "Feature": ["Series.dt.normalize"], "Description": "Convert times to midnight.\nThe time component of the date-time is converted to midnight i.e.\n00:00:00. This is useful in cases, when the time does not matter.\nLength is unaltered. The timezones are unaffected.\nThis method is available on Series with datetime values under\nthe.dtaccessor, and directly on Datetime Array/Index.\nSee alsofloorFloor the datetimes to the specified freq.ceilCeil the datetimes to the specified freq.roundRound the datetimes to the specified freq.", "Examples": [">>> idx = pd.date_range(start='2014-08-01 10:00', freq='h',\n...                     periods=3, tz='Asia/Calcutta')\n>>> idx\nDatetimeIndex(['2014-08-01 10:00:00+05:30',\n               '2014-08-01 11:00:00+05:30',\n               '2014-08-01 12:00:00+05:30'],\n                dtype='datetime64[ns, Asia/Calcutta]', freq='h')\n>>> idx.normalize()\nDatetimeIndex(['2014-08-01 00:00:00+05:30',\n               '2014-08-01 00:00:00+05:30',\n               '2014-08-01 00:00:00+05:30'],\n               dtype='datetime64[ns, Asia/Calcutta]', freq=None)\n"], "Parameters": [], "Returns": [["DatetimeArray, DatetimeIndex or Series", "The same type as the original data. Series will have the same\nname and index. DatetimeIndex will have the same name."]], "Category": ["Series"], "index": 640}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.strftime.html#pandas.Series.dt.strftime"], "Title": ["Series.dt.strftime"], "Feature": ["Series.dt.strftime"], "Description": "Convert to Index using specified date_format.\nReturn an Index of formatted strings specified by date_format, which\nsupports the same string format as the python standard library. Details\nof the string format can be found inpython string format\ndoc.\nFormats supported by the CstrftimeAPI but not by the python string format\ndoc (such as“%R”,“%r”) are not officially supported and should be\npreferably replaced with their supported equivalents (such as“%H:%M”,“%I:%M:%S %p”).\nNote thatPeriodIndexsupport additional directives, detailed inPeriod.strftime.\nSee alsoto_datetimeConvert the given argument to datetime.DatetimeIndex.normalizeReturn DatetimeIndex with times to midnight.DatetimeIndex.roundRound the DatetimeIndex to the specified freq.DatetimeIndex.floorFloor the DatetimeIndex to the specified freq.Timestamp.strftimeFormat a single Timestamp.Period.strftimeFormat a single Period.", "Examples": [">>> rng = pd.date_range(pd.Timestamp(\"2018-03-10 09:00\"),\n...                     periods=3, freq='s')\n>>> rng.strftime('%B %d, %Y, %r')\nIndex(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',\n       'March 10, 2018, 09:00:02 AM'],\n      dtype='object')\n"], "Parameters": [["date_format str", "Date format string (e.g. “%Y-%m-%d”)."]], "Returns": [["ndarray[object]", "NumPy ndarray of formatted strings."]], "Category": ["Series"], "index": 641}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.round.html#pandas.Series.dt.round"], "Title": ["Series.dt.round"], "Feature": ["Series.dt.round"], "Description": "Perform round operation on the data to the specifiedfreq.\nNotes\nIf the timestamps have a timezone, rounding will take place relative to the\nlocal (“wall”) time and re-localized to the same timezone. When rounding\nnear daylight savings time, usenonexistentandambiguousto\ncontrol the re-localization behavior.", "Examples": [">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n>>> rng\nDatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n               '2018-01-01 12:01:00'],\n              dtype='datetime64[ns]', freq='min')\n>>> rng.round('h')\nDatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',\n               '2018-01-01 12:00:00'],\n              dtype='datetime64[ns]', freq=None)\n"], "Parameters": [["freq str or Offset", "The frequency level to round the index to. Must be a fixed\nfrequency like ‘S’ (second) not ‘ME’ (month end). See frequency aliases for\na list of possible freq values."], ["ambiguous ‘infer’, bool-ndarray, ‘NaT’, default ‘raise’", "Only relevant for DatetimeIndex: ‘infer’ will attempt to infer fall dst-transition hours based on\norder bool-ndarray where True signifies a DST time, False designates\na non-DST time (note that this flag is only applicable for\nambiguous times) ‘NaT’ will return NaT where there are ambiguous times ‘raise’ will raise an AmbiguousTimeError if there are ambiguous\ntimes."], ["nonexistent ‘shift_forward’, ‘shift_backward’, ‘NaT’, timedelta, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time ‘NaT’ will return NaT where there are nonexistent times timedelta objects will shift nonexistent times by the timedelta ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["DatetimeIndex, TimedeltaIndex, or Series", "Index of the same type for a DatetimeIndex or TimedeltaIndex,\nor a Series with the same index for a Series."]], "Category": ["Series"], "index": 642}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html#pandas.Series.dt.floor"], "Title": ["Series.dt.floor"], "Feature": ["Series.dt.floor"], "Description": "Perform floor operation on the data to the specifiedfreq.\nNotes\nIf the timestamps have a timezone, flooring will take place relative to the\nlocal (“wall”) time and re-localized to the same timezone. When flooring\nnear daylight savings time, usenonexistentandambiguousto\ncontrol the re-localization behavior.", "Examples": [">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n>>> rng\nDatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n               '2018-01-01 12:01:00'],\n              dtype='datetime64[ns]', freq='min')\n>>> rng.floor('h')\nDatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',\n               '2018-01-01 12:00:00'],\n              dtype='datetime64[ns]', freq=None)\n"], "Parameters": [["freq str or Offset", "The frequency level to floor the index to. Must be a fixed\nfrequency like ‘S’ (second) not ‘ME’ (month end). See frequency aliases for\na list of possible freq values."], ["ambiguous ‘infer’, bool-ndarray, ‘NaT’, default ‘raise’", "Only relevant for DatetimeIndex: ‘infer’ will attempt to infer fall dst-transition hours based on\norder bool-ndarray where True signifies a DST time, False designates\na non-DST time (note that this flag is only applicable for\nambiguous times) ‘NaT’ will return NaT where there are ambiguous times ‘raise’ will raise an AmbiguousTimeError if there are ambiguous\ntimes."], ["nonexistent ‘shift_forward’, ‘shift_backward’, ‘NaT’, timedelta, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time ‘NaT’ will return NaT where there are nonexistent times timedelta objects will shift nonexistent times by the timedelta ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["DatetimeIndex, TimedeltaIndex, or Series", "Index of the same type for a DatetimeIndex or TimedeltaIndex,\nor a Series with the same index for a Series."]], "Category": ["Series"], "index": 643}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.ceil.html#pandas.Series.dt.ceil"], "Title": ["Series.dt.ceil"], "Feature": ["Series.dt.ceil"], "Description": "Perform ceil operation on the data to the specifiedfreq.\nNotes\nIf the timestamps have a timezone, ceiling will take place relative to the\nlocal (“wall”) time and re-localized to the same timezone. When ceiling\nnear daylight savings time, usenonexistentandambiguousto\ncontrol the re-localization behavior.", "Examples": [">>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')\n>>> rng\nDatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',\n               '2018-01-01 12:01:00'],\n              dtype='datetime64[ns]', freq='min')\n>>> rng.ceil('h')\nDatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',\n               '2018-01-01 13:00:00'],\n              dtype='datetime64[ns]', freq=None)\n"], "Parameters": [["freq str or Offset", "The frequency level to ceil the index to. Must be a fixed\nfrequency like ‘S’ (second) not ‘ME’ (month end). See frequency aliases for\na list of possible freq values."], ["ambiguous ‘infer’, bool-ndarray, ‘NaT’, default ‘raise’", "Only relevant for DatetimeIndex: ‘infer’ will attempt to infer fall dst-transition hours based on\norder bool-ndarray where True signifies a DST time, False designates\na non-DST time (note that this flag is only applicable for\nambiguous times) ‘NaT’ will return NaT where there are ambiguous times ‘raise’ will raise an AmbiguousTimeError if there are ambiguous\ntimes."], ["nonexistent ‘shift_forward’, ‘shift_backward’, ‘NaT’, timedelta, default ‘raise’", "A nonexistent time does not exist in a particular timezone\nwhere clocks moved forward due to DST. ‘shift_forward’ will shift the nonexistent time forward to the\nclosest existing time ‘shift_backward’ will shift the nonexistent time backward to the\nclosest existing time ‘NaT’ will return NaT where there are nonexistent times timedelta objects will shift nonexistent times by the timedelta ‘raise’ will raise an NonExistentTimeError if there are\nnonexistent times."]], "Returns": [["DatetimeIndex, TimedeltaIndex, or Series", "Index of the same type for a DatetimeIndex or TimedeltaIndex,\nor a Series with the same index for a Series."]], "Category": ["Series"], "index": 644}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month_name.html#pandas.Series.dt.month_name"], "Title": ["Series.dt.month_name"], "Feature": ["Series.dt.month_name"], "Description": "Return the month names with specified locale.", "Examples": [">>> s = pd.Series(pd.date_range(start='2018-01', freq='ME', periods=3))\n>>> s\n0   2018-01-31\n1   2018-02-28\n2   2018-03-31\ndtype: datetime64[ns]\n>>> s.dt.month_name()\n0     January\n1    February\n2       March\ndtype: object\n"], "Parameters": [["locale str, optional", "Locale determining the language in which to return the month name.\nDefault is English locale ( 'en_US.utf8' ). Use the command locale -a on your terminal on Unix systems to find your locale\nlanguage code."]], "Returns": [["Series or Index", "Series or Index of month names."]], "Category": ["Series"], "index": 645}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.day_name.html#pandas.Series.dt.day_name"], "Title": ["Series.dt.day_name"], "Feature": ["Series.dt.day_name"], "Description": "Return the day names with specified locale.", "Examples": [">>> s = pd.Series(pd.date_range(start='2018-01-01', freq='D', periods=3))\n>>> s\n0   2018-01-01\n1   2018-01-02\n2   2018-01-03\ndtype: datetime64[ns]\n>>> s.dt.day_name()\n0       Monday\n1      Tuesday\n2    Wednesday\ndtype: object\n"], "Parameters": [["locale str, optional", "Locale determining the language in which to return the day name.\nDefault is English locale ( 'en_US.utf8' ). Use the command locale -a on your terminal on Unix systems to find your locale\nlanguage code."]], "Returns": [["Series or Index", "Series or Index of day names."]], "Category": ["Series"], "index": 646}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.as_unit.html#pandas.Series.dt.as_unit"], "Title": ["Series.dt.as_unit"], "Feature": ["Series.dt.as_unit"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 647}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.qyear.html#pandas.Series.dt.qyear"], "Title": ["Series.dt.qyear"], "Feature": ["Series.dt.qyear"], "Description": "", "Examples": [], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 648}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.to_period.html#pandas.Series.to_period"], "Title": ["Series.to_period"], "Feature": ["Series.to_period"], "Description": "Convert Series from DatetimeIndex to PeriodIndex.", "Examples": [">>> idx = pd.DatetimeIndex(['2023', '2024', '2025'])\n>>> s = pd.Series([1, 2, 3], index=idx)\n>>> s = s.to_period()\n>>> s\n2023    1\n2024    2\n2025    3\nFreq: Y-DEC, dtype: int64\n"], "Parameters": [["freq str, default None", "Frequency associated with the PeriodIndex."], ["copy bool, default True", "Whether or not to return a copy. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["Series", "Series with index converted to PeriodIndex."]], "Category": ["Series"], "index": 649}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.start_time.html#pandas.Series.dt.start_time"], "Title": ["Series.dt.start_time"], "Feature": ["Series.dt.start_time"], "Description": "Get the Timestamp for the start of the period.\nSee alsoPeriod.end_timeReturn the end Timestamp.Period.dayofyearReturn the day of year.Period.daysinmonthReturn the days in that month.Period.dayofweekReturn the day of the week.", "Examples": [">>> period = pd.Period('2012-1-1', freq='D')\n>>> period\nPeriod('2012-01-01', 'D')\n"], "Parameters": [], "Returns": [["Timestamp", ""]], "Category": ["Series"], "index": 650}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.end_time.html#pandas.Series.dt.end_time"], "Title": ["Series.dt.end_time"], "Feature": ["Series.dt.end_time"], "Description": "Get the Timestamp for the end of the period.\nSee alsoPeriod.start_timeReturn the start Timestamp.Period.dayofyearReturn the day of year.Period.daysinmonthReturn the days in that month.Period.dayofweekReturn the day of the week.", "Examples": [">>> pd.Period('2020-01', 'D').end_time\nTimestamp('2020-01-01 23:59:59.999999999')\n"], "Parameters": [], "Returns": [["Timestamp", ""]], "Category": ["Series"], "index": 651}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.days.html#pandas.Series.dt.days"], "Title": ["Series.dt.days"], "Feature": ["Series.dt.days"], "Description": "Number of days for each element.", "Examples": [">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='d'))\n>>> ser\n0   1 days\n1   2 days\n2   3 days\ndtype: timedelta64[ns]\n>>> ser.dt.days\n0    1\n1    2\n2    3\ndtype: int64\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 652}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.seconds.html#pandas.Series.dt.seconds"], "Title": ["Series.dt.seconds"], "Feature": ["Series.dt.seconds"], "Description": "Number of seconds (>= 0 and less than 1 day) for each element.", "Examples": [">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='s'))\n>>> ser\n0   0 days 00:00:01\n1   0 days 00:00:02\n2   0 days 00:00:03\ndtype: timedelta64[ns]\n>>> ser.dt.seconds\n0    1\n1    2\n2    3\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 653}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.microseconds.html#pandas.Series.dt.microseconds"], "Title": ["Series.dt.microseconds"], "Feature": ["Series.dt.microseconds"], "Description": "Number of microseconds (>= 0 and less than 1 second) for each element.", "Examples": [">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='us'))\n>>> ser\n0   0 days 00:00:00.000001\n1   0 days 00:00:00.000002\n2   0 days 00:00:00.000003\ndtype: timedelta64[ns]\n>>> ser.dt.microseconds\n0    1\n1    2\n2    3\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 654}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.nanoseconds.html#pandas.Series.dt.nanoseconds"], "Title": ["Series.dt.nanoseconds"], "Feature": ["Series.dt.nanoseconds"], "Description": "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.", "Examples": [">>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='ns'))\n>>> ser\n0   0 days 00:00:00.000000001\n1   0 days 00:00:00.000000002\n2   0 days 00:00:00.000000003\ndtype: timedelta64[ns]\n>>> ser.dt.nanoseconds\n0    1\n1    2\n2    3\ndtype: int32\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 655}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.components.html#pandas.Series.dt.components"], "Title": ["Series.dt.components"], "Feature": ["Series.dt.components"], "Description": "Return a Dataframe of the components of the Timedeltas.", "Examples": [">>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='s'))\n>>> s\n0   0 days 00:00:00\n1   0 days 00:00:01\n2   0 days 00:00:02\n3   0 days 00:00:03\n4   0 days 00:00:04\ndtype: timedelta64[ns]\n>>> s.dt.components\n   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds\n0     0      0        0        0             0             0            0\n1     0      0        0        1             0             0            0\n2     0      0        0        2             0             0            0\n3     0      0        0        3             0             0            0\n4     0      0        0        4             0             0            0\n"], "Parameters": [], "Returns": [["DataFrame", ""]], "Category": ["Series"], "index": 656}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_pytimedelta.html#pandas.Series.dt.to_pytimedelta"], "Title": ["Series.dt.to_pytimedelta"], "Feature": ["Series.dt.to_pytimedelta"], "Description": "Return an array of nativedatetime.timedeltaobjects.\nPython’s standarddatetimelibrary uses a different representation\ntimedelta’s. This method converts a Series of pandas Timedeltas\ntodatetime.timedeltaformat with the same length as the original\nSeries.\nSee alsodatetime.timedeltaA duration expressing the difference between two date, time, or datetime.", "Examples": [">>> s = pd.Series(pd.to_timedelta(np.arange(5), unit=\"d\"))\n>>> s\n0   0 days\n1   1 days\n2   2 days\n3   3 days\n4   4 days\ndtype: timedelta64[ns]\n"], "Parameters": [], "Returns": [["numpy.ndarray", "Array of 1D containing data with datetime.timedelta type."]], "Category": ["Series"], "index": 657}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.total_seconds.html#pandas.Series.dt.total_seconds"], "Title": ["Series.dt.total_seconds"], "Feature": ["Series.dt.total_seconds"], "Description": "Return total duration of each element expressed in seconds.\nThis method is available directly on TimedeltaArray, TimedeltaIndex\nand on Series containing timedelta values under the.dtnamespace.\nSee alsodatetime.timedelta.total_secondsStandard library version of this method.TimedeltaIndex.componentsReturn a DataFrame with components of each Timedelta.", "Examples": [">>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))\n>>> s\n0   0 days\n1   1 days\n2   2 days\n3   3 days\n4   4 days\ndtype: timedelta64[ns]\n"], "Parameters": [], "Returns": [["ndarray, Index or Series", "When the calling object is a TimedeltaArray, the return type\nis ndarray.  When the calling object is a TimedeltaIndex,\nthe return type is an Index with a float64 dtype. When the calling object\nis a Series, the return type is Series of type float64 whose\nindex is the same as the original."]], "Category": ["Series"], "index": 658}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html#pandas.Series.str.capitalize"], "Title": ["Series.str.capitalize"], "Feature": ["Series.str.capitalize"], "Description": "Convert strings in the Series/Index to be capitalized.\nEquivalent tostr.capitalize().\nSee alsoSeries.str.lowerConverts all characters to lowercase.Series.str.upperConverts all characters to uppercase.Series.str.titleConverts first character of each word to uppercase and remaining to lowercase.Series.str.capitalizeConverts first character to uppercase and remaining to lowercase.Series.str.swapcaseConverts uppercase to lowercase and lowercase to uppercase.Series.str.casefoldRemoves all case distinctions in the string.", "Examples": [">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])\n>>> s\n0                 lower\n1              CAPITALS\n2    this is a sentence\n3              SwApCaSe\ndtype: object\n"], "Parameters": [], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 659}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.to_timestamp.html#pandas.Series.to_timestamp"], "Title": ["Series.to_timestamp"], "Feature": ["Series.to_timestamp"], "Description": "Cast to DatetimeIndex of Timestamps, atbeginningof period.", "Examples": [">>> idx = pd.PeriodIndex(['2023', '2024', '2025'], freq='Y')\n>>> s1 = pd.Series([1, 2, 3], index=idx)\n>>> s1\n2023    1\n2024    2\n2025    3\nFreq: Y-DEC, dtype: int64\n"], "Parameters": [["freq str, default frequency of PeriodIndex", "Desired frequency."], ["how {‘s’, ‘e’, ‘start’, ‘end’}", "Convention for converting period to timestamp; start of period\nvs. end."], ["copy bool, default True", "Whether or not to return a copy. Note The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and\nignore the copy keyword. The copy keyword will be removed in a\nfuture version of pandas. You can already get the future behavior and improvements through\nenabling copy on write pd.options.mode.copy_on_write = True"]], "Returns": [["Series with DatetimeIndex", ""]], "Category": ["Series"], "index": 660}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.casefold.html#pandas.Series.str.casefold"], "Title": ["Series.str.casefold"], "Feature": ["Series.str.casefold"], "Description": "Convert strings in the Series/Index to be casefolded.\nEquivalent tostr.casefold().\nSee alsoSeries.str.lowerConverts all characters to lowercase.Series.str.upperConverts all characters to uppercase.Series.str.titleConverts first character of each word to uppercase and remaining to lowercase.Series.str.capitalizeConverts first character to uppercase and remaining to lowercase.Series.str.swapcaseConverts uppercase to lowercase and lowercase to uppercase.Series.str.casefoldRemoves all case distinctions in the string.", "Examples": [">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])\n>>> s\n0                 lower\n1              CAPITALS\n2    this is a sentence\n3              SwApCaSe\ndtype: object\n"], "Parameters": [], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 661}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.cat.html#pandas.Series.str.cat"], "Title": ["Series.str.cat"], "Feature": ["Series.str.cat"], "Description": "Concatenate strings in the Series/Index with given separator.\nIfothersis specified, this function concatenates the Series/Index\nand elements ofotherselement-wise.\nIfothersis not passed, then all values in the Series/Index are\nconcatenated into a single string with a givensep.\nSee alsosplitSplit each string in the Series/Index.joinJoin lists contained as elements in the Series/Index.", "Examples": [">>> s = pd.Series(['a', 'b', np.nan, 'd'])\n>>> s.str.cat(sep=' ')\n'a b d'\n"], "Parameters": [["others Series, Index, DataFrame, np.ndarray or list-like", "Series, Index, DataFrame, np.ndarray (one- or two-dimensional) and\nother list-likes of strings must have the same length as the\ncalling Series/Index, with the exception of indexed objects (i.e.\nSeries/Index/DataFrame) if join is not None. If others is a list-like that contains a combination of Series,\nIndex or np.ndarray (1-dim), then all elements will be unpacked and\nmust satisfy the above criteria individually. If others is None, the method returns the concatenation of all\nstrings in the calling Series/Index."], ["sep str, default ‘’", "The separator between the different elements/columns. By default\nthe empty string ‘’ is used."], ["na_rep str or None, default None", "Representation that is inserted for all missing values: If na_rep is None, and others is None, missing values in the\nSeries/Index are omitted from the result. If na_rep is None, and others is not None, a row containing a\nmissing value in any of the columns (before concatenation) will\nhave a missing value in the result."], ["join {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘left’", "Determines the join-style between the calling Series/Index and any\nSeries/Index/DataFrame in others (objects without an index need\nto match the length of the calling Series/Index). To disable\nalignment, use .values on any Series/Index/DataFrame in others ."]], "Returns": [["str, Series or Index", "If others is None, str is returned, otherwise a Series/Index (same type as caller) of objects is returned."]], "Category": ["Series"], "index": 662}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.center.html#pandas.Series.str.center"], "Title": ["Series.str.center"], "Feature": ["Series.str.center"], "Description": "Pad left and right side of strings in the Series/Index.\nEquivalent tostr.center().", "Examples": [">>> ser = pd.Series(['dog', 'bird', 'mouse'])\n>>> ser.str.center(8, fillchar='.')\n0   ..dog...\n1   ..bird..\n2   .mouse..\ndtype: object\n"], "Parameters": [["width int", "Minimum width of resulting string; additional characters will be filled\nwith fillchar ."], ["fillchar str", "Additional character for filling, default is whitespace."]], "Returns": [["Series/Index of objects.", ""]], "Category": ["Series"], "index": 663}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains"], "Title": ["Series.str.contains"], "Feature": ["Series.str.contains"], "Description": "Test if pattern or regex is contained within a string of a Series or Index.\nReturn boolean Series or Index based on whether a given pattern or regex is\ncontained within a string of a Series or Index.\nSee alsomatchAnalogous, but stricter, relying on re.match instead of re.search.Series.str.startswithTest if the start of each string element matches a pattern.Series.str.endswithSame as startswith, but tests the end of string.", "Examples": [">>> s1 = pd.Series(['Mouse', 'dog', 'house and parrot', '23', np.nan])\n>>> s1.str.contains('og', regex=False)\n0    False\n1     True\n2    False\n3    False\n4      NaN\ndtype: object\n"], "Parameters": [["pat str", "Character sequence or regular expression."], ["case bool, default True", "If True, case sensitive."], ["flags int, default 0 (no flags)", "Flags to pass through to the re module, e.g. re.IGNORECASE."], ["na scalar, optional", "Fill value for missing values. The default depends on dtype of the\narray. For object-dtype, numpy.nan is used. For the nullable StringDtype , pandas.NA is used. For the \"str\" dtype, False is used."], ["regex bool, default True", "If True, assumes the pat is a regular expression. If False, treats the pat as a literal string."]], "Returns": [["Series or Index of boolean values", "A Series or Index of boolean values indicating whether the\ngiven pattern is contained within the string of each element\nof the Series or Index."]], "Category": ["Series"], "index": 664}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html#pandas.Series.str.count"], "Title": ["Series.str.count"], "Feature": ["Series.str.count"], "Description": "Count occurrences of pattern in each string of the Series/Index.\nThis function is used to count the number of times a particular regex\npattern is repeated in each of the string elements of theSeries.\nSee alsoreStandard library module for regular expressions.str.countStandard library version, without regular expression support.\nNotes\nSome characters need to be escaped when passing inpat.\neg.'$'has a special meaning in regex and must be escaped when\nfinding this literal character.", "Examples": [">>> s = pd.Series(['A', 'B', 'Aaba', 'Baca', np.nan, 'CABA', 'cat'])\n>>> s.str.count('a')\n0    0.0\n1    0.0\n2    2.0\n3    2.0\n4    NaN\n5    0.0\n6    1.0\ndtype: float64\n"], "Parameters": [["pat str", "Valid regular expression."], ["flags int, default 0, meaning no flags", "Flags for the re module. For a complete list, see here ."], ["**kwargs", "For compatibility with other string methods. Not used."]], "Returns": [["Series or Index", "Same type as the calling object containing the integer counts."]], "Category": ["Series"], "index": 665}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.decode.html#pandas.Series.str.decode"], "Title": ["Series.str.decode"], "Feature": ["Series.str.decode"], "Description": "Decode character string in the Series/Index using indicated encoding.\nEquivalent tostr.decode()in python2 andbytes.decode()in\npython3.", "Examples": [">>> ser = pd.Series([b'cow', b'123', b'()'])\n>>> ser.str.decode('ascii')\n0   cow\n1   123\n2   ()\ndtype: object\n"], "Parameters": [["encoding str", ""], ["errors str, optional", "Specifies the error handling scheme.\nPossible values are those supported by bytes.decode() ."], ["dtype str or dtype, optional", "The dtype of the result. When not None , must be either a string or\nobject dtype. When None , the dtype of the result is determined by pd.options.future.infer_string . Added in version 2.3.0."]], "Returns": [["Series or Index", ""]], "Category": ["Series"], "index": 666}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.encode.html#pandas.Series.str.encode"], "Title": ["Series.str.encode"], "Feature": ["Series.str.encode"], "Description": "Encode character string in the Series/Index using indicated encoding.\nEquivalent tostr.encode().", "Examples": [">>> ser = pd.Series(['cow', '123', '()'])\n>>> ser.str.encode(encoding='ascii')\n0     b'cow'\n1     b'123'\n2      b'()'\ndtype: object\n"], "Parameters": [["encoding str", ""], ["errors str, optional", ""]], "Returns": [["Series/Index of objects", ""]], "Category": ["Series"], "index": 667}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.endswith.html#pandas.Series.str.endswith"], "Title": ["Series.str.endswith"], "Feature": ["Series.str.endswith"], "Description": "Test if the end of each string element matches a pattern.\nEquivalent tostr.endswith().\nSee alsostr.endswithPython standard library string method.Series.str.startswithSame as endswith, but tests the start of string.Series.str.containsTests if string element contains a pattern.", "Examples": [">>> s = pd.Series(['bat', 'bear', 'caT', np.nan])\n>>> s\n0     bat\n1    bear\n2     caT\n3     NaN\ndtype: object\n"], "Parameters": [["pat str or tuple[str, …]", "Character sequence or tuple of strings. Regular expressions are not\naccepted."], ["na scalar, optional", "Object shown if element tested is not a string. The default depends\non dtype of the array. For object-dtype, numpy.nan is used.\nFor the nullable StringDtype , pandas.NA is used.\nFor the \"str\" dtype, False is used."]], "Returns": [["Series or Index of bool", "A Series of booleans indicating whether the given pattern matches\nthe end of each string element."]], "Category": ["Series"], "index": 668}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html#pandas.Series.str.extract"], "Title": ["Series.str.extract"], "Feature": ["Series.str.extract"], "Description": "Extract capture groups in the regexpatas columns in a DataFrame.\nFor each subject string in the Series, extract groups from the\nfirst match of regular expressionpat.\nSee alsoextractallReturns all matches (not just the first match).", "Examples": [">>> s = pd.Series(['a1', 'b2', 'c3'])\n>>> s.str.extract(r'([ab])(\\d)')\n    0    1\n0    a    1\n1    b    2\n2  NaN  NaN\n"], "Parameters": [["pat str", "Regular expression pattern with capturing groups."], ["flags int, default 0 (no flags)", "Flags from the re module, e.g. re.IGNORECASE , that\nmodify regular expression matching for things like case,\nspaces, etc. For more details, see re ."], ["expand bool, default True", "If True, return DataFrame with one column per capture group.\nIf False, return a Series/Index if there is one capture group\nor DataFrame if there are multiple capture groups."]], "Returns": [["DataFrame or Series or Index", "A DataFrame with one row for each subject string, and one\ncolumn for each group. Any capture group names in regular\nexpression pat will be used for column names; otherwise\ncapture group numbers will be used. The dtype of each result\ncolumn is always object, even when no match is found. If expand=False and pat has only one capture group, then\nreturn a Series (if subject is a Series) or Index (if subject\nis an Index)."]], "Category": ["Series"], "index": 669}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extractall.html#pandas.Series.str.extractall"], "Title": ["Series.str.extractall"], "Feature": ["Series.str.extractall"], "Description": "Extract capture groups in the regexpatas columns in DataFrame.\nFor each subject string in the Series, extract groups from all\nmatches of regular expression pat. When each subject string in the\nSeries has exactly one match, extractall(pat).xs(0, level=’match’)\nis the same as extract(pat).\nSee alsoextractReturns first match only (not all matches).", "Examples": [">>> s = pd.Series([\"a1a2\", \"b1\", \"c1\"], index=[\"A\", \"B\", \"C\"])\n>>> s.str.extractall(r\"[ab](\\d)\")\n        0\nmatch\nA 0      1\n  1      2\nB 0      1\n"], "Parameters": [["pat str", "Regular expression pattern with capturing groups."], ["flags int, default 0 (no flags)", "A re module flag, for example re.IGNORECASE . These allow\nto modify regular expression matching for things like case, spaces,\netc. Multiple flags can be combined with the bitwise OR operator,\nfor example re.IGNORECASE | re.MULTILINE ."]], "Returns": [["DataFrame", "A DataFrame with one row for each match, and one column for each\ngroup. Its rows have a MultiIndex with first levels that come from\nthe subject Series . The last level is named ‘match’ and indexes the\nmatches in each item of the Series . Any capture group names in\nregular expression pat will be used for column names; otherwise capture\ngroup numbers will be used."]], "Category": ["Series"], "index": 670}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.to_list.html#pandas.Series.to_list"], "Title": ["Series.to_list"], "Feature": ["Series.to_list"], "Description": "Return a list of the values.\nThese are each a scalar type, which is a Python scalar\n(for str, int, float) or a pandas scalar\n(for Timestamp/Timedelta/Interval/Period)\nSee alsonumpy.ndarray.tolistReturn the array as an a.ndim-levels deep nested list of Python scalars.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.to_list()\n[1, 2, 3]\n"], "Parameters": [], "Returns": [["list", ""]], "Category": ["Series"], "index": 671}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.find.html#pandas.Series.str.find"], "Title": ["Series.str.find"], "Feature": ["Series.str.find"], "Description": "Return lowest indexes in each strings in the Series/Index.\nEach of returned indexes corresponds to the position where the\nsubstring is fully contained between [start:end]. Return -1 on\nfailure. Equivalent to standardstr.find().\nSee alsorfindReturn highest indexes in each strings.", "Examples": [">>> ser = pd.Series([\"cow_\", \"duck_\", \"do_ve\"])\n>>> ser.str.find(\"_\")\n0   3\n1   4\n2   2\ndtype: int64\n"], "Parameters": [["sub str", "Substring being searched."], ["start int", "Left edge index."], ["end int", "Right edge index."]], "Returns": [["Series or Index of int.", ""]], "Category": ["Series"], "index": 672}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html#pandas.Series.str.findall"], "Title": ["Series.str.findall"], "Feature": ["Series.str.findall"], "Description": "Find all occurrences of pattern or regular expression in the Series/Index.\nEquivalent to applyingre.findall()to all the elements in the\nSeries/Index.\nSee alsocountCount occurrences of pattern or regular expression in each string of the Series/Index.extractallFor each string in the Series, extract groups from all matches of regular expression and return a DataFrame with one row for each match and one column for each group.re.findallThe equivalentrefunction to all non-overlapping matches of pattern or regular expression in string, as a list of strings.", "Examples": [">>> s = pd.Series(['Lion', 'Monkey', 'Rabbit'])\n"], "Parameters": [["pat str", "Pattern or regular expression."], ["flags int, default 0", "Flags from re module, e.g. re.IGNORECASE (default is 0, which\nmeans no flags)."]], "Returns": [["Series/Index of lists of strings", "All non-overlapping matches of pattern or regular expression in each\nstring of this Series/Index."]], "Category": ["Series"], "index": 673}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.fullmatch.html#pandas.Series.str.fullmatch"], "Title": ["Series.str.fullmatch"], "Feature": ["Series.str.fullmatch"], "Description": "Determine if each string entirely matches a regular expression.\nSee alsomatchSimilar, but also returnsTruewhen only aprefixof the string matches the regular expression.extractExtract matched groups.", "Examples": [">>> ser = pd.Series([\"cat\", \"duck\", \"dove\"])\n>>> ser.str.fullmatch(r'd.+')\n0   False\n1    True\n2    True\ndtype: bool\n"], "Parameters": [["pat str", "Character sequence or regular expression."], ["case bool, default True", "If True, case sensitive."], ["flags int, default 0 (no flags)", "Regex module flags, e.g. re.IGNORECASE."], ["na scalar, optional", "Fill value for missing values. The default depends on dtype of the\narray. For object-dtype, numpy.nan is used. For the nullable StringDtype , pandas.NA is used. For the \"str\" dtype, False is used."]], "Returns": [["Series/Index/array of boolean values", ""]], "Category": ["Series"], "index": 674}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html#pandas.Series.str.get"], "Title": ["Series.str.get"], "Feature": ["Series.str.get"], "Description": "Extract element from each component at specified position or with specified key.\nExtract element from lists, tuples, dict, or strings in each element in the\nSeries/Index.", "Examples": [">>> s = pd.Series([\"String\",\n...               (1, 2, 3),\n...               [\"a\", \"b\", \"c\"],\n...               123,\n...               -456,\n...               {1: \"Hello\", \"2\": \"World\"}])\n>>> s\n0                        String\n1                     (1, 2, 3)\n2                     [a, b, c]\n3                           123\n4                          -456\n5    {1: 'Hello', '2': 'World'}\ndtype: object\n"], "Parameters": [["i int or hashable dict label", "Position or key of element to extract."]], "Returns": [["Series or Index", ""]], "Category": ["Series"], "index": 675}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.index.html#pandas.Series.str.index"], "Title": ["Series.str.index"], "Feature": ["Series.str.index"], "Description": "Return lowest indexes in each string in Series/Index.\nEach of the returned indexes corresponds to the position where the\nsubstring is fully contained between [start:end]. This is the same\nasstr.findexcept instead of returning -1, it raises a\nValueError when the substring is not found. Equivalent to standardstr.index.\nSee alsorindexReturn highest indexes in each strings.", "Examples": [">>> ser = pd.Series([\"horse\", \"eagle\", \"donkey\"])\n>>> ser.str.index(\"e\")\n0   4\n1   0\n2   4\ndtype: int64\n"], "Parameters": [["sub str", "Substring being searched."], ["start int", "Left edge index."], ["end int", "Right edge index."]], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 676}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.join.html#pandas.Series.str.join"], "Title": ["Series.str.join"], "Feature": ["Series.str.join"], "Description": "Join lists contained as elements in the Series/Index with passed delimiter.\nIf the elements of a Series are lists themselves, join the content of these\nlists using the delimiter passed to the function.\nThis function is an equivalent tostr.join().\nSee alsostr.joinStandard library version of this method.Series.str.splitSplit strings around given separator/delimiter.\nNotes\nIf any of the list items is not a string object, the result of the join\nwill beNaN.", "Examples": [">>> s = pd.Series([['lion', 'elephant', 'zebra'],\n...                [1.1, 2.2, 3.3],\n...                ['cat', np.nan, 'dog'],\n...                ['cow', 4.5, 'goat'],\n...                ['duck', ['swan', 'fish'], 'guppy']])\n>>> s\n0        [lion, elephant, zebra]\n1                [1.1, 2.2, 3.3]\n2                [cat, nan, dog]\n3               [cow, 4.5, goat]\n4    [duck, [swan, fish], guppy]\ndtype: object\n"], "Parameters": [["sep str", "Delimiter to use between list entries."]], "Returns": [["Series/Index: object", "The list entries concatenated by intervening occurrences of the\ndelimiter."]], "Category": ["Series"], "index": 677}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html#pandas.Series.str.len"], "Title": ["Series.str.len"], "Feature": ["Series.str.len"], "Description": "Compute the length of each element in the Series/Index.\nThe element may be a sequence (such as a string, tuple or list) or a collection\n(such as a dictionary).\nSee alsostr.lenPython built-in function returning the length of an object.Series.sizeReturns the length of the Series.", "Examples": [">>> s = pd.Series(['dog',\n...                 '',\n...                 5,\n...                 {'foo' : 'bar'},\n...                 [2, 3, 5, 7],\n...                 ('one', 'two', 'three')])\n>>> s\n0                  dog\n1\n2                    5\n3       {'foo': 'bar'}\n4         [2, 3, 5, 7]\n5    (one, two, three)\ndtype: object\n>>> s.str.len()\n0    3.0\n1    0.0\n2    NaN\n3    1.0\n4    4.0\n5    3.0\ndtype: float64\n"], "Parameters": [], "Returns": [["Series or Index of int", "A Series or Index of integer values indicating the length of each\nelement in the Series or Index."]], "Category": ["Series"], "index": 678}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.ljust.html#pandas.Series.str.ljust"], "Title": ["Series.str.ljust"], "Feature": ["Series.str.ljust"], "Description": "Pad right side of strings in the Series/Index.\nEquivalent tostr.ljust().", "Examples": [">>> ser = pd.Series(['dog', 'bird', 'mouse'])\n>>> ser.str.center(8, fillchar='.')\n0   ..dog...\n1   ..bird..\n2   .mouse..\ndtype: object\n"], "Parameters": [["width int", "Minimum width of resulting string; additional characters will be filled\nwith fillchar ."], ["fillchar str", "Additional character for filling, default is whitespace."]], "Returns": [["Series/Index of objects.", ""]], "Category": ["Series"], "index": 679}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html#pandas.Series.str.lower"], "Title": ["Series.str.lower"], "Feature": ["Series.str.lower"], "Description": "Convert strings in the Series/Index to lowercase.\nEquivalent tostr.lower().\nSee alsoSeries.str.lowerConverts all characters to lowercase.Series.str.upperConverts all characters to uppercase.Series.str.titleConverts first character of each word to uppercase and remaining to lowercase.Series.str.capitalizeConverts first character to uppercase and remaining to lowercase.Series.str.swapcaseConverts uppercase to lowercase and lowercase to uppercase.Series.str.casefoldRemoves all case distinctions in the string.", "Examples": [">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])\n>>> s\n0                 lower\n1              CAPITALS\n2    this is a sentence\n3              SwApCaSe\ndtype: object\n"], "Parameters": [], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 680}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lstrip.html#pandas.Series.str.lstrip"], "Title": ["Series.str.lstrip"], "Feature": ["Series.str.lstrip"], "Description": "Remove leading characters.\nStrip whitespaces (including newlines) or a set of specified characters\nfrom each string in the Series/Index from left side.\nReplaces any non-strings in Series with NaNs.\nEquivalent tostr.lstrip().\nSee alsoSeries.str.stripRemove leading and trailing characters in Series/Index.Series.str.lstripRemove leading characters in Series/Index.Series.str.rstripRemove trailing characters in Series/Index.", "Examples": [">>> s = pd.Series(['1. Ant.  ', '2. Bee!\\n', '3. Cat?\\t', np.nan, 10, True])\n>>> s\n0    1. Ant.\n1    2. Bee!\\n\n2    3. Cat?\\t\n3          NaN\n4           10\n5         True\ndtype: object\n"], "Parameters": [["to_strip str or None, default None", "Specifying the set of characters to be removed.\nAll combinations of this set of characters will be stripped.\nIf None then whitespaces are removed."]], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 681}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.match.html#pandas.Series.str.match"], "Title": ["Series.str.match"], "Feature": ["Series.str.match"], "Description": "Determine if each string starts with a match of a regular expression.\nSee alsofullmatchStricter matching that requires the entire string to match.containsAnalogous, but less strict, relying on re.search instead of re.match.extractExtract matched groups.", "Examples": [">>> ser = pd.Series([\"horse\", \"eagle\", \"donkey\"])\n>>> ser.str.match(\"e\")\n0   False\n1   True\n2   False\ndtype: bool\n"], "Parameters": [["pat str or compiled regex", "Character sequence or regular expression."], ["case bool, default True", "If True, case sensitive."], ["flags int, default 0 (no flags)", "Regex module flags, e.g. re.IGNORECASE."], ["na scalar, optional", "Fill value for missing values. The default depends on dtype of the\narray. For object-dtype, numpy.nan is used. For the nullable StringDtype , pandas.NA is used. For the \"str\" dtype, False is used."]], "Returns": [["Series/Index/array of boolean values", ""]], "Category": ["Series"], "index": 683}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.normalize.html#pandas.Series.str.normalize"], "Title": ["Series.str.normalize"], "Feature": ["Series.str.normalize"], "Description": "Return the Unicode normal form for the strings in the Series/Index.\nFor more information on the forms, see theunicodedata.normalize().", "Examples": [">>> ser = pd.Series(['ñ'])\n>>> ser.str.normalize('NFC') == ser.str.normalize('NFD')\n0   False\ndtype: bool\n"], "Parameters": [["form {‘NFC’, ‘NFKC’, ‘NFD’, ‘NFKD’}", "Unicode form."]], "Returns": [["Series/Index of objects", ""]], "Category": ["Series"], "index": 684}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.pad.html#pandas.Series.str.pad"], "Title": ["Series.str.pad"], "Feature": ["Series.str.pad"], "Description": "Pad strings in the Series/Index up to width.\nSee alsoSeries.str.rjustFills the left side of strings with an arbitrary character. Equivalent toSeries.str.pad(side='left').Series.str.ljustFills the right side of strings with an arbitrary character. Equivalent toSeries.str.pad(side='right').Series.str.centerFills both sides of strings with an arbitrary character. Equivalent toSeries.str.pad(side='both').Series.str.zfillPad strings in the Series/Index by prepending ‘0’ character. Equivalent toSeries.str.pad(side='left',fillchar='0').", "Examples": [">>> s = pd.Series([\"caribou\", \"tiger\"])\n>>> s\n0    caribou\n1      tiger\ndtype: object\n"], "Parameters": [["width int", "Minimum width of resulting string; additional characters will be filled\nwith character defined in fillchar ."], ["side {‘left’, ‘right’, ‘both’}, default ‘left’", "Side from which to fill resulting string."], ["fillchar str, default ‘ ‘", "Additional character for filling, default is whitespace."]], "Returns": [["Series or Index of object", "Returns Series or Index with minimum number of char in object."]], "Category": ["Series"], "index": 685}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html#pandas.Series.str.partition"], "Title": ["Series.str.partition"], "Feature": ["Series.str.partition"], "Description": "Split the string at the first occurrence ofsep.\nThis method splits the string at the first occurrence ofsep,\nand returns 3 elements containing the part before the separator,\nthe separator itself, and the part after the separator.\nIf the separator is not found, return 3 elements containing the string itself, followed by two empty strings.\nSee alsorpartitionSplit the string at the last occurrence ofsep.Series.str.splitSplit strings around given separators.str.partitionStandard library version.", "Examples": [">>> s = pd.Series(['Linda van der Berg', 'George Pitt-Rivers'])\n>>> s\n0    Linda van der Berg\n1    George Pitt-Rivers\ndtype: object\n"], "Parameters": [["sep str, default whitespace", "String to split on."], ["expand bool, default True", "If True, return DataFrame/MultiIndex expanding dimensionality.\nIf False, return Series/Index."]], "Returns": [["DataFrame/MultiIndex or Series/Index of objects", ""]], "Category": ["Series"], "index": 686}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removeprefix.html#pandas.Series.str.removeprefix"], "Title": ["Series.str.removeprefix"], "Feature": ["Series.str.removeprefix"], "Description": "Remove a prefix from an object series.\nIf the prefix is not present, the original string will be returned.\nSee alsoSeries.str.removesuffixRemove a suffix from an object series.", "Examples": [">>> s = pd.Series([\"str_foo\", \"str_bar\", \"no_prefix\"])\n>>> s\n0    str_foo\n1    str_bar\n2    no_prefix\ndtype: object\n>>> s.str.removeprefix(\"str_\")\n0    foo\n1    bar\n2    no_prefix\ndtype: object\n"], "Parameters": [["prefix str", "Remove the prefix of the string."]], "Returns": [["Series/Index: object", "The Series or Index with given prefix removed."]], "Category": ["Series"], "index": 687}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.removesuffix.html#pandas.Series.str.removesuffix"], "Title": ["Series.str.removesuffix"], "Feature": ["Series.str.removesuffix"], "Description": "Remove a suffix from an object series.\nIf the suffix is not present, the original string will be returned.\nSee alsoSeries.str.removeprefixRemove a prefix from an object series.", "Examples": [">>> s = pd.Series([\"str_foo\", \"str_bar\", \"no_prefix\"])\n>>> s\n0    str_foo\n1    str_bar\n2    no_prefix\ndtype: object\n>>> s.str.removeprefix(\"str_\")\n0    foo\n1    bar\n2    no_prefix\ndtype: object\n"], "Parameters": [["suffix str", "Remove the suffix of the string."]], "Returns": [["Series/Index: object", "The Series or Index with given suffix removed."]], "Category": ["Series"], "index": 688}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.repeat.html#pandas.Series.str.repeat"], "Title": ["Series.str.repeat"], "Feature": ["Series.str.repeat"], "Description": "Duplicate each string in the Series or Index.", "Examples": [">>> s = pd.Series(['a', 'b', 'c'])\n>>> s\n0    a\n1    b\n2    c\ndtype: object\n"], "Parameters": [["repeats int or sequence of int", "Same value for all (int) or different value per (sequence)."]], "Returns": [["Series or pandas.Index", "Series or Index of repeated string objects specified by\ninput parameter repeats."]], "Category": ["Series"], "index": 689}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html#pandas.Series.str.replace"], "Title": ["Series.str.replace"], "Feature": ["Series.str.replace"], "Description": "Replace each occurrence of pattern/regex in the Series/Index.\nEquivalent tostr.replace()orre.sub(), depending on\nthe regex value.\nNotes\nWhenpatis a compiled regex, all flags should be included in the\ncompiled regex. Use ofcase,flags, orregex=Falsewith a compiled\nregex will raise an error.", "Examples": [">>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f.', 'ba', regex=True)\n0    bao\n1    baz\n2    NaN\ndtype: object\n"], "Parameters": [["pat str or compiled regex", "String can be a character sequence or regular expression."], ["repl str or callable", "Replacement string or a callable. The callable is passed the regex\nmatch object and must return a replacement string to be used.\nSee re.sub() ."], ["n int, default -1 (all)", "Number of replacements to make from start."], ["case bool, default None", "Determines if replace is case sensitive: If True, case sensitive (the default if pat is a string) Set to False for case insensitive Cannot be set if pat is a compiled regex."], ["flags int, default 0 (no flags)", "Regex module flags, e.g. re.IGNORECASE. Cannot be set if pat is a compiled\nregex."], ["regex bool, default False", "Determines if the passed-in pattern is a regular expression: If True, assumes the passed-in pattern is a regular expression. If False, treats the pattern as a literal string Cannot be set to False if pat is a compiled regex or repl is\na callable."]], "Returns": [["Series or Index of object", "A copy of the object with all matching occurrences of pat replaced by repl ."]], "Category": ["Series"], "index": 690}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rfind.html#pandas.Series.str.rfind"], "Title": ["Series.str.rfind"], "Feature": ["Series.str.rfind"], "Description": "Return highest indexes in each strings in the Series/Index.\nEach of returned indexes corresponds to the position where the\nsubstring is fully contained between [start:end]. Return -1 on\nfailure. Equivalent to standardstr.rfind().\nSee alsofindReturn lowest indexes in each strings.", "Examples": [">>> ser = pd.Series([\"cow_\", \"duck_\", \"do_ve\"])\n>>> ser.str.find(\"_\")\n0   3\n1   4\n2   2\ndtype: int64\n"], "Parameters": [["sub str", "Substring being searched."], ["start int", "Left edge index."], ["end int", "Right edge index."]], "Returns": [["Series or Index of int.", ""]], "Category": ["Series"], "index": 691}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rindex.html#pandas.Series.str.rindex"], "Title": ["Series.str.rindex"], "Feature": ["Series.str.rindex"], "Description": "Return highest indexes in each string in Series/Index.\nEach of the returned indexes corresponds to the position where the\nsubstring is fully contained between [start:end]. This is the same\nasstr.rfindexcept instead of returning -1, it raises a\nValueError when the substring is not found. Equivalent to standardstr.rindex.\nSee alsoindexReturn lowest indexes in each strings.", "Examples": [">>> ser = pd.Series([\"horse\", \"eagle\", \"donkey\"])\n>>> ser.str.index(\"e\")\n0   4\n1   0\n2   4\ndtype: int64\n"], "Parameters": [["sub str", "Substring being searched."], ["start int", "Left edge index."], ["end int", "Right edge index."]], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 692}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.get.html#pandas.Series.get"], "Title": ["Series.get"], "Feature": ["Series.get"], "Description": "Get item from object for given key (ex: DataFrame column).\nReturns default value if not found.", "Examples": [">>> df = pd.DataFrame(\n...     [\n...         [24.3, 75.7, \"high\"],\n...         [31, 87.8, \"high\"],\n...         [22, 71.6, \"medium\"],\n...         [35, 95, \"medium\"],\n...     ],\n...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n... )\n"], "Parameters": [["key object", ""]], "Returns": [["same type as items contained in object", ""]], "Category": ["Series"], "index": 693}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rjust.html#pandas.Series.str.rjust"], "Title": ["Series.str.rjust"], "Feature": ["Series.str.rjust"], "Description": "Pad left side of strings in the Series/Index.\nEquivalent tostr.rjust().", "Examples": [">>> ser = pd.Series(['dog', 'bird', 'mouse'])\n>>> ser.str.center(8, fillchar='.')\n0   ..dog...\n1   ..bird..\n2   .mouse..\ndtype: object\n"], "Parameters": [["width int", "Minimum width of resulting string; additional characters will be filled\nwith fillchar ."], ["fillchar str", "Additional character for filling, default is whitespace."]], "Returns": [["Series/Index of objects.", ""]], "Category": ["Series"], "index": 694}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rpartition.html#pandas.Series.str.rpartition"], "Title": ["Series.str.rpartition"], "Feature": ["Series.str.rpartition"], "Description": "Split the string at the last occurrence ofsep.\nThis method splits the string at the last occurrence ofsep,\nand returns 3 elements containing the part before the separator,\nthe separator itself, and the part after the separator.\nIf the separator is not found, return 3 elements containing two empty strings, followed by the string itself.\nSee alsopartitionSplit the string at the first occurrence ofsep.Series.str.splitSplit strings around given separators.str.partitionStandard library version.", "Examples": [">>> s = pd.Series(['Linda van der Berg', 'George Pitt-Rivers'])\n>>> s\n0    Linda van der Berg\n1    George Pitt-Rivers\ndtype: object\n"], "Parameters": [["sep str, default whitespace", "String to split on."], ["expand bool, default True", "If True, return DataFrame/MultiIndex expanding dimensionality.\nIf False, return Series/Index."]], "Returns": [["DataFrame/MultiIndex or Series/Index of objects", ""]], "Category": ["Series"], "index": 695}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rstrip.html#pandas.Series.str.rstrip"], "Title": ["Series.str.rstrip"], "Feature": ["Series.str.rstrip"], "Description": "Remove trailing characters.\nStrip whitespaces (including newlines) or a set of specified characters\nfrom each string in the Series/Index from right side.\nReplaces any non-strings in Series with NaNs.\nEquivalent tostr.rstrip().\nSee alsoSeries.str.stripRemove leading and trailing characters in Series/Index.Series.str.lstripRemove leading characters in Series/Index.Series.str.rstripRemove trailing characters in Series/Index.", "Examples": [">>> s = pd.Series(['1. Ant.  ', '2. Bee!\\n', '3. Cat?\\t', np.nan, 10, True])\n>>> s\n0    1. Ant.\n1    2. Bee!\\n\n2    3. Cat?\\t\n3          NaN\n4           10\n5         True\ndtype: object\n"], "Parameters": [["to_strip str or None, default None", "Specifying the set of characters to be removed.\nAll combinations of this set of characters will be stripped.\nIf None then whitespaces are removed."]], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 696}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice.html#pandas.Series.str.slice"], "Title": ["Series.str.slice"], "Feature": ["Series.str.slice"], "Description": "Slice substrings from each element in the Series or Index.\nSee alsoSeries.str.slice_replaceReplace a slice with a string.Series.str.getReturn element at position. Equivalent toSeries.str.slice(start=i, stop=i+1)withibeing the position.", "Examples": [">>> s = pd.Series([\"koala\", \"dog\", \"chameleon\"])\n>>> s\n0        koala\n1          dog\n2    chameleon\ndtype: object\n"], "Parameters": [["start int, optional", "Start position for slice operation."], ["stop int, optional", "Stop position for slice operation."], ["step int, optional", "Step size for slice operation."]], "Returns": [["Series or Index of object", "Series or Index from sliced substring from original string object."]], "Category": ["Series"], "index": 697}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.slice_replace.html#pandas.Series.str.slice_replace"], "Title": ["Series.str.slice_replace"], "Feature": ["Series.str.slice_replace"], "Description": "Replace a positional slice of a string with another value.\nSee alsoSeries.str.sliceJust slicing without replacement.", "Examples": [">>> s = pd.Series(['a', 'ab', 'abc', 'abdc', 'abcde'])\n>>> s\n0        a\n1       ab\n2      abc\n3     abdc\n4    abcde\ndtype: object\n"], "Parameters": [["start int, optional", "Left index position to use for the slice. If not specified (None),\nthe slice is unbounded on the left, i.e. slice from the start\nof the string."], ["stop int, optional", "Right index position to use for the slice. If not specified (None),\nthe slice is unbounded on the right, i.e. slice until the\nend of the string."], ["repl str, optional", "String for replacement. If not specified (None), the sliced region\nis replaced with an empty string."]], "Returns": [["Series or Index", "Same type as the original object."]], "Category": ["Series"], "index": 698}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html#pandas.Series.str.split"], "Title": ["Series.str.split"], "Feature": ["Series.str.split"], "Description": "Split strings around given separator/delimiter.\nSplits the string in the Series/Index from the beginning,\nat the specified delimiter string.\nSee alsoSeries.str.splitSplit strings around given separator/delimiter.Series.str.rsplitSplits string around given separator/delimiter, starting from the right.Series.str.joinJoin lists contained as elements in the Series/Index with passed delimiter.str.splitStandard library version for split.str.rsplitStandard library version for rsplit.\nNotes\nThe handling of thenkeyword depends on the number of found splits:\nIf found splits >n,  make firstnsplits onlyIf found splits <=n, make all splitsIf for a certain row the number of found splits <n,\nappendNonefor padding up tonifexpand=True\nIf usingexpand=True, Series and Index callers return DataFrame and\nMultiIndex objects, respectively.\nUse ofregex =Falsewith apatas a compiled regex will raise an error.", "Examples": [">>> s = pd.Series(\n...     [\n...         \"this is a regular sentence\",\n...         \"https://docs.python.org/3/tutorial/index.html\",\n...         np.nan\n...     ]\n... )\n>>> s\n0                       this is a regular sentence\n1    https://docs.python.org/3/tutorial/index.html\n2                                              NaN\ndtype: object\n"], "Parameters": [["pat str or compiled regex, optional", "String or regular expression to split on.\nIf not specified, split on whitespace."], ["n int, default -1 (all)", "Limit number of splits in output. None , 0 and -1 will be interpreted as return all splits."], ["expand bool, default False", "Expand the split strings into separate columns. If True , return DataFrame/MultiIndex expanding dimensionality. If False , return Series/Index, containing lists of strings."], ["regex bool, default None", "Determines if the passed-in pattern is a regular expression: If True , assumes the passed-in pattern is a regular expression If False , treats the pattern as a literal string. If None and pat length is 1, treats pat as a literal string. If None and pat length is not 1, treats pat as a regular expression. Cannot be set to False if pat is a compiled regex Added in version 1.4.0."]], "Returns": [["Series, Index, DataFrame or MultiIndex", "Type matches caller unless expand=True (see Notes)."]], "Category": ["Series"], "index": 699}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.rsplit.html#pandas.Series.str.rsplit"], "Title": ["Series.str.rsplit"], "Feature": ["Series.str.rsplit"], "Description": "Split strings around given separator/delimiter.\nSplits the string in the Series/Index from the end,\nat the specified delimiter string.\nSee alsoSeries.str.splitSplit strings around given separator/delimiter.Series.str.rsplitSplits string around given separator/delimiter, starting from the right.Series.str.joinJoin lists contained as elements in the Series/Index with passed delimiter.str.splitStandard library version for split.str.rsplitStandard library version for rsplit.\nNotes\nThe handling of thenkeyword depends on the number of found splits:\nIf found splits >n,  make firstnsplits onlyIf found splits <=n, make all splitsIf for a certain row the number of found splits <n,\nappendNonefor padding up tonifexpand=True\nIf usingexpand=True, Series and Index callers return DataFrame and\nMultiIndex objects, respectively.", "Examples": [">>> s = pd.Series(\n...     [\n...         \"this is a regular sentence\",\n...         \"https://docs.python.org/3/tutorial/index.html\",\n...         np.nan\n...     ]\n... )\n>>> s\n0                       this is a regular sentence\n1    https://docs.python.org/3/tutorial/index.html\n2                                              NaN\ndtype: object\n"], "Parameters": [["pat str, optional", "String to split on.\nIf not specified, split on whitespace."], ["n int, default -1 (all)", "Limit number of splits in output. None , 0 and -1 will be interpreted as return all splits."], ["expand bool, default False", "Expand the split strings into separate columns. If True , return DataFrame/MultiIndex expanding dimensionality. If False , return Series/Index, containing lists of strings."]], "Returns": [["Series, Index, DataFrame or MultiIndex", "Type matches caller unless expand=True (see Notes)."]], "Category": ["Series"], "index": 700}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html#pandas.Series.str.startswith"], "Title": ["Series.str.startswith"], "Feature": ["Series.str.startswith"], "Description": "Test if the start of each string element matches a pattern.\nEquivalent tostr.startswith().\nSee alsostr.startswithPython standard library string method.Series.str.endswithSame as startswith, but tests the end of string.Series.str.containsTests if string element contains a pattern.", "Examples": [">>> s = pd.Series(['bat', 'Bear', 'cat', np.nan])\n>>> s\n0     bat\n1    Bear\n2     cat\n3     NaN\ndtype: object\n"], "Parameters": [["pat str or tuple[str, …]", "Character sequence or tuple of strings. Regular expressions are not\naccepted."], ["na scalar, optional", "Object shown if element tested is not a string. The default depends\non dtype of the array. For object-dtype, numpy.nan is used.\nFor the nullable StringDtype , pandas.NA is used.\nFor the \"str\" dtype, False is used."]], "Returns": [["Series or Index of bool", "A Series of booleans indicating whether the given pattern matches\nthe start of each string element."]], "Category": ["Series"], "index": 701}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html#pandas.Series.str.strip"], "Title": ["Series.str.strip"], "Feature": ["Series.str.strip"], "Description": "Remove leading and trailing characters.\nStrip whitespaces (including newlines) or a set of specified characters\nfrom each string in the Series/Index from left and right sides.\nReplaces any non-strings in Series with NaNs.\nEquivalent tostr.strip().\nSee alsoSeries.str.stripRemove leading and trailing characters in Series/Index.Series.str.lstripRemove leading characters in Series/Index.Series.str.rstripRemove trailing characters in Series/Index.", "Examples": [">>> s = pd.Series(['1. Ant.  ', '2. Bee!\\n', '3. Cat?\\t', np.nan, 10, True])\n>>> s\n0    1. Ant.\n1    2. Bee!\\n\n2    3. Cat?\\t\n3          NaN\n4           10\n5         True\ndtype: object\n"], "Parameters": [["to_strip str or None, default None", "Specifying the set of characters to be removed.\nAll combinations of this set of characters will be stripped.\nIf None then whitespaces are removed."]], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 702}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.swapcase.html#pandas.Series.str.swapcase"], "Title": ["Series.str.swapcase"], "Feature": ["Series.str.swapcase"], "Description": "Convert strings in the Series/Index to be swapcased.\nEquivalent tostr.swapcase().\nSee alsoSeries.str.lowerConverts all characters to lowercase.Series.str.upperConverts all characters to uppercase.Series.str.titleConverts first character of each word to uppercase and remaining to lowercase.Series.str.capitalizeConverts first character to uppercase and remaining to lowercase.Series.str.swapcaseConverts uppercase to lowercase and lowercase to uppercase.Series.str.casefoldRemoves all case distinctions in the string.", "Examples": [">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])\n>>> s\n0                 lower\n1              CAPITALS\n2    this is a sentence\n3              SwApCaSe\ndtype: object\n"], "Parameters": [], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 703}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.at.html#pandas.Series.at"], "Title": ["Series.at"], "Feature": ["Series.at"], "Description": "Access a single value for a row/column label pair.\nSimilar toloc, in that both provide label-based lookups. Useatif you only need to get or set a single value in a DataFrame\nor Series.\nSee alsoDataFrame.atAccess a single value for a row/column pair by label.DataFrame.iatAccess a single value for a row/column pair by integer position.DataFrame.locAccess a group of rows and columns by label(s).DataFrame.ilocAccess a group of rows and columns by integer position(s).Series.atAccess a single value by label.Series.iatAccess a single value by integer position.Series.locAccess a group of rows by label(s).Series.ilocAccess a group of rows by integer position(s).\nNotes\nSeeFast scalar value getting and settingfor more details.", "Examples": [">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n>>> df\n    A   B   C\n4   0   2   3\n5   0   4   1\n6  10  20  30\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 704}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.title.html#pandas.Series.str.title"], "Title": ["Series.str.title"], "Feature": ["Series.str.title"], "Description": "Convert strings in the Series/Index to titlecase.\nEquivalent tostr.title().\nSee alsoSeries.str.lowerConverts all characters to lowercase.Series.str.upperConverts all characters to uppercase.Series.str.titleConverts first character of each word to uppercase and remaining to lowercase.Series.str.capitalizeConverts first character to uppercase and remaining to lowercase.Series.str.swapcaseConverts uppercase to lowercase and lowercase to uppercase.Series.str.casefoldRemoves all case distinctions in the string.", "Examples": [">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])\n>>> s\n0                 lower\n1              CAPITALS\n2    this is a sentence\n3              SwApCaSe\ndtype: object\n"], "Parameters": [], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 705}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.translate.html#pandas.Series.str.translate"], "Title": ["Series.str.translate"], "Feature": ["Series.str.translate"], "Description": "Map all characters in the string through the given mapping table.\nEquivalent to standardstr.translate().", "Examples": [">>> ser = pd.Series([\"El niño\", \"Françoise\"])\n>>> mytable = str.maketrans({'ñ': 'n', 'ç': 'c'})\n>>> ser.str.translate(mytable)\n0   El nino\n1   Francoise\ndtype: object\n"], "Parameters": [["table dict", "Table is a mapping of Unicode ordinals to Unicode ordinals, strings, or\nNone. Unmapped characters are left untouched.\nCharacters mapped to None are deleted. str.maketrans() is a\nhelper function for making translation tables."]], "Returns": [["Series or Index", ""]], "Category": ["Series"], "index": 706}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.upper.html#pandas.Series.str.upper"], "Title": ["Series.str.upper"], "Feature": ["Series.str.upper"], "Description": "Convert strings in the Series/Index to uppercase.\nEquivalent tostr.upper().\nSee alsoSeries.str.lowerConverts all characters to lowercase.Series.str.upperConverts all characters to uppercase.Series.str.titleConverts first character of each word to uppercase and remaining to lowercase.Series.str.capitalizeConverts first character to uppercase and remaining to lowercase.Series.str.swapcaseConverts uppercase to lowercase and lowercase to uppercase.Series.str.casefoldRemoves all case distinctions in the string.", "Examples": [">>> s = pd.Series(['lower', 'CAPITALS', 'this is a sentence', 'SwApCaSe'])\n>>> s\n0                 lower\n1              CAPITALS\n2    this is a sentence\n3              SwApCaSe\ndtype: object\n"], "Parameters": [], "Returns": [["Series or Index of object", ""]], "Category": ["Series"], "index": 707}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.wrap.html#pandas.Series.str.wrap"], "Title": ["Series.str.wrap"], "Feature": ["Series.str.wrap"], "Description": "Wrap strings in Series/Index at specified line width.\nThis method has the same keyword parameters and defaults astextwrap.TextWrapper.\nNotes\nInternally, this method uses atextwrap.TextWrapperinstance with\ndefault settings. To achieve behavior matching R’s stringr library str_wrap\nfunction, use the arguments:\nexpand_tabs = Falsereplace_whitespace = Truedrop_whitespace = Truebreak_long_words = Falsebreak_on_hyphens = False", "Examples": [">>> s = pd.Series(['line to be wrapped', 'another line to be wrapped'])\n>>> s.str.wrap(12)\n0             line to be\\nwrapped\n1    another line\\nto be\\nwrapped\ndtype: object\n"], "Parameters": [["width int", "Maximum line width."], ["expand_tabs bool, optional", "If True, tab characters will be expanded to spaces (default: True)."], ["replace_whitespace bool, optional", "If True, each whitespace character (as defined by string.whitespace)\nremaining after tab expansion will be replaced by a single space\n(default: True)."], ["drop_whitespace bool, optional", "If True, whitespace that, after wrapping, happens to end up at the\nbeginning or end of a line is dropped (default: True)."], ["break_long_words bool, optional", "If True, then words longer than width will be broken in order to ensure\nthat no lines are longer than width. If it is false, long words will\nnot be broken, and some lines may be longer than width (default: True)."], ["break_on_hyphens bool, optional", "If True, wrapping will occur preferably on whitespace and right after\nhyphens in compound words, as it is customary in English. If false,\nonly whitespaces will be considered as potentially good places for line\nbreaks, but you need to set break_long_words to false if you want truly\ninsecable words (default: True)."]], "Returns": [["Series or Index", ""]], "Category": ["Series"], "index": 708}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.zfill.html#pandas.Series.str.zfill"], "Title": ["Series.str.zfill"], "Feature": ["Series.str.zfill"], "Description": "Pad strings in the Series/Index by prepending ‘0’ characters.\nStrings in the Series/Index are padded with ‘0’ characters on the\nleft of the string to reach a total string lengthwidth. Strings\nin the Series/Index with length greater or equal towidthare\nunchanged.\nSee alsoSeries.str.rjustFills the left side of strings with an arbitrary character.Series.str.ljustFills the right side of strings with an arbitrary character.Series.str.padFills the specified sides of strings with an arbitrary character.Series.str.centerFills both sides of strings with an arbitrary character.\nNotes\nDiffers fromstr.zfill()which has special handling\nfor ‘+’/’-’ in the string.", "Examples": [">>> s = pd.Series(['-1', '1', '1000', 10, np.nan])\n>>> s\n0      -1\n1       1\n2    1000\n3      10\n4     NaN\ndtype: object\n"], "Parameters": [["width int", "Minimum length of resulting string; strings with length less\nthan width be prepended with ‘0’ characters."]], "Returns": [["Series/Index of objects.", ""]], "Category": ["Series"], "index": 709}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalnum.html#pandas.Series.str.isalnum"], "Title": ["Series.str.isalnum"], "Feature": ["Series.str.isalnum"], "Description": "Check whether all characters in each string are alphanumeric.\nThis is equivalent to running the Python string methodstr.isalnum()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 710}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isalpha.html#pandas.Series.str.isalpha"], "Title": ["Series.str.isalpha"], "Feature": ["Series.str.isalpha"], "Description": "Check whether all characters in each string are alphabetic.\nThis is equivalent to running the Python string methodstr.isalpha()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 711}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdigit.html#pandas.Series.str.isdigit"], "Title": ["Series.str.isdigit"], "Feature": ["Series.str.isdigit"], "Description": "Check whether all characters in each string are digits.\nThis is equivalent to running the Python string methodstr.isdigit()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 712}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html#pandas.Series.str.isspace"], "Title": ["Series.str.isspace"], "Feature": ["Series.str.isspace"], "Description": "Check whether all characters in each string are whitespace.\nThis is equivalent to running the Python string methodstr.isspace()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 713}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.islower.html#pandas.Series.str.islower"], "Title": ["Series.str.islower"], "Feature": ["Series.str.islower"], "Description": "Check whether all characters in each string are lowercase.\nThis is equivalent to running the Python string methodstr.islower()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 714}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.iat.html#pandas.Series.iat"], "Title": ["Series.iat"], "Feature": ["Series.iat"], "Description": "Access a single value for a row/column pair by integer position.\nSimilar toiloc, in that both provide integer-based lookups. Useiatif you only need to get or set a single value in a DataFrame\nor Series.\nSee alsoDataFrame.atAccess a single value for a row/column label pair.DataFrame.locAccess a group of rows and columns by label(s).DataFrame.ilocAccess a group of rows and columns by integer position(s).", "Examples": [">>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n...                   columns=['A', 'B', 'C'])\n>>> df\n    A   B   C\n0   0   2   3\n1   0   4   1\n2  10  20  30\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 715}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isupper.html#pandas.Series.str.isupper"], "Title": ["Series.str.isupper"], "Feature": ["Series.str.isupper"], "Description": "Check whether all characters in each string are uppercase.\nThis is equivalent to running the Python string methodstr.isupper()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 716}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.istitle.html#pandas.Series.str.istitle"], "Title": ["Series.str.istitle"], "Feature": ["Series.str.istitle"], "Description": "Check whether all characters in each string are titlecase.\nThis is equivalent to running the Python string methodstr.istitle()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 717}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html#pandas.Series.str.isnumeric"], "Title": ["Series.str.isnumeric"], "Feature": ["Series.str.isnumeric"], "Description": "Check whether all characters in each string are numeric.\nThis is equivalent to running the Python string methodstr.isnumeric()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 718}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isdecimal.html#pandas.Series.str.isdecimal"], "Title": ["Series.str.isdecimal"], "Feature": ["Series.str.isdecimal"], "Description": "Check whether all characters in each string are decimal.\nThis is equivalent to running the Python string methodstr.isdecimal()for each element of the Series/Index. If a string\nhas zero characters,Falseis returned for that check.\nSee alsoSeries.str.isalphaCheck whether all characters are alphabetic.Series.str.isnumericCheck whether all characters are numeric.Series.str.isalnumCheck whether all characters are alphanumeric.Series.str.isdigitCheck whether all characters are digits.Series.str.isdecimalCheck whether all characters are decimal.Series.str.isspaceCheck whether all characters are whitespace.Series.str.islowerCheck whether all characters are lowercase.Series.str.isupperCheck whether all characters are uppercase.Series.str.istitleCheck whether all characters are titlecase.", "Examples": [">>> s1 = pd.Series(['one', 'one1', '1', ''])\n"], "Parameters": [], "Returns": [["Series or Index of bool", "Series or Index of boolean values with the same length as the original\nSeries/Index."]], "Category": ["Series"], "index": 719}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get_dummies.html#pandas.Series.str.get_dummies"], "Title": ["Series.str.get_dummies"], "Feature": ["Series.str.get_dummies"], "Description": "Return DataFrame of dummy/indicator variables for Series.\nEach string in Series is split by sep and returned as a DataFrame\nof dummy/indicator variables.\nSee alsoget_dummiesConvert categorical variable into dummy/indicator variables.", "Examples": [">>> pd.Series(['a|b', 'a', 'a|c']).str.get_dummies()\n   a  b  c\n0  1  1  0\n1  1  0  0\n2  1  0  1\n"], "Parameters": [["sep str, default “|”", "String to split on."]], "Returns": [["DataFrame", "Dummy variables corresponding to values of the Series."]], "Category": ["Series"], "index": 720}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html#pandas.Series.cat.categories"], "Title": ["Series.cat.categories"], "Feature": ["Series.cat.categories"], "Description": "The categories of this categorical.\nSetting assigns new values to each category (effectively a rename of\neach individual category).\nThe assigned value has to be a list-like object. All items must be\nunique and the number of items in the new categories must be the same\nas the number of items in the old categories.\nSee alsorename_categoriesRename categories.reorder_categoriesReorder categories.add_categoriesAdd new categories.remove_categoriesRemove the specified categories.remove_unused_categoriesRemove categories which are not used.set_categoriesSet the categories to the specified ones.", "Examples": [">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n>>> ser.cat.categories\nIndex(['a', 'b', 'c'], dtype='object')\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 721}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.ordered.html#pandas.Series.cat.ordered"], "Title": ["Series.cat.ordered"], "Feature": ["Series.cat.ordered"], "Description": "Whether the categories have an ordered relationship.", "Examples": [">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n>>> ser.cat.ordered\nFalse\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 722}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.codes.html#pandas.Series.cat.codes"], "Title": ["Series.cat.codes"], "Feature": ["Series.cat.codes"], "Description": "Return Series of codes as well as the index.", "Examples": [">>> raw_cate = pd.Categorical([\"a\", \"b\", \"c\", \"a\"], categories=[\"a\", \"b\"])\n>>> ser = pd.Series(raw_cate)\n>>> ser.cat.codes\n0   0\n1   1\n2  -1\n3   0\ndtype: int8\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 723}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.rename_categories.html#pandas.Series.cat.rename_categories"], "Title": ["Series.cat.rename_categories"], "Feature": ["Series.cat.rename_categories"], "Description": "Rename categories.\nSee alsoreorder_categoriesReorder categories.add_categoriesAdd new categories.remove_categoriesRemove the specified categories.remove_unused_categoriesRemove categories which are not used.set_categoriesSet the categories to the specified ones.", "Examples": [">>> c = pd.Categorical(['a', 'a', 'b'])\n>>> c.rename_categories([0, 1])\n[0, 0, 1]\nCategories (2, int64): [0, 1]\n"], "Parameters": [["new_categories list-like, dict-like or callable", "New categories which will replace old categories. list-like: all items must be unique and the number of items in\nthe new categories must match the existing number of categories. dict-like: specifies a mapping from\nold categories to new. Categories not contained in the mapping\nare passed through and extra categories in the mapping are\nignored. callable : a callable that is called on all items in the old\ncategories and whose return values comprise the new categories."]], "Returns": [["Categorical", "Categorical with renamed categories."]], "Category": ["Series"], "index": 724}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html#pandas.Series.cat.reorder_categories"], "Title": ["Series.cat.reorder_categories"], "Feature": ["Series.cat.reorder_categories"], "Description": "Reorder categories as specified in new_categories.\nnew_categoriesneed to include all old categories and no new category\nitems.\nSee alsorename_categoriesRename categories.add_categoriesAdd new categories.remove_categoriesRemove the specified categories.remove_unused_categoriesRemove categories which are not used.set_categoriesSet the categories to the specified ones.", "Examples": [">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n>>> ser = ser.cat.reorder_categories(['c', 'b', 'a'], ordered=True)\n>>> ser\n0   a\n1   b\n2   c\n3   a\ndtype: category\nCategories (3, object): ['c' < 'b' < 'a']\n"], "Parameters": [["new_categories Index-like", "The categories in new order."], ["ordered bool, optional", "Whether or not the categorical is treated as a ordered categorical.\nIf not given, do not change the ordered information."]], "Returns": [["Categorical", "Categorical with reordered categories."]], "Category": ["Series"], "index": 725}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html#pandas.Series.values"], "Title": ["Series.values"], "Feature": ["Series.values"], "Description": "Return Series as ndarray or ndarray-like depending on the dtype.\nWarningWe recommend usingSeries.arrayorSeries.to_numpy(), depending on whether you need\na reference to the underlying data or a NumPy array.\nSee alsoSeries.arrayReference to the underlying data.Series.to_numpyA NumPy array representing the underlying data.", "Examples": [">>> pd.Series([1, 2, 3]).values\narray([1, 2, 3])\n"], "Parameters": [], "Returns": [["numpy.ndarray or ndarray-like", ""]], "Category": ["Series"], "index": 726}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.loc.html#pandas.Series.loc"], "Title": ["Series.loc"], "Feature": ["Series.loc"], "Description": "Access a group of rows and columns by label(s) or a boolean array.\n.loc[]is primarily label based, but may also be used with a\nboolean array.\nAllowed inputs are:\nA single label, e.g.5or'a', (note that5is\ninterpreted as alabelof the index, andneveras an\ninteger position along the index).A list or array of labels, e.g.['a','b','c'].A slice object with labels, e.g.'a':'f'.WarningNote that contrary to usual python slices,boththe\nstart and the stop are includedA boolean array of the same length as the axis being sliced,\ne.g.[True,False,True].An alignable boolean Series. The index of the key will be aligned before\nmasking.An alignable Index. The Index of the returned selection will be the input.Acallablefunction with one argument (the calling Series or\nDataFrame) and that returns valid output for indexing (one of the above)\nSee more atSelection by Label.\nSee alsoDataFrame.atAccess a single value for a row/column label pair.DataFrame.ilocAccess group of rows and columns by integer position(s).DataFrame.xsReturns a cross-section (row(s) or column(s)) from the Series/DataFrame.Series.locAccess group of values using labels.", "Examples": [">>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n...                   index=['cobra', 'viper', 'sidewinder'],\n...                   columns=['max_speed', 'shield'])\n>>> df\n            max_speed  shield\ncobra               1       2\nviper               4       5\nsidewinder          7       8\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 727}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.add_categories.html#pandas.Series.cat.add_categories"], "Title": ["Series.cat.add_categories"], "Feature": ["Series.cat.add_categories"], "Description": "Add new categories.\nnew_categorieswill be included at the last/highest place in the\ncategories and will be unused directly after this call.\nSee alsorename_categoriesRename categories.reorder_categoriesReorder categories.remove_categoriesRemove the specified categories.remove_unused_categoriesRemove categories which are not used.set_categoriesSet the categories to the specified ones.", "Examples": [">>> c = pd.Categorical(['c', 'b', 'c'])\n>>> c\n['c', 'b', 'c']\nCategories (2, object): ['b', 'c']\n"], "Parameters": [["new_categories category or list-like of category", "The new categories to be included."]], "Returns": [["Categorical", "Categorical with new categories added."]], "Category": ["Series"], "index": 728}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_categories.html#pandas.Series.cat.remove_categories"], "Title": ["Series.cat.remove_categories"], "Feature": ["Series.cat.remove_categories"], "Description": "Remove the specified categories.\nremovalsmust be included in the old categories. Values which were in\nthe removed categories will be set to NaN\nSee alsorename_categoriesRename categories.reorder_categoriesReorder categories.add_categoriesAdd new categories.remove_unused_categoriesRemove categories which are not used.set_categoriesSet the categories to the specified ones.", "Examples": [">>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])\n>>> c\n['a', 'c', 'b', 'c', 'd']\nCategories (4, object): ['a', 'b', 'c', 'd']\n"], "Parameters": [["removals category or list of categories", "The categories which should be removed."]], "Returns": [["Categorical", "Categorical with removed categories."]], "Category": ["Series"], "index": 729}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html#pandas.Series.cat.remove_unused_categories"], "Title": ["Series.cat.remove_unused_categories"], "Feature": ["Series.cat.remove_unused_categories"], "Description": "Remove categories which are not used.\nSee alsorename_categoriesRename categories.reorder_categoriesReorder categories.add_categoriesAdd new categories.remove_categoriesRemove the specified categories.set_categoriesSet the categories to the specified ones.", "Examples": [">>> c = pd.Categorical(['a', 'c', 'b', 'c', 'd'])\n>>> c\n['a', 'c', 'b', 'c', 'd']\nCategories (4, object): ['a', 'b', 'c', 'd']\n"], "Parameters": [], "Returns": [["Categorical", "Categorical with unused categories dropped."]], "Category": ["Series"], "index": 730}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.set_categories.html#pandas.Series.cat.set_categories"], "Title": ["Series.cat.set_categories"], "Feature": ["Series.cat.set_categories"], "Description": "Set the categories to the specified new categories.\nnew_categoriescan include new categories (which will result in\nunused categories) or remove old categories (which results in values\nset toNaN). Ifrename=True, the categories will simply be renamed\n(less or more items than in old categories will result in values set toNaNor in unused categories respectively).\nThis method can be used to perform more than one action of adding,\nremoving, and reordering simultaneously and is therefore faster than\nperforming the individual steps via the more specialised methods.\nOn the other hand this methods does not do checks (e.g., whether the\nold categories are included in the new categories on a reorder), which\ncan result in surprising changes, for example when using special string\ndtypes, which does not considers a S1 string equal to a single char\npython string.\nSee alsorename_categoriesRename categories.reorder_categoriesReorder categories.add_categoriesAdd new categories.remove_categoriesRemove the specified categories.remove_unused_categoriesRemove categories which are not used.", "Examples": [">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'A'],\n...                           categories=['a', 'b', 'c'], ordered=True)\n>>> ser = pd.Series(raw_cat)\n>>> ser\n0   a\n1   b\n2   c\n3   NaN\ndtype: category\nCategories (3, object): ['a' < 'b' < 'c']\n"], "Parameters": [["new_categories Index-like", "The categories in new order."], ["ordered bool, default False", "Whether or not the categorical is treated as a ordered categorical.\nIf not given, do not change the ordered information."], ["rename bool, default False", "Whether or not the new_categories should be considered as a rename\nof the old categories or as reordered categories."]], "Returns": [["Categorical with reordered categories.", ""]], "Category": ["Series"], "index": 731}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_ordered.html#pandas.Series.cat.as_ordered"], "Title": ["Series.cat.as_ordered"], "Feature": ["Series.cat.as_ordered"], "Description": "Set the Categorical to be ordered.", "Examples": [">>> ser = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n>>> ser.cat.ordered\nFalse\n>>> ser = ser.cat.as_ordered()\n>>> ser.cat.ordered\nTrue\n"], "Parameters": [], "Returns": [["Categorical", "Ordered Categorical."]], "Category": ["Series"], "index": 732}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.as_unordered.html#pandas.Series.cat.as_unordered"], "Title": ["Series.cat.as_unordered"], "Feature": ["Series.cat.as_unordered"], "Description": "Set the Categorical to be unordered.", "Examples": [">>> raw_cat = pd.Categorical(['a', 'b', 'c', 'a'], ordered=True)\n>>> ser = pd.Series(raw_cat)\n>>> ser.cat.ordered\nTrue\n>>> ser = ser.cat.as_unordered()\n>>> ser.cat.ordered\nFalse\n"], "Parameters": [], "Returns": [["Categorical", "Unordered Categorical."]], "Category": ["Series"], "index": 733}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.npoints.html#pandas.Series.sparse.npoints"], "Title": ["Series.sparse.npoints"], "Feature": ["Series.sparse.npoints"], "Description": "The number of non-fill_valuepoints.", "Examples": [">>> from pandas.arrays import SparseArray\n>>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)\n>>> s.npoints\n3\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 734}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.density.html#pandas.Series.sparse.density"], "Title": ["Series.sparse.density"], "Feature": ["Series.sparse.density"], "Description": "The percent of non-fill_valuepoints, as decimal.", "Examples": [">>> from pandas.arrays import SparseArray\n>>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)\n>>> s.density\n0.6\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 735}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.fill_value.html#pandas.Series.sparse.fill_value"], "Title": ["Series.sparse.fill_value"], "Feature": ["Series.sparse.fill_value"], "Description": "Elements indatathat arefill_valueare not stored.\nFor memory savings, this should be the most common value in the array.", "Examples": [">>> ser = pd.Series([0, 0, 2, 2, 2], dtype=\"Sparse[int]\")\n>>> ser.sparse.fill_value\n0\n>>> spa_dtype = pd.SparseDtype(dtype=np.int32, fill_value=2)\n>>> ser = pd.Series([0, 0, 2, 2, 2], dtype=spa_dtype)\n>>> ser.sparse.fill_value\n2\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 736}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.sp_values.html#pandas.Series.sparse.sp_values"], "Title": ["Series.sparse.sp_values"], "Feature": ["Series.sparse.sp_values"], "Description": "An ndarray containing the non-fill_valuevalues.", "Examples": [">>> from pandas.arrays import SparseArray\n>>> s = SparseArray([0, 0, 1, 0, 2], fill_value=0)\n>>> s.sp_values\narray([1, 2])\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 737}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.iloc.html#pandas.Series.iloc"], "Title": ["Series.iloc"], "Feature": ["Series.iloc"], "Description": "Purely integer-location based indexing for selection by position.\nDeprecated since version 2.2.0:Returning a tuple from a callable is deprecated.\n.iloc[]is primarily integer position based (from0tolength-1of the axis), but may also be used with a boolean\narray.\nAllowed inputs are:\nAn integer, e.g.5.A list or array of integers, e.g.[4,3,0].A slice object with ints, e.g.1:7.A boolean array.Acallablefunction with one argument (the calling Series or\nDataFrame) and that returns valid output for indexing (one of the above).\nThis is useful in method chains, when you don’t have a reference to the\ncalling object, but would like to base your selection on\nsome value.A tuple of row and column indexes. The tuple elements consist of one of the\nabove inputs, e.g.(0,1).\n.ilocwill raiseIndexErrorif a requested indexer is\nout-of-bounds, exceptsliceindexers which allow out-of-bounds\nindexing (this conforms with python/numpyslicesemantics).\nSee more atSelection by Position.\nSee alsoDataFrame.iatFast integer location scalar accessor.DataFrame.locPurely label-location based indexer for selection by label.Series.ilocPurely integer-location based indexing for selection by position.", "Examples": [">>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]\n>>> df = pd.DataFrame(mydict)\n>>> df\n      a     b     c     d\n0     1     2     3     4\n1   100   200   300   400\n2  1000  2000  3000  4000\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 738}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.from_coo.html#pandas.Series.sparse.from_coo"], "Title": ["Series.sparse.from_coo"], "Feature": ["Series.sparse.from_coo"], "Description": "Create a Series with sparse values from a scipy.sparse.coo_matrix.", "Examples": [">>> from scipy import sparse\n"], "Parameters": [["A scipy.sparse.coo_matrix", ""], ["dense_index bool, default False", "If False (default), the index consists of only the\ncoords of the non-null entries of the original coo_matrix.\nIf True, the index consists of the full sorted\n(row, col) coordinates of the coo_matrix."]], "Returns": [["s Series", "A Series with sparse values."]], "Category": ["Series"], "index": 739}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sparse.to_coo.html#pandas.Series.sparse.to_coo"], "Title": ["Series.sparse.to_coo"], "Feature": ["Series.sparse.to_coo"], "Description": "Create a scipy.sparse.coo_matrix from a Series with MultiIndex.\nUse row_levels and column_levels to determine the row and column\ncoordinates respectively. row_levels and column_levels are the names\n(labels) or numbers of the levels. {row_levels, column_levels} must be\na partition of the MultiIndex level names (or numbers).", "Examples": [">>> s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])\n>>> s.index = pd.MultiIndex.from_tuples(\n...     [\n...         (1, 2, \"a\", 0),\n...         (1, 2, \"a\", 1),\n...         (1, 1, \"b\", 0),\n...         (1, 1, \"b\", 1),\n...         (2, 1, \"b\", 0),\n...         (2, 1, \"b\", 1)\n...     ],\n...     names=[\"A\", \"B\", \"C\", \"D\"],\n... )\n>>> s\nA  B  C  D\n1  2  a  0    3.0\n         1    NaN\n   1  b  0    1.0\n         1    3.0\n2  1  b  0    NaN\n         1    NaN\ndtype: float64\n"], "Parameters": [["row_levels tuple/list", ""], ["column_levels tuple/list", ""], ["sort_labels bool, default False", "Sort the row and column labels before forming the sparse matrix.\nWhen row_levels and/or column_levels refer to a single level,\nset to True for a faster execution."]], "Returns": [["y scipy.sparse.coo_matrix", ""], ["rows list (row labels)", ""], ["columns list (column labels)", ""]], "Category": ["Series"], "index": 740}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.list.flatten.html#pandas.Series.list.flatten"], "Title": ["Series.list.flatten"], "Feature": ["Series.list.flatten"], "Description": "Flatten list values.", "Examples": [">>> import pyarrow as pa\n>>> s = pd.Series(\n...     [\n...         [1, 2, 3],\n...         [3],\n...     ],\n...     dtype=pd.ArrowDtype(pa.list_(\n...         pa.int64()\n...     ))\n... )\n>>> s.list.flatten()\n0    1\n1    2\n2    3\n3    3\ndtype: int64[pyarrow]\n"], "Parameters": [], "Returns": [["pandas.Series", "The data from all lists in the series flattened."]], "Category": ["Series"], "index": 741}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.list.len.html#pandas.Series.list.len"], "Title": ["Series.list.len"], "Feature": ["Series.list.len"], "Description": "Return the length of each list in the Series.", "Examples": [">>> import pyarrow as pa\n>>> s = pd.Series(\n...     [\n...         [1, 2, 3],\n...         [3],\n...     ],\n...     dtype=pd.ArrowDtype(pa.list_(\n...         pa.int64()\n...     ))\n... )\n>>> s.list.len()\n0    3\n1    1\ndtype: int32[pyarrow]\n"], "Parameters": [], "Returns": [["pandas.Series", "The length of each list."]], "Category": ["Series"], "index": 742}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.dtypes.html#pandas.Series.struct.dtypes"], "Title": ["Series.struct.dtypes"], "Feature": ["Series.struct.dtypes"], "Description": "Return the dtype object of each child field of the struct.", "Examples": [">>> import pyarrow as pa\n>>> s = pd.Series(\n...     [\n...         {\"version\": 1, \"project\": \"pandas\"},\n...         {\"version\": 2, \"project\": \"pandas\"},\n...         {\"version\": 1, \"project\": \"numpy\"},\n...     ],\n...     dtype=pd.ArrowDtype(pa.struct(\n...         [(\"version\", pa.int64()), (\"project\", pa.string())]\n...     ))\n... )\n>>> s.struct.dtypes\nversion     int64[pyarrow]\nproject    string[pyarrow]\ndtype: object\n"], "Parameters": [], "Returns": [["pandas.Series", "The data type of each child field."]], "Category": ["Series"], "index": 744}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.field.html#pandas.Series.struct.field"], "Title": ["Series.struct.field"], "Feature": ["Series.struct.field"], "Description": "Extract a child field of a struct as a Series.\nSee alsoSeries.struct.explodeReturn all child fields as a DataFrame.\nNotes\nThe name of the resulting Series will be set using the following\nrules:\nFor string, bytes, or integername_or_index(or a list of these, for\na nested selection), the Series name is set to the selected\nfield’s name.For apyarrow.compute.Expression, this is set to\nthe string form of the expression.For list-likename_or_index, the name will be set to the\nname of the final field selected.", "Examples": [">>> import pyarrow as pa\n>>> s = pd.Series(\n...     [\n...         {\"version\": 1, \"project\": \"pandas\"},\n...         {\"version\": 2, \"project\": \"pandas\"},\n...         {\"version\": 1, \"project\": \"numpy\"},\n...     ],\n...     dtype=pd.ArrowDtype(pa.struct(\n...         [(\"version\", pa.int64()), (\"project\", pa.string())]\n...     ))\n... )\n"], "Parameters": [["name_or_index str | bytes | int | expression | list", "Name or index of the child field to extract. For list-like inputs, this will index into a nested\nstruct."]], "Returns": [["pandas.Series", "The data corresponding to the selected child field."]], "Category": ["Series"], "index": 745}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.struct.explode.html#pandas.Series.struct.explode"], "Title": ["Series.struct.explode"], "Feature": ["Series.struct.explode"], "Description": "Extract all child fields of a struct as a DataFrame.\nSee alsoSeries.struct.fieldReturn a single child field as a Series.", "Examples": [">>> import pyarrow as pa\n>>> s = pd.Series(\n...     [\n...         {\"version\": 1, \"project\": \"pandas\"},\n...         {\"version\": 2, \"project\": \"pandas\"},\n...         {\"version\": 1, \"project\": \"numpy\"},\n...     ],\n...     dtype=pd.ArrowDtype(pa.struct(\n...         [(\"version\", pa.int64()), (\"project\", pa.string())]\n...     ))\n... )\n"], "Parameters": [], "Returns": [["pandas.DataFrame", "The data corresponding to all child fields."]], "Category": ["Series"], "index": 746}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Flags.html#pandas.Flags"], "Title": ["Flags"], "Feature": ["Flags"], "Description": "Flags that apply to pandas objects.", "Examples": [">>> df = pd.DataFrame()\n>>> df.flags\n<Flags(allows_duplicate_labels=True)>\n>>> df.flags.allows_duplicate_labels = False\n>>> df.flags\n<Flags(allows_duplicate_labels=False)>\n"], "Parameters": [["obj Series or DataFrame", "The object these flags are associated with."], ["allows_duplicate_labels bool, default True", "Whether to allow duplicate labels in this object. By default,\nduplicate labels are permitted. Setting this to False will\ncause an errors.DuplicateLabelError to be raised when index (or columns for DataFrame) is not unique, or any\nsubsequent operation on introduces duplicates.\nSee Disallowing Duplicate Labels for more. Warning This is an experimental feature. Currently, many methods fail to\npropagate the allows_duplicate_labels value. In future versions\nit is expected that every method taking or returning one or more\nDataFrame or Series objects will propagate allows_duplicate_labels ."]], "Returns": [], "Category": ["Series"], "index": 747}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.attrs.html#pandas.Series.attrs"], "Title": ["Series.attrs"], "Feature": ["Series.attrs"], "Description": "Dictionary of global attributes of this dataset.\nWarningattrs is experimental and may change without warning.\nSee alsoDataFrame.flagsGlobal flags applying to this object.\nNotes\nMany operations that create new datasets will copyattrs. Copies\nare always deep so that changingattrswill only affect the\npresent dataset.pandas.concatcopiesattrsonly if all input\ndatasets have the sameattrs.", "Examples": [">>> ser = pd.Series([1, 2, 3])\n>>> ser.attrs = {\"A\": [10, 20, 30]}\n>>> ser.attrs\n{'A': [10, 20, 30]}\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 748}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html#pandas.Series.plot"], "Title": ["Series.plot"], "Feature": ["Series.plot"], "Description": "Make plots of Series or DataFrame.\nUses the backend specified by the\noptionplotting.backend. By default, matplotlib is used.\nNotes\nSee matplotlib documentation online for more on this subjectIfkind= ‘bar’ or ‘barh’, you can specify relative alignments\nfor bar plot layout bypositionkeyword.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center)", "Examples": [">>> ser = pd.Series([1, 2, 3, 3])\n>>> plot = ser.plot(kind='hist', title=\"My plot\")\n"], "Parameters": [["data Series or DataFrame", "The object for which the method is called."], ["x label or position, default None", "Only used if data is a DataFrame."], ["y label, position or list of label, positions, default None", "Allows plotting of one column versus another. Only used if data is a\nDataFrame."], ["kind str", "The kind of plot to produce: ‘line’ : line plot (default) ‘bar’ : vertical bar plot ‘barh’ : horizontal bar plot ‘hist’ : histogram ‘box’ : boxplot ‘kde’ : Kernel Density Estimation plot ‘density’ : same as ‘kde’ ‘area’ : area plot ‘pie’ : pie plot ‘scatter’ : scatter plot (DataFrame only) ‘hexbin’ : hexbin plot (DataFrame only)"], ["ax matplotlib axes object, default None", "An axes of the current figure."], ["subplots bool or sequence of iterables, default False", "Whether to group columns into subplots: False : No subplots will be used True : Make separate subplots for each column. sequence of iterables of column labels: Create a subplot for each\ngroup of columns. For example [(‘a’, ‘c’), (‘b’, ‘d’)] will\ncreate 2 subplots: one with columns ‘a’ and ‘c’, and one\nwith columns ‘b’ and ‘d’. Remaining columns that aren’t specified\nwill be plotted in additional subplots (one per column). Added in version 1.5.0."], ["sharex bool, default True if ax is None else False", "In case subplots=True , share x axis and set some x axis labels\nto invisible; defaults to True if ax is None otherwise False if\nan ax is passed in; Be aware, that passing in both an ax and sharex=True will alter all x axis labels for all axis in a figure."], ["sharey bool, default False", "In case subplots=True , share y axis and set some y axis labels to invisible."], ["layout tuple, optional", "(rows, columns) for the layout of subplots."], ["figsize a tuple (width, height) in inches", "Size of a figure object."], ["use_index bool, default True", "Use index as ticks for x axis."], ["title str or list", "Title to use for the plot. If a string is passed, print the string\nat the top of the figure. If a list is passed and subplots is\nTrue, print each item in the list above the corresponding subplot."], ["grid bool, default None (matlab style default)", "Axis grid lines."], ["legend bool or {‘reverse’}", "Place legend on axis subplots."], ["style list or dict", "The matplotlib line style per column."], ["logx bool or ‘sym’, default False", "Use log scaling or symlog scaling on x axis."], ["logy bool or ‘sym’ default False", "Use log scaling or symlog scaling on y axis."], ["loglog bool or ‘sym’, default False", "Use log scaling or symlog scaling on both x and y axes."], ["xticks sequence", "Values to use for the xticks."], ["yticks sequence", "Values to use for the yticks."], ["xlim 2-tuple/list", "Set the x limits of the current axes."], ["ylim 2-tuple/list", "Set the y limits of the current axes."], ["xlabel label, optional", "Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\nx-column name for planar plots. Changed in version 2.0.0: Now applicable to histograms."], ["ylabel label, optional", "Name to use for the ylabel on y-axis. Default will show no ylabel, or the\ny-column name for planar plots. Changed in version 2.0.0: Now applicable to histograms."], ["rot float, default None", "Rotation for ticks (xticks for vertical, yticks for horizontal\nplots)."], ["fontsize float, default None", "Font size for xticks and yticks."], ["colormap str or matplotlib colormap object, default None", "Colormap to select colors from. If string, load colormap with that\nname from matplotlib."], ["colorbar bool, optional", "If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’\nplots)."], ["position float", "Specify relative alignments for bar plot layout.\nFrom 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n(center)."], ["table bool, Series or DataFrame, default False", "If True, draw a table using the data in the DataFrame and the data\nwill be transposed to meet matplotlib’s default layout.\nIf a Series or DataFrame is passed, use passed data to draw a\ntable."], ["yerr DataFrame, Series, array-like, dict and str", "See Plotting with Error Bars for\ndetail."], ["xerr DataFrame, Series, array-like, dict and str", "Equivalent to yerr."], ["stacked bool, default False in line and bar plots, and True in area plot", "If True, create stacked plot."], ["secondary_y bool or sequence, default False", "Whether to plot on the secondary y-axis if a list/tuple, which\ncolumns to plot on secondary y-axis."], ["mark_right bool, default True", "When using a secondary_y axis, automatically mark the column\nlabels with “(right)” in the legend."], ["include_bool bool, default is False", "If True, boolean values can be plotted."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["**kwargs", "Options to pass to matplotlib plotting method."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray of them", "If the backend is not the default matplotlib one, the return value\nwill be the object returned by the backend."]], "Category": ["Series"], "index": 750}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.area.html#pandas.Series.plot.area"], "Title": ["Series.plot.area"], "Feature": ["Series.plot.area"], "Description": "Draw a stacked area plot.\nAn area plot displays quantitative data visually.\nThis function wraps the matplotlib area function.\nSee alsoDataFrame.plotMake plots of DataFrame using matplotlib / pylab.", "Examples": [">>> df = pd.DataFrame({\n...     'sales': [3, 2, 3, 9, 10, 6],\n...     'signups': [5, 5, 6, 12, 14, 13],\n...     'visits': [20, 42, 28, 62, 81, 50],\n... }, index=pd.date_range(start='2018/01/01', end='2018/07/01',\n...                        freq='ME'))\n>>> ax = df.plot.area()\n"], "Parameters": [["x label or position, optional", "Coordinates for the X axis. By default uses the index."], ["y label or position, optional", "Column to plot. By default uses all columns."], ["stacked bool, default True", "Area plots are stacked by default. Set to False to create a\nunstacked plot."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray", "Area plot, or array of area plots if subplots is True."]], "Category": ["Series"], "index": 751}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.bar.html#pandas.Series.plot.bar"], "Title": ["Series.plot.bar"], "Feature": ["Series.plot.bar"], "Description": "Vertical bar plot.\nA bar plot is a plot that presents categorical data with\nrectangular bars with lengths proportional to the values that they\nrepresent. A bar plot shows comparisons among discrete categories. One\naxis of the plot shows the specific categories being compared, and the\nother axis represents a measured value.\nSee alsoDataFrame.plot.barhHorizontal bar plot.DataFrame.plotMake plots of a DataFrame.matplotlib.pyplot.barMake a bar plot with matplotlib.", "Examples": [">>> df = pd.DataFrame({'lab':['A', 'B', 'C'], 'val':[10, 30, 20]})\n>>> ax = df.plot.bar(x='lab', y='val', rot=0)\n"], "Parameters": [["x label or position, optional", "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used."], ["y label or position, optional", "Allows plotting of one column versus another. If not specified,\nall numerical columns are used."], ["color str, array-like, or dict, optional", "The color for each of the DataFrame’s columns. Possible values are: A single color string referred to by name, RGB or RGBA code, for instance ‘red’ or ‘#a98d19’. A sequence of color strings referred to by name, RGB or RGBA code, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused. A dict of the form {column name color}, so that each column will be colored accordingly. For example, if your columns are called a and b , then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red."], ["A single color string referred to by name, RGB or RGBA code,", "for instance ‘red’ or ‘#a98d19’."], ["A sequence of color strings referred to by name, RGB or RGBA", "code, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused."], ["A dict of the form {column name color}, so that each column will be", "colored accordingly. For example, if your columns are called a and b , then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or np.ndarray of them", "An ndarray is returned with one matplotlib.axes.Axes per column when subplots=True ."]], "Category": ["Series"], "index": 752}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.barh.html#pandas.Series.plot.barh"], "Title": ["Series.plot.barh"], "Feature": ["Series.plot.barh"], "Description": "Make a horizontal bar plot.\nA horizontal bar plot is a plot that presents quantitative data with\nrectangular bars with lengths proportional to the values that they\nrepresent. A bar plot shows comparisons among discrete categories. One\naxis of the plot shows the specific categories being compared, and the\nother axis represents a measured value.\nSee alsoDataFrame.plot.barVertical bar plot.DataFrame.plotMake plots of DataFrame using matplotlib.matplotlib.axes.Axes.barPlot a vertical bar plot using matplotlib.", "Examples": [">>> df = pd.DataFrame({'lab': ['A', 'B', 'C'], 'val': [10, 30, 20]})\n>>> ax = df.plot.barh(x='lab', y='val')\n"], "Parameters": [["x label or position, optional", "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used."], ["y label or position, optional", "Allows plotting of one column versus another. If not specified,\nall numerical columns are used."], ["color str, array-like, or dict, optional", "The color for each of the DataFrame’s columns. Possible values are: A single color string referred to by name, RGB or RGBA code, for instance ‘red’ or ‘#a98d19’. A sequence of color strings referred to by name, RGB or RGBA code, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused. A dict of the form {column name color}, so that each column will be colored accordingly. For example, if your columns are called a and b , then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red."], ["A single color string referred to by name, RGB or RGBA code,", "for instance ‘red’ or ‘#a98d19’."], ["A sequence of color strings referred to by name, RGB or RGBA", "code, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s bar will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused."], ["A dict of the form {column name color}, so that each column will be", "colored accordingly. For example, if your columns are called a and b , then passing {‘a’: ‘green’, ‘b’: ‘red’} will color bars for\ncolumn a in green and bars for column b in red."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or np.ndarray of them", "An ndarray is returned with one matplotlib.axes.Axes per column when subplots=True ."]], "Category": ["Series"], "index": 753}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.box.html#pandas.Series.plot.box"], "Title": ["Series.plot.box"], "Feature": ["Series.plot.box"], "Description": "Make a box plot of the DataFrame columns.\nA box plot is a method for graphically depicting groups of numerical\ndata through their quartiles.\nThe box extends from the Q1 to Q3 quartile values of the data,\nwith a line at the median (Q2). The whiskers extend from the edges\nof box to show the range of the data. The position of the whiskers\nis set by default to 1.5*IQR (IQR = Q3 - Q1) from the edges of the\nbox. Outlier points are those past the end of the whiskers.\nFor further details see Wikipedia’s\nentry forboxplot.\nA consideration when using this chart is that the box and the whiskers\ncan overlap, which is very common when plotting small sets of data.\nSee alsoDataFrame.boxplotAnother method to draw a box plot.Series.plot.boxDraw a box plot from a Series object.matplotlib.pyplot.boxplotDraw a box plot in matplotlib.", "Examples": [">>> data = np.random.randn(25, 4)\n>>> df = pd.DataFrame(data, columns=list('ABCD'))\n>>> ax = df.plot.box()\n"], "Parameters": [["by str or sequence", "Column in the DataFrame to group by. Changed in version 1.4.0: Previously, by is silently ignore and makes no groupings"], ["**kwargs", "Additional keywords are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray of them", ""]], "Category": ["Series"], "index": 754}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.density.html#pandas.Series.plot.density"], "Title": ["Series.plot.density"], "Feature": ["Series.plot.density"], "Description": "Generate Kernel Density Estimate plot using Gaussian kernels.\nIn statistics,kernel density estimation(KDE) is a non-parametric\nway to estimate the probability density function (PDF) of a random\nvariable. This function uses Gaussian kernels and includes automatic\nbandwidth determination.\nSee alsoscipy.stats.gaussian_kdeRepresentation of a kernel-density estimate using Gaussian kernels. This is the function used internally to estimate the PDF.", "Examples": [">>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])\n>>> ax = s.plot.kde()\n"], "Parameters": [["bw_method str, scalar or callable, optional", "The method used to calculate the estimator bandwidth. This can be\n‘scott’, ‘silverman’, a scalar constant or a callable.\nIf None (default), ‘scott’ is used.\nSee scipy.stats.gaussian_kde for more information."], ["ind NumPy array or int, optional", "Evaluation points for the estimated PDF. If None (default),\n1000 equally spaced points are used. If ind is a NumPy array, the\nKDE is evaluated at the points passed. If ind is an integer, ind number of equally spaced points are used."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray of them", ""]], "Category": ["Series"], "index": 755}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.hist.html#pandas.Series.plot.hist"], "Title": ["Series.plot.hist"], "Feature": ["Series.plot.hist"], "Description": "Draw one histogram of the DataFrame’s columns.\nA histogram is a representation of the distribution of data.\nThis function groups the values of all given Series in the DataFrame\ninto bins and draws all bins in onematplotlib.axes.Axes.\nThis is useful when the DataFrame’s Series are in a similar scale.\nSee alsoDataFrame.histDraw histograms per DataFrame’s Series.Series.histDraw a histogram with Series’ data.", "Examples": [">>> df = pd.DataFrame(np.random.randint(1, 7, 6000), columns=['one'])\n>>> df['two'] = df['one'] + np.random.randint(1, 7, 6000)\n>>> ax = df.plot.hist(bins=12, alpha=0.5)\n"], "Parameters": [["by str or sequence, optional", "Column in the DataFrame to group by. Changed in version 1.4.0: Previously, by is silently ignore and makes no groupings"], ["bins int, default 10", "Number of histogram bins to be used."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["class: matplotlib.AxesSubplot", "Return a histogram plot."]], "Category": ["Series"], "index": 756}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.kde.html#pandas.Series.plot.kde"], "Title": ["Series.plot.kde"], "Feature": ["Series.plot.kde"], "Description": "Generate Kernel Density Estimate plot using Gaussian kernels.\nIn statistics,kernel density estimation(KDE) is a non-parametric\nway to estimate the probability density function (PDF) of a random\nvariable. This function uses Gaussian kernels and includes automatic\nbandwidth determination.\nSee alsoscipy.stats.gaussian_kdeRepresentation of a kernel-density estimate using Gaussian kernels. This is the function used internally to estimate the PDF.", "Examples": [">>> s = pd.Series([1, 2, 2.5, 3, 3.5, 4, 5])\n>>> ax = s.plot.kde()\n"], "Parameters": [["bw_method str, scalar or callable, optional", "The method used to calculate the estimator bandwidth. This can be\n‘scott’, ‘silverman’, a scalar constant or a callable.\nIf None (default), ‘scott’ is used.\nSee scipy.stats.gaussian_kde for more information."], ["ind NumPy array or int, optional", "Evaluation points for the estimated PDF. If None (default),\n1000 equally spaced points are used. If ind is a NumPy array, the\nKDE is evaluated at the points passed. If ind is an integer, ind number of equally spaced points are used."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or numpy.ndarray of them", ""]], "Category": ["Series"], "index": 757}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.line.html#pandas.Series.plot.line"], "Title": ["Series.plot.line"], "Feature": ["Series.plot.line"], "Description": "Plot Series or DataFrame as lines.\nThis function is useful to plot lines using DataFrame’s values\nas coordinates.\nSee alsomatplotlib.pyplot.plotPlot y versus x as lines and/or markers.", "Examples": [">>> s = pd.Series([1, 3, 2])\n>>> s.plot.line()  \n"], "Parameters": [["x label or position, optional", "Allows plotting of one column versus another. If not specified,\nthe index of the DataFrame is used."], ["y label or position, optional", "Allows plotting of one column versus another. If not specified,\nall numerical columns are used."], ["color str, array-like, or dict, optional", "The color for each of the DataFrame’s columns. Possible values are: A single color string referred to by name, RGB or RGBA code, for instance ‘red’ or ‘#a98d19’. A sequence of color strings referred to by name, RGB or RGBA code, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s line will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused. A dict of the form {column name color}, so that each column will be colored accordingly. For example, if your columns are called a and b , then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\ncolumn a in green and lines for column b in red."], ["A single color string referred to by name, RGB or RGBA code,", "for instance ‘red’ or ‘#a98d19’."], ["A sequence of color strings referred to by name, RGB or RGBA", "code, which will be used for each column recursively. For\ninstance [‘green’,’yellow’] each column’s line will be filled in\ngreen or yellow, alternatively. If there is only a single column to\nbe plotted, then only the first color from the color list will be\nused."], ["A dict of the form {column name color}, so that each column will be", "colored accordingly. For example, if your columns are called a and b , then passing {‘a’: ‘green’, ‘b’: ‘red’} will color lines for\ncolumn a in green and lines for column b in red."], ["**kwargs", "Additional keyword arguments are documented in DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or np.ndarray of them", "An ndarray is returned with one matplotlib.axes.Axes per column when subplots=True ."]], "Category": ["Series"], "index": 758}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.pie.html#pandas.Series.plot.pie"], "Title": ["Series.plot.pie"], "Feature": ["Series.plot.pie"], "Description": "Generate a pie plot.\nA pie plot is a proportional representation of the numerical data in a\ncolumn. This function wrapsmatplotlib.pyplot.pie()for the\nspecified column. If no column reference is passed andsubplots=Truea pie plot is drawn for each numerical column\nindependently.\nSee alsoSeries.plot.pieGenerate a pie plot for a Series.DataFrame.plotMake plots of a DataFrame.", "Examples": [">>> df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],\n...                    'radius': [2439.7, 6051.8, 6378.1]},\n...                   index=['Mercury', 'Venus', 'Earth'])\n>>> plot = df.plot.pie(y='mass', figsize=(5, 5))\n"], "Parameters": [["y int or label, optional", "Label or position of the column to plot.\nIf not provided, subplots=True argument must be passed."], ["**kwargs", "Keyword arguments to pass on to DataFrame.plot() ."]], "Returns": [["matplotlib.axes.Axes or np.ndarray of them", "A NumPy array is returned when subplots is True."]], "Category": ["Series"], "index": 759}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.items.html#pandas.Series.items"], "Title": ["Series.items"], "Feature": ["Series.items"], "Description": "Lazily iterate over (index, value) tuples.\nThis method returns an iterable tuple (index, value). This is\nconvenient if you want to create a lazy iterator.\nSee alsoDataFrame.itemsIterate over (column name, Series) pairs.DataFrame.iterrowsIterate over DataFrame rows as (index, Series) pairs.", "Examples": [">>> s = pd.Series(['A', 'B', 'C'])\n>>> for index, value in s.items():\n...     print(f\"Index : {index}, Value : {value}\")\nIndex : 0, Value : A\nIndex : 1, Value : B\nIndex : 2, Value : C\n"], "Parameters": [], "Returns": [["iterable", "Iterable of tuples containing the (index, value) pairs from a\nSeries."]], "Category": ["Series"], "index": 760}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html#pandas.Series.hist"], "Title": ["Series.hist"], "Feature": ["Series.hist"], "Description": "Draw histogram of the input series using matplotlib.\nSee alsomatplotlib.axes.Axes.histPlot a histogram using matplotlib.", "Examples": [">>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n>>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n>>> hist = ser.hist()\n"], "Parameters": [["by object, optional", "If passed, then used to form histograms for separate groups."], ["ax matplotlib axis object", "If not passed, uses gca()."], ["grid bool, default True", "Whether to show axis grid lines."], ["xlabelsize int, default None", "If specified changes the x-axis label size."], ["xrot float, default None", "Rotation of x axis labels."], ["ylabelsize int, default None", "If specified changes the y-axis label size."], ["yrot float, default None", "Rotation of y axis labels."], ["figsize tuple, default None", "Figure size in inches by default."], ["bins int or sequence, default 10", "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["legend bool, default False", "Whether to show the legend."], ["**kwargs", "To be passed to the actual plotting function."]], "Returns": [["matplotlib.AxesSubplot", "A histogram plot."]], "Category": ["Series"], "index": 761}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.keys.html#pandas.Series.keys"], "Title": ["Series.keys"], "Feature": ["Series.keys"], "Description": "Return alias for index.", "Examples": [">>> s = pd.Series([1, 2, 3], index=[0, 1, 2])\n>>> s.keys()\nIndex([0, 1, 2], dtype='int64')\n"], "Parameters": [], "Returns": [["Index", "Index of the Series."]], "Category": ["Series"], "index": 771}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.to_string.html#pandas.Series.to_string"], "Title": ["Series.to_string"], "Feature": ["Series.to_string"], "Description": "Render a string representation of the Series.", "Examples": [">>> ser = pd.Series([1, 2, 3]).to_string()\n>>> ser\n'0    1\\n1    2\\n2    3'\n"], "Parameters": [["buf StringIO-like, optional", "Buffer to write to."], ["na_rep str, optional", "String representation of NaN to use, default ‘NaN’."], ["float_format one-parameter function, optional", "Formatter function to apply to columns’ elements if they are\nfloats, default None."], ["header bool, default True", "Add the Series header (index name)."], ["index bool, optional", "Add index (row) labels, default True."], ["length bool, default False", "Add the Series length."], ["dtype bool, default False", "Add the Series dtype."], ["name bool, default False", "Add the Series name if not None."], ["max_rows int, optional", "Maximum number of rows to show before truncating. If None, show\nall."], ["min_rows int, optional", "The number of rows to display in a truncated repr (when number\nof rows is above max_rows )."]], "Returns": [["str or None", "String representation of Series if buf=None , otherwise None."]], "Category": ["Series"], "index": 772}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.pop.html#pandas.Series.pop"], "Title": ["Series.pop"], "Feature": ["Series.pop"], "Description": "Return item and drops from series. Raise KeyError if not found.", "Examples": [">>> ser = pd.Series([1, 2, 3])\n"], "Parameters": [["item label", "Index of the element that needs to be removed."]], "Returns": [["Value that is popped from series.", ""]], "Category": ["Series"], "index": 776}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.item.html#pandas.Series.item"], "Title": ["Series.item"], "Feature": ["Series.item"], "Description": "Return the first element of the underlying data as a Python scalar.", "Examples": [">>> s = pd.Series([1])\n>>> s.item()\n1\n"], "Parameters": [], "Returns": [["scalar", "The first element of Series or Index."]], "Category": ["Series"], "index": 777}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.xs.html#pandas.Series.xs"], "Title": ["Series.xs"], "Feature": ["Series.xs"], "Description": "Return cross-section from the Series/DataFrame.\nThis method takes akeyargument to select data at a particular\nlevel of a MultiIndex.\nSee alsoDataFrame.locAccess a group of rows and columns by label(s) or a boolean array.DataFrame.ilocPurely integer-location based indexing for selection by position.\nNotes\nxscan not be used to set values.\nMultiIndex Slicers is a generic way to get/set values on\nany level or levels.\nIt is a superset ofxsfunctionality, seeMultiIndex Slicers.", "Examples": [">>> d = {'num_legs': [4, 4, 2, 2],\n...      'num_wings': [0, 0, 2, 2],\n...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n>>> df = pd.DataFrame(data=d)\n>>> df = df.set_index(['class', 'animal', 'locomotion'])\n>>> df\n                           num_legs  num_wings\nclass  animal  locomotion\nmammal cat     walks              4          0\n       dog     walks              4          0\n       bat     flies              2          2\nbird   penguin walks              2          2\n"], "Parameters": [["key label or tuple of label", "Label contained in the index, or partially in a MultiIndex."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Axis to retrieve cross-section on."], ["level object, defaults to first n levels (n=1 or len(key))", "In case of a key partially contained in a MultiIndex, indicate\nwhich levels are used. Levels can be referred by label or position."], ["drop_level bool, default True", "If False, returns object with same levels as self."]], "Returns": [["Series or DataFrame", "Cross-section from the original Series or DataFrame\ncorresponding to the selected index levels."]], "Category": ["Series"], "index": 778}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.add.html#pandas.Series.add"], "Title": ["Series.add"], "Feature": ["Series.add"], "Description": "Return Addition of series and other, element-wise (binary operatoradd).\nEquivalent toseries+other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.raddReverse of the Addition operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.add(b, fill_value=0)\na    2.0\nb    1.0\nc    1.0\nd    1.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 779}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.sub.html#pandas.Series.sub"], "Title": ["Series.sub"], "Feature": ["Series.sub"], "Description": "Return Subtraction of series and other, element-wise (binary operatorsub).\nEquivalent toseries-other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rsubReverse of the Subtraction operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.subtract(b, fill_value=0)\na    0.0\nb    1.0\nc    1.0\nd   -1.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 780}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dtype.html#pandas.Series.dtype"], "Title": ["Series.dtype"], "Feature": ["Series.dtype"], "Description": "Return the dtype object of the underlying data.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.dtype\ndtype('int64')\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 781}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.mul.html#pandas.Series.mul"], "Title": ["Series.mul"], "Feature": ["Series.mul"], "Description": "Return Multiplication of series and other, element-wise (binary operatormul).\nEquivalent toseries*other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rmulReverse of the Multiplication operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.multiply(b, fill_value=0)\na    1.0\nb    0.0\nc    0.0\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 782}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.div.html#pandas.Series.div"], "Title": ["Series.div"], "Feature": ["Series.div"], "Description": "Return Floating division of series and other, element-wise (binary operatortruediv).\nEquivalent toseries/other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rtruedivReverse of the Floating division operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.divide(b, fill_value=0)\na    1.0\nb    inf\nc    inf\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 783}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.truediv.html#pandas.Series.truediv"], "Title": ["Series.truediv"], "Feature": ["Series.truediv"], "Description": "Return Floating division of series and other, element-wise (binary operatortruediv).\nEquivalent toseries/other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rtruedivReverse of the Floating division operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.divide(b, fill_value=0)\na    1.0\nb    inf\nc    inf\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 784}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.floordiv.html#pandas.Series.floordiv"], "Title": ["Series.floordiv"], "Feature": ["Series.floordiv"], "Description": "Return Integer division of series and other, element-wise (binary operatorfloordiv).\nEquivalent toseries//other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rfloordivReverse of the Integer division operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.floordiv(b, fill_value=0)\na    1.0\nb    inf\nc    inf\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 785}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.mod.html#pandas.Series.mod"], "Title": ["Series.mod"], "Feature": ["Series.mod"], "Description": "Return Modulo of series and other, element-wise (binary operatormod).\nEquivalent toseries%other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rmodReverse of the Modulo operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.mod(b, fill_value=0)\na    0.0\nb    NaN\nc    NaN\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 786}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.pow.html#pandas.Series.pow"], "Title": ["Series.pow"], "Feature": ["Series.pow"], "Description": "Return Exponential power of series and other, element-wise (binary operatorpow).\nEquivalent toseries**other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.rpowReverse of the Exponential power operator, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.pow(b, fill_value=0)\na    1.0\nb    1.0\nc    1.0\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 787}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.radd.html#pandas.Series.radd"], "Title": ["Series.radd"], "Feature": ["Series.radd"], "Description": "Return Addition of series and other, element-wise (binary operatorradd).\nEquivalent toother+series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.addElement-wise Addition, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.add(b, fill_value=0)\na    2.0\nb    1.0\nc    1.0\nd    1.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 788}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rsub.html#pandas.Series.rsub"], "Title": ["Series.rsub"], "Feature": ["Series.rsub"], "Description": "Return Subtraction of series and other, element-wise (binary operatorrsub).\nEquivalent toother-series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.subElement-wise Subtraction, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.subtract(b, fill_value=0)\na    0.0\nb    1.0\nc    1.0\nd   -1.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 789}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rmul.html#pandas.Series.rmul"], "Title": ["Series.rmul"], "Feature": ["Series.rmul"], "Description": "Return Multiplication of series and other, element-wise (binary operatorrmul).\nEquivalent toother*series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.mulElement-wise Multiplication, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.multiply(b, fill_value=0)\na    1.0\nb    0.0\nc    0.0\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 790}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rdiv.html#pandas.Series.rdiv"], "Title": ["Series.rdiv"], "Feature": ["Series.rdiv"], "Description": "Return Floating division of series and other, element-wise (binary operatorrtruediv).\nEquivalent toother/series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.truedivElement-wise Floating division, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.divide(b, fill_value=0)\na    1.0\nb    inf\nc    inf\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 791}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.shape.html#pandas.Series.shape"], "Title": ["Series.shape"], "Feature": ["Series.shape"], "Description": "Return a tuple of the shape of the underlying data.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.shape\n(3,)\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 792}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rtruediv.html#pandas.Series.rtruediv"], "Title": ["Series.rtruediv"], "Feature": ["Series.rtruediv"], "Description": "Return Floating division of series and other, element-wise (binary operatorrtruediv).\nEquivalent toother/series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.truedivElement-wise Floating division, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.divide(b, fill_value=0)\na    1.0\nb    inf\nc    inf\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 793}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rfloordiv.html#pandas.Series.rfloordiv"], "Title": ["Series.rfloordiv"], "Feature": ["Series.rfloordiv"], "Description": "Return Integer division of series and other, element-wise (binary operatorrfloordiv).\nEquivalent toother//series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.floordivElement-wise Integer division, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.floordiv(b, fill_value=0)\na    1.0\nb    inf\nc    inf\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 794}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rmod.html#pandas.Series.rmod"], "Title": ["Series.rmod"], "Feature": ["Series.rmod"], "Description": "Return Modulo of series and other, element-wise (binary operatorrmod).\nEquivalent toother%series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.modElement-wise Modulo, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.mod(b, fill_value=0)\na    0.0\nb    NaN\nc    NaN\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 795}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rpow.html#pandas.Series.rpow"], "Title": ["Series.rpow"], "Feature": ["Series.rpow"], "Description": "Return Exponential power of series and other, element-wise (binary operatorrpow).\nEquivalent toother**series, but with support to substitute a fill_value for\nmissing data in either one of the inputs.\nSee alsoSeries.powElement-wise Exponential power, seePython documentationfor more details.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.pow(b, fill_value=0)\na    1.0\nb    1.0\nc    1.0\nd    0.0\ne    NaN\ndtype: float64\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 796}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.combine.html#pandas.Series.combine"], "Title": ["Series.combine"], "Feature": ["Series.combine"], "Description": "Combine the Series with a Series or scalar according tofunc.\nCombine the Series andotherusingfuncto perform elementwise\nselection for combined Series.fill_valueis assumed when value is missing at some index\nfrom one of the two objects being combined.\nSee alsoSeries.combine_firstCombine Series values, choosing the calling Series’ values first.", "Examples": [">>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n>>> s1\nfalcon    330.0\neagle     160.0\ndtype: float64\n>>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n>>> s2\nfalcon    345.0\neagle     200.0\nduck       30.0\ndtype: float64\n"], "Parameters": [["other Series or scalar", "The value(s) to be combined with the Series ."], ["func function", "Function that takes two scalars as inputs and returns an element."], ["fill_value scalar, optional", "The value to assume when an index is missing from\none Series or the other. The default specifies to use the\nappropriate NaN value for the underlying dtype of the Series."]], "Returns": [["Series", "The result of combining the Series with the other object."]], "Category": ["Series"], "index": 797}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.combine_first.html#pandas.Series.combine_first"], "Title": ["Series.combine_first"], "Feature": ["Series.combine_first"], "Description": "Update null elements with value in the same location in ‘other’.\nCombine two Series objects by filling null values in one Series with\nnon-null values from the other Series. Result index will be the union\nof the two indexes.\nSee alsoSeries.combinePerform element-wise operation on two Series using a given function.", "Examples": [">>> s1 = pd.Series([1, np.nan])\n>>> s2 = pd.Series([3, 4, 5])\n>>> s1.combine_first(s2)\n0    1.0\n1    4.0\n2    5.0\ndtype: float64\n"], "Parameters": [["other Series", "The value(s) to be used for filling null values."]], "Returns": [["Series", "The result of combining the provided Series with the other object."]], "Category": ["Series"], "index": 798}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.round.html#pandas.Series.round"], "Title": ["Series.round"], "Feature": ["Series.round"], "Description": "Round each value in a Series to the given number of decimals.\nSee alsonumpy.aroundRound values of an np.array.DataFrame.roundRound values of a DataFrame.", "Examples": [">>> s = pd.Series([0.1, 1.3, 2.7])\n>>> s.round()\n0    0.0\n1    1.0\n2    3.0\ndtype: float64"], "Parameters": [["decimals int, default 0", "Number of decimal places to round to. If decimals is negative,\nit specifies the number of positions to the left of the decimal point."], ["*args, **kwargs", "Additional arguments and keywords have no effect but might be\naccepted for compatibility with NumPy."]], "Returns": [["Series", "Rounded values of the Series."]], "Category": ["Series"], "index": 799}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.lt.html#pandas.Series.lt"], "Title": ["Series.lt"], "Feature": ["Series.lt"], "Description": "Return Less than of series and other, element-wise (binary operatorlt).\nEquivalent toseries<other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ne    1.0\ndtype: float64\n>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n>>> b\na    0.0\nb    1.0\nc    2.0\nd    NaN\nf    1.0\ndtype: float64\n>>> a.lt(b, fill_value=0)\na    False\nb    False\nc     True\nd    False\ne    False\nf     True\ndtype: bool\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 800}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.gt.html#pandas.Series.gt"], "Title": ["Series.gt"], "Feature": ["Series.gt"], "Description": "Return Greater than of series and other, element-wise (binary operatorgt).\nEquivalent toseries>other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ne    1.0\ndtype: float64\n>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n>>> b\na    0.0\nb    1.0\nc    2.0\nd    NaN\nf    1.0\ndtype: float64\n>>> a.gt(b, fill_value=0)\na     True\nb    False\nc    False\nd    False\ne     True\nf    False\ndtype: bool\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 801}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.le.html#pandas.Series.le"], "Title": ["Series.le"], "Feature": ["Series.le"], "Description": "Return Less than or equal to of series and other, element-wise (binary operatorle).\nEquivalent toseries<=other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ne    1.0\ndtype: float64\n>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n>>> b\na    0.0\nb    1.0\nc    2.0\nd    NaN\nf    1.0\ndtype: float64\n>>> a.le(b, fill_value=0)\na    False\nb     True\nc     True\nd    False\ne    False\nf     True\ndtype: bool\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 802}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.nbytes.html#pandas.Series.nbytes"], "Title": ["Series.nbytes"], "Feature": ["Series.nbytes"], "Description": "Return the number of bytes in the underlying data.", "Examples": [">>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n>>> s\n0     Ant\n1    Bear\n2     Cow\ndtype: object\n>>> s.nbytes\n24\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 803}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.ge.html#pandas.Series.ge"], "Title": ["Series.ge"], "Feature": ["Series.ge"], "Description": "Return Greater than or equal to of series and other, element-wise (binary operatorge).\nEquivalent toseries>=other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ne    1.0\ndtype: float64\n>>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n>>> b\na    0.0\nb    1.0\nc    2.0\nd    NaN\nf    1.0\ndtype: float64\n>>> a.ge(b, fill_value=0)\na     True\nb     True\nc    False\nd    False\ne     True\nf    False\ndtype: bool\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 804}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.ne.html#pandas.Series.ne"], "Title": ["Series.ne"], "Feature": ["Series.ne"], "Description": "Return Not equal to of series and other, element-wise (binary operatorne).\nEquivalent toseries!=other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.ne(b, fill_value=0)\na    False\nb     True\nc     True\nd     True\ne     True\ndtype: bool\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 805}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.eq.html#pandas.Series.eq"], "Title": ["Series.eq"], "Feature": ["Series.eq"], "Description": "Return Equal to of series and other, element-wise (binary operatoreq).\nEquivalent toseries==other, but with support to substitute a fill_value for\nmissing data in either one of the inputs.", "Examples": [">>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n>>> a\na    1.0\nb    1.0\nc    1.0\nd    NaN\ndtype: float64\n>>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n>>> b\na    1.0\nb    NaN\nd    1.0\ne    NaN\ndtype: float64\n>>> a.eq(b, fill_value=0)\na     True\nb    False\nc    False\nd    False\ne    False\ndtype: bool\n"], "Parameters": [["other Series or scalar value", ""], ["level int or name", "Broadcast across a level, matching Index values on the\npassed MultiIndex level."], ["fill_value None or float value, default None (NaN)", "Fill existing missing (NaN) values, and any new element needed for\nsuccessful Series alignment, with this value before computation.\nIf data in both corresponding Series locations is missing\nthe result of filling (at that location) will be missing."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."]], "Returns": [["Series", "The result of the operation."]], "Category": ["Series"], "index": 806}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.product.html#pandas.Series.product"], "Title": ["Series.product"], "Feature": ["Series.product"], "Description": "Return the product of the values over the requested axis.\nSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.", "Examples": [">>> pd.Series([], dtype=\"float64\").prod()\n1.0\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. Warning The behavior of DataFrame.prod with axis=None is deprecated,\nin a future version this will reduce over both axes and return a scalar\nTo retain the old behavior, pass axis=0 (or do not pass axis). Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["min_count int, default 0", "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 807}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.dot.html#pandas.Series.dot"], "Title": ["Series.dot"], "Feature": ["Series.dot"], "Description": "Compute the dot product between the Series and the columns of other.\nThis method computes the dot product between the Series and another\none, or the Series and each columns of a DataFrame, or the Series and\neach columns of an array.\nIt can also be called usingself @ other.\nSee alsoDataFrame.dotCompute the matrix product with the DataFrame.Series.mulMultiplication of series and other, element-wise.\nNotes\nThe Series and other has to share the same index if other is a Series\nor a DataFrame.", "Examples": [">>> s = pd.Series([0, 1, 2, 3])\n>>> other = pd.Series([-1, 2, -3, 4])\n>>> s.dot(other)\n8\n>>> s @ other\n8\n>>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n>>> s.dot(df)\n0    24\n1    14\ndtype: int64\n>>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n>>> s.dot(arr)\narray([24, 14])\n"], "Parameters": [["other Series, DataFrame or array-like", "The other object to compute the dot product with its columns."]], "Returns": [["scalar, Series or numpy.ndarray", "Return the dot product of the Series and other if other is a\nSeries, the Series of the dot product of Series and each rows of\nother if other is a DataFrame or a numpy.ndarray between the Series\nand each columns of the numpy array."]], "Category": ["Series"], "index": 808}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html#pandas.Series.apply"], "Title": ["Series.apply"], "Feature": ["Series.apply"], "Description": "Invoke function on values of Series.\nCan be ufunc (a NumPy function that applies to the entire Series)\nor a Python function that only works on single values.\nSee alsoSeries.mapFor element-wise operations.Series.aggOnly perform aggregating type operations.Series.transformOnly perform transforming type operations.\nNotes\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.", "Examples": [">>> s = pd.Series([20, 21, 12],\n...               index=['London', 'New York', 'Helsinki'])\n>>> s\nLondon      20\nNew York    21\nHelsinki    12\ndtype: int64\n"], "Parameters": [["func function", "Python function or NumPy ufunc to apply."], ["convert_dtype bool, default True", "Try to find better dtype for elementwise function results. If\nFalse, leave as dtype=object. Note that the dtype is always\npreserved for some extension array dtypes, such as Categorical. Deprecated since version 2.1.0: convert_dtype has been deprecated. Do ser.astype(object).apply() instead if you want convert_dtype=False ."], ["args tuple", "Positional arguments passed to func after the series value."], ["by_row False or “compat”, default “compat”", "If \"compat\" and func is a callable, func will be passed each element of\nthe Series, like Series.map . If func is a list or dict of\ncallables, will first try to translate each func into pandas methods. If\nthat doesn’t work, will try call to apply again with by_row=\"compat\" and if that fails, will call apply again with by_row=False (backward compatible).\nIf False, the func will be passed the whole Series at once. by_row has no effect when func is a string. Added in version 2.1.0."], ["**kwargs", "Additional keyword arguments passed to func."]], "Returns": [["Series or DataFrame", "If func returns a Series object the result will be a DataFrame."]], "Category": ["Series"], "index": 809}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.agg.html#pandas.Series.agg"], "Title": ["Series.agg"], "Feature": ["Series.agg"], "Description": "Aggregate using one or more operations over the specified axis.\nSee alsoSeries.applyInvoke function on a Series.Series.transformTransform function producing a Series with like indexes.\nNotes\nThe aggregation operations are always performed over an axis, either the\nindex (default) or the column axis. This behavior is different fromnumpyaggregation functions (mean,median,prod,sum,std,var), where the default is to compute the aggregation of the flattened\narray, e.g.,numpy.mean(arr_2d)as opposed tonumpy.mean(arr_2d,axis=0).\naggis an alias foraggregate. Use the alias.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.\nA passed user-defined-function will be passed a Series for evaluation.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s\n0    1\n1    2\n2    3\n3    4\ndtype: int64\n"], "Parameters": [["func function, str, list or dict", "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] dict of axis labels -> functions, function names or list of such."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["*args", "Positional arguments to pass to func ."], ["**kwargs", "Keyword arguments to pass to func ."]], "Returns": [["scalar, Series or DataFrame", "The return can be: scalar : when Series.agg is called with single function Series : when DataFrame.agg is called with a single function DataFrame : when DataFrame.agg is called with several functions"]], "Category": ["Series"], "index": 810}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.aggregate.html#pandas.Series.aggregate"], "Title": ["Series.aggregate"], "Feature": ["Series.aggregate"], "Description": "Aggregate using one or more operations over the specified axis.\nSee alsoSeries.applyInvoke function on a Series.Series.transformTransform function producing a Series with like indexes.\nNotes\nThe aggregation operations are always performed over an axis, either the\nindex (default) or the column axis. This behavior is different fromnumpyaggregation functions (mean,median,prod,sum,std,var), where the default is to compute the aggregation of the flattened\narray, e.g.,numpy.mean(arr_2d)as opposed tonumpy.mean(arr_2d,axis=0).\naggis an alias foraggregate. Use the alias.\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.\nA passed user-defined-function will be passed a Series for evaluation.", "Examples": [">>> s = pd.Series([1, 2, 3, 4])\n>>> s\n0    1\n1    2\n2    3\n3    4\ndtype: int64\n"], "Parameters": [["func function, str, list or dict", "Function to use for aggregating the data. If a function, must either\nwork when passed a Series or when passed to Series.apply. Accepted combinations are: function string function name list of functions and/or function names, e.g. [np.sum, 'mean'] dict of axis labels -> functions, function names or list of such."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["*args", "Positional arguments to pass to func ."], ["**kwargs", "Keyword arguments to pass to func ."]], "Returns": [["scalar, Series or DataFrame", "The return can be: scalar : when Series.agg is called with single function Series : when DataFrame.agg is called with a single function DataFrame : when DataFrame.agg is called with several functions"]], "Category": ["Series"], "index": 811}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.transform.html#pandas.Series.transform"], "Title": ["Series.transform"], "Feature": ["Series.transform"], "Description": "Callfuncon self producing a Series with the same axis shape as self.\nSee alsoSeries.aggOnly perform aggregating type operations.Series.applyInvoke function on a Series.\nNotes\nFunctions that mutate the passed object can produce unexpected\nbehavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.", "Examples": [">>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n>>> df\n   A  B\n0  0  1\n1  1  2\n2  2  3\n>>> df.transform(lambda x: x + 1)\n   A  B\n0  1  2\n1  2  3\n2  3  4\n"], "Parameters": [["func function, str, list-like or dict-like", "Function to use for transforming the data. If a function, must either\nwork when passed a Series or when passed to Series.apply. If func\nis both list-like and dict-like, dict-like behavior takes precedence. Accepted combinations are: function string function name list-like of functions and/or function names, e.g. [np.exp, 'sqrt'] dict-like of axis labels -> functions, function names or list-like of such."], ["axis {0 or ‘index’}", "Unused. Parameter needed for compatibility with DataFrame."], ["*args", "Positional arguments to pass to func ."], ["**kwargs", "Keyword arguments to pass to func ."]], "Returns": [["Series", "A Series that must have the same length as self."]], "Category": ["Series"], "index": 812}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html#pandas.Series.map"], "Title": ["Series.map"], "Feature": ["Series.map"], "Description": "Map values of Series according to an input mapping or function.\nUsed for substituting each value in a Series with another value,\nthat may be derived from a function, adictor\naSeries.\nSee alsoSeries.applyFor applying more complex functions on a Series.Series.replaceReplace values given into_replacewithvalue.DataFrame.applyApply a function row-/column-wise.DataFrame.mapApply a function elementwise on a whole DataFrame.\nNotes\nWhenargis a dictionary, values in Series that are not in the\ndictionary (as keys) are converted toNaN. However, if the\ndictionary is adictsubclass that defines__missing__(i.e.\nprovides a method for default values), then this default is used\nrather thanNaN.", "Examples": [">>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n>>> s\n0      cat\n1      dog\n2      NaN\n3   rabbit\ndtype: object\n"], "Parameters": [["arg function, collections.abc.Mapping subclass or Series", "Mapping correspondence."], ["na_action {None, ‘ignore’}, default None", "If ‘ignore’, propagate NaN values, without passing them to the\nmapping correspondence."]], "Returns": [["Series", "Same index as caller."]], "Category": ["Series"], "index": 813}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.ndim.html#pandas.Series.ndim"], "Title": ["Series.ndim"], "Feature": ["Series.ndim"], "Description": "Number of dimensions of the underlying data, by definition 1.", "Examples": [">>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n>>> s\n0     Ant\n1    Bear\n2     Cow\ndtype: object\n>>> s.ndim\n1\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 814}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.groupby.html#pandas.Series.groupby"], "Title": ["Series.groupby"], "Feature": ["Series.groupby"], "Description": "Group Series using a mapper or by a Series of columns.\nA groupby operation involves some combination of splitting the\nobject, applying a function, and combining the results. This can be\nused to group large amounts of data and compute operations on these\ngroups.\nSee alsoresampleConvenience method for frequency conversion and resampling of time series.\nNotes\nSee theuser guidefor more\ndetailed usage and examples, including splitting an object into groups,\niterating through groups, selecting a group, aggregation, and more.", "Examples": [">>> ser = pd.Series([390., 350., 30., 20.],\n...                 index=['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n...                 name=\"Max Speed\")\n>>> ser\nFalcon    390.0\nFalcon    350.0\nParrot     30.0\nParrot     20.0\nName: Max Speed, dtype: float64\n>>> ser.groupby([\"a\", \"b\", \"a\", \"b\"]).mean()\na    210.0\nb    185.0\nName: Max Speed, dtype: float64\n>>> ser.groupby(level=0).mean()\nFalcon    370.0\nParrot     25.0\nName: Max Speed, dtype: float64\n>>> ser.groupby(ser > 100).mean()\nMax Speed\nFalse     25.0\nTrue     370.0\nName: Max Speed, dtype: float64\n"], "Parameters": [["by mapping, function, label, pd.Grouper or list of such", "Used to determine the groups for the groupby.\nIf by is a function, it’s called on each value of the object’s\nindex. If a dict or Series is passed, the Series or dict VALUES\nwill be used to determine the groups (the Series’ values are first\naligned; see .align() method). If a list or ndarray of length\nequal to the selected axis is passed (see the groupby user guide ),\nthe values are used as-is to determine the groups. A label or list\nof labels may be passed to group by the columns in self .\nNotice that a tuple is interpreted as a (single) key."], ["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "Split along rows (0) or columns (1). For Series this parameter\nis unused and defaults to 0. Deprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version.\nFor axis=1 , do frame.T.groupby(...) instead."], ["level int, level name, or sequence of such, default None", "If the axis is a MultiIndex (hierarchical), group by a particular\nlevel or levels. Do not specify both by and level ."], ["as_index bool, default True", "Return object with group labels as the\nindex. Only relevant for DataFrame input. as_index=False is\neffectively “SQL-style” grouped output. This argument has no effect\non filtrations (see the filtrations in the user guide ),\nsuch as head() , tail() , nth() and in transformations\n(see the transformations in the user guide )."], ["sort bool, default True", "Sort group keys. Get better performance by turning this off.\nNote this does not influence the order of observations within each\ngroup. Groupby preserves the order of rows within each group. If False,\nthe groups will appear in the same order as they did in the original DataFrame.\nThis argument has no effect on filtrations (see the filtrations in the user guide ),\nsuch as head() , tail() , nth() and in transformations\n(see the transformations in the user guide ). Changed in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no\nlonger sort the values."], ["group_keys bool, default True", "When calling apply and the by argument produces a like-indexed\n(i.e. a transform ) result, add group keys to\nindex to identify pieces. By default group keys are not included\nwhen the result’s index (and column) labels match the inputs, and\nare included otherwise. Changed in version 1.5.0: Warns that group_keys will no longer be ignored when the\nresult from apply is a like-indexed Series or DataFrame.\nSpecify group_keys explicitly to include the group keys or\nnot. Changed in version 2.0.0: group_keys now defaults to True ."], ["observed bool, default False", "This only applies if any of the groupers are Categoricals.\nIf True: only show observed values for categorical groupers.\nIf False: show all values for categorical groupers. Deprecated since version 2.1.0: The default value will change to True in a future version of pandas."], ["dropna bool, default True", "If True, and if group keys contain NA values, NA values together\nwith row/column will be dropped.\nIf False, NA values will also be treated as the key in groups."]], "Returns": [["pandas.api.typing.SeriesGroupBy", "Returns a groupby object that contains information about the groups."]], "Category": ["Series"], "index": 815}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.rolling.html#pandas.Series.rolling"], "Title": ["Series.rolling"], "Feature": ["Series.rolling"], "Description": "Provide rolling window calculations.\nSee alsoexpandingProvides expanding transformations.ewmProvides exponential weighted functions.\nNotes\nSeeWindowing Operationsfor further usage details\nand examples.", "Examples": [">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n>>> df\n     B\n0  0.0\n1  1.0\n2  2.0\n3  NaN\n4  4.0\n"], "Parameters": [["window int, timedelta, str, offset, or BaseIndexer subclass", "Size of the moving window. If an integer, the fixed number of observations used for\neach window. If a timedelta, str, or offset, the time period of each window. Each\nwindow will be a variable sized based on the observations included in\nthe time-period. This is only valid for datetimelike indexes.\nTo learn more about the offsets & frequency strings, please see this link . If a BaseIndexer subclass, the window boundaries\nbased on the defined get_window_bounds method. Additional rolling\nkeyword arguments, namely min_periods , center , closed and step will be passed to get_window_bounds ."], ["min_periods int, default None", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan . For a window that is specified by an offset, min_periods will default to 1. For a window that is specified by an integer, min_periods will default\nto the size of the window."], ["center bool, default False", "If False, set the window labels as the right edge of the window index. If True, set the window labels as the center of the window index."], ["win_type str, default None", "If None , all points are evenly weighted. If a string, it must be a valid scipy.signal window function . Certain Scipy window types require additional parameters to be passed\nin the aggregation function. The additional parameters must match\nthe keywords specified in the Scipy window type method signature."], ["on str, optional", "For a DataFrame, a column label or Index level on which\nto calculate the rolling window, rather than the DataFrame’s index. Provided integer column is ignored and excluded from result since\nan integer index is not used to calculate the rolling window."], ["axis int or str, default 0", "If 0 or 'index' , roll across the rows. If 1 or 'columns' , roll across the columns. For Series this parameter is unused and defaults to 0. Deprecated since version 2.1.0: The axis keyword is deprecated. For axis=1 ,\ntranspose the DataFrame first instead."], ["closed str, default None", "If 'right' , the first point in the window is excluded from calculations. If 'left' , the last point in the window is excluded from calculations. If 'both' , the no points in the window are excluded from calculations. If 'neither' , the first and last points in the window are excluded\nfrom calculations. Default None ( 'right' )."], ["step int, default None", "Added in version 1.5.0. Evaluate the window at every step result, equivalent to slicing as [::step] . window must be an integer. Using a step argument other\nthan None or 1 will produce a result with a different shape than the input."], ["method str {‘single’, ‘table’}, default ‘single’", "Added in version 1.3.0. Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call."]], "Returns": [["pandas.api.typing.Window or pandas.api.typing.Rolling", "An instance of Window is returned if win_type is passed. Otherwise,\nan instance of Rolling is returned."]], "Category": ["Series"], "index": 816}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.expanding.html#pandas.Series.expanding"], "Title": ["Series.expanding"], "Feature": ["Series.expanding"], "Description": "Provide expanding window calculations.\nSee alsorollingProvides rolling window calculations.ewmProvides exponential weighted functions.\nNotes\nSeeWindowing Operationsfor further usage details\nand examples.", "Examples": [">>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n>>> df\n     B\n0  0.0\n1  1.0\n2  2.0\n3  NaN\n4  4.0\n"], "Parameters": [["min_periods int, default 1", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan ."], ["axis int or str, default 0", "If 0 or 'index' , roll across the rows. If 1 or 'columns' , roll across the columns. For Series this parameter is unused and defaults to 0."], ["method str {‘single’, ‘table’}, default ‘single’", "Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call. Added in version 1.3.0."]], "Returns": [["pandas.api.typing.Expanding", ""]], "Category": ["Series"], "index": 817}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.ewm.html#pandas.Series.ewm"], "Title": ["Series.ewm"], "Feature": ["Series.ewm"], "Description": "Provide exponentially weighted (EW) calculations.\nExactly one ofcom,span,halflife, oralphamust be\nprovided iftimesis not provided. Iftimesis provided,halflifeand one ofcom,spanoralphamay be provided.\nSee alsorollingProvides rolling window calculations.expandingProvides expanding transformations.\nNotes\nSeeWindowing Operationsfor further usage details and examples.", "Examples": [">>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n>>> df\n     B\n0  0.0\n1  1.0\n2  2.0\n3  NaN\n4  4.0\n"], "Parameters": [["com float, optional", "Specify decay in terms of center of mass α = 1 / ( 1 + c o m ) , for c o m ≥ 0 ."], ["span float, optional", "Specify decay in terms of span α = 2 / ( s p a n + 1 ) , for s p a n ≥ 1 ."], ["halflife float, str, timedelta, optional", "Specify decay in terms of half-life α = 1 − exp ⁡ ( − ln ⁡ ( 2 ) / h a l f l i f e ) , for h a l f l i f e > 0 . If times is specified, a timedelta convertible unit over which an\nobservation decays to half its value. Only applicable to mean() ,\nand halflife value will not apply to the other functions."], ["alpha float, optional", "Specify smoothing factor α directly 0 < α ≤ 1 ."], ["min_periods int, default 0", "Minimum number of observations in window required to have a value;\notherwise, result is np.nan ."], ["adjust bool, default True", "Divide by decaying adjustment factor in beginning periods to account\nfor imbalance in relative weightings (viewing EWMA as a moving average). When adjust=True (default), the EW function is calculated using weights w i = ( 1 − α ) i . For example, the EW moving average of the series\n[ x 0 , x 1 , . . . , x t ] would be: y t = x t + ( 1 − α ) x t − 1 + ( 1 − α ) 2 x t − 2 + . . . + ( 1 − α ) t x 0 1 + ( 1 − α ) + ( 1 − α ) 2 + . . . + ( 1 − α ) t When adjust=False , the exponentially weighted function is calculated\nrecursively: y 0 = x 0 y t = ( 1 − α ) y t − 1 + α x t ,"], ["ignore_na bool, default False", "Ignore missing values when calculating weights. When ignore_na=False (default), weights are based on absolute positions.\nFor example, the weights of x 0 and x 2 used in calculating\nthe final weighted average of [ x 0 , None, x 2 ] are ( 1 − α ) 2 and 1 if adjust=True , and ( 1 − α ) 2 and α if adjust=False . When ignore_na=True , weights are based\non relative positions. For example, the weights of x 0 and x 2 used in calculating the final weighted average of\n[ x 0 , None, x 2 ] are 1 − α and 1 if adjust=True , and 1 − α and α if adjust=False ."], ["axis {0, 1}, default 0", "If 0 or 'index' , calculate across the rows. If 1 or 'columns' , calculate across the columns. For Series this parameter is unused and defaults to 0."], ["times np.ndarray, Series, default None", "Only applicable to mean() . Times corresponding to the observations. Must be monotonically increasing and datetime64[ns] dtype. If 1-D array like, a sequence with the same shape as the observations."], ["method str {‘single’, ‘table’}, default ‘single’", "Added in version 1.4.0. Execute the rolling operation per single column or row ( 'single' )\nor over the entire object ( 'table' ). This argument is only implemented when specifying engine='numba' in the method call. Only applicable to mean()"]], "Returns": [["pandas.api.typing.ExponentialMovingWindow", ""]], "Category": ["Series"], "index": 818}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.pipe.html#pandas.Series.pipe"], "Title": ["Series.pipe"], "Feature": ["Series.pipe"], "Description": "Apply chainable functions that expect Series or DataFrames.\nSee alsoDataFrame.applyApply a function along input axis of DataFrame.DataFrame.mapApply a function elementwise on a whole DataFrame.Series.mapApply a mapping correspondence on aSeries.\nNotes\nUse.pipewhen chaining together functions that expect\nSeries, DataFrames or GroupBy objects.", "Examples": [">>> data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n>>> df = pd.DataFrame(data, columns=['Salary', 'Others'])\n>>> df\n   Salary  Others\n0    8000  1000.0\n1    9500     NaN\n2    5000  2000.0\n"], "Parameters": [["func function", "Function to apply to the Series/DataFrame. args , and kwargs are passed into func .\nAlternatively a (callable, data_keyword) tuple where data_keyword is a string indicating the keyword of callable that expects the Series/DataFrame."], ["*args iterable, optional", "Positional arguments passed into func ."], ["**kwargs mapping, optional", "A dictionary of keyword arguments passed into func ."]], "Returns": [["the return type of func .", ""]], "Category": ["Series"], "index": 819}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html#pandas.Series.abs"], "Title": ["Series.abs"], "Feature": ["Series.abs"], "Description": "Return a Series/DataFrame with absolute numeric value of each element.\nThis function only applies to elements that are all numeric.\nSee alsonumpy.absoluteCalculate the absolute value element-wise.\nNotes\nForcomplexinputs,1.2+1j, the absolute value isa2+b2.", "Examples": [">>> s = pd.Series([-1.10, 2, -3.33, 4])\n>>> s.abs()\n0    1.10\n1    2.00\n2    3.33\n3    4.00\ndtype: float64\n"], "Parameters": [], "Returns": [["abs", "Series/DataFrame containing the absolute value of each element."]], "Category": ["Series"], "index": 820}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.all.html#pandas.Series.all"], "Title": ["Series.all"], "Feature": ["Series.all"], "Description": "Return whether all elements are True, potentially over an axis.\nReturns True unless there at least one element within a series or\nalong a Dataframe axis that is False or equivalent (e.g. zero or\nempty).\nSee alsoSeries.allReturn True if all elements are True.DataFrame.anyReturn True if one (or more) elements are True.", "Examples": [">>> pd.Series([True, True]).all()\nTrue\n>>> pd.Series([True, False]).all()\nFalse\n>>> pd.Series([], dtype=\"float64\").all()\nTrue\n>>> pd.Series([np.nan]).all()\nTrue\n>>> pd.Series([np.nan]).all(skipna=False)\nTrue\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0. 0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels. 1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index. None : reduce all axes, return a scalar."], ["bool_only bool, default False", "Include only boolean columns. Not implemented for Series."], ["skipna bool, default True", "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be True, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero."], ["**kwargs any, default None", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["scalar or Series", "If level is specified, then, Series is returned; otherwise, scalar\nis returned."]], "Category": ["Series"], "index": 821}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html#pandas.Series.any"], "Title": ["Series.any"], "Feature": ["Series.any"], "Description": "Return whether any element is True, potentially over an axis.\nReturns False unless there is at least one element within a series or\nalong a Dataframe axis that is True or equivalent (e.g. non-zero or\nnon-empty).\nSee alsonumpy.anyNumpy version of this method.Series.anyReturn whether any element is True.Series.allReturn whether all elements are True.DataFrame.anyReturn whether any element is True over requested axis.DataFrame.allReturn whether all elements are True over requested axis.", "Examples": [">>> pd.Series([False, False]).any()\nFalse\n>>> pd.Series([True, False]).any()\nTrue\n>>> pd.Series([], dtype=\"float64\").any()\nFalse\n>>> pd.Series([np.nan]).any()\nFalse\n>>> pd.Series([np.nan]).any(skipna=False)\nTrue\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’, None}, default 0", "Indicate which axis or axes should be reduced. For Series this parameter\nis unused and defaults to 0. 0 / ‘index’ : reduce the index, return a Series whose index is the\noriginal column labels. 1 / ‘columns’ : reduce the columns, return a Series whose index is the\noriginal index. None : reduce all axes, return a scalar."], ["bool_only bool, default False", "Include only boolean columns. Not implemented for Series."], ["skipna bool, default True", "Exclude NA/null values. If the entire row/column is NA and skipna is\nTrue, then the result will be False, as for an empty row/column.\nIf skipna is False, then NA are treated as True, because these are not\nequal to zero."], ["**kwargs any, default None", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["scalar or Series", "If level is specified, then, Series is returned; otherwise, scalar\nis returned."]], "Category": ["Series"], "index": 822}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.autocorr.html#pandas.Series.autocorr"], "Title": ["Series.autocorr"], "Feature": ["Series.autocorr"], "Description": "Compute the lag-N autocorrelation.\nThis method computes the Pearson correlation between\nthe Series and its shifted self.\nSee alsoSeries.corrCompute the correlation between two Series.Series.shiftShift index by desired number of periods.DataFrame.corrCompute pairwise correlation of columns.DataFrame.corrwithCompute pairwise correlation between rows or columns of two DataFrame objects.\nNotes\nIf the Pearson correlation is not well defined return ‘NaN’.", "Examples": [">>> s = pd.Series([0.25, 0.5, 0.2, -0.05])\n>>> s.autocorr()  \n0.10355...\n>>> s.autocorr(lag=2)  \n-0.99999...\n"], "Parameters": [["lag int, default 1", "Number of lags to apply before performing autocorrelation."]], "Returns": [["float", "The Pearson correlation between self and self.shift(lag)."]], "Category": ["Series"], "index": 823}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html#pandas.Series.between"], "Title": ["Series.between"], "Feature": ["Series.between"], "Description": "Return boolean Series equivalent to left <= series <= right.\nThis function returns a boolean vector containingTruewherever the\ncorresponding Series element is between the boundary valuesleftandright. NA values are treated asFalse.\nSee alsoSeries.gtGreater than of series and other.Series.ltLess than of series and other.\nNotes\nThis function is equivalent to(left<=ser)&(ser<=right)", "Examples": [">>> s = pd.Series([2, 0, 4, 8, np.nan])\n"], "Parameters": [["left scalar or list-like", "Left boundary."], ["right scalar or list-like", "Right boundary."], ["inclusive {“both”, “neither”, “left”, “right”}", "Include boundaries. Whether to set each bound as closed or open. Changed in version 1.3.0."]], "Returns": [["Series", "Series representing whether each element is between left and\nright (inclusive)."]], "Category": ["Series"], "index": 824}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.size.html#pandas.Series.size"], "Title": ["Series.size"], "Feature": ["Series.size"], "Description": "Return the number of elements in the underlying data.", "Examples": [">>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n>>> s\n0     Ant\n1    Bear\n2     Cow\ndtype: object\n>>> s.size\n3\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 825}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html#pandas.Series.clip"], "Title": ["Series.clip"], "Feature": ["Series.clip"], "Description": "Trim values at input threshold(s).\nAssigns values outside boundary to boundary values. Thresholds\ncan be singular values or array like, and in the latter case\nthe clipping is performed element-wise in the specified axis.\nSee alsoSeries.clipTrim values at input threshold in series.DataFrame.clipTrim values at input threshold in dataframe.numpy.clipClip (limit) the values in an array.", "Examples": [">>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n>>> df = pd.DataFrame(data)\n>>> df\n   col_0  col_1\n0      9     -2\n1     -3     -7\n2      0      6\n3     -1      8\n4      5     -5\n"], "Parameters": [["lower float or array-like, default None", "Minimum threshold value. All values below this\nthreshold will be set to it. A missing\nthreshold (e.g NA ) will not clip the value."], ["upper float or array-like, default None", "Maximum threshold value. All values above this\nthreshold will be set to it. A missing\nthreshold (e.g NA ) will not clip the value."], ["axis {{0 or ‘index’, 1 or ‘columns’, None}}, default None", "Align object with lower and upper along the given axis.\nFor Series this parameter is unused and defaults to None ."], ["inplace bool, default False", "Whether to perform the operation in place on the data."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted\nfor compatibility with numpy."]], "Returns": [["Series or DataFrame or None", "Same type as calling object with the values outside the\nclip boundaries replaced or None if inplace=True ."]], "Category": ["Series"], "index": 826}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html#pandas.Series.corr"], "Title": ["Series.corr"], "Feature": ["Series.corr"], "Description": "Compute correlation withotherSeries, excluding missing values.\nThe twoSeriesobjects are not required to be the same length and will be\naligned internally before the correlation function is applied.\nSee alsoDataFrame.corrCompute pairwise correlation between columns.DataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.\nNotes\nPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\nPearson correlation coefficientKendall rank correlation coefficientSpearman’s rank correlation coefficient\nAutomatic data alignment: as with all pandas operations, automatic data alignment is performed for this method.corr()automatically considers values with matching indices.", "Examples": [">>> def histogram_intersection(a, b):\n...     v = np.minimum(a, b).sum().round(decimals=1)\n...     return v\n>>> s1 = pd.Series([.2, .0, .6, .2])\n>>> s2 = pd.Series([.3, .6, .0, .1])\n>>> s1.corr(s2, method=histogram_intersection)\n0.3\n"], "Parameters": [["other Series", "Series with which to compute the correlation."], ["method {‘pearson’, ‘kendall’, ‘spearman’} or callable", "Method used to compute correlation: pearson : Standard correlation coefficient kendall : Kendall Tau correlation coefficient spearman : Spearman rank correlation callable: Callable with input two 1d ndarrays and returning a float. Warning Note that the returned matrix from corr will have 1 along the\ndiagonals and will be symmetric regardless of the callable’s\nbehavior."], ["min_periods int, optional", "Minimum number of observations needed to have a valid result."]], "Returns": [["float", "Correlation with other."]], "Category": ["Series"], "index": 827}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.count.html#pandas.Series.count"], "Title": ["Series.count"], "Feature": ["Series.count"], "Description": "Return number of non-NA/null observations in the Series.\nSee alsoDataFrame.countCount non-NA cells for each column or row.", "Examples": [">>> s = pd.Series([0.0, 1.0, np.nan])\n>>> s.count()\n2\n"], "Parameters": [], "Returns": [["int", "Number of non-null values in the Series."]], "Category": ["Series"], "index": 828}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cov.html#pandas.Series.cov"], "Title": ["Series.cov"], "Feature": ["Series.cov"], "Description": "Compute covariance with Series, excluding missing values.\nThe twoSeriesobjects are not required to be the same length and\nwill be aligned internally before the covariance is calculated.\nSee alsoDataFrame.covCompute pairwise covariance of columns.", "Examples": [">>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n>>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n>>> s1.cov(s2)\n-0.01685762652715874\n"], "Parameters": [["other Series", "Series with which to compute the covariance."], ["min_periods int, optional", "Minimum number of observations needed to have a valid result."], ["ddof int, default 1", "Delta degrees of freedom.  The divisor used in calculations\nis N - ddof , where N represents the number of elements."]], "Returns": [["float", "Covariance between Series and other normalized by N-1\n(unbiased estimator)."]], "Category": ["Series"], "index": 829}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cummax.html#pandas.Series.cummax"], "Title": ["Series.cummax"], "Feature": ["Series.cummax"], "Description": "Return cumulative maximum over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nmaximum.\nSee alsocore.window.expanding.Expanding.maxSimilar functionality but ignoresNaNvalues.Series.maxReturn the maximum over Series axis.Series.cummaxReturn cumulative maximum over Series axis.Series.cumminReturn cumulative minimum over Series axis.Series.cumsumReturn cumulative sum over Series axis.Series.cumprodReturn cumulative product over Series axis.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["scalar or Series", "Return cumulative maximum of scalar or Series."]], "Category": ["Series"], "index": 830}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cummin.html#pandas.Series.cummin"], "Title": ["Series.cummin"], "Feature": ["Series.cummin"], "Description": "Return cumulative minimum over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nminimum.\nSee alsocore.window.expanding.Expanding.minSimilar functionality but ignoresNaNvalues.Series.minReturn the minimum over Series axis.Series.cummaxReturn cumulative maximum over Series axis.Series.cumminReturn cumulative minimum over Series axis.Series.cumsumReturn cumulative sum over Series axis.Series.cumprodReturn cumulative product over Series axis.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["scalar or Series", "Return cumulative minimum of scalar or Series."]], "Category": ["Series"], "index": 831}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cumprod.html#pandas.Series.cumprod"], "Title": ["Series.cumprod"], "Feature": ["Series.cumprod"], "Description": "Return cumulative product over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nproduct.\nSee alsocore.window.expanding.Expanding.prodSimilar functionality but ignoresNaNvalues.Series.prodReturn the product over Series axis.Series.cummaxReturn cumulative maximum over Series axis.Series.cumminReturn cumulative minimum over Series axis.Series.cumsumReturn cumulative sum over Series axis.Series.cumprodReturn cumulative product over Series axis.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["scalar or Series", "Return cumulative product of scalar or Series."]], "Category": ["Series"], "index": 832}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html#pandas.Series.cumsum"], "Title": ["Series.cumsum"], "Feature": ["Series.cumsum"], "Description": "Return cumulative sum over a DataFrame or Series axis.\nReturns a DataFrame or Series of the same size containing the cumulative\nsum.\nSee alsocore.window.expanding.Expanding.sumSimilar functionality but ignoresNaNvalues.Series.sumReturn the sum over Series axis.Series.cummaxReturn cumulative maximum over Series axis.Series.cumminReturn cumulative minimum over Series axis.Series.cumsumReturn cumulative sum over Series axis.Series.cumprodReturn cumulative product over Series axis.", "Examples": [">>> s = pd.Series([2, np.nan, 5, -1, 0])\n>>> s\n0    2.0\n1    NaN\n2    5.0\n3   -1.0\n4    0.0\ndtype: float64\n"], "Parameters": [["axis {0 or ‘index’, 1 or ‘columns’}, default 0", "The index or the name of the axis. 0 is equivalent to None or ‘index’.\nFor Series this parameter is unused and defaults to 0."], ["skipna bool, default True", "Exclude NA/null values. If an entire row/column is NA, the result\nwill be NA."], ["*args, **kwargs", "Additional keywords have no effect but might be accepted for\ncompatibility with NumPy."]], "Returns": [["scalar or Series", "Return cumulative sum of scalar or Series."]], "Category": ["Series"], "index": 833}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.describe.html#pandas.Series.describe"], "Title": ["Series.describe"], "Feature": ["Series.describe"], "Description": "Generate descriptive statistics.\nDescriptive statistics include those that summarize the central\ntendency, dispersion and shape of a\ndataset’s distribution, excludingNaNvalues.\nAnalyzes both numeric and object series, as well\nasDataFramecolumn sets of mixed data types. The output\nwill vary depending on what is provided. Refer to the notes\nbelow for more detail.\nSee alsoDataFrame.countCount number of non-NA/null observations.DataFrame.maxMaximum of the values in the object.DataFrame.minMinimum of the values in the object.DataFrame.meanMean of the values.DataFrame.stdStandard deviation of the observations.DataFrame.select_dtypesSubset of a DataFrame including/excluding columns based on their dtype.\nNotes\nFor numeric data, the result’s index will includecount,mean,std,min,maxas well as lower,50and\nupper percentiles. By default the lower percentile is25and the\nupper percentile is75. The50percentile is the\nsame as the median.\nFor object data (e.g. strings or timestamps), the result’s index\nwill includecount,unique,top, andfreq. Thetopis the most common value. Thefreqis the most common value’s\nfrequency. Timestamps also include thefirstandlastitems.\nIf multiple object values have the highest count, then thecountandtopresults will be arbitrarily chosen from\namong those with the highest count.\nFor mixed data types provided via aDataFrame, the default is to\nreturn only an analysis of numeric columns. If the dataframe consists\nonly of object and categorical data without any numeric columns, the\ndefault is to return an analysis of both the object and categorical\ncolumns. Ifinclude='all'is provided as an option, the result\nwill include a union of attributes of each type.\nTheincludeandexcludeparameters can be used to limit\nwhich columns in aDataFrameare analyzed for the output.\nThe parameters are ignored when analyzing aSeries.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.describe()\ncount    3.0\nmean     2.0\nstd      1.0\nmin      1.0\n25%      1.5\n50%      2.0\n75%      2.5\nmax      3.0\ndtype: float64\n"], "Parameters": [["percentiles list-like of numbers, optional", "The percentiles to include in the output. All should\nfall between 0 and 1. The default is [.25, .5, .75] , which returns the 25th, 50th, and\n75th percentiles."], ["include ‘all’, list-like of dtypes or None (default), optional", "A white list of data types to include in the result. Ignored\nfor Series . Here are the options: ‘all’ : All columns of the input will be included in the output. A list-like of dtypes : Limits the results to the\nprovided data types.\nTo limit the result to numeric types submit numpy.number . To limit it instead to object columns submit\nthe numpy.object data type. Strings\ncan also be used in the style of select_dtypes (e.g. df.describe(include=['O']) ). To\nselect pandas categorical columns, use 'category' None (default) : The result will include all numeric columns."], ["exclude list-like of dtypes or None (default), optional,", "A black list of data types to omit from the result. Ignored\nfor Series . Here are the options: A list-like of dtypes : Excludes the provided data types\nfrom the result. To exclude numeric types submit numpy.number . To exclude object columns submit the data\ntype numpy.object . Strings can also be used in the style of select_dtypes (e.g. df.describe(exclude=['O']) ). To\nexclude pandas categorical columns, use 'category' None (default) : The result will exclude nothing."]], "Returns": [["Series or DataFrame", "Summary statistics of the Series or Dataframe provided."]], "Category": ["Series"], "index": 834}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.diff.html#pandas.Series.diff"], "Title": ["Series.diff"], "Feature": ["Series.diff"], "Description": "First discrete difference of element.\nCalculates the difference of a Series element compared with another\nelement in the Series (default is element in previous row).\nSee alsoSeries.pct_changePercent change over given number of periods.Series.shiftShift index by desired number of periods with an optional time freq.DataFrame.diffFirst discrete difference of object.\nNotes\nFor boolean dtypes, this usesoperator.xor()rather thanoperator.sub().\nThe result is calculated according to current dtype in Series,\nhowever dtype of the result is always float64.", "Examples": [">>> s = pd.Series([1, 1, 2, 3, 5, 8])\n>>> s.diff()\n0    NaN\n1    0.0\n2    1.0\n3    1.0\n4    2.0\n5    3.0\ndtype: float64\n"], "Parameters": [["periods int, default 1", "Periods to shift for calculating difference, accepts negative\nvalues."]], "Returns": [["Series", "First differences of the Series."]], "Category": ["Series"], "index": 835}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.T.html#pandas.Series.T"], "Title": ["Series.T"], "Feature": ["Series.T"], "Description": "Return the transpose, which is by definition self.", "Examples": [">>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n>>> s\n0     Ant\n1    Bear\n2     Cow\ndtype: object\n>>> s.T\n0     Ant\n1    Bear\n2     Cow\ndtype: object\n"], "Parameters": [], "Returns": [], "Category": ["Series"], "index": 836}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.factorize.html#pandas.Series.factorize"], "Title": ["Series.factorize"], "Feature": ["Series.factorize"], "Description": "Encode the object as an enumerated type or categorical variable.\nThis method is useful for obtaining a numeric representation of an\narray when all that matters is identifying distinct values.factorizeis available as both a top-level functionpandas.factorize(),\nand as a methodSeries.factorize()andIndex.factorize().\nSee alsocutDiscretize continuous-valued array.uniqueFind the unique value in an array.\nNotes\nReferencethe user guidefor more examples.", "Examples": [">>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"))\n>>> codes\narray([0, 0, 1, 2, 0])\n>>> uniques\narray(['b', 'a', 'c'], dtype=object)\n"], "Parameters": [["sort bool, default False", "Sort uniques and shuffle codes to maintain the\nrelationship."], ["use_na_sentinel bool, default True", "If True, the sentinel -1 will be used for NaN values. If False,\nNaN values will be encoded as non-negative integers and will not drop the\nNaN from the uniques of the values. Added in version 1.5.0."]], "Returns": [["codes ndarray", "An integer ndarray that’s an indexer into uniques . uniques.take(codes) will have the same values as values ."], ["uniques ndarray, Index, or Categorical", "The unique valid values. When values is Categorical, uniques is a Categorical. When values is some other pandas object, an Index is returned. Otherwise, a 1-D ndarray is returned. Note Even if there’s a missing value in values , uniques will not contain an entry for it."]], "Category": ["Series"], "index": 837}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.kurt.html#pandas.Series.kurt"], "Title": ["Series.kurt"], "Feature": ["Series.kurt"], "Description": "Return unbiased kurtosis over requested axis.\nKurtosis obtained using Fisher’s definition of\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.", "Examples": [">>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n>>> s\ncat    1\ndog    2\ndog    2\nmouse  3\ndtype: int64\n>>> s.kurt()\n1.5\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 838}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html#pandas.Series.max"], "Title": ["Series.max"], "Feature": ["Series.max"], "Description": "Return the maximum of the values over the requested axis.\nIf you want theindexof the maximum, useidxmax. This is the equivalent of thenumpy.ndarraymethodargmax.\nSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.", "Examples": [">>> idx = pd.MultiIndex.from_arrays([\n...     ['warm', 'warm', 'cold', 'cold'],\n...     ['dog', 'falcon', 'fish', 'spider']],\n...     names=['blooded', 'animal'])\n>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n>>> s\nblooded  animal\nwarm     dog       4\n         falcon    2\ncold     fish      0\n         spider    8\nName: legs, dtype: int64\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 839}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html#pandas.Series.mean"], "Title": ["Series.mean"], "Feature": ["Series.mean"], "Description": "Return the mean of the values over the requested axis.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.mean()\n2.0\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 840}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html#pandas.Series.median"], "Title": ["Series.median"], "Feature": ["Series.median"], "Description": "Return the median of the values over the requested axis.", "Examples": [">>> s = pd.Series([1, 2, 3])\n>>> s.median()\n2.0\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 841}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html#pandas.Series.min"], "Title": ["Series.min"], "Feature": ["Series.min"], "Description": "Return the minimum of the values over the requested axis.\nIf you want theindexof the minimum, useidxmin. This is the equivalent of thenumpy.ndarraymethodargmin.\nSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.", "Examples": [">>> idx = pd.MultiIndex.from_arrays([\n...     ['warm', 'warm', 'cold', 'cold'],\n...     ['dog', 'falcon', 'fish', 'spider']],\n...     names=['blooded', 'animal'])\n>>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n>>> s\nblooded  animal\nwarm     dog       4\n         falcon    2\ncold     fish      0\n         spider    8\nName: legs, dtype: int64\n"], "Parameters": [["axis {index (0)}", "Axis for the function to be applied on.\nFor Series this parameter is unused and defaults to 0. For DataFrames, specifying axis=None will apply the aggregation\nacross both axes. Added in version 2.0.0."], ["skipna bool, default True", "Exclude NA/null values when computing the result."], ["numeric_only bool, default False", "Include only float, int, boolean columns. Not implemented for Series."], ["**kwargs", "Additional keyword arguments to be passed to the function."]], "Returns": [["scalar or scalar", ""]], "Category": ["Series"], "index": 842}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html#pandas.Series.mode"], "Title": ["Series.mode"], "Feature": ["Series.mode"], "Description": "Return the mode(s) of the Series.\nThe mode is the value that appears most often. There can be multiple modes.\nAlways returns Series even if only one value is returned.", "Examples": [">>> s = pd.Series([2, 4, 2, 2, 4, None])\n>>> s.mode()\n0    2.0\ndtype: float64\n"], "Parameters": [["dropna bool, default True", "Don’t consider counts of NaN/NaT."]], "Returns": [["Series", "Modes of the Series in sorted order."]], "Category": ["Series"], "index": 843}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.nlargest.html#pandas.Series.nlargest"], "Title": ["Series.nlargest"], "Feature": ["Series.nlargest"], "Description": "Return the largestnelements.\nSee alsoSeries.nsmallestGet thensmallest elements.Series.sort_valuesSort Series by values.Series.headReturn the firstnrows.\nNotes\nFaster than.sort_values(ascending=False).head(n)for smallnrelative to the size of theSeriesobject.", "Examples": [">>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n...                         \"Malta\": 434000, \"Maldives\": 434000,\n...                         \"Brunei\": 434000, \"Iceland\": 337000,\n...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n>>> s = pd.Series(countries_population)\n>>> s\nItaly       59000000\nFrance      65000000\nMalta         434000\nMaldives      434000\nBrunei        434000\nIceland       337000\nNauru          11300\nTuvalu         11300\nAnguilla       11300\nMontserrat      5200\ndtype: int64\n"], "Parameters": [["n int, default 5", "Return this many descending sorted values."], ["keep {‘first’, ‘last’, ‘all’}, default ‘first’", "When there are duplicate values that cannot all fit in a\nSeries of n elements: first : return the first n occurrences in order\nof appearance. last : return the last n occurrences in reverse\norder of appearance. all : keep all occurrences. This can result in a Series of\nsize larger than n ."]], "Returns": [["Series", "The n largest values in the Series, sorted in decreasing order."]], "Category": ["Series"], "index": 844}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html#pandas.Series.nsmallest"], "Title": ["Series.nsmallest"], "Feature": ["Series.nsmallest"], "Description": "Return the smallestnelements.\nSee alsoSeries.nlargestGet thenlargest elements.Series.sort_valuesSort Series by values.Series.headReturn the firstnrows.\nNotes\nFaster than.sort_values().head(n)for smallnrelative to\nthe size of theSeriesobject.", "Examples": [">>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n...                         \"Brunei\": 434000, \"Malta\": 434000,\n...                         \"Maldives\": 434000, \"Iceland\": 337000,\n...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n>>> s = pd.Series(countries_population)\n>>> s\nItaly       59000000\nFrance      65000000\nBrunei        434000\nMalta         434000\nMaldives      434000\nIceland       337000\nNauru          11300\nTuvalu         11300\nAnguilla       11300\nMontserrat      5200\ndtype: int64\n"], "Parameters": [["n int, default 5", "Return this many ascending sorted values."], ["keep {‘first’, ‘last’, ‘all’}, default ‘first’", "When there are duplicate values that cannot all fit in a\nSeries of n elements: first : return the first n occurrences in order\nof appearance. last : return the last n occurrences in reverse\norder of appearance. all : keep all occurrences. This can result in a Series of\nsize larger than n ."]], "Returns": [["Series", "The n smallest values in the Series, sorted in increasing order."]], "Category": ["Series"], "index": 845}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.Series.pct_change.html#pandas.Series.pct_change"], "Title": ["Series.pct_change"], "Feature": ["Series.pct_change"], "Description": "Fractional change between the current and a prior element.\nComputes the fractional change from the immediately previous row by\ndefault. This is useful in comparing the fraction of change in a time\nseries of elements.\nNoteDespite the name of this method, it calculates fractional change\n(also known as per unit change or relative change) and not\npercentage change. If you need the percentage change, multiply\nthese values by 100.\nSee alsoSeries.diffCompute the difference of two elements in a Series.DataFrame.diffCompute the difference of two elements in a DataFrame.Series.shiftShift the index by some number of periods.DataFrame.shiftShift the index by some number of periods.", "Examples": [">>> s = pd.Series([90, 91, 85])\n>>> s\n0    90\n1    91\n2    85\ndtype: int64\n"], "Parameters": [["periods int, default 1", "Periods to shift for forming percent change."], ["fill_method {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’", "How to handle NAs before computing percent changes. Deprecated since version 2.1: All options of fill_method are deprecated except fill_method=None ."], ["limit int, default None", "The number of consecutive NAs to fill before stopping. Deprecated since version 2.1."], ["freq DateOffset, timedelta, or str, optional", "Increment to use from time series API (e.g. ‘ME’ or BDay())."], ["**kwargs", "Additional keyword arguments are passed into DataFrame.shift or Series.shift ."]], "Returns": [["Series or DataFrame", "The same type as the calling object."]], "Category": ["Series"], "index": 846}
{"HTML": ["https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html#pandas.DataFrame.hist"], "Title": ["DataFrame.hist"], "Feature": ["DataFrame.hist"], "Description": "Make a histogram of the DataFrame’s columns.\nAhistogramis a representation of the distribution of data.\nThis function callsmatplotlib.pyplot.hist(), on each series in\nthe DataFrame, resulting in one histogram per column.\nSee alsomatplotlib.pyplot.histPlot a histogram using matplotlib.", "Examples": [">>> data = {'length': [1.5, 0.5, 1.2, 0.9, 3],\n...         'width': [0.7, 0.2, 0.15, 0.2, 1.1]}\n>>> index = ['pig', 'rabbit', 'duck', 'chicken', 'horse']\n>>> df = pd.DataFrame(data, index=index)\n>>> hist = df.hist(bins=3)"], "Parameters": [["data DataFrame", "The pandas object holding the data."], ["column str or sequence, optional", "If passed, will be used to limit data to a subset of columns."], ["by object, optional", "If passed, then used to form histograms for separate groups."], ["grid bool, default True", "Whether to show axis grid lines."], ["xlabelsize int, default None", "If specified changes the x-axis label size."], ["xrot float, default None", "Rotation of x axis labels. For example, a value of 90 displays the\nx labels rotated 90 degrees clockwise."], ["ylabelsize int, default None", "If specified changes the y-axis label size."], ["yrot float, default None", "Rotation of y axis labels. For example, a value of 90 displays the\ny labels rotated 90 degrees clockwise."], ["ax Matplotlib axes object, default None", "The axes to plot the histogram on."], ["sharex bool, default True if ax is None else False", "In case subplots=True, share x axis and set some x axis labels to\ninvisible; defaults to True if ax is None otherwise False if an ax\nis passed in.\nNote that passing in both an ax and sharex=True will alter all x axis\nlabels for all subplots in a figure."], ["sharey bool, default False", "In case subplots=True, share y axis and set some y axis labels to\ninvisible."], ["figsize tuple, optional", "The size in inches of the figure to create. Uses the value in matplotlib.rcParams by default."], ["layout tuple, optional", "Tuple of (rows, columns) for the layout of the histograms."], ["bins int or sequence, default 10", "Number of histogram bins to be used. If an integer is given, bins + 1\nbin edges are calculated and returned. If bins is a sequence, gives\nbin edges, including left edge of first bin and right edge of last\nbin. In this case, bins is returned unmodified."], ["backend str, default None", "Backend to use instead of the backend specified in the option plotting.backend . For instance, ‘matplotlib’. Alternatively, to\nspecify the plotting.backend for the whole session, set pd.options.plotting.backend ."], ["legend bool, default False", "Whether to show the legend."], ["**kwargs", "All other plotting keyword arguments to be passed to matplotlib.pyplot.hist() ."]], "Returns": [["matplotlib.AxesSubplot or numpy.ndarray of them", ""]], "Category": ["Dataframe"], "index": 847}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.acos.html#numpy.acos"], "Title": ["acos"], "Feature": ["np.acos"], "Description": "Trigonometric inverse cosine, element-wise.\nThe inverse ofcosso that, ify=cos(x), thenx=arccos(y).\nSee alsocos,arctan,arcsin,emath.arccos\nNotes\narccosis a multivalued function: for eachxthere are infinitely\nmany numberszsuch thatcos(z)=x. The convention is to return\nthe anglezwhose real part lies in[0, pi].\nFor real-valued input data types,arccosalways returns real output.\nFor each value that cannot be expressed as a real number or infinity,\nit yieldsnanand sets theinvalidfloating point error flag.\nFor complex-valued input,arccosis a complex analytic function that\nhas branch cuts[-inf,-1]and[1, inf]and is continuous from\nabove on the former and from below on the latter.\nThe inversecosis also known asacosor cos^-1.\nReferences\nM. Abramowitz and I.A. Stegun, “Handbook of Mathematical Functions”,\n10th printing, 1964, pp. 79.https://personal.math.ubc.ca/~cbm/aands/page_79.htm", "Examples": [">>> import numpy as np\n"], "Parameters": [["x array_like", "x -coordinate on the unit circle.\nFor real arguments, the domain is [-1, 1]."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["angle ndarray", "The angle of the ray intersecting the unit circle at the given x -coordinate in radians [0, pi].\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 848}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.asin.html#numpy.asin"], "Title": ["asin"], "Feature": ["np.asin"], "Description": "Inverse sine, element-wise.\nSee alsosin,cos,arccos,tan,arctan,arctan2,emath.arcsin\nNotes\narcsinis a multivalued function: for eachxthere are infinitely\nmany numberszsuch thatsin(z)=x.  The convention is to\nreturn the anglezwhose real part lies in [-pi/2, pi/2].\nFor real-valued input data types,arcsinalways returns real output.\nFor each value that cannot be expressed as a real number or infinity,\nit yieldsnanand sets theinvalidfloating point error flag.\nFor complex-valued input,arcsinis a complex analytic function that\nhas, by convention, the branch cuts [-inf, -1] and [1, inf]  and is\ncontinuous from above on the former and from below on the latter.\nThe inverse sine is also known asasinor sin^{-1}.\nReferences\nAbramowitz, M. and Stegun, I. A.,Handbook of Mathematical Functions,\n10th printing, New York: Dover, 1964, pp. 79ff.https://personal.math.ubc.ca/~cbm/aands/page_79.htm", "Examples": [">>> import numpy as np\n>>> np.arcsin(1)     # pi/2\n1.5707963267948966\n>>> np.arcsin(-1)    # -pi/2\n-1.5707963267948966\n>>> np.arcsin(0)\n0.0\n"], "Parameters": [["x array_like", "y -coordinate on the unit circle."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["angle ndarray", "The inverse sine of each element in x , in radians and in the\nclosed interval [-pi/2, pi/2] .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 849}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.atan.html#numpy.atan"], "Title": ["atan"], "Feature": ["np.atan"], "Description": "Trigonometric inverse tangent, element-wise.\nThe inverse of tan, so that ify=tan(x)thenx=arctan(y).\nSee alsoarctan2The “four quadrant” arctan of the angle formed by (x,y) and the positivex-axis.angleArgument of complex values.\nNotes\narctanis a multi-valued function: for eachxthere are infinitely\nmany numberszsuch that tan(z) =x.  The convention is to return\nthe anglezwhose real part lies in [-pi/2, pi/2].\nFor real-valued input data types,arctanalways returns real output.\nFor each value that cannot be expressed as a real number or infinity,\nit yieldsnanand sets theinvalidfloating point error flag.\nFor complex-valued input,arctanis a complex analytic function that\nhas [1j,infj] and [-1j,-infj] as branch cuts, and is continuous\nfrom the left on the former and from the right on the latter.\nThe inverse tangent is also known asatanor tan^{-1}.\nReferences\nAbramowitz, M. and Stegun, I. A.,Handbook of Mathematical Functions,\n10th printing, New York: Dover, 1964, pp. 79.https://personal.math.ubc.ca/~cbm/aands/page_79.htm", "Examples": [">>> import numpy as np\n>>> np.arctan([0, 1])\narray([ 0.        ,  0.78539816])\n"], "Parameters": [["x array_like", ""], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["out ndarray or scalar", "Out has the same shape as x .  Its real part is in [-pi/2, pi/2] ( arctan(+/-inf) returns +/-pi/2 ).\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 850}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.atan2.html#numpy.atan2"], "Title": ["atan2"], "Feature": ["np.atan2"], "Description": "Element-wise arc tangent ofx1/x2choosing the quadrant correctly.\nThe quadrant (i.e., branch) is chosen so thatarctan2(x1,x2)is\nthe signed angle in radians between the ray ending at the origin and\npassing through the point (1,0), and the ray ending at the origin and\npassing through the point (x2,x1).  (Note the role reversal: the\n“y-coordinate” is the first function parameter, the “x-coordinate”\nis the second.)  By IEEE convention, this function is defined forx2= +/-0 and for either or both ofx1andx2= +/-inf (see\nNotes for specific values).\nThis function is not defined for complex-valued arguments; for the\nso-called argument of complex values, useangle.\nSee alsoarctan,tan,angle\nNotes\narctan2is identical to theatan2function of the underlying\nC library.  The following special values are defined in the C\nstandard:[1]\nx1x2arctan2(x1,x2)+/- 0+0+/- 0+/- 0-0+/- pi> 0+/-inf+0 / +pi< 0+/-inf-0 / -pi+/-inf+inf+/- (pi/4)+/-inf-inf+/- (3*pi/4)\nNote that +0 and -0 are distinct floating point numbers, as are +inf\nand -inf.\nReferences\n[1]ISO/IEC standard 9899:1999, “Programming language C.”", "Examples": [">>> import numpy as np\n>>> x = np.array([-1, +1, +1, -1])\n>>> y = np.array([-1, -1, +1, +1])\n>>> np.arctan2(y, x) * 180 / np.pi\narray([-135.,  -45.,   45.,  135.])\n"], "Parameters": [["x1 array_like, real-valued", "y -coordinates."], ["x2 array_like, real-valued", "x -coordinates.\nIf x1.shape != x2.shape , they must be broadcastable to a common\nshape (which becomes the shape of the output)."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["angle ndarray", "Array of angles in radians, in the range [-pi, pi] .\nThis is a scalar if both x1 and x2 are scalars."]], "Category": ["Mathematical_functions"], "index": 851}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.cbrt.html#numpy.cbrt"], "Title": ["cbrt"], "Feature": ["np.cbrt"], "Description": "Return the cube-root of an array, element-wise.", "Examples": [">>> import numpy as np\n>>> np.cbrt([1,8,27])\narray([ 1.,  2.,  3.])\n"], "Parameters": [["x array_like", "The values whose cube-roots are required."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "An array of the same shape as x , containing the\ncube root of each element in x .\nIf out was provided, y is a reference to it.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 852}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.ceil.html#numpy.ceil"], "Title": ["ceil"], "Feature": ["np.ceil"], "Description": "Return the ceiling of the input, element-wise.\nThe ceil of the scalarxis the smallest integeri, such thati>=x.  It is often denoted as⌈x⌉.\nSee alsofloor,trunc,rint,fix", "Examples": [">>> import numpy as np\n"], "Parameters": [["x array_like", "Input data."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray or scalar", "The ceiling of each element in x .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 853}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.cos.html#numpy.cos"], "Title": ["cos"], "Feature": ["np.cos"], "Description": "Cosine element-wise.\nNotes", "Examples": [">>> import numpy as np\n>>> np.cos(np.array([0, np.pi/2, np.pi]))\narray([  1.00000000e+00,   6.12303177e-17,  -1.00000000e+00])\n>>>\n>>> # Example of providing the optional output parameter\n>>> out1 = np.array([0], dtype='d')\n>>> out2 = np.cos([0.1], out1)\n>>> out2 is out1\nTrue\n>>>\n>>> # Example of ValueError due to provision of shape mis-matched `out`\n>>> np.cos(np.zeros((3,3)),np.zeros((2,2)))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: operands could not be broadcast together with shapes (3,3) (2,2)\n"], "Parameters": [["x array_like", "Input array in radians."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The corresponding cosine values.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 854}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.exp.html#numpy.exp"], "Title": ["exp"], "Feature": ["np.exp"], "Description": "Calculate the exponential of all elements in the input array.\nSee alsoexpm1Calculateexp(x)-1for all elements in the array.exp2Calculate2**xfor all elements in the array.\nNotes\nThe irrational numbereis also known as Euler’s number.  It is\napproximately 2.718281, and is the base of the natural logarithm,ln(this means that, ifx=ln⁡y=loge⁡y,\nthenex=y. For real input,exp(x)is always positive.\nFor complex arguments,x=a+ib, we can writeex=eaeib.  The first term,ea, is already\nknown (it is the real argument, described above).  The second term,eib, iscos⁡b+isin⁡b, a function with\nmagnitude 1 and a periodic phase.\nReferences\n[1]Wikipedia, “Exponential function”,https://en.wikipedia.org/wiki/Exponential_function[2]M. Abramovitz and I. A. Stegun, “Handbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables,” Dover, 1964, p. 69,https://personal.math.ubc.ca/~cbm/aands/page_69.htm", "Examples": [">>> import numpy as np\n"], "Parameters": [["x array_like", "Input values."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["out ndarray or scalar", "Output array, element-wise exponential of x .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 855}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.floor.html#numpy.floor"], "Title": ["floor"], "Feature": ["np.floor"], "Description": "Return the floor of the input, element-wise.\nThe floor of the scalarxis the largest integeri, such thati <= x.  It is often denoted as\\lfloor x \\rfloor.\nSee alsoceil,trunc,rint,fix\nNotes\nSome spreadsheet programs calculate the “floor-towards-zero”, wherefloor(-2.5)==-2.  NumPy instead uses the definition offloorwherefloor(-2.5) == -3. The “floor-towards-zero”\nfunction is calledfixin NumPy.", "Examples": [">>> import numpy as np\n>>> a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n>>> np.floor(a)\narray([-2., -2., -1.,  0.,  1.,  1.,  2.])\n"], "Parameters": [["x array_like", "Input data."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray or scalar", "The floor of each element in x .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 856}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.log10.html#numpy.log10"], "Title": ["log10"], "Feature": ["np.log10"], "Description": "Return the base 10 logarithm of the input array, element-wise.\nSee alsoemath.log10\nNotes\nLogarithm is a multivalued function: for eachxthere is an infinite\nnumber ofzsuch that10**z = x. The convention is to return thezwhose imaginary part lies in(-pi, pi].\nFor real-valued input data types,log10always returns real output.\nFor each value that cannot be expressed as a real number or infinity,\nit yieldsnanand sets theinvalidfloating point error flag.\nFor complex-valued input,log10is a complex analytical function that\nhas a branch cut[-inf, 0]and is continuous from above on it.log10handles the floating-point negative zero as an infinitesimal\nnegative number, conforming to the C99 standard.\nIn the cases where the input has a negative real part and a very small\nnegative complex part (approaching 0), the result is so close to-pithat it evaluates to exactly-pi.\nReferences\n[1]M. Abramowitz and I.A. Stegun, “Handbook of Mathematical Functions”,\n10th printing, 1964, pp. 67.https://personal.math.ubc.ca/~cbm/aands/page_67.htm[2]Wikipedia, “Logarithm”.https://en.wikipedia.org/wiki/Logarithm", "Examples": [">>> import numpy as np\n>>> np.log10([1e-15, -3.])\narray([-15.,  nan])\n"], "Parameters": [["x array_like", "Input values."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The logarithm to the base 10 of x , element-wise. NaNs are\nreturned where x is negative.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 857}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.log.html#numpy.log"], "Title": ["log"], "Feature": ["np.log"], "Description": "Natural logarithm, element-wise.\nThe natural logarithmlogis the inverse of the exponential function,\nso thatlog(exp(x)) = x. The natural logarithm is logarithm in basee.\nSee alsolog10,log2,log1p,emath.log\nNotes\nLogarithm is a multivalued function: for eachxthere is an infinite\nnumber ofzsuch thatexp(z) = x. The convention is to return thezwhose imaginary part lies in(-pi, pi].\nFor real-valued input data types,logalways returns real output. For\neach value that cannot be expressed as a real number or infinity, it\nyieldsnanand sets theinvalidfloating point error flag.\nFor complex-valued input,logis a complex analytical function that\nhas a branch cut[-inf, 0]and is continuous from above on it.loghandles the floating-point negative zero as an infinitesimal negative\nnumber, conforming to the C99 standard.\nIn the cases where the input has a negative real part and a very small\nnegative complex part (approaching 0), the result is so close to-pithat it evaluates to exactly-pi.\nReferences\n[1]M. Abramowitz and I.A. Stegun, “Handbook of Mathematical Functions”,\n10th printing, 1964, pp. 67.https://personal.math.ubc.ca/~cbm/aands/page_67.htm[2]Wikipedia, “Logarithm”.https://en.wikipedia.org/wiki/Logarithm", "Examples": [">>> import numpy as np\n>>> np.log([1, np.e, np.e**2, 0])\narray([  0.,   1.,   2., -inf])\n"], "Parameters": [["x array_like", "Input value."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The natural logarithm of x , element-wise.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 858}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.log2.html#numpy.log2"], "Title": ["log2"], "Feature": ["np.log2"], "Description": "Base-2 logarithm ofx.\nSee alsolog,log10,log1p,emath.log2\nNotes\nLogarithm is a multivalued function: for eachxthere is an infinite\nnumber ofzsuch that2**z = x. The convention is to return thezwhose imaginary part lies in(-pi, pi].\nFor real-valued input data types,log2always returns real output.\nFor each value that cannot be expressed as a real number or infinity,\nit yieldsnanand sets theinvalidfloating point error flag.\nFor complex-valued input,log2is a complex analytical function that\nhas a branch cut[-inf, 0]and is continuous from above on it.log2handles the floating-point negative zero as an infinitesimal negative\nnumber, conforming to the C99 standard.\nIn the cases where the input has a negative real part and a very small\nnegative complex part (approaching 0), the result is so close to-pithat it evaluates to exactly-pi.", "Examples": [">>> import numpy as np\n>>> x = np.array([0, 1, 2, 2**4])\n>>> np.log2(x)\narray([-inf,   0.,   1.,   4.])\n"], "Parameters": [["x array_like", "Input values."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "Base-2 logarithm of x .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 859}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.sign.html#numpy.sign"], "Title": ["sign"], "Feature": ["np.sign"], "Description": "Returns an element-wise indication of the sign of a number.\nThesignfunction returns-1ifx<0,0ifx==0,1ifx>0.  nan\nis returned for nan inputs.\nFor complex inputs, thesignfunction returnsx/abs(x), the\ngeneralization of the above (and0ifx==0).\nChanged in version 2.0.0:Definition of complex sign changed to follow the Array API standard.\nNotes\nThere is more than one definition of sign in common use for complex\nnumbers.  The definition used here,x/|x|, is the more common\nand useful one, but is different from the one used in numpy prior to\nversion 2.0,x/x∗x, which is equivalent tosign(x.real)+0jifx.real!=0elsesign(x.imag)+0j.", "Examples": [">>> import numpy as np\n>>> np.sign([-5., 4.5])\narray([-1.,  1.])\n>>> np.sign(0)\n0\n>>> np.sign([3-4j, 8j])\narray([0.6-0.8j, 0. +1.j ])\n"], "Parameters": [["x array_like", "Input values."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The sign of x .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 860}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.signbit.html#numpy.signbit"], "Title": ["signbit"], "Feature": ["np.signbit"], "Description": "Returns element-wise True where signbit is set (less than zero).", "Examples": [">>> import numpy as np\n>>> np.signbit(-1.2)\nTrue\n>>> np.signbit(np.array([1, -2.3, 2.1]))\narray([False,  True, False])\n"], "Parameters": [["x array_like", "The input value(s)."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["result ndarray of bool", "Output array, or reference to out if that was supplied.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 861}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.sin.html#numpy.sin"], "Title": ["sin"], "Feature": ["np.sin"], "Description": "Trigonometric sine, element-wise.\nSee alsoarcsin,sinh,cos\nNotes\nThe sine is one of the fundamental functions of trigonometry (the\nmathematical study of triangles).  Consider a circle of radius 1\ncentered on the origin.  A ray comes in from the\\(+x\\)axis, makes\nan angle at the origin (measured counter-clockwise from that axis), and\ndeparts from the origin.  The\\(y\\)coordinate of the outgoing\nray’s intersection with the unit circle is the sine of that angle.  It\nranges from -1 for\\(x=3\\pi / 2\\)to +1 for\\(\\pi / 2.\\)The\nfunction has zeroes where the angle is a multiple of\\(\\pi\\).\nSines of angles between\\(\\pi\\)and\\(2\\pi\\)are negative.\nThe numerous properties of the sine and related functions are included\nin any standard trigonometry text.", "Examples": [">>> import numpy as np\n"], "Parameters": [["x array_like", "Angle, in radians ( \\(2 \\pi\\) rad equals 360 degrees)."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y array_like", "The sine of each element of x.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 862}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.sqrt.html#numpy.sqrt"], "Title": ["sqrt"], "Feature": ["np.sqrt"], "Description": "Return the non-negative square-root of an array, element-wise.\nSee alsoemath.sqrtA version which returns complex numbers when given negative reals. Note that 0.0 and -0.0 are handled differently for complex inputs.\nNotes\nsqrthas–consistent with common convention–as its branch cut the\nreal “interval” [-inf, 0), and is continuous from above on it.\nA branch cut is a curve in the complex plane across which a given\ncomplex function fails to be continuous.", "Examples": [">>> import numpy as np\n>>> np.sqrt([1,4,9])\narray([ 1.,  2.,  3.])\n"], "Parameters": [["x array_like", "The values whose square-roots are required."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "An array of the same shape as x , containing the positive\nsquare-root of each element in x .  If any element in x is\ncomplex, a complex array is returned (and the square-roots of\nnegative reals are calculated).  If all of the elements in x are real, so is y , with negative elements returning nan .\nIf out was provided, y is a reference to it.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 863}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.tan.html#numpy.tan"], "Title": ["tan"], "Feature": ["np.tan"], "Description": "Compute tangent element-wise.\nEquivalent tonp.sin(x)/np.cos(x)element-wise.\nNotes", "Examples": [">>> import numpy as np\n>>> from math import pi\n>>> np.tan(np.array([-pi,pi/2,pi]))\narray([  1.22460635e-16,   1.63317787e+16,  -1.22460635e-16])\n>>>\n>>> # Example of providing the optional output parameter illustrating\n>>> # that what is returned is a reference to said parameter\n>>> out1 = np.array([0], dtype='d')\n>>> out2 = np.cos([0.1], out1)\n>>> out2 is out1\nTrue\n>>>\n>>> # Example of ValueError due to provision of shape mis-matched `out`\n>>> np.cos(np.zeros((3,3)),np.zeros((2,2)))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: operands could not be broadcast together with shapes (3,3) (2,2)\n"], "Parameters": [["x array_like", "Input array."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The corresponding tangent values.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 864}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.trunc.html#numpy.trunc"], "Title": ["trunc"], "Feature": ["np.trunc"], "Description": "Return the truncated value of the input, element-wise.\nThe truncated value of the scalarxis the nearest integeriwhich\nis closer to zero thanxis. In short, the fractional part of the\nsigned numberxis discarded.\nSee alsoceil,floor,rint,fix", "Examples": [">>> import numpy as np\n>>> a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n>>> np.trunc(a)\narray([-1., -1., -0.,  0.,  1.,  1.,  2.])\n"], "Parameters": [["x array_like", "Input data."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray or scalar", "The truncated value of each element in x .\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 865}
{"HTML": ["https://numpy.org/doc/stable/reference/constants.html#numpy.pi"], "Title": ["pi"], "Feature": ["np.pi"], "Description": "The number π(pi) is a mathematical constant.\n", "Examples": ["numpy.pi = 3.1415926535897932384626433...\n"], "Parameters": [], "Returns": [], "Category": ["Mathematical_functions"], "index": 866}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.degrees.html#numpy.degrees"], "Title": ["degrees"], "Feature": ["np.degrees"], "Description": "Convert angles from radians to degrees.\nSee alsorad2degequivalent function", "Examples": [">>> import numpy as np\n>>> rad = np.arange(12.)*np.pi/6\n>>> np.degrees(rad)\narray([   0.,   30.,   60.,   90.,  120.,  150.,  180.,  210.,  240.,\n        270.,  300.,  330.])\n"], "Parameters": [["x array_like", "Input array in radians."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray of floats", "The corresponding degree values; if out was supplied this is a\nreference to it.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 867}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.gcd.html#numpy.gcd"], "Title": ["gcd"], "Feature": ["np.gcd"], "Description": "Returns the greatest common divisor of|x1|and|x2|\nSee alsolcmThe lowest common multiple", "Examples": [">>> import numpy as np\n>>> np.gcd(12, 20)\n4\n>>> np.gcd.reduce([15, 25, 35])\n5\n>>> np.gcd(np.arange(6), 20)\narray([20,  1,  2,  1,  4,  5])\n"], "Parameters": [["x1, x2 array_like, int", "Arrays of values.\nIf x1.shape != x2.shape , they must be broadcastable to a common\nshape (which becomes the shape of the output)."]], "Returns": [["y ndarray or scalar", "The greatest common divisor of the absolute value of the inputs\nThis is a scalar if both x1 and x2 are scalars."]], "Category": ["Mathematical_functions"], "index": 868}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.lcm.html#numpy.lcm"], "Title": ["lcm"], "Feature": ["np.lcm"], "Description": "Returns the lowest common multiple of|x1|and|x2|\nSee alsogcdThe greatest common divisor", "Examples": [">>> import numpy as np\n>>> np.lcm(12, 20)\n60\n>>> np.lcm.reduce([3, 12, 20])\n60\n>>> np.lcm.reduce([40, 12, 20])\n120\n>>> np.lcm(np.arange(6), 20)\narray([ 0, 20, 20, 60, 20, 20])\n"], "Parameters": [["x1, x2 array_like, int", "Arrays of values.\nIf x1.shape != x2.shape , they must be broadcastable to a common\nshape (which becomes the shape of the output)."]], "Returns": [["y ndarray or scalar", "The lowest common multiple of the absolute value of the inputs\nThis is a scalar if both x1 and x2 are scalars."]], "Category": ["Mathematical_functions"], "index": 869}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.radians.html#numpy.radians"], "Title": ["radians"], "Feature": ["np.radians"], "Description": "Convert angles from degrees to radians.\nSee alsodeg2radequivalent function", "Examples": [">>> import numpy as np\n"], "Parameters": [["x array_like", "Input array in degrees."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The corresponding radian values.\nThis is a scalar if x is a scalar."]], "Category": ["Mathematical_functions"], "index": 870}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.nextafter.html#numpy.nextafter"], "Title": ["nextafter"], "Feature": ["np.nextafter"], "Description": "Return the next floating-point value after x1 towards x2, element-wise.", "Examples": [">>> import numpy as np\n>>> eps = np.finfo(np.float64).eps\n>>> np.nextafter(1, 2) == eps + 1\nTrue\n>>> np.nextafter([1, 2], [2, 1]) == [eps + 1, 2 - eps]\narray([ True,  True])\n"], "Parameters": [["x1 array_like", "Values to find the next representable value of."], ["x2 array_like", "The direction where to look for the next representable value of x1 .\nIf x1.shape != x2.shape , they must be broadcastable to a common\nshape (which becomes the shape of the output)."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["out ndarray or scalar", "The next representable values of x1 in the direction of x2 .\nThis is a scalar if both x1 and x2 are scalars."]], "Category": ["Mathematical_functions"], "index": 871}
{"HTML": ["https://numpy.org/doc/stable/reference/generated/numpy.subtract.html#numpy.subtract"], "Title": ["subtract"], "Feature": ["np.subtract"], "Description": "Subtract arguments, element-wise.\nNotes\nEquivalent tox1-x2in terms of array broadcasting.", "Examples": [">>> import numpy as np\n>>> np.subtract(1.0, 4.0)\n-3.0\n"], "Parameters": [["x1, x2 array_like", "The arrays to be subtracted from each other.\nIf x1.shape != x2.shape , they must be broadcastable to a common\nshape (which becomes the shape of the output)."], ["out ndarray, None, or tuple of ndarray and None, optional", "A location into which the result is stored. If provided, it must have\na shape that the inputs broadcast to. If not provided or None,\na freshly-allocated array is returned. A tuple (possible only as a\nkeyword argument) must have length equal to the number of outputs."], ["where array_like, optional", "This condition is broadcast over the input. At locations where the\ncondition is True, the out array will be set to the ufunc result.\nElsewhere, the out array will retain its original value.\nNote that if an uninitialized out array is created via the default out=None , locations within it where the condition is False will\nremain uninitialized."], ["**kwargs", "For other keyword-only arguments, see the ufunc docs ."]], "Returns": [["y ndarray", "The difference of x1 and x2 , element-wise.\nThis is a scalar if both x1 and x2 are scalars."]], "Category": ["Mathematical_functions"], "index": 872}