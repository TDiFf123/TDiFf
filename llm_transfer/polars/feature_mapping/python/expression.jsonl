{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.agg_groups.html#polars.Expr.agg_groups"], "Title": ["Expr.agg_groups"], "Feature": ["Expr.agg_groups"], "Description": ["Get the group indexes of the group by operation."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\n...             \"one\",\n...             \"one\",\n...             \"one\",\n...             \"two\",\n...             \"two\",\n...             \"two\",\n...         ],\n...         \"value\": [94, 95, 96, 97, 97, 99],\n...     }\n... )\n>>> df.group_by(\"group\", maintain_order=True).agg(pl.col(\"value\").agg_groups())\nshape: (2, 2)\n┌───────┬───────────┐\n│ group ┆ value     │\n│ ---   ┆ ---       │\n│ str   ┆ list[u32] │\n╞═══════╪═══════════╡\n│ one   ┆ [0, 1, 2] │\n│ two   ┆ [3, 4, 5] │\n└───────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 0}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.all.html#polars.Expr.all"], "Title": ["Expr.all"], "Feature": ["Expr.all"], "Description": ["Return whether all values in the column areTrue."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, True],\n...         \"b\": [False, True],\n...         \"c\": [None, True],\n...     }\n... )\n>>> df.select(pl.col(\"*\").all())\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ true │\n└──────┴───────┴──────┘", ">>> df.select(pl.col(\"*\").all(ignore_nulls=False))\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ null │\n└──────┴───────┴──────┘"], "Parameters": [["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is True . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no False values,\nthe output is null."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Aggregation"], "index": 1}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.first.html#polars.Expr.first"], "Title": ["Expr.first"], "Feature": ["Expr.first"], "Description": ["Get the first value."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2]})\n>>> df.select(pl.col(\"a\").first())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 2}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.diff.html#polars.Expr.diff"], "Title": ["Expr.diff"], "Feature": ["Expr.diff"], "Description": ["Calculate the first discrete difference between shifted items."], "Examples": [">>> df = pl.DataFrame({\"int\": [20, 10, 30, 25, 35]})\n>>> df.with_columns(change=pl.col(\"int\").diff())\nshape: (5, 2)\n┌─────┬────────┐\n│ int ┆ change │\n│ --- ┆ ---    │\n│ i64 ┆ i64    │\n╞═════╪════════╡\n│ 20  ┆ null   │\n│ 10  ┆ -10    │\n│ 30  ┆ 20     │\n│ 25  ┆ -5     │\n│ 35  ┆ 10     │\n└─────┴────────┘", ">>> df.with_columns(change=pl.col(\"int\").diff(n=2))\nshape: (5, 2)\n┌─────┬────────┐\n│ int ┆ change │\n│ --- ┆ ---    │\n│ i64 ┆ i64    │\n╞═════╪════════╡\n│ 20  ┆ null   │\n│ 10  ┆ null   │\n│ 30  ┆ 10     │\n│ 25  ┆ 15     │\n│ 35  ┆ 5      │\n└─────┴────────┘", ">>> df.select(pl.col(\"int\").diff(n=2, null_behavior=\"drop\").alias(\"diff\"))\nshape: (3, 1)\n┌──────┐\n│ diff │\n│ ---  │\n│ i64  │\n╞══════╡\n│ 10   │\n│ 15   │\n│ 5    │\n└──────┘"], "Parameters": [["n", "Number of slots to shift."], ["null_behavior {‘ignore’, ‘drop’}", "How to handle null values."]], "Returns": [], "Category": ["Computation"], "index": 3}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dot.html#polars.Expr.dot"], "Title": ["Expr.dot"], "Feature": ["Expr.dot"], "Description": ["Compute the dot/inner product between two Expressions."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 3, 5],\n...         \"b\": [2, 4, 6],\n...     }\n... )\n>>> df.select(pl.col(\"a\").dot(pl.col(\"b\")))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 44  │\n└─────┘"], "Parameters": [["other", "Expression to compute dot product with."]], "Returns": [], "Category": ["Computation"], "index": 4}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.entropy.html#polars.Expr.entropy"], "Title": ["Expr.entropy"], "Feature": ["Expr.entropy"], "Description": ["Computes the entropy."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").entropy(base=2))\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.459148 │\n└──────────┘\n>>> df.select(pl.col(\"a\").entropy(base=2, normalize=False))\nshape: (1, 1)\n┌───────────┐\n│ a         │\n│ ---       │\n│ f64       │\n╞═══════════╡\n│ -6.754888 │\n└───────────┘"], "Parameters": [["base", "Given base, defaults to e"], ["normalize", "Normalize pk if it doesn’t sum to 1."]], "Returns": [], "Category": ["Computation"], "index": 5}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ewm_mean.html#polars.Expr.ewm_mean"], "Title": ["Expr.ewm_mean"], "Feature": ["Expr.ewm_mean"], "Description": ["Compute exponentially-weighted moving average."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").ewm_mean(com=1, ignore_nulls=False))\nshape: (3, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.0      │\n│ 1.666667 │\n│ 2.428571 │\n└──────────┘"], "Parameters": [["com", "Specify decay in terms of center of mass, \\(\\gamma\\) , with \\[\\alpha = \\frac{1}{1 + \\gamma} \\; \\forall \\; \\gamma \\geq 0\\]"], ["span", "Specify decay in terms of span, \\(\\theta\\) , with \\[\\alpha = \\frac{2}{\\theta + 1} \\; \\forall \\; \\theta \\geq 1\\]"], ["half_life", "Specify decay in terms of half-life, \\(\\tau\\) , with \\[\\alpha = 1 - \\exp \\left\\{ \\frac{ -\\ln(2) }{ \\tau } \\right\\} \\;\n\\forall \\; \\tau > 0\\]"], ["alpha", "Specify smoothing factor alpha directly, \\(0 < \\alpha \\leq 1\\) ."], ["adjust", "Divide by decaying adjustment factor in beginning periods to account for\nimbalance in relative weightings When adjust=True (the default) the EW function is calculated\nusing weights \\(w_i = (1 - \\alpha)^i\\) When adjust=False the EW function is calculated\nrecursively by \\[\\begin{split}y_0 &= x_0 \\\\\ny_t &= (1 - \\alpha)y_{t - 1} + \\alpha x_t\\end{split}\\]"], ["min_samples", "Minimum number of observations in window required to have a value\n(otherwise result is null)."], ["ignore_nulls", "Ignore missing values when calculating weights. When ignore_nulls=False (default), weights are based on absolute\npositions.\nFor example, the weights of \\(x_0\\) and \\(x_2\\) used in\ncalculating the final weighted average of\n[ \\(x_0\\) , None, \\(x_2\\) ] are \\((1-\\alpha)^2\\) and \\(1\\) if adjust=True , and \\((1-\\alpha)^2\\) and \\(\\alpha\\) if adjust=False . When ignore_nulls=True , weights are based\non relative positions. For example, the weights of \\(x_0\\) and \\(x_2\\) used in calculating the final weighted\naverage of [ \\(x_0\\) , None, \\(x_2\\) ] are \\(1-\\alpha\\) and \\(1\\) if adjust=True ,\nand \\(1-\\alpha\\) and \\(\\alpha\\) if adjust=False ."]], "Returns": [], "Category": ["Computation"], "index": 6}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ewm_mean_by.html#polars.Expr.ewm_mean_by"], "Title": ["Expr.ewm_mean_by"], "Feature": ["Expr.ewm_mean_by"], "Description": ["Compute time-based exponentially weighted moving average."], "Examples": [">>> from datetime import date, timedelta\n>>> df = pl.DataFrame(\n...     {\n...         \"values\": [0, 1, 2, None, 4],\n...         \"times\": [\n...             date(2020, 1, 1),\n...             date(2020, 1, 3),\n...             date(2020, 1, 10),\n...             date(2020, 1, 15),\n...             date(2020, 1, 17),\n...         ],\n...     }\n... ).sort(\"times\")\n>>> df.with_columns(\n...     result=pl.col(\"values\").ewm_mean_by(\"times\", half_life=\"4d\"),\n... )\nshape: (5, 3)\n┌────────┬────────────┬──────────┐\n│ values ┆ times      ┆ result   │\n│ ---    ┆ ---        ┆ ---      │\n│ i64    ┆ date       ┆ f64      │\n╞════════╪════════════╪══════════╡\n│ 0      ┆ 2020-01-01 ┆ 0.0      │\n│ 1      ┆ 2020-01-03 ┆ 0.292893 │\n│ 2      ┆ 2020-01-10 ┆ 1.492474 │\n│ null   ┆ 2020-01-15 ┆ null     │\n│ 4      ┆ 2020-01-17 ┆ 3.254508 │\n└────────┴────────────┴──────────┘"], "Parameters": [["by", "Times to calculate average by. Should be DateTime , Date , UInt64 , UInt32 , Int64 , or Int32 data type."], ["half_life", "Unit over which observation decays to half its value. Can be created either from a timedelta, or\nby using the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 day) 1w    (1 week) 1i    (1 index count) Or combine them:\n“3d12h4m25s” # 3 days, 12 hours, 4 minutes, and 25 seconds Note that half_life is treated as a constant duration - calendar\ndurations such as months (or even days in the time-zone-aware case)\nare not supported, please express your duration in an approximately\nequivalent number of hours (e.g. ‘370h’ instead of ‘1mo’)."]], "Returns": [["Expr", "Float32 if input is Float32, otherwise Float64."]], "Category": ["Computation"], "index": 7}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ewm_std.html#polars.Expr.ewm_std"], "Title": ["Expr.ewm_std"], "Feature": ["Expr.ewm_std"], "Description": ["Compute exponentially-weighted moving standard deviation."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").ewm_std(com=1, ignore_nulls=False))\nshape: (3, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.0      │\n│ 0.707107 │\n│ 0.963624 │\n└──────────┘"], "Parameters": [["com", "Specify decay in terms of center of mass, γ , with α = 1 1 + γ ∀ γ ≥ 0"], ["span", "Specify decay in terms of span, θ , with α = 2 θ + 1 ∀ θ ≥ 1"], ["half_life", "Specify decay in terms of half-life, λ , with α = 1 − exp ⁡ { − ln ⁡ ( 2 ) λ } ∀ λ > 0"], ["alpha", "Specify smoothing factor alpha directly, 0 < α ≤ 1 ."], ["adjust", "Divide by decaying adjustment factor in beginning periods to account for\nimbalance in relative weightings When adjust=True (the default) the EW function is calculated\nusing weights w i = ( 1 − α ) i When adjust=False the EW function is calculated\nrecursively by y 0 = x 0 y t = ( 1 − α ) y t − 1 + α x t"], ["bias", "When bias=False , apply a correction to make the estimate statistically\nunbiased."], ["min_samples", "Minimum number of observations in window required to have a value\n(otherwise result is null)."], ["ignore_nulls", "Ignore missing values when calculating weights. When ignore_nulls=False (default), weights are based on absolute\npositions.\nFor example, the weights of x 0 and x 2 used in\ncalculating the final weighted average of\n[ x 0 , None, x 2 ] are ( 1 − α ) 2 and 1 if adjust=True , and ( 1 − α ) 2 and α if adjust=False . When ignore_nulls=True , weights are based\non relative positions. For example, the weights of x 0 and x 2 used in calculating the final weighted\naverage of [ x 0 , None, x 2 ] are 1 − α and 1 if adjust=True ,\nand 1 − α and α if adjust=False ."]], "Returns": [], "Category": ["Computation"], "index": 8}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ewm_var.html#polars.Expr.ewm_var"], "Title": ["Expr.ewm_var"], "Feature": ["Expr.ewm_var"], "Description": ["Compute exponentially-weighted moving variance."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 9}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.exp.html#polars.Expr.exp"], "Title": ["Expr.exp"], "Feature": ["Expr.exp"], "Description": ["Compute the exponential, element-wise."], "Examples": [">>> df = pl.DataFrame({\"values\": [1.0, 2.0, 4.0]})\n>>> df.select(pl.col(\"values\").exp())\nshape: (3, 1)\n┌──────────┐\n│ values   │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 2.718282 │\n│ 7.389056 │\n│ 54.59815 │\n└──────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 10}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.hash.html#polars.Expr.hash"], "Title": ["Expr.hash"], "Feature": ["Expr.hash"], "Description": ["Hash the elements in the selection."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None],\n...         \"b\": [\"x\", None, \"z\"],\n...     }\n... )\n>>> df.with_columns(pl.all().hash(10, 20, 30, 40))  \nshape: (3, 2)\n┌──────────────────────┬──────────────────────┐\n│ a                    ┆ b                    │\n│ ---                  ┆ ---                  │\n│ u64                  ┆ u64                  │\n╞══════════════════════╪══════════════════════╡\n│ 9774092659964970114  ┆ 13614470193936745724 │\n│ 1101441246220388612  ┆ 11638928888656214026 │\n│ 11638928888656214026 ┆ 13382926553367784577 │\n└──────────────────────┴──────────────────────┘"], "Parameters": [["seed", "Random seed parameter. Defaults to 0."], ["seed_1", "Random seed parameter. Defaults to seed if not set."], ["seed_2", "Random seed parameter. Defaults to seed if not set."], ["seed_3", "Random seed parameter. Defaults to seed if not set."]], "Returns": [], "Category": ["Computation"], "index": 11}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.hist.html#polars.Expr.hist"], "Title": ["Expr.hist"], "Feature": ["Expr.hist"], "Description": ["Bin values into buckets and count their occurrences."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 3, 8, 8, 2, 1, 3]})\n>>> df.select(pl.col(\"a\").hist(bins=[1, 2, 3]))\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 3   │\n│ 2   │\n└─────┘\n>>> df.select(\n...     pl.col(\"a\").hist(\n...         bins=[1, 2, 3], include_breakpoint=True, include_category=True\n...     )\n... )\nshape: (2, 1)\n┌──────────────────────┐\n│ a                    │\n│ ---                  │\n│ struct[3]            │\n╞══════════════════════╡\n│ {2.0,\"[1.0, 2.0]\",3} │\n│ {3.0,\"(2.0, 3.0]\",2} │\n└──────────────────────┘"], "Parameters": [["bins", "Bin edges. If None given, we determine the edges based on the data."], ["bin_count", "If bins is not provided, bin_count uniform bins are created that fully\nencompass the data."], ["include_breakpoint", "Include a column that indicates the upper breakpoint."], ["include_category", "Include a column that shows the intervals as categories."]], "Returns": [["DataFrame", ""]], "Category": ["Computation"], "index": 12}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.implode.html#polars.Expr.implode"], "Title": ["Expr.implode"], "Feature": ["Expr.implode"], "Description": ["Aggregate values into a list."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [4, 5, 6],\n...     }\n... )\n>>> df.select(pl.all().implode())\nshape: (1, 2)\n┌───────────┬───────────┐\n│ a         ┆ b         │\n│ ---       ┆ ---       │\n│ list[i64] ┆ list[i64] │\n╞═══════════╪═══════════╡\n│ [1, 2, 3] ┆ [4, 5, 6] │\n└───────────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 13}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.index_of.html#polars.Expr.index_of"], "Title": ["Expr.index_of"], "Feature": ["Expr.index_of"], "Description": ["Get the index of the first occurrence of a value, orNoneif it's not found."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, None, 17]})\n>>> df.select(\n...     [\n...         pl.col(\"a\").index_of(17).alias(\"seventeen\"),\n...         pl.col(\"a\").index_of(None).alias(\"null\"),\n...         pl.col(\"a\").index_of(55).alias(\"fiftyfive\"),\n...     ]\n... )\nshape: (1, 3)\n┌───────────┬──────┬───────────┐\n│ seventeen ┆ null ┆ fiftyfive │\n│ ---       ┆ ---  ┆ ---       │\n│ u32       ┆ u32  ┆ u32       │\n╞═══════════╪══════╪═══════════╡\n│ 2         ┆ 1    ┆ null      │\n└───────────┴──────┴───────────┘"], "Parameters": [["element", "Value to find."]], "Returns": [], "Category": ["Computation"], "index": 14}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.kurtosis.html#polars.Expr.kurtosis"], "Title": ["Expr.kurtosis"], "Feature": ["Expr.kurtosis"], "Description": ["Compute the kurtosis (Fisher or Pearson) of a dataset."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 2, 1]})\n>>> df.select(pl.col(\"a\").kurtosis())\nshape: (1, 1)\n┌───────────┐\n│ a         │\n│ ---       │\n│ f64       │\n╞═══════════╡\n│ -1.153061 │\n└───────────┘"], "Parameters": [["fisher bool, optional", "If True, Fisher’s definition is used (normal ==> 0.0). If False,\nPearson’s definition is used (normal ==> 3.0)."], ["bias bool, optional", "If False, the calculations are corrected for statistical bias."]], "Returns": [], "Category": ["Computation"], "index": 15}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.log.html#polars.Expr.log"], "Title": ["Expr.log"], "Feature": ["Expr.log"], "Description": ["Compute the logarithm to a given base."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").log(base=2))\nshape: (3, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.0      │\n│ 1.0      │\n│ 1.584963 │\n└──────────┘"], "Parameters": [["base", "Given base, defaults to e"]], "Returns": [], "Category": ["Computation"], "index": 16}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.log10.html#polars.Expr.log10"], "Title": ["Expr.log10"], "Feature": ["Expr.log10"], "Description": ["Compute the base 10 logarithm of the input array, element-wise."], "Examples": [">>> df = pl.DataFrame({\"values\": [1.0, 2.0, 4.0]})\n>>> df.select(pl.col(\"values\").log10())\nshape: (3, 1)\n┌─────────┐\n│ values  │\n│ ---     │\n│ f64     │\n╞═════════╡\n│ 0.0     │\n│ 0.30103 │\n│ 0.60206 │\n└─────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 17}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.log1p.html#polars.Expr.log1p"], "Title": ["Expr.log1p"], "Feature": ["Expr.log1p"], "Description": ["Compute the natural logarithm of each element plus one."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").log1p())\nshape: (3, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.693147 │\n│ 1.098612 │\n│ 1.386294 │\n└──────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 18}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.mode.html#polars.Expr.mode"], "Title": ["Expr.mode"], "Feature": ["Expr.mode"], "Description": ["Compute the most occurring value(s)."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 1, 2, 3],\n...         \"b\": [1, 1, 2, 2],\n...     }\n... )\n>>> df.select(pl.all().mode().first())  \nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 1   │\n└─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 19}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.n_unique.html#polars.Expr.n_unique"], "Title": ["Expr.n_unique"], "Feature": ["Expr.n_unique"], "Description": ["Count unique values."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 1, 2, 2, 3], \"y\": [1, 1, 1, None, None]})\n>>> df.select(\n...     x_unique=pl.col(\"x\").n_unique(),\n...     y_unique=pl.col(\"y\").n_unique(),\n... )\nshape: (1, 2)\n┌──────────┬──────────┐\n│ x_unique ┆ y_unique │\n│ ---      ┆ ---      │\n│ u32      ┆ u32      │\n╞══════════╪══════════╡\n│ 3        ┆ 2        │\n└──────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 20}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.pct_change.html#polars.Expr.pct_change"], "Title": ["Expr.pct_change"], "Feature": ["Expr.pct_change"], "Description": ["Computes percentage change between values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [10, 11, 12, None, 12],\n...     }\n... )\n>>> df.with_columns(pl.col(\"a\").pct_change().alias(\"pct_change\"))\nshape: (5, 2)\n┌──────┬────────────┐\n│ a    ┆ pct_change │\n│ ---  ┆ ---        │\n│ i64  ┆ f64        │\n╞══════╪════════════╡\n│ 10   ┆ null       │\n│ 11   ┆ 0.1        │\n│ 12   ┆ 0.090909   │\n│ null ┆ 0.0        │\n│ 12   ┆ 0.0        │\n└──────┴────────────┘"], "Parameters": [["n", "periods to shift for forming percent change."]], "Returns": [], "Category": ["Computation"], "index": 21}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.peak_max.html#polars.Expr.peak_max"], "Title": ["Expr.peak_max"], "Feature": ["Expr.peak_max"], "Description": ["Get a boolean mask of the local maximum peaks."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4, 5]})\n>>> df.select(pl.col(\"a\").peak_max())\nshape: (5, 1)\n┌───────┐\n│ a     │\n│ ---   │\n│ bool  │\n╞═══════╡\n│ false │\n│ false │\n│ false │\n│ false │\n│ true  │\n└───────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 22}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.peak_min.html#polars.Expr.peak_min"], "Title": ["Expr.peak_min"], "Feature": ["Expr.peak_min"], "Description": ["Get a boolean mask of the local minimum peaks."], "Examples": [">>> df = pl.DataFrame({\"a\": [4, 1, 3, 2, 5]})\n>>> df.select(pl.col(\"a\").peak_min())\nshape: (5, 1)\n┌───────┐\n│ a     │\n│ ---   │\n│ bool  │\n╞═══════╡\n│ false │\n│ true  │\n│ false │\n│ true  │\n│ false │\n└───────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 23}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.last.html#polars.Expr.last"], "Title": ["Expr.last"], "Feature": ["Expr.last"], "Description": ["Get the last value."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 3, 2]})\n>>> df.select(pl.col(\"a\").last())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 24}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.radians.html#polars.Expr.radians"], "Title": ["Expr.radians"], "Feature": ["Expr.radians"], "Description": ["Convert from degrees to radians."], "Examples": [">>> df = pl.DataFrame({\"a\": [-720, -540, -360, -180, 0, 180, 360, 540, 720]})\n>>> df.select(pl.col(\"a\").radians())\nshape: (9, 1)\n┌────────────┐\n│ a          │\n│ ---        │\n│ f64        │\n╞════════════╡\n│ -12.566371 │\n│ -9.424778  │\n│ -6.283185  │\n│ -3.141593  │\n│ 0.0        │\n│ 3.141593   │\n│ 6.283185   │\n│ 9.424778   │\n│ 12.566371  │\n└────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 25}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rank.html#polars.Expr.rank"], "Title": ["Expr.rank"], "Feature": ["Expr.rank"], "Description": ["Assign ranks to data, dealing with ties appropriately."], "Examples": [">>> df = pl.DataFrame({\"a\": [3, 6, 1, 1, 6]})\n>>> df.select(pl.col(\"a\").rank())\nshape: (5, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 3.0 │\n│ 4.5 │\n│ 1.5 │\n│ 1.5 │\n│ 4.5 │\n└─────┘", ">>> df = pl.DataFrame({\"a\": [3, 6, 1, 1, 6]})\n>>> df.select(pl.col(\"a\").rank(\"ordinal\"))\nshape: (5, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 3   │\n│ 4   │\n│ 1   │\n│ 2   │\n│ 5   │\n└─────┘", ">>> df = pl.DataFrame({\"a\": [1, 1, 2, 2, 2], \"b\": [6, 7, 5, 14, 11]})\n>>> df.with_columns(pl.col(\"b\").rank().over(\"a\").alias(\"rank\"))\nshape: (5, 3)\n┌─────┬─────┬──────┐\n│ a   ┆ b   ┆ rank │\n│ --- ┆ --- ┆ ---  │\n│ i64 ┆ i64 ┆ f64  │\n╞═════╪═════╪══════╡\n│ 1   ┆ 6   ┆ 1.0  │\n│ 1   ┆ 7   ┆ 2.0  │\n│ 2   ┆ 5   ┆ 1.0  │\n│ 2   ┆ 14  ┆ 3.0  │\n│ 2   ┆ 11  ┆ 2.0  │\n└─────┴─────┴──────┘", ">>> df = pl.DataFrame({\"a\": [6, 7, None, 14, 11]})\n>>> df.with_columns(\n...     pct=pl.col(\"a\").rank() / pl.len(),\n...     pct_valid=pl.col(\"a\").rank() / pl.count(\"a\"),\n... )\nshape: (5, 3)\n┌──────┬──────┬───────────┐\n│ a    ┆ pct  ┆ pct_valid │\n│ ---  ┆ ---  ┆ ---       │\n│ i64  ┆ f64  ┆ f64       │\n╞══════╪══════╪═══════════╡\n│ 6    ┆ 0.2  ┆ 0.25      │\n│ 7    ┆ 0.4  ┆ 0.5       │\n│ null ┆ null ┆ null      │\n│ 14   ┆ 0.8  ┆ 1.0       │\n│ 11   ┆ 0.6  ┆ 0.75      │\n└──────┴──────┴───────────┘"], "Parameters": [["method {‘average’, ‘min’, ‘max’, ‘dense’, ‘ordinal’, ‘random’}", "The method used to assign ranks to tied elements.\nThe following methods are available (default is ‘average’): ‘average’ : The average of the ranks that would have been assigned to\nall the tied values is assigned to each value. ‘min’ : The minimum of the ranks that would have been assigned to all\nthe tied values is assigned to each value. (This is also referred to\nas “competition” ranking.) ‘max’ : The maximum of the ranks that would have been assigned to all\nthe tied values is assigned to each value. ‘dense’ : Like ‘min’, but the rank of the next highest element is\nassigned the rank immediately after those assigned to the tied\nelements. ‘ordinal’ : All values are given a distinct rank, corresponding to\nthe order that the values occur in the Series. ‘random’ : Like ‘ordinal’, but the rank for ties is not dependent\non the order that the values occur in the Series."], ["descending", "Rank in descending order."], ["seed", "If method=\"random\" , use this as seed."]], "Returns": [], "Category": ["Computation"], "index": 26}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_kurtosis.html#polars.Expr.rolling_kurtosis"], "Title": ["Expr.rolling_kurtosis"], "Feature": ["Expr.rolling_kurtosis"], "Description": ["Compute a rolling kurtosis."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 4, 2, 9]})\n>>> df.select(pl.col(\"a\").rolling_kurtosis(3))\nshape: (4, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ null │\n│ null │\n│ -1.5 │\n│ -1.5 │\n└──────┘"], "Parameters": [["window_size", "Integer size of the rolling window."], ["fisher bool, optional", "If True, Fisher’s definition is used (normal ==> 0.0). If False,\nPearson’s definition is used (normal ==> 3.0)."], ["bias bool, optional", "If False, the calculations are corrected for statistical bias."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 27}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_map.html#polars.Expr.rolling_map"], "Title": ["Expr.rolling_map"], "Feature": ["Expr.rolling_map"], "Description": ["Compute a custom rolling window function."], "Examples": [">>> from numpy import nansum\n>>> df = pl.DataFrame({\"a\": [11.0, 2.0, 9.0, float(\"nan\"), 8.0]})\n>>> df.select(pl.col(\"a\").rolling_map(nansum, window_size=3))\nshape: (5, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ null │\n│ null │\n│ 22.0 │\n│ 11.0 │\n│ 17.0 │\n└──────┘"], "Parameters": [["function", "Custom aggregation function."], ["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 28}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_max.html#polars.Expr.rolling_max"], "Title": ["Expr.rolling_max"], "Feature": ["Expr.rolling_max"], "Description": ["Apply a rolling max (moving max) over the values in this array."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_max=pl.col(\"A\").rolling_max(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_max │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 2.0         │\n│ 3.0 ┆ 3.0         │\n│ 4.0 ┆ 4.0         │\n│ 5.0 ┆ 5.0         │\n│ 6.0 ┆ 6.0         │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_max=pl.col(\"A\").rolling_max(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_max │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 1.5         │\n│ 3.0 ┆ 2.25        │\n│ 4.0 ┆ 3.0         │\n│ 5.0 ┆ 3.75        │\n│ 6.0 ┆ 4.5         │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_max=pl.col(\"A\").rolling_max(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_max │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 3.0         │\n│ 3.0 ┆ 4.0         │\n│ 4.0 ┆ 5.0         │\n│ 5.0 ┆ 6.0         │\n│ 6.0 ┆ null        │\n└─────┴─────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 29}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_max_by.html#polars.Expr.rolling_max_by"], "Title": ["Expr.rolling_max_by"], "Feature": ["Expr.rolling_max_by"], "Description": ["Apply a rolling max based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_max=pl.col(\"index\").rolling_max_by(\"date\", window_size=\"2h\")\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_max │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ u32             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0               │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 1               │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 2               │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 3               │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 4               │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 20              │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 21              │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 22              │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 23              │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 24              │\n└───────┴─────────────────────┴─────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_max=pl.col(\"index\").rolling_max_by(\n...         \"date\", window_size=\"2h\", closed=\"both\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_max │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ u32             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0               │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 1               │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 2               │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 3               │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 4               │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 20              │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 21              │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 22              │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 23              │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 24              │\n└───────┴─────────────────────┴─────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."]], "Returns": [], "Category": ["Computation"], "index": 30}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_mean.html#polars.Expr.rolling_mean"], "Title": ["Expr.rolling_mean"], "Feature": ["Expr.rolling_mean"], "Description": ["Apply a rolling mean (moving mean) over the values in this array."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_mean=pl.col(\"A\").rolling_mean(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬──────────────┐\n│ A   ┆ rolling_mean │\n│ --- ┆ ---          │\n│ f64 ┆ f64          │\n╞═════╪══════════════╡\n│ 1.0 ┆ null         │\n│ 2.0 ┆ 1.5          │\n│ 3.0 ┆ 2.5          │\n│ 4.0 ┆ 3.5          │\n│ 5.0 ┆ 4.5          │\n│ 6.0 ┆ 5.5          │\n└─────┴──────────────┘", ">>> df.with_columns(\n...     rolling_mean=pl.col(\"A\").rolling_mean(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬──────────────┐\n│ A   ┆ rolling_mean │\n│ --- ┆ ---          │\n│ f64 ┆ f64          │\n╞═════╪══════════════╡\n│ 1.0 ┆ null         │\n│ 2.0 ┆ 1.75         │\n│ 3.0 ┆ 2.75         │\n│ 4.0 ┆ 3.75         │\n│ 5.0 ┆ 4.75         │\n│ 6.0 ┆ 5.75         │\n└─────┴──────────────┘", ">>> df.with_columns(\n...     rolling_mean=pl.col(\"A\").rolling_mean(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬──────────────┐\n│ A   ┆ rolling_mean │\n│ --- ┆ ---          │\n│ f64 ┆ f64          │\n╞═════╪══════════════╡\n│ 1.0 ┆ null         │\n│ 2.0 ┆ 2.0          │\n│ 3.0 ┆ 3.0          │\n│ 4.0 ┆ 4.0          │\n│ 5.0 ┆ 5.0          │\n│ 6.0 ┆ null         │\n└─────┴──────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window, after being normalized to sum to\n1."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 31}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_mean_by.html#polars.Expr.rolling_mean_by"], "Title": ["Expr.rolling_mean_by"], "Feature": ["Expr.rolling_mean_by"], "Description": ["Apply a rolling mean based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_mean=pl.col(\"index\").rolling_mean_by(\n...         \"date\", window_size=\"2h\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬──────────────────┐\n│ index ┆ date                ┆ rolling_row_mean │\n│ ---   ┆ ---                 ┆ ---              │\n│ u32   ┆ datetime[μs]        ┆ f64              │\n╞═══════╪═════════════════════╪══════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0.0              │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.5              │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1.5              │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 2.5              │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 3.5              │\n│ …     ┆ …                   ┆ …                │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 19.5             │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 20.5             │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 21.5             │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 22.5             │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 23.5             │\n└───────┴─────────────────────┴──────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_mean=pl.col(\"index\").rolling_mean_by(\n...         \"date\", window_size=\"2h\", closed=\"both\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬──────────────────┐\n│ index ┆ date                ┆ rolling_row_mean │\n│ ---   ┆ ---                 ┆ ---              │\n│ u32   ┆ datetime[μs]        ┆ f64              │\n╞═══════╪═════════════════════╪══════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0.0              │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.5              │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1.0              │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 2.0              │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 3.0              │\n│ …     ┆ …                   ┆ …                │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 19.0             │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 20.0             │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 21.0             │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 22.0             │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 23.0             │\n└───────┴─────────────────────┴──────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."]], "Returns": [], "Category": ["Computation"], "index": 32}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_median.html#polars.Expr.rolling_median"], "Title": ["Expr.rolling_median"], "Feature": ["Expr.rolling_median"], "Description": ["Compute a rolling median."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_median=pl.col(\"A\").rolling_median(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬────────────────┐\n│ A   ┆ rolling_median │\n│ --- ┆ ---            │\n│ f64 ┆ f64            │\n╞═════╪════════════════╡\n│ 1.0 ┆ null           │\n│ 2.0 ┆ 1.5            │\n│ 3.0 ┆ 2.5            │\n│ 4.0 ┆ 3.5            │\n│ 5.0 ┆ 4.5            │\n│ 6.0 ┆ 5.5            │\n└─────┴────────────────┘", ">>> df.with_columns(\n...     rolling_median=pl.col(\"A\").rolling_median(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬────────────────┐\n│ A   ┆ rolling_median │\n│ --- ┆ ---            │\n│ f64 ┆ f64            │\n╞═════╪════════════════╡\n│ 1.0 ┆ null           │\n│ 2.0 ┆ 1.5            │\n│ 3.0 ┆ 2.5            │\n│ 4.0 ┆ 3.5            │\n│ 5.0 ┆ 4.5            │\n│ 6.0 ┆ 5.5            │\n└─────┴────────────────┘", ">>> df.with_columns(\n...     rolling_median=pl.col(\"A\").rolling_median(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬────────────────┐\n│ A   ┆ rolling_median │\n│ --- ┆ ---            │\n│ f64 ┆ f64            │\n╞═════╪════════════════╡\n│ 1.0 ┆ null           │\n│ 2.0 ┆ 2.0            │\n│ 3.0 ┆ 3.0            │\n│ 4.0 ┆ 4.0            │\n│ 5.0 ┆ 5.0            │\n│ 6.0 ┆ null           │\n└─────┴────────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 33}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_median_by.html#polars.Expr.rolling_median_by"], "Title": ["Expr.rolling_median_by"], "Feature": ["Expr.rolling_median_by"], "Description": ["Compute a rolling median based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_median=pl.col(\"index\").rolling_median_by(\n...         \"date\", window_size=\"2h\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬────────────────────┐\n│ index ┆ date                ┆ rolling_row_median │\n│ ---   ┆ ---                 ┆ ---                │\n│ u32   ┆ datetime[μs]        ┆ f64                │\n╞═══════╪═════════════════════╪════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0.0                │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.5                │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1.5                │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 2.5                │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 3.5                │\n│ …     ┆ …                   ┆ …                  │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 19.5               │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 20.5               │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 21.5               │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 22.5               │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 23.5               │\n└───────┴─────────────────────┴────────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."]], "Returns": [], "Category": ["Computation"], "index": 34}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.len.html#polars.Expr.len"], "Title": ["Expr.len"], "Feature": ["Expr.len"], "Description": ["Return the number of elements in the column."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [None, 4, 4]})\n>>> df.select(pl.all().len())\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 3   ┆ 3   │\n└─────┴─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Aggregation"], "index": 35}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_min.html#polars.Expr.rolling_min"], "Title": ["Expr.rolling_min"], "Feature": ["Expr.rolling_min"], "Description": ["Apply a rolling min (moving min) over the values in this array."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_min=pl.col(\"A\").rolling_min(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_min │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 1.0         │\n│ 3.0 ┆ 2.0         │\n│ 4.0 ┆ 3.0         │\n│ 5.0 ┆ 4.0         │\n│ 6.0 ┆ 5.0         │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_min=pl.col(\"A\").rolling_min(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_min │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 0.25        │\n│ 3.0 ┆ 0.5         │\n│ 4.0 ┆ 0.75        │\n│ 5.0 ┆ 1.0         │\n│ 6.0 ┆ 1.25        │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_min=pl.col(\"A\").rolling_min(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_min │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 1.0         │\n│ 3.0 ┆ 2.0         │\n│ 4.0 ┆ 3.0         │\n│ 5.0 ┆ 4.0         │\n│ 6.0 ┆ null        │\n└─────┴─────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 36}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_min_by.html#polars.Expr.rolling_min_by"], "Title": ["Expr.rolling_min_by"], "Feature": ["Expr.rolling_min_by"], "Description": ["Apply a rolling min based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_min=pl.col(\"index\").rolling_min_by(\"date\", window_size=\"2h\")\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_min │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ u32             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0               │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0               │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1               │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 2               │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 3               │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 19              │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 20              │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 21              │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 22              │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 23              │\n└───────┴─────────────────────┴─────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."]], "Returns": [], "Category": ["Computation"], "index": 37}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_quantile.html#polars.Expr.rolling_quantile"], "Title": ["Expr.rolling_quantile"], "Feature": ["Expr.rolling_quantile"], "Description": ["Compute a rolling quantile."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_quantile=pl.col(\"A\").rolling_quantile(\n...         quantile=0.25, window_size=4\n...     ),\n... )\nshape: (6, 2)\n┌─────┬──────────────────┐\n│ A   ┆ rolling_quantile │\n│ --- ┆ ---              │\n│ f64 ┆ f64              │\n╞═════╪══════════════════╡\n│ 1.0 ┆ null             │\n│ 2.0 ┆ null             │\n│ 3.0 ┆ null             │\n│ 4.0 ┆ 2.0              │\n│ 5.0 ┆ 3.0              │\n│ 6.0 ┆ 4.0              │\n└─────┴──────────────────┘", ">>> df.with_columns(\n...     rolling_quantile=pl.col(\"A\").rolling_quantile(\n...         quantile=0.25, window_size=4, weights=[0.2, 0.4, 0.4, 0.2]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬──────────────────┐\n│ A   ┆ rolling_quantile │\n│ --- ┆ ---              │\n│ f64 ┆ f64              │\n╞═════╪══════════════════╡\n│ 1.0 ┆ null             │\n│ 2.0 ┆ null             │\n│ 3.0 ┆ null             │\n│ 4.0 ┆ 2.0              │\n│ 5.0 ┆ 3.0              │\n│ 6.0 ┆ 4.0              │\n└─────┴──────────────────┘", ">>> df.with_columns(\n...     rolling_quantile=pl.col(\"A\").rolling_quantile(\n...         quantile=0.25,\n...         window_size=4,\n...         weights=[0.2, 0.4, 0.4, 0.2],\n...         interpolation=\"linear\",\n...     ),\n... )\nshape: (6, 2)\n┌─────┬──────────────────┐\n│ A   ┆ rolling_quantile │\n│ --- ┆ ---              │\n│ f64 ┆ f64              │\n╞═════╪══════════════════╡\n│ 1.0 ┆ null             │\n│ 2.0 ┆ null             │\n│ 3.0 ┆ null             │\n│ 4.0 ┆ 1.625            │\n│ 5.0 ┆ 2.625            │\n│ 6.0 ┆ 3.625            │\n└─────┴──────────────────┘", ">>> df.with_columns(\n...     rolling_quantile=pl.col(\"A\").rolling_quantile(\n...         quantile=0.2, window_size=5, center=True\n...     ),\n... )\nshape: (6, 2)\n┌─────┬──────────────────┐\n│ A   ┆ rolling_quantile │\n│ --- ┆ ---              │\n│ f64 ┆ f64              │\n╞═════╪══════════════════╡\n│ 1.0 ┆ null             │\n│ 2.0 ┆ null             │\n│ 3.0 ┆ 2.0              │\n│ 4.0 ┆ 3.0              │\n│ 5.0 ┆ null             │\n│ 6.0 ┆ null             │\n└─────┴──────────────────┘"], "Parameters": [["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."], ["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 38}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_quantile_by.html#polars.Expr.rolling_quantile_by"], "Title": ["Expr.rolling_quantile_by"], "Feature": ["Expr.rolling_quantile_by"], "Description": ["Compute a rolling quantile based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_quantile=pl.col(\"index\").rolling_quantile_by(\n...         \"date\", window_size=\"2h\", quantile=0.3\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬──────────────────────┐\n│ index ┆ date                ┆ rolling_row_quantile │\n│ ---   ┆ ---                 ┆ ---                  │\n│ u32   ┆ datetime[μs]        ┆ f64                  │\n╞═══════╪═════════════════════╪══════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0.0                  │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.0                  │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1.0                  │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 2.0                  │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 3.0                  │\n│ …     ┆ …                   ┆ …                    │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 19.0                 │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 20.0                 │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 21.0                 │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 22.0                 │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 23.0                 │\n└───────┴─────────────────────┴──────────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."], ["window_size", "The length of the window. Can be a dynamic\ntemporal size indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."]], "Returns": [], "Category": ["Computation"], "index": 39}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_skew.html#polars.Expr.rolling_skew"], "Title": ["Expr.rolling_skew"], "Feature": ["Expr.rolling_skew"], "Description": ["Compute a rolling skew."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 4, 2, 9]})\n>>> df.select(pl.col(\"a\").rolling_skew(3))\nshape: (4, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ null     │\n│ null     │\n│ 0.381802 │\n│ 0.47033  │\n└──────────┘", ">>> pl.Series([1, 4, 2]).skew(), pl.Series([4, 2, 9]).skew()\n(0.38180177416060584, 0.47033046033698594)"], "Parameters": [["window_size", "Integer size of the rolling window."], ["bias", "If False, the calculations are corrected for statistical bias. bias: bool = True,"], ["If False, the calculations are corrected for statistical bias.", "bias: bool = True,"], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 40}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_std.html#polars.Expr.rolling_std"], "Title": ["Expr.rolling_std"], "Feature": ["Expr.rolling_std"], "Description": ["Compute a rolling standard deviation."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_std=pl.col(\"A\").rolling_std(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_std │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 0.707107    │\n│ 3.0 ┆ 0.707107    │\n│ 4.0 ┆ 0.707107    │\n│ 5.0 ┆ 0.707107    │\n│ 6.0 ┆ 0.707107    │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_std=pl.col(\"A\").rolling_std(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_std │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 0.433013    │\n│ 3.0 ┆ 0.433013    │\n│ 4.0 ┆ 0.433013    │\n│ 5.0 ┆ 0.433013    │\n│ 6.0 ┆ 0.433013    │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_std=pl.col(\"A\").rolling_std(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_std │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 1.0         │\n│ 3.0 ┆ 1.0         │\n│ 4.0 ┆ 1.0         │\n│ 5.0 ┆ 1.0         │\n│ 6.0 ┆ null        │\n└─────┴─────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window after being normalized to sum to\n1."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."], ["ddof", "“Delta Degrees of Freedom”: The divisor for a length N window is N - ddof"]], "Returns": [], "Category": ["Computation"], "index": 41}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_std_by.html#polars.Expr.rolling_std_by"], "Title": ["Expr.rolling_std_by"], "Feature": ["Expr.rolling_std_by"], "Description": ["Compute a rolling standard deviation based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_std=pl.col(\"index\").rolling_std_by(\"date\", window_size=\"2h\")\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_std │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ f64             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ null            │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.707107        │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 0.707107        │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 0.707107        │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 0.707107        │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 0.707107        │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 0.707107        │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 0.707107        │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 0.707107        │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 0.707107        │\n└───────┴─────────────────────┴─────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_std=pl.col(\"index\").rolling_std_by(\n...         \"date\", window_size=\"2h\", closed=\"both\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_std │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ f64             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ null            │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.707107        │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1.0             │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 1.0             │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 1.0             │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 1.0             │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 1.0             │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 1.0             │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 1.0             │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 1.0             │\n└───────┴─────────────────────┴─────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."], ["ddof", "“Delta Degrees of Freedom”: The divisor for a length N window is N - ddof"]], "Returns": [], "Category": ["Computation"], "index": 42}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_sum.html#polars.Expr.rolling_sum"], "Title": ["Expr.rolling_sum"], "Feature": ["Expr.rolling_sum"], "Description": ["Apply a rolling sum (moving sum) over the values in this array."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_sum=pl.col(\"A\").rolling_sum(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_sum │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 3.0         │\n│ 3.0 ┆ 5.0         │\n│ 4.0 ┆ 7.0         │\n│ 5.0 ┆ 9.0         │\n│ 6.0 ┆ 11.0        │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_sum=pl.col(\"A\").rolling_sum(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_sum │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 1.75        │\n│ 3.0 ┆ 2.75        │\n│ 4.0 ┆ 3.75        │\n│ 5.0 ┆ 4.75        │\n│ 6.0 ┆ 5.75        │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_sum=pl.col(\"A\").rolling_sum(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_sum │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 6.0         │\n│ 3.0 ┆ 9.0         │\n│ 4.0 ┆ 12.0        │\n│ 5.0 ┆ 15.0        │\n│ 6.0 ┆ null        │\n└─────┴─────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."]], "Returns": [], "Category": ["Computation"], "index": 43}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_sum_by.html#polars.Expr.rolling_sum_by"], "Title": ["Expr.rolling_sum_by"], "Feature": ["Expr.rolling_sum_by"], "Description": ["Apply a rolling sum based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_sum=pl.col(\"index\").rolling_sum_by(\"date\", window_size=\"2h\")\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_sum │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ u32             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0               │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 1               │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 3               │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 5               │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 7               │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 39              │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 41              │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 43              │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 45              │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 47              │\n└───────┴─────────────────────┴─────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_sum=pl.col(\"index\").rolling_sum_by(\n...         \"date\", window_size=\"2h\", closed=\"both\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_sum │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ u32             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ 0               │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 1               │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 3               │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 6               │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 9               │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 57              │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 60              │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 63              │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 66              │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 69              │\n└───────┴─────────────────────┴─────────────────┘"], "Parameters": [["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."]], "Returns": [], "Category": ["Computation"], "index": 44}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_var.html#polars.Expr.rolling_var"], "Title": ["Expr.rolling_var"], "Feature": ["Expr.rolling_var"], "Description": ["Compute a rolling variance."], "Examples": [">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]})\n>>> df.with_columns(\n...     rolling_var=pl.col(\"A\").rolling_var(window_size=2),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_var │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 0.5         │\n│ 3.0 ┆ 0.5         │\n│ 4.0 ┆ 0.5         │\n│ 5.0 ┆ 0.5         │\n│ 6.0 ┆ 0.5         │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_var=pl.col(\"A\").rolling_var(\n...         window_size=2, weights=[0.25, 0.75]\n...     ),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_var │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 0.1875      │\n│ 3.0 ┆ 0.1875      │\n│ 4.0 ┆ 0.1875      │\n│ 5.0 ┆ 0.1875      │\n│ 6.0 ┆ 0.1875      │\n└─────┴─────────────┘", ">>> df.with_columns(\n...     rolling_var=pl.col(\"A\").rolling_var(window_size=3, center=True),\n... )\nshape: (6, 2)\n┌─────┬─────────────┐\n│ A   ┆ rolling_var │\n│ --- ┆ ---         │\n│ f64 ┆ f64         │\n╞═════╪═════════════╡\n│ 1.0 ┆ null        │\n│ 2.0 ┆ 1.0         │\n│ 3.0 ┆ 1.0         │\n│ 4.0 ┆ 1.0         │\n│ 5.0 ┆ 1.0         │\n│ 6.0 ┆ null        │\n└─────┴─────────────┘"], "Parameters": [["window_size", "The length of the window in number of elements."], ["weights", "An optional slice with the same length as the window that will be multiplied\nelementwise with the values in the window after being normalized to sum to\n1."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If set to None (default), it will be set equal to window_size ."], ["center", "Set the labels at the center of the window."], ["ddof", "“Delta Degrees of Freedom”: The divisor for a length N window is N - ddof"]], "Returns": [], "Category": ["Computation"], "index": 45}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.max.html#polars.Expr.max"], "Title": ["Expr.max"], "Feature": ["Expr.max"], "Description": ["Get maximum value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1.0, float(\"nan\"), 1.0]})\n>>> df.select(pl.col(\"a\").max())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 46}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling_var_by.html#polars.Expr.rolling_var_by"], "Title": ["Expr.rolling_var_by"], "Feature": ["Expr.rolling_var_by"], "Description": ["Compute a rolling variance based on another column."], "Examples": [">>> from datetime import timedelta, datetime\n>>> start = datetime(2001, 1, 1)\n>>> stop = datetime(2001, 1, 2)\n>>> df_temporal = pl.DataFrame(\n...     {\"date\": pl.datetime_range(start, stop, \"1h\", eager=True)}\n... ).with_row_index()\n>>> df_temporal\nshape: (25, 2)\n┌───────┬─────────────────────┐\n│ index ┆ date                │\n│ ---   ┆ ---                 │\n│ u32   ┆ datetime[μs]        │\n╞═══════╪═════════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 │\n│ 1     ┆ 2001-01-01 01:00:00 │\n│ 2     ┆ 2001-01-01 02:00:00 │\n│ 3     ┆ 2001-01-01 03:00:00 │\n│ 4     ┆ 2001-01-01 04:00:00 │\n│ …     ┆ …                   │\n│ 20    ┆ 2001-01-01 20:00:00 │\n│ 21    ┆ 2001-01-01 21:00:00 │\n│ 22    ┆ 2001-01-01 22:00:00 │\n│ 23    ┆ 2001-01-01 23:00:00 │\n│ 24    ┆ 2001-01-02 00:00:00 │\n└───────┴─────────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_var=pl.col(\"index\").rolling_var_by(\"date\", window_size=\"2h\")\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_var │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ f64             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ null            │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.5             │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 0.5             │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 0.5             │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 0.5             │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 0.5             │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 0.5             │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 0.5             │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 0.5             │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 0.5             │\n└───────┴─────────────────────┴─────────────────┘", ">>> df_temporal.with_columns(\n...     rolling_row_var=pl.col(\"index\").rolling_var_by(\n...         \"date\", window_size=\"2h\", closed=\"both\"\n...     )\n... )\nshape: (25, 3)\n┌───────┬─────────────────────┬─────────────────┐\n│ index ┆ date                ┆ rolling_row_var │\n│ ---   ┆ ---                 ┆ ---             │\n│ u32   ┆ datetime[μs]        ┆ f64             │\n╞═══════╪═════════════════════╪═════════════════╡\n│ 0     ┆ 2001-01-01 00:00:00 ┆ null            │\n│ 1     ┆ 2001-01-01 01:00:00 ┆ 0.5             │\n│ 2     ┆ 2001-01-01 02:00:00 ┆ 1.0             │\n│ 3     ┆ 2001-01-01 03:00:00 ┆ 1.0             │\n│ 4     ┆ 2001-01-01 04:00:00 ┆ 1.0             │\n│ …     ┆ …                   ┆ …               │\n│ 20    ┆ 2001-01-01 20:00:00 ┆ 1.0             │\n│ 21    ┆ 2001-01-01 21:00:00 ┆ 1.0             │\n│ 22    ┆ 2001-01-01 22:00:00 ┆ 1.0             │\n│ 23    ┆ 2001-01-01 23:00:00 ┆ 1.0             │\n│ 24    ┆ 2001-01-02 00:00:00 ┆ 1.0             │\n└───────┴─────────────────────┴─────────────────┘"], "Parameters": [["by", "Should be DateTime , Date , UInt64 , UInt32 , Int64 ,\nor Int32 data type (note that the integral ones require using 'i' in window size )."], ["window_size", "The length of the window. Can be a dynamic temporal\nsize indicated by a timedelta or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) 1i    (1 index count) By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["min_samples", "The number of values in the window that should be non-null before computing\na result."], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive),\ndefaults to 'right' ."], ["ddof", "“Delta Degrees of Freedom”: The divisor for a length N window is N - ddof"]], "Returns": [], "Category": ["Computation"], "index": 47}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.search_sorted.html#polars.Expr.search_sorted"], "Title": ["Expr.search_sorted"], "Feature": ["Expr.search_sorted"], "Description": ["Find indices where elements should be inserted to maintain order."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"values\": [1, 2, 3, 5],\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"values\").search_sorted(0).alias(\"zero\"),\n...         pl.col(\"values\").search_sorted(3).alias(\"three\"),\n...         pl.col(\"values\").search_sorted(6).alias(\"six\"),\n...     ]\n... )\nshape: (1, 3)\n┌──────┬───────┬─────┐\n│ zero ┆ three ┆ six │\n│ ---  ┆ ---   ┆ --- │\n│ u32  ┆ u32   ┆ u32 │\n╞══════╪═══════╪═════╡\n│ 0    ┆ 2     ┆ 4   │\n└──────┴───────┴─────┘"], "Parameters": [["element", "Expression or scalar value."], ["side {‘any’, ‘left’, ‘right’}", "If ‘any’, the index of the first suitable location found is given.\nIf ‘left’, the index of the leftmost suitable location found is given.\nIf ‘right’, return the rightmost suitable location found is given."], ["descending", "Boolean indicating whether the values are descending or not (they\nare required to be sorted either way)."]], "Returns": [], "Category": ["Computation"], "index": 48}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sign.html#polars.Expr.sign"], "Title": ["Expr.sign"], "Feature": ["Expr.sign"], "Description": ["Compute the element-wise sign function on numeric types."], "Examples": [">>> df = pl.DataFrame({\"a\": [-9.0, -0.0, 0.0, 4.0, float(\"nan\"), None]})\n>>> df.select(pl.col.a.sign())\nshape: (6, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ -1.0 │\n│ -0.0 │\n│ 0.0  │\n│ 1.0  │\n│ NaN  │\n│ null │\n└──────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 49}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sin.html#polars.Expr.sin"], "Title": ["Expr.sin"], "Feature": ["Expr.sin"], "Description": ["Compute the element-wise value for the sine."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.0]})\n>>> df.select(pl.col(\"a\").sin())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 50}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sinh.html#polars.Expr.sinh"], "Title": ["Expr.sinh"], "Feature": ["Expr.sinh"], "Description": ["Compute the element-wise value for the hyperbolic sine."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").sinh())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.175201 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 51}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.skew.html#polars.Expr.skew"], "Title": ["Expr.skew"], "Feature": ["Expr.skew"], "Description": ["Compute the sample skewness of a data set."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 2, 1]})\n>>> df.select(pl.col(\"a\").skew())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.343622 │\n└──────────┘"], "Parameters": [["bias bool, optional", "If False, the calculations are corrected for statistical bias."]], "Returns": [], "Category": ["Computation"], "index": 52}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sqrt.html#polars.Expr.sqrt"], "Title": ["Expr.sqrt"], "Feature": ["Expr.sqrt"], "Description": ["Compute the square root of the elements."], "Examples": [">>> df = pl.DataFrame({\"values\": [1.0, 2.0, 4.0]})\n>>> df.select(pl.col(\"values\").sqrt())\nshape: (3, 1)\n┌──────────┐\n│ values   │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.0      │\n│ 1.414214 │\n│ 2.0      │\n└──────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 53}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.tan.html#polars.Expr.tan"], "Title": ["Expr.tan"], "Feature": ["Expr.tan"], "Description": ["Compute the element-wise value for the tangent."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").tan().round(2))\nshape: (1, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ 1.56 │\n└──────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 54}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.tanh.html#polars.Expr.tanh"], "Title": ["Expr.tanh"], "Feature": ["Expr.tanh"], "Description": ["Compute the element-wise value for the hyperbolic tangent."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").tanh())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.761594 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 55}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.unique.html#polars.Expr.unique"], "Title": ["Expr.unique"], "Feature": ["Expr.unique"], "Description": ["Get unique values of this expression."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2]})\n>>> df.select(pl.col(\"a\").unique())  \nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n│ 1   │\n└─────┘\n>>> df.select(pl.col(\"a\").unique(maintain_order=True))\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n└─────┘"], "Parameters": [["maintain_order", "Maintain order of data. This requires more work."]], "Returns": [], "Category": ["Computation"], "index": 56}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.mean.html#polars.Expr.mean"], "Title": ["Expr.mean"], "Feature": ["Expr.mean"], "Description": ["Get mean value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").mean())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 57}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.unique_counts.html#polars.Expr.unique_counts"], "Title": ["Expr.unique_counts"], "Feature": ["Expr.unique_counts"], "Description": ["Return a count of the unique values in the order of appearance."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"id\": [\"a\", \"b\", \"b\", \"c\", \"c\", \"c\"],\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"id\").unique_counts(),\n...     ]\n... )\nshape: (3, 1)\n┌─────┐\n│ id  │\n│ --- │\n│ u32 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 58}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.value_counts.html#polars.Expr.value_counts"], "Title": ["Expr.value_counts"], "Feature": ["Expr.value_counts"], "Description": ["Count the occurrence of unique values."], "Examples": [">>> df = pl.DataFrame(\n...     {\"color\": [\"red\", \"blue\", \"red\", \"green\", \"blue\", \"blue\"]}\n... )\n>>> df_count = df.select(pl.col(\"color\").value_counts())\n>>> df_count  \nshape: (3, 1)\n┌─────────────┐\n│ color       │\n│ ---         │\n│ struct[2]   │\n╞═════════════╡\n│ {\"green\",1} │\n│ {\"blue\",3}  │\n│ {\"red\",2}   │\n└─────────────┘", ">>> df_count.unnest(\"color\")  \nshape: (3, 2)\n┌───────┬───────┐\n│ color ┆ count │\n│ ---   ┆ ---   │\n│ str   ┆ u32   │\n╞═══════╪═══════╡\n│ green ┆ 1     │\n│ blue  ┆ 3     │\n│ red   ┆ 2     │\n└───────┴───────┘", ">>> df_count = df.select(\n...     pl.col(\"color\").value_counts(\n...         name=\"fraction\",\n...         normalize=True,\n...         sort=True,\n...     )\n... )\n>>> df_count\nshape: (3, 1)\n┌────────────────────┐\n│ color              │\n│ ---                │\n│ struct[2]          │\n╞════════════════════╡\n│ {\"blue\",0.5}       │\n│ {\"red\",0.333333}   │\n│ {\"green\",0.166667} │\n└────────────────────┘", ">>> df_count.unnest(\"color\")\nshape: (3, 2)\n┌───────┬──────────┐\n│ color ┆ fraction │\n│ ---   ┆ ---      │\n│ str   ┆ f64      │\n╞═══════╪══════════╡\n│ blue  ┆ 0.5      │\n│ red   ┆ 0.333333 │\n│ green ┆ 0.166667 │\n└───────┴──────────┘"], "Parameters": [["sort", "Sort the output by count, in descending order.\nIf set to False (default), the order is non-deterministic."], ["parallel", "Execute the computation in parallel. Note This option should likely not be enabled in a group_by context,\nas the computation will already be parallelized per group."], ["name", "Give the resulting count column a specific name; if normalize is\nTrue this defaults to “proportion”, otherwise defaults to “count”."], ["normalize", "If True, the count is returned as the relative frequency of unique\nvalues normalized to 1.0."]], "Returns": [["Expr", "Expression of type Struct , mapping unique values to their\ncount (or proportion)."]], "Category": ["Computation"], "index": 59}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.all.html#polars.all"], "Title": ["all"], "Feature": ["all"], "Description": ["Either return an expression representing all columns, or evaluate a bitwise AND operation."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, False, True],\n...         \"b\": [False, False, False],\n...     }\n... )\n>>> df.select(pl.all().sum())\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 2   ┆ 0   │\n└─────┴─────┘", ">>> df.select(pl.all(\"a\"))\nshape: (1, 1)\n┌───────┐\n│ a     │\n│ ---   │\n│ bool  │\n╞═══════╡\n│ false │\n└───────┘"], "Parameters": [["*names", "Name(s) of the columns to use in the aggregation."], ["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is True . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no False values,\nthe output is null."]], "Returns": [], "Category": ["Functions"], "index": 60}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.all_horizontal.html#polars.all_horizontal"], "Title": ["all_horizontal"], "Feature": ["all_horizontal"], "Description": ["Compute the bitwise AND horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [False, False, True, True, False, None],\n...         \"b\": [False, True, True, None, None, None],\n...         \"c\": [\"u\", \"v\", \"w\", \"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(all=pl.all_horizontal(\"a\", \"b\"))\nshape: (6, 4)\n┌───────┬───────┬─────┬───────┐\n│ a     ┆ b     ┆ c   ┆ all   │\n│ ---   ┆ ---   ┆ --- ┆ ---   │\n│ bool  ┆ bool  ┆ str ┆ bool  │\n╞═══════╪═══════╪═════╪═══════╡\n│ false ┆ false ┆ u   ┆ false │\n│ false ┆ true  ┆ v   ┆ false │\n│ true  ┆ true  ┆ w   ┆ true  │\n│ true  ┆ null  ┆ x   ┆ null  │\n│ false ┆ null  ┆ y   ┆ false │\n│ null  ┆ null  ┆ z   ┆ null  │\n└───────┴───────┴─────┴───────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."]], "Returns": [], "Category": ["Functions"], "index": 61}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.any.html#polars.any"], "Title": ["any"], "Feature": ["any"], "Description": ["Evaluate a bitwise OR operation."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, False, True],\n...         \"b\": [False, False, False],\n...     }\n... )\n>>> df.select(pl.any(\"a\"))\nshape: (1, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ bool │\n╞══════╡\n│ true │\n└──────┘"], "Parameters": [["*names", "Name(s) of the columns to use in the aggregation."], ["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is False . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no True values,\nthe output is null."]], "Returns": [], "Category": ["Functions"], "index": 62}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.any_horizontal.html#polars.any_horizontal"], "Title": ["any_horizontal"], "Feature": ["any_horizontal"], "Description": ["Compute the bitwise OR horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [False, False, True, True, False, None],\n...         \"b\": [False, True, True, None, None, None],\n...         \"c\": [\"u\", \"v\", \"w\", \"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(any=pl.any_horizontal(\"a\", \"b\"))\nshape: (6, 4)\n┌───────┬───────┬─────┬───────┐\n│ a     ┆ b     ┆ c   ┆ any   │\n│ ---   ┆ ---   ┆ --- ┆ ---   │\n│ bool  ┆ bool  ┆ str ┆ bool  │\n╞═══════╪═══════╪═════╪═══════╡\n│ false ┆ false ┆ u   ┆ false │\n│ false ┆ true  ┆ v   ┆ true  │\n│ true  ┆ true  ┆ w   ┆ true  │\n│ true  ┆ null  ┆ x   ┆ true  │\n│ false ┆ null  ┆ y   ┆ null  │\n│ null  ┆ null  ┆ z   ┆ null  │\n└───────┴───────┴─────┴───────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."]], "Returns": [], "Category": ["Functions"], "index": 63}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.approx_n_unique.html#polars.approx_n_unique"], "Title": ["approx_n_unique"], "Feature": ["approx_n_unique"], "Description": ["Approximate count of unique values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 1],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.approx_n_unique(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘\n>>> df.select(pl.approx_n_unique(\"b\", \"c\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ b   ┆ c   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 3   ┆ 2   │\n└─────┴─────┘"], "Parameters": [["columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 64}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.arange.html#polars.arange"], "Title": ["arange"], "Feature": ["arange"], "Description": ["Generate a range of integers."], "Examples": [">>> pl.arange(0, 3, eager=True)\nshape: (3,)\nSeries: 'literal' [i64]\n[\n        0\n        1\n        2\n]"], "Parameters": [["start", "Lower bound of the range (inclusive)."], ["end", "Upper bound of the range (exclusive)."], ["step", "Step size of the range."], ["dtype", "Data type of the range. Defaults to Int64 ."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of integer data type dtype ."]], "Category": ["Functions"], "index": 65}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.arctan2.html#polars.arctan2"], "Title": ["arctan2"], "Feature": ["arctan2"], "Description": ["Compute two argument arctan in radians."], "Examples": [">>> c = (2**0.5) / 2\n>>> df = pl.DataFrame(\n...     {\n...         \"y\": [c, -c, c, -c],\n...         \"x\": [c, c, -c, -c],\n...     }\n... )\n>>> df.with_columns(pl.arctan2(\"y\", \"x\").alias(\"atan2\"))\nshape: (4, 3)\n┌───────────┬───────────┬───────────┐\n│ y         ┆ x         ┆ atan2     │\n│ ---       ┆ ---       ┆ ---       │\n│ f64       ┆ f64       ┆ f64       │\n╞═══════════╪═══════════╪═══════════╡\n│ 0.707107  ┆ 0.707107  ┆ 0.785398  │\n│ -0.707107 ┆ 0.707107  ┆ -0.785398 │\n│ 0.707107  ┆ -0.707107 ┆ 2.356194  │\n│ -0.707107 ┆ -0.707107 ┆ -2.356194 │\n└───────────┴───────────┴───────────┘"], "Parameters": [["y", "Column name or Expression."], ["x", "Column name or Expression."]], "Returns": [], "Category": ["Functions"], "index": 66}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.arctan2d.html#polars.arctan2d"], "Title": ["arctan2d"], "Feature": ["arctan2d"], "Description": ["Compute two argument arctan in degrees."], "Examples": [">>> c = (2**0.5) / 2\n>>> df = pl.DataFrame(\n...     {\n...         \"y\": [c, -c, c, -c],\n...         \"x\": [c, c, -c, -c],\n...     }\n... )\n>>> df.select(  \n...     pl.arctan2d(\"y\", \"x\").alias(\"atan2d\"),\n...     pl.arctan2(\"y\", \"x\").alias(\"atan2\"),\n... )\nshape: (4, 2)\n┌────────┬───────────┐\n│ atan2d ┆ atan2     │\n│ ---    ┆ ---       │\n│ f64    ┆ f64       │\n╞════════╪═══════════╡\n│ 45.0   ┆ 0.785398  │\n│ -45.0  ┆ -0.785398 │\n│ 135.0  ┆ 2.356194  │\n│ -135.0 ┆ -2.356194 │\n└────────┴───────────┘"], "Parameters": [["y", "Column name or Expression."], ["x", "Column name or Expression."]], "Returns": [], "Category": ["Functions"], "index": 67}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.median.html#polars.Expr.median"], "Title": ["Expr.median"], "Feature": ["Expr.median"], "Description": ["Get median value using linear interpolation."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").median())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 68}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.arg_sort_by.html#polars.arg_sort_by"], "Title": ["arg_sort_by"], "Feature": ["arg_sort_by"], "Description": ["Return the row indices that would sort the column(s)."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [0, 1, 1, 0],\n...         \"b\": [3, 2, 3, 2],\n...         \"c\": [1, 2, 3, 4],\n...     }\n... )\n>>> df.select(pl.arg_sort_by(\"a\"))\nshape: (4, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 0   │\n│ 3   │\n│ 1   │\n│ 2   │\n└─────┘", ">>> df.select(pl.arg_sort_by([\"a\", \"b\"], descending=True))\nshape: (4, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n│ 1   │\n│ 0   │\n│ 3   │\n└─────┘", ">>> df.select(pl.col(\"c\").gather(pl.arg_sort_by(\"a\")))\nshape: (4, 1)\n┌─────┐\n│ c   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 4   │\n│ 2   │\n│ 3   │\n└─────┘"], "Parameters": [["exprs", "Column(s) to arg sort by. Accepts expression input. Strings are parsed as column\nnames."], ["*more_exprs", "Additional columns to arg sort by, specified as positional arguments."], ["descending", "Sort in descending order. When sorting by multiple columns, can be specified\nper column by passing a sequence of booleans."], ["nulls_last", "Place null values last."], ["multithreaded", "Sort using multiple threads."], ["maintain_order", "Whether the order should be maintained if elements are equal."]], "Returns": [], "Category": ["Functions"], "index": 69}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.arg_where.html#polars.arg_where"], "Title": ["arg_where"], "Feature": ["arg_where"], "Description": ["Return indices whereconditionevaluatesTrue."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4, 5]})\n>>> df.select(\n...     [\n...         pl.arg_where(pl.col(\"a\") % 2 == 0),\n...     ]\n... ).to_series()\nshape: (2,)\nSeries: 'a' [u32]\n[\n    1\n    3\n]"], "Parameters": [["condition", "Boolean expression to evaluate"], ["eager", "Evaluate immediately and return a Series ; this requires that the given\ncondition is itself a Series . If set to False (default), return\nan expression instead."]], "Returns": [], "Category": ["Functions"], "index": 70}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.business_day_count.html#polars.business_day_count"], "Title": ["business_day_count"], "Feature": ["business_day_count"], "Description": ["Count the number of business days betweenstartandend(not includingend)."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"start\": [date(2020, 1, 1), date(2020, 1, 2)],\n...         \"end\": [date(2020, 1, 2), date(2020, 1, 10)],\n...     }\n... )\n>>> df.with_columns(\n...     business_day_count=pl.business_day_count(\"start\", \"end\"),\n... )\nshape: (2, 3)\n┌────────────┬────────────┬────────────────────┐\n│ start      ┆ end        ┆ business_day_count │\n│ ---        ┆ ---        ┆ ---                │\n│ date       ┆ date       ┆ i32                │\n╞════════════╪════════════╪════════════════════╡\n│ 2020-01-01 ┆ 2020-01-02 ┆ 1                  │\n│ 2020-01-02 ┆ 2020-01-10 ┆ 6                  │\n└────────────┴────────────┴────────────────────┘", ">>> week_mask = (True, True, True, True, True, True, False)\n>>> df.with_columns(\n...     business_day_count=pl.business_day_count(\n...         \"start\", \"end\", week_mask=week_mask\n...     ),\n... )\nshape: (2, 3)\n┌────────────┬────────────┬────────────────────┐\n│ start      ┆ end        ┆ business_day_count │\n│ ---        ┆ ---        ┆ ---                │\n│ date       ┆ date       ┆ i32                │\n╞════════════╪════════════╪════════════════════╡\n│ 2020-01-01 ┆ 2020-01-02 ┆ 1                  │\n│ 2020-01-02 ┆ 2020-01-10 ┆ 7                  │\n└────────────┴────────────┴────────────────────┘", ">>> from datetime import date\n>>> holidays = [date(2020, 1, 1), date(2020, 1, 2)]\n>>> df.with_columns(\n...     business_day_count=pl.business_day_count(\"start\", \"end\", holidays=holidays)\n... )\nshape: (2, 3)\n┌────────────┬────────────┬────────────────────┐\n│ start      ┆ end        ┆ business_day_count │\n│ ---        ┆ ---        ┆ ---                │\n│ date       ┆ date       ┆ i32                │\n╞════════════╪════════════╪════════════════════╡\n│ 2020-01-01 ┆ 2020-01-02 ┆ 0                  │\n│ 2020-01-02 ┆ 2020-01-10 ┆ 5                  │\n└────────────┴────────────┴────────────────────┘"], "Parameters": [["start", "Start dates."], ["end", "End dates."], ["week_mask", "Which days of the week to count. The default is Monday to Friday.\nIf you wanted to count only Monday to Thursday, you would pass (True, True, True, True, False, False, False) ."], ["holidays", "Holidays to exclude from the count. The Python package python-holidays may come in handy here. You can install it with pip install holidays ,\nand then, to get all Dutch holidays for years 2020-2024: import holidays my_holidays = holidays . country_holidays ( \"NL\" , years = range ( 2020 , 2025 )) Copy to clipboard and pass holidays=my_holidays when you call business_day_count ."]], "Returns": [["Expr", ""]], "Category": ["Functions"], "index": 71}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.coalesce.html#polars.coalesce"], "Title": ["coalesce"], "Feature": ["coalesce"], "Description": ["Folds the columns from left to right, keeping the first non-null value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, None, None, None],\n...         \"b\": [1, 2, None, None],\n...         \"c\": [5, None, 3, None],\n...     }\n... )", ">>> df.with_columns(pl.coalesce(\"a\", \"b\", \"c\", 10).alias(\"d\"))\nshape: (4, 4)\n┌──────┬──────┬──────┬─────┐\n│ a    ┆ b    ┆ c    ┆ d   │\n│ ---  ┆ ---  ┆ ---  ┆ --- │\n│ i64  ┆ i64  ┆ i64  ┆ i64 │\n╞══════╪══════╪══════╪═════╡\n│ 1    ┆ 1    ┆ 5    ┆ 1   │\n│ null ┆ 2    ┆ null ┆ 2   │\n│ null ┆ null ┆ 3    ┆ 3   │\n│ null ┆ null ┆ null ┆ 10  │\n└──────┴──────┴──────┴─────┘", ">>> df.with_columns(pl.coalesce(pl.col([\"a\", \"b\", \"c\"]), 10.0).alias(\"d\"))\nshape: (4, 4)\n┌──────┬──────┬──────┬──────┐\n│ a    ┆ b    ┆ c    ┆ d    │\n│ ---  ┆ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ i64  ┆ f64  │\n╞══════╪══════╪══════╪══════╡\n│ 1    ┆ 1    ┆ 5    ┆ 1.0  │\n│ null ┆ 2    ┆ null ┆ 2.0  │\n│ null ┆ null ┆ 3    ┆ 3.0  │\n│ null ┆ null ┆ null ┆ 10.0 │\n└──────┴──────┴──────┴──────┘", ">>> s1 = pl.Series(\"a\", [None, 2, None])\n>>> s2 = pl.Series(\"b\", [1, None, 3])\n>>> pl.coalesce(s1, s2, eager=True)\nshape: (3,)\nSeries: 'a' [i64]\n[\n    1\n    2\n    3\n]"], "Parameters": [["exprs", "Columns to coalesce. Accepts expression input. Strings are parsed as column\nnames, other non-expression inputs are parsed as literals."], ["*more_exprs", "Additional columns to coalesce, specified as positional arguments."], ["eager", "Evaluate immediately and return a Series ; this requires that at least one\nof the given arguments is a Series . If set to False (default), return\nan expression instead."]], "Returns": [], "Category": ["Functions"], "index": 72}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.concat_arr.html#polars.concat_arr"], "Title": ["concat_arr"], "Feature": ["concat_arr"], "Description": ["Horizontally concatenate columns into a single array column."], "Examples": [">>> (\n...     pl.select(\n...         a=pl.Series([[1], [3], None], dtype=pl.Array(pl.Int64, 1)),\n...         b=pl.Series([[3], [None], [5]], dtype=pl.Array(pl.Int64, 1)),\n...     ).with_columns(\n...         pl.concat_arr(\"a\", \"b\").alias(\"concat_arr(a, b)\"),\n...         pl.concat_arr(\"a\", pl.first(\"b\")).alias(\"concat_arr(a, first(b))\"),\n...     )\n... )\nshape: (3, 4)\n┌───────────────┬───────────────┬──────────────────┬─────────────────────────┐\n│ a             ┆ b             ┆ concat_arr(a, b) ┆ concat_arr(a, first(b)) │\n│ ---           ┆ ---           ┆ ---              ┆ ---                     │\n│ array[i64, 1] ┆ array[i64, 1] ┆ array[i64, 2]    ┆ array[i64, 2]           │\n╞═══════════════╪═══════════════╪══════════════════╪═════════════════════════╡\n│ [1]           ┆ [3]           ┆ [1, 3]           ┆ [1, 3]                  │\n│ [3]           ┆ [null]        ┆ [3, null]        ┆ [3, 3]                  │\n│ null          ┆ [5]           ┆ null             ┆ null                    │\n└───────────────┴───────────────┴──────────────────┴─────────────────────────┘", ">>> (\n...     pl.select(\n...         c=pl.Series([None, 5, 6], dtype=pl.Int64),\n...     )\n...     .with_columns(d=pl.col(\"c\").reverse())\n...     .with_columns(\n...         pl.concat_arr(\"c\", \"d\").alias(\"concat_arr(c, d)\"),\n...     )\n... )\nshape: (3, 3)\n┌──────┬──────┬──────────────────┐\n│ c    ┆ d    ┆ concat_arr(c, d) │\n│ ---  ┆ ---  ┆ ---              │\n│ i64  ┆ i64  ┆ array[i64, 2]    │\n╞══════╪══════╪══════════════════╡\n│ null ┆ 6    ┆ [null, 6]        │\n│ 5    ┆ 5    ┆ [5, 5]           │\n│ 6    ┆ null ┆ [6, null]        │\n└──────┴──────┴──────────────────┘", ">>> (\n...     pl.select(\n...         a=pl.Series([[1], [3], None], dtype=pl.Array(pl.Int64, 1)),\n...         b=pl.Series([[3], [None], [5]], dtype=pl.Array(pl.Int64, 1)),\n...         c=pl.Series([None, 5, 6], dtype=pl.Int64),\n...     ).with_columns(\n...         pl.concat_arr(\"a\", \"b\", \"c\").alias(\"concat_arr(a, b, c)\"),\n...     )\n... )\nshape: (3, 4)\n┌───────────────┬───────────────┬──────┬─────────────────────┐\n│ a             ┆ b             ┆ c    ┆ concat_arr(a, b, c) │\n│ ---           ┆ ---           ┆ ---  ┆ ---                 │\n│ array[i64, 1] ┆ array[i64, 1] ┆ i64  ┆ array[i64, 3]       │\n╞═══════════════╪═══════════════╪══════╪═════════════════════╡\n│ [1]           ┆ [3]           ┆ null ┆ [1, 3, null]        │\n│ [3]           ┆ [null]        ┆ 5    ┆ [3, null, 5]        │\n│ null          ┆ [5]           ┆ 6    ┆ null                │\n└───────────────┴───────────────┴──────┴─────────────────────┘", ">>> (\n...     pl.select(\n...         a=pl.Series([1, 3, None]),\n...     ).with_columns(\n...         pl.concat_arr(\"a\", pl.lit(0, dtype=pl.Int64)).alias(\"concat_arr(a, 0)\"),\n...         pl.concat_arr(\"a\", pl.sum(\"a\")).alias(\"concat_arr(a, sum(a))\"),\n...         pl.concat_arr(\"a\", pl.max(\"a\")).alias(\"concat_arr(a, max(a))\"),\n...     )\n... )\nshape: (3, 4)\n┌──────┬──────────────────┬───────────────────────┬───────────────────────┐\n│ a    ┆ concat_arr(a, 0) ┆ concat_arr(a, sum(a)) ┆ concat_arr(a, max(a)) │\n│ ---  ┆ ---              ┆ ---                   ┆ ---                   │\n│ i64  ┆ array[i64, 2]    ┆ array[i64, 2]         ┆ array[i64, 2]         │\n╞══════╪══════════════════╪═══════════════════════╪═══════════════════════╡\n│ 1    ┆ [1, 0]           ┆ [1, 4]                ┆ [1, 3]                │\n│ 3    ┆ [3, 0]           ┆ [3, 4]                ┆ [3, 3]                │\n│ null ┆ [null, 0]        ┆ [null, 4]             ┆ [null, 3]             │\n└──────┴──────────────────┴───────────────────────┴───────────────────────┘"], "Parameters": [["exprs", "Columns to concatenate into a single array column. Accepts expression input.\nStrings are parsed as column names, other non-expression inputs are parsed as\nliterals."], ["*more_exprs", "Additional columns to concatenate into a single array column, specified as\npositional arguments."]], "Returns": [], "Category": ["Functions"], "index": 73}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.concat_list.html#polars.concat_list"], "Title": ["concat_list"], "Feature": ["concat_list"], "Description": ["Horizontally concatenate columns into a single list column."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2], [3], [4, 5]], \"b\": [[4], [], None]})\n>>> df.with_columns(concat_list=pl.concat_list(\"a\", \"b\"))\nshape: (3, 3)\n┌───────────┬───────────┬─────────────┐\n│ a         ┆ b         ┆ concat_list │\n│ ---       ┆ ---       ┆ ---         │\n│ list[i64] ┆ list[i64] ┆ list[i64]   │\n╞═══════════╪═══════════╪═════════════╡\n│ [1, 2]    ┆ [4]       ┆ [1, 2, 4]   │\n│ [3]       ┆ []        ┆ [3]         │\n│ [4, 5]    ┆ null      ┆ null        │\n└───────────┴───────────┴─────────────┘", ">>> df.select(\"a\", concat_list=pl.concat_list(\"a\", pl.lit(\"x\")))\nshape: (3, 2)\n┌───────────┬─────────────────┐\n│ a         ┆ concat_list     │\n│ ---       ┆ ---             │\n│ list[i64] ┆ list[str]       │\n╞═══════════╪═════════════════╡\n│ [1, 2]    ┆ [\"1\", \"2\", \"x\"] │\n│ [3]       ┆ [\"3\", \"x\"]      │\n│ [4, 5]    ┆ [\"4\", \"5\", \"x\"] │\n└───────────┴─────────────────┘", ">>> df = pl.DataFrame({\"A\": [1.0, 2.0, 9.0, 2.0, 13.0]})\n>>> df = df.select([pl.col(\"A\").shift(i).alias(f\"A_lag_{i}\") for i in range(3)])\n>>> df.select(\n...     pl.concat_list([f\"A_lag_{i}\" for i in range(3)][::-1]).alias(\"A_rolling\")\n... )\nshape: (5, 1)\n┌───────────────────┐\n│ A_rolling         │\n│ ---               │\n│ list[f64]         │\n╞═══════════════════╡\n│ [null, null, 1.0] │\n│ [null, 1.0, 2.0]  │\n│ [1.0, 2.0, 9.0]   │\n│ [2.0, 9.0, 2.0]   │\n│ [9.0, 2.0, 13.0]  │\n└───────────────────┘"], "Parameters": [["exprs", "Columns to concatenate into a single list column. Accepts expression input.\nStrings are parsed as column names, other non-expression inputs are parsed as\nliterals."], ["*more_exprs", "Additional columns to concatenate into a single list column, specified as\npositional arguments."]], "Returns": [], "Category": ["Functions"], "index": 74}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.concat_str.html#polars.concat_str"], "Title": ["concat_str"], "Feature": ["concat_str"], "Description": ["Horizontally concatenate columns into a single string column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [\"dogs\", \"cats\", None],\n...         \"c\": [\"play\", \"swim\", \"walk\"],\n...     }\n... )\n>>> df.with_columns(\n...     pl.concat_str(\n...         [\n...             pl.col(\"a\") * 2,\n...             pl.col(\"b\"),\n...             pl.col(\"c\"),\n...         ],\n...         separator=\" \",\n...     ).alias(\"full_sentence\"),\n... )\nshape: (3, 4)\n┌─────┬──────┬──────┬───────────────┐\n│ a   ┆ b    ┆ c    ┆ full_sentence │\n│ --- ┆ ---  ┆ ---  ┆ ---           │\n│ i64 ┆ str  ┆ str  ┆ str           │\n╞═════╪══════╪══════╪═══════════════╡\n│ 1   ┆ dogs ┆ play ┆ 2 dogs play   │\n│ 2   ┆ cats ┆ swim ┆ 4 cats swim   │\n│ 3   ┆ null ┆ walk ┆ null          │\n└─────┴──────┴──────┴───────────────┘"], "Parameters": [["exprs", "Columns to concatenate into a single string column. Accepts expression input.\nStrings are parsed as column names, other non-expression inputs are parsed as\nliterals. Non- String columns are cast to String ."], ["*more_exprs", "Additional columns to concatenate into a single string column, specified as\npositional arguments."], ["separator", "String that will be used to separate the values of each column."], ["ignore_nulls", "Ignore null values (default is False ). If set to False , null values will be propagated.\nif the row contains any null values, the output is null."]], "Returns": [], "Category": ["Functions"], "index": 75}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.corr.html#polars.corr"], "Title": ["corr"], "Feature": ["corr"], "Description": ["Compute the Pearson's or Spearman rank correlation between two columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.corr(\"a\", \"b\"))\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.544705 │\n└──────────┘", ">>> df.select(pl.corr(\"a\", \"b\", method=\"spearman\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.5 │\n└─────┘", ">>> s1 = pl.Series(\"a\", [1, 8, 3])\n>>> s2 = pl.Series(\"b\", [4, 5, 2])\n>>> pl.corr(s1, s2, eager=True)\nshape: (1,)\nSeries: 'a' [f64]\n[\n    0.544705\n]\n>>> pl.corr(s1, s2, method=\"spearman\", eager=True)\nshape: (1,)\nSeries: 'a' [f64]\n[\n    0.5\n]"], "Parameters": [["a", "Column name or Expression."], ["b", "Column name or Expression."], ["ddof", "Has no effect, do not use. Deprecated since version 1.17.0."], ["method {‘pearson’, ‘spearman’}", "Correlation method."], ["propagate_nans", "If True any NaN encountered will lead to NaN in the output.\nDefaults to False where NaN are regarded as larger than any finite number\nand thus lead to the highest rank."], ["eager", "Evaluate immediately and return a Series ; this requires that at least one\nof the given arguments is a Series . If set to False (default), return\nan expression instead."]], "Returns": [], "Category": ["Functions"], "index": 76}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.count.html#polars.count"], "Title": ["count"], "Feature": ["count"], "Description": ["Return the number of non-null values in the column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None],\n...         \"b\": [3, None, None],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.count(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘", ">>> df.select(pl.count(\"b\", \"c\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ b   ┆ c   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 1   ┆ 3   │\n└─────┴─────┘", ">>> df.select(pl.count())  \nshape: (1, 1)\n┌───────┐\n│ count │\n│ ---   │\n│ u32   │\n╞═══════╡\n│ 3     │\n└───────┘"], "Parameters": [["*columns", "One or more column names."]], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Functions"], "index": 77}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.cov.html#polars.cov"], "Title": ["cov"], "Feature": ["cov"], "Description": ["Compute the covariance between two columns/ expressions."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     },\n... )", ">>> df.select(\n...     x=pl.cov(\"a\", \"b\"),\n...     y=pl.cov(\"a\", \"b\", ddof=2),\n... )\nshape: (1, 2)\n┌─────┬─────┐\n│ x   ┆ y   │\n│ --- ┆ --- │\n│ f64 ┆ f64 │\n╞═════╪═════╡\n│ 3.0 ┆ 6.0 │\n└─────┴─────┘", ">>> s1 = pl.Series(\"a\", [1, 8, 3])\n>>> s2 = pl.Series(\"b\", [4, 5, 2])\n>>> pl.cov(s1, s2, eager=True)\nshape: (1,)\nSeries: 'a' [f64]\n[\n    3.0\n]"], "Parameters": [["a", "Column name or Expression."], ["b", "Column name or Expression."], ["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."], ["eager", "Evaluate immediately and return a Series ; this requires that at least one\nof the given arguments is a Series . If set to False (default), return\nan expression instead."]], "Returns": [], "Category": ["Functions"], "index": 78}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.min.html#polars.Expr.min"], "Title": ["Expr.min"], "Feature": ["Expr.min"], "Description": ["Get minimum value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1.0, float(\"nan\"), 1.0]})\n>>> df.select(pl.col(\"a\").min())\nshape: (1, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ -1.0 │\n└──────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 79}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.cum_count.html#polars.cum_count"], "Title": ["cum_count"], "Feature": ["cum_count"], "Description": ["Return the cumulative count of the non-null values in the column."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, None], \"b\": [3, None, None]})\n>>> df.with_columns(\n...     ca=pl.cum_count(\"a\"),\n...     cb=pl.cum_count(\"b\"),\n... )\nshape: (3, 4)\n┌──────┬──────┬─────┬─────┐\n│ a    ┆ b    ┆ ca  ┆ cb  │\n│ ---  ┆ ---  ┆ --- ┆ --- │\n│ i64  ┆ i64  ┆ u32 ┆ u32 │\n╞══════╪══════╪═════╪═════╡\n│ 1    ┆ 3    ┆ 1   ┆ 1   │\n│ 2    ┆ null ┆ 2   ┆ 1   │\n│ null ┆ null ┆ 2   ┆ 1   │\n└──────┴──────┴─────┴─────┘"], "Parameters": [["*columns", "Name(s) of the columns to use."], ["reverse", "Reverse the operation."]], "Returns": [], "Category": ["Functions"], "index": 80}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.cum_fold.html#polars.cum_fold"], "Title": ["cum_fold"], "Feature": ["cum_fold"], "Description": ["Cumulatively fold horizontally across columns with a left fold."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [3, 4, 5],\n...         \"c\": [5, 6, 7],\n...     }\n... )\n>>> df.with_columns(\n...     pl.cum_fold(acc=pl.lit(1), function=lambda acc, x: acc + x, exprs=pl.all())\n... )\nshape: (3, 4)\n┌─────┬─────┬─────┬───────────┐\n│ a   ┆ b   ┆ c   ┆ cum_fold  │\n│ --- ┆ --- ┆ --- ┆ ---       │\n│ i64 ┆ i64 ┆ i64 ┆ struct[3] │\n╞═════╪═════╪═════╪═══════════╡\n│ 1   ┆ 3   ┆ 5   ┆ {2,5,10}  │\n│ 2   ┆ 4   ┆ 6   ┆ {3,7,13}  │\n│ 3   ┆ 5   ┆ 7   ┆ {4,9,16}  │\n└─────┴─────┴─────┴───────────┘"], "Parameters": [["acc", "Accumulator expression. This is the value that will be initialized when the fold\nstarts. For a sum this could for instance be lit(0)."], ["function", "Function to apply over the accumulator and the value.\nFn(acc, value) -> new_value"], ["exprs", "Expressions to aggregate over. May also be a wildcard expression."], ["returns_scalar", "Whether or not function applied returns a scalar. This must be set correctly\nby the user."], ["return_dtype", "Output datatype.\nIf not set, the dtype will be inferred based on the dtype of the accumulator."], ["include_init", "Include the initial accumulator state as struct field."]], "Returns": [], "Category": ["Functions"], "index": 81}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.cum_reduce.html#polars.cum_reduce"], "Title": ["cum_reduce"], "Feature": ["cum_reduce"], "Description": ["Cumulatively reduce horizontally across columns with a left fold."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [3, 4, 5],\n...         \"c\": [5, 6, 7],\n...     }\n... )\n>>> df.with_columns(pl.cum_reduce(function=lambda acc, x: acc + x, exprs=pl.all()))\nshape: (3, 4)\n┌─────┬─────┬─────┬────────────┐\n│ a   ┆ b   ┆ c   ┆ cum_reduce │\n│ --- ┆ --- ┆ --- ┆ ---        │\n│ i64 ┆ i64 ┆ i64 ┆ struct[3]  │\n╞═════╪═════╪═════╪════════════╡\n│ 1   ┆ 3   ┆ 5   ┆ {1,4,9}    │\n│ 2   ┆ 4   ┆ 6   ┆ {2,6,12}   │\n│ 3   ┆ 5   ┆ 7   ┆ {3,8,15}   │\n└─────┴─────┴─────┴────────────┘"], "Parameters": [["function", "Function to apply over the accumulator and the value.\nFn(acc, value) -> new_value"], ["exprs", "Expressions to aggregate over. May also be a wildcard expression."], ["return_dtype", "Output datatype.\nIf not set, the dtype will be inferred based on the dtype of the input\nexpressions."], ["include_init", "Include the initial accumulator state as struct field."]], "Returns": [], "Category": ["Functions"], "index": 82}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.cum_sum.html#polars.cum_sum"], "Title": ["cum_sum"], "Feature": ["cum_sum"], "Description": ["Cumulatively sum all values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [4, 5, 6],\n...     }\n... )\n>>> df.select(pl.cum_sum(\"a\"))\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 3   │\n│ 6   │\n└─────┘"], "Parameters": [["*names", "Name(s) of the columns to use in the aggregation."]], "Returns": [], "Category": ["Functions"], "index": 83}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.cum_sum_horizontal.html#polars.cum_sum_horizontal"], "Title": ["cum_sum_horizontal"], "Feature": ["cum_sum_horizontal"], "Description": ["Cumulatively sum all values horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, None],\n...         \"c\": [\"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(pl.cum_sum_horizontal(\"a\", \"b\"))\nshape: (3, 4)\n┌─────┬──────┬─────┬───────────┐\n│ a   ┆ b    ┆ c   ┆ cum_sum   │\n│ --- ┆ ---  ┆ --- ┆ ---       │\n│ i64 ┆ i64  ┆ str ┆ struct[2] │\n╞═════╪══════╪═════╪═══════════╡\n│ 1   ┆ 4    ┆ x   ┆ {1,5}     │\n│ 8   ┆ 5    ┆ y   ┆ {8,13}    │\n│ 3   ┆ null ┆ z   ┆ {3,null}  │\n└─────┴──────┴─────┴───────────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."]], "Returns": [], "Category": ["Functions"], "index": 84}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.date.html#polars.date"], "Title": ["date"], "Feature": ["date"], "Description": ["Create a Polars literal expression of type Date."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"month\": [1, 2, 3],\n...         \"day\": [4, 5, 6],\n...     }\n... )\n>>> df.with_columns(pl.date(2024, pl.col(\"month\"), pl.col(\"day\")))\nshape: (3, 3)\n┌───────┬─────┬────────────┐\n│ month ┆ day ┆ date       │\n│ ---   ┆ --- ┆ ---        │\n│ i64   ┆ i64 ┆ date       │\n╞═══════╪═════╪════════════╡\n│ 1     ┆ 4   ┆ 2024-01-04 │\n│ 2     ┆ 5   ┆ 2024-02-05 │\n│ 3     ┆ 6   ┆ 2024-03-06 │\n└───────┴─────┴────────────┘", ">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"start\": [date(2024, 1, 1), date(2024, 1, 1), date(2024, 1, 1)],\n...         \"end\": [date(2024, 5, 1), date(2024, 7, 1), date(2024, 9, 1)],\n...     }\n... )\n>>> df.filter(pl.col(\"end\") > pl.date(2024, 6, 1))\nshape: (2, 2)\n┌────────────┬────────────┐\n│ start      ┆ end        │\n│ ---        ┆ ---        │\n│ date       ┆ date       │\n╞════════════╪════════════╡\n│ 2024-01-01 ┆ 2024-07-01 │\n│ 2024-01-01 ┆ 2024-09-01 │\n└────────────┴────────────┘"], "Parameters": [["year", "column or literal."], ["month", "column or literal, ranging from 1-12."], ["day", "column or literal, ranging from 1-31."]], "Returns": [["Expr", "Expression of data type Date ."]], "Category": ["Functions"], "index": 85}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.date_range.html#polars.date_range"], "Title": ["date_range"], "Feature": ["date_range"], "Description": ["Generate a date range."], "Examples": [">>> from datetime import date\n>>> pl.date_range(date(2022, 1, 1), date(2022, 3, 1), \"1mo\", eager=True).alias(\n...     \"date\"\n... )\nshape: (3,)\nSeries: 'date' [date]\n[\n    2022-01-01\n    2022-02-01\n    2022-03-01\n]", ">>> from datetime import timedelta\n>>> pl.date_range(\n...     date(1985, 1, 1),\n...     date(1985, 1, 10),\n...     timedelta(days=2),\n...     eager=True,\n... ).alias(\"date\")\nshape: (5,)\nSeries: 'date' [date]\n[\n    1985-01-01\n    1985-01-03\n    1985-01-05\n    1985-01-07\n    1985-01-09\n]", ">>> df = pl.DataFrame(\n...     {\n...         \"date\": [\n...             date(2024, 1, 1),\n...             date(2024, 1, 2),\n...             date(2024, 1, 1),\n...             date(2024, 1, 3),\n...         ],\n...         \"key\": [\"one\", \"one\", \"two\", \"two\"],\n...     }\n... )\n>>> result = (\n...     df.group_by(\"key\")\n...     .agg(pl.date_range(pl.col(\"date\").min(), pl.col(\"date\").max()))\n...     .sort(\"key\")\n... )\n>>> with pl.Config(fmt_str_lengths=50):\n...     print(result)\nshape: (2, 2)\n┌─────┬──────────────────────────────────────┐\n│ key ┆ date                                 │\n│ --- ┆ ---                                  │\n│ str ┆ list[date]                           │\n╞═════╪══════════════════════════════════════╡\n│ one ┆ [2024-01-01, 2024-01-02]             │\n│ two ┆ [2024-01-01, 2024-01-02, 2024-01-03] │\n└─────┴──────────────────────────────────────┘"], "Parameters": [["start", "Lower bound of the date range."], ["end", "Upper bound of the date range."], ["interval", "Interval of the range periods, specified as a Python timedelta object\nor using the Polars duration string language (see “Notes” section below).\nMust consist of full days."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the range are closed (inclusive)."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type Date ."]], "Category": ["Functions"], "index": 86}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.date_ranges.html#polars.date_ranges"], "Title": ["date_ranges"], "Feature": ["date_ranges"], "Description": ["Create a column of date ranges."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"start\": [date(2022, 1, 1), date(2022, 1, 2)],\n...         \"end\": date(2022, 1, 3),\n...     }\n... )\n>>> with pl.Config(fmt_str_lengths=50):\n...     df.with_columns(date_range=pl.date_ranges(\"start\", \"end\"))\nshape: (2, 3)\n┌────────────┬────────────┬──────────────────────────────────────┐\n│ start      ┆ end        ┆ date_range                           │\n│ ---        ┆ ---        ┆ ---                                  │\n│ date       ┆ date       ┆ list[date]                           │\n╞════════════╪════════════╪══════════════════════════════════════╡\n│ 2022-01-01 ┆ 2022-01-03 ┆ [2022-01-01, 2022-01-02, 2022-01-03] │\n│ 2022-01-02 ┆ 2022-01-03 ┆ [2022-01-02, 2022-01-03]             │\n└────────────┴────────────┴──────────────────────────────────────┘"], "Parameters": [["start", "Lower bound of the date range."], ["end", "Upper bound of the date range."], ["interval", "Interval of the range periods, specified as a Python timedelta object\nor using the Polars duration string language (see “Notes” section below).\nMust consist of full days."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the range are closed (inclusive)."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type List(Date) ."]], "Category": ["Functions"], "index": 87}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.datetime.html#polars.datetime"], "Title": ["datetime"], "Feature": ["datetime"], "Description": ["Create a Polars literal expression of type Datetime."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"month\": [1, 2, 3],\n...         \"day\": [4, 5, 6],\n...         \"hour\": [12, 13, 14],\n...         \"minute\": [15, 30, 45],\n...     }\n... )\n>>> df.with_columns(\n...     pl.datetime(\n...         2024,\n...         pl.col(\"month\"),\n...         pl.col(\"day\"),\n...         pl.col(\"hour\"),\n...         pl.col(\"minute\"),\n...         time_zone=\"Australia/Sydney\",\n...     )\n... )\nshape: (3, 5)\n┌───────┬─────┬──────┬────────┬────────────────────────────────┐\n│ month ┆ day ┆ hour ┆ minute ┆ datetime                       │\n│ ---   ┆ --- ┆ ---  ┆ ---    ┆ ---                            │\n│ i64   ┆ i64 ┆ i64  ┆ i64    ┆ datetime[μs, Australia/Sydney] │\n╞═══════╪═════╪══════╪════════╪════════════════════════════════╡\n│ 1     ┆ 4   ┆ 12   ┆ 15     ┆ 2024-01-04 12:15:00 AEDT       │\n│ 2     ┆ 5   ┆ 13   ┆ 30     ┆ 2024-02-05 13:30:00 AEDT       │\n│ 3     ┆ 6   ┆ 14   ┆ 45     ┆ 2024-03-06 14:45:00 AEDT       │\n└───────┴─────┴──────┴────────┴────────────────────────────────┘", ">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"start\": [\n...             datetime(2024, 1, 1, 0, 0, 0),\n...             datetime(2024, 1, 1, 0, 0, 0),\n...             datetime(2024, 1, 1, 0, 0, 0),\n...         ],\n...         \"end\": [\n...             datetime(2024, 5, 1, 20, 15, 10),\n...             datetime(2024, 7, 1, 21, 25, 20),\n...             datetime(2024, 9, 1, 22, 35, 30),\n...         ],\n...     }\n... )\n>>> df.filter(pl.col(\"end\") > pl.datetime(2024, 6, 1))\n    shape: (2, 2)\n┌─────────────────────┬─────────────────────┐\n│ start               ┆ end                 │\n│ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╡\n│ 2024-01-01 00:00:00 ┆ 2024-07-01 21:25:20 │\n│ 2024-01-01 00:00:00 ┆ 2024-09-01 22:35:30 │\n└─────────────────────┴─────────────────────┘"], "Parameters": [["year", "Column or literal."], ["month", "Column or literal, ranging from 1-12."], ["day", "Column or literal, ranging from 1-31."], ["hour", "Column or literal, ranging from 0-23."], ["minute", "Column or literal, ranging from 0-59."], ["second", "Column or literal, ranging from 0-59."], ["microsecond", "Column or literal, ranging from 0-999999."], ["time_unit {‘us’, ‘ms’, ‘ns’}", "Time unit of the resulting expression."], ["time_zone", "Time zone of the resulting expression."], ["ambiguous", "Determine how to deal with ambiguous datetimes: 'raise' (default): raise 'earliest' : use the earliest datetime 'latest' : use the latest datetime 'null' : set to null"]], "Returns": [["Expr", "Expression of data type Datetime ."]], "Category": ["Functions"], "index": 88}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.datetime_range.html#polars.datetime_range"], "Title": ["datetime_range"], "Feature": ["datetime_range"], "Description": ["Generate a datetime range."], "Examples": [">>> from datetime import datetime\n>>> pl.datetime_range(\n...     datetime(2022, 1, 1), datetime(2022, 3, 1), \"1mo\", eager=True\n... ).alias(\"datetime\")\nshape: (3,)\nSeries: 'datetime' [datetime[μs]]\n[\n    2022-01-01 00:00:00\n    2022-02-01 00:00:00\n    2022-03-01 00:00:00\n]", ">>> from datetime import date, timedelta\n>>> pl.datetime_range(\n...     date(1985, 1, 1),\n...     date(1985, 1, 10),\n...     timedelta(days=1, hours=12),\n...     time_unit=\"ms\",\n...     eager=True,\n... ).alias(\"datetime\")\nshape: (7,)\nSeries: 'datetime' [datetime[ms]]\n[\n    1985-01-01 00:00:00\n    1985-01-02 12:00:00\n    1985-01-04 00:00:00\n    1985-01-05 12:00:00\n    1985-01-07 00:00:00\n    1985-01-08 12:00:00\n    1985-01-10 00:00:00\n]", ">>> pl.datetime_range(\n...     datetime(2022, 1, 1),\n...     datetime(2022, 3, 1),\n...     \"1mo\",\n...     time_zone=\"America/New_York\",\n...     eager=True,\n... ).alias(\"datetime\")\nshape: (3,)\nSeries: 'datetime' [datetime[μs, America/New_York]]\n[\n    2022-01-01 00:00:00 EST\n    2022-02-01 00:00:00 EST\n    2022-03-01 00:00:00 EST\n]", ">>> df = pl.DataFrame(\n...     {\n...         \"date\": [\n...             date(2024, 1, 1),\n...             date(2024, 1, 2),\n...             date(2024, 1, 1),\n...             date(2024, 1, 3),\n...         ],\n...         \"key\": [\"one\", \"one\", \"two\", \"two\"],\n...     }\n... )\n>>> result = (\n...     df.group_by(\"key\")\n...     .agg(pl.datetime_range(pl.col(\"date\").min(), pl.col(\"date\").max()))\n...     .sort(\"key\")\n... )\n>>> with pl.Config(fmt_str_lengths=70):\n...     print(result)\nshape: (2, 2)\n┌─────┬─────────────────────────────────────────────────────────────────┐\n│ key ┆ date                                                            │\n│ --- ┆ ---                                                             │\n│ str ┆ list[datetime[μs]]                                              │\n╞═════╪═════════════════════════════════════════════════════════════════╡\n│ one ┆ [2024-01-01 00:00:00, 2024-01-02 00:00:00]                      │\n│ two ┆ [2024-01-01 00:00:00, 2024-01-02 00:00:00, 2024-01-03 00:00:00] │\n└─────┴─────────────────────────────────────────────────────────────────┘"], "Parameters": [["start", "Lower bound of the datetime range."], ["end", "Upper bound of the datetime range."], ["interval", "Interval of the range periods, specified as a Python timedelta object\nor using the Polars duration string language (see “Notes” section below)."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the range are closed (inclusive)."], ["time_unit {None, ‘ns’, ‘us’, ‘ms’}", "Time unit of the resulting Datetime data type."], ["time_zone", "Time zone of the resulting Datetime data type."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type Datetime ."]], "Category": ["Functions"], "index": 89}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.n_unique.html#polars.Expr.n_unique"], "Title": ["Expr.n_unique"], "Feature": ["Expr.n_unique"], "Description": ["Count unique values."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 1, 2, 2, 3], \"y\": [1, 1, 1, None, None]})\n>>> df.select(\n...     x_unique=pl.col(\"x\").n_unique(),\n...     y_unique=pl.col(\"y\").n_unique(),\n... )\nshape: (1, 2)\n┌──────────┬──────────┐\n│ x_unique ┆ y_unique │\n│ ---      ┆ ---      │\n│ u32      ┆ u32      │\n╞══════════╪══════════╡\n│ 3        ┆ 2        │\n└──────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 90}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.datetime_ranges.html#polars.datetime_ranges"], "Title": ["datetime_ranges"], "Feature": ["datetime_ranges"], "Description": ["Create a column of datetime ranges."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"start\": [datetime(2022, 1, 1), datetime(2022, 1, 2)],\n...         \"end\": datetime(2022, 1, 3),\n...     }\n... )\n>>> with pl.Config(fmt_str_lengths=100):\n...     df.select(datetime_range=pl.datetime_ranges(\"start\", \"end\"))\nshape: (2, 1)\n┌─────────────────────────────────────────────────────────────────┐\n│ datetime_range                                                  │\n│ ---                                                             │\n│ list[datetime[μs]]                                              │\n╞═════════════════════════════════════════════════════════════════╡\n│ [2022-01-01 00:00:00, 2022-01-02 00:00:00, 2022-01-03 00:00:00] │\n│ [2022-01-02 00:00:00, 2022-01-03 00:00:00]                      │\n└─────────────────────────────────────────────────────────────────┘"], "Parameters": [["start", "Lower bound of the datetime range."], ["end", "Upper bound of the datetime range."], ["interval", "Interval of the range periods, specified as a Python timedelta object\nor using the Polars duration string language (see “Notes” section below)."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the range are closed (inclusive)."], ["time_unit {None, ‘ns’, ‘us’, ‘ms’}", "Time unit of the resulting Datetime data type."], ["time_zone", "Time zone of the resulting Datetime data type."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type List(Datetime) ."]], "Category": ["Functions"], "index": 91}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.duration.html#polars.duration"], "Title": ["duration"], "Feature": ["duration"], "Description": ["Create polarsDurationfrom distinct time components."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"dt\": [datetime(2022, 1, 1), datetime(2022, 1, 2)],\n...         \"add\": [1, 2],\n...     }\n... )\n>>> df\nshape: (2, 2)\n┌─────────────────────┬─────┐\n│ dt                  ┆ add │\n│ ---                 ┆ --- │\n│ datetime[μs]        ┆ i64 │\n╞═════════════════════╪═════╡\n│ 2022-01-01 00:00:00 ┆ 1   │\n│ 2022-01-02 00:00:00 ┆ 2   │\n└─────────────────────┴─────┘\n>>> with pl.Config(tbl_width_chars=120):\n...     df.select(\n...         (pl.col(\"dt\") + pl.duration(weeks=\"add\")).alias(\"add_weeks\"),\n...         (pl.col(\"dt\") + pl.duration(days=\"add\")).alias(\"add_days\"),\n...         (pl.col(\"dt\") + pl.duration(seconds=\"add\")).alias(\"add_seconds\"),\n...         (pl.col(\"dt\") + pl.duration(milliseconds=\"add\")).alias(\"add_millis\"),\n...         (pl.col(\"dt\") + pl.duration(hours=\"add\")).alias(\"add_hours\"),\n...     )\nshape: (2, 5)\n┌─────────────────────┬─────────────────────┬─────────────────────┬─────────────────────────┬─────────────────────┐\n│ add_weeks           ┆ add_days            ┆ add_seconds         ┆ add_millis              ┆ add_hours           │\n│ ---                 ┆ ---                 ┆ ---                 ┆ ---                     ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]            ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╪═════════════════════╪═════════════════════════╪═════════════════════╡\n│ 2022-01-08 00:00:00 ┆ 2022-01-02 00:00:00 ┆ 2022-01-01 00:00:01 ┆ 2022-01-01 00:00:00.001 ┆ 2022-01-01 01:00:00 │\n│ 2022-01-16 00:00:00 ┆ 2022-01-04 00:00:00 ┆ 2022-01-02 00:00:02 ┆ 2022-01-02 00:00:00.002 ┆ 2022-01-02 02:00:00 │\n└─────────────────────┴─────────────────────┴─────────────────────┴─────────────────────────┴─────────────────────┘", ">>> with pl.Config(tbl_width_chars=120):\n...     df.select(\n...         add_calendar_days=pl.col(\"dt\").dt.offset_by(\n...             pl.format(\"{}d\", pl.col(\"add\"))\n...         ),\n...         add_calendar_months=pl.col(\"dt\").dt.offset_by(\n...             pl.format(\"{}mo\", pl.col(\"add\"))\n...         ),\n...         add_calendar_years=pl.col(\"dt\").dt.offset_by(\n...             pl.format(\"{}y\", pl.col(\"add\"))\n...         ),\n...     )\nshape: (2, 3)\n┌─────────────────────┬─────────────────────┬─────────────────────┐\n│ add_calendar_days   ┆ add_calendar_months ┆ add_calendar_years  │\n│ ---                 ┆ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╪═════════════════════╡\n│ 2022-01-02 00:00:00 ┆ 2022-02-01 00:00:00 ┆ 2023-01-01 00:00:00 │\n│ 2022-01-04 00:00:00 ┆ 2022-03-02 00:00:00 ┆ 2024-01-02 00:00:00 │\n└─────────────────────┴─────────────────────┴─────────────────────┘"], "Parameters": [["weeks", "Number of weeks."], ["days", "Number of days."], ["hours", "Number of hours."], ["minutes", "Number of minutes."], ["seconds", "Number of seconds."], ["milliseconds", "Number of milliseconds."], ["microseconds", "Number of microseconds."], ["nanoseconds", "Number of nanoseconds."], ["time_unit {None, ‘us’, ‘ms’, ‘ns’}", "Time unit of the resulting expression. If set to None (default), the time\nunit will be inferred from the other inputs: 'ns' if nanoseconds was\nspecified, 'us' otherwise."]], "Returns": [["Expr", "Expression of data type Duration ."]], "Category": ["Functions"], "index": 92}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.element.html#polars.element"], "Title": ["element"], "Feature": ["element"], "Description": ["Alias for an element being evaluated in anevalorfilterexpression."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...     }\n... )\n>>> df.with_columns(\n...     pl.concat_list([\"a\", \"b\"]).list.eval(pl.element().rank()).alias(\"rank\")\n... )\nshape: (3, 3)\n┌─────┬─────┬────────────┐\n│ a   ┆ b   ┆ rank       │\n│ --- ┆ --- ┆ ---        │\n│ i64 ┆ i64 ┆ list[f64]  │\n╞═════╪═════╪════════════╡\n│ 1   ┆ 4   ┆ [1.0, 2.0] │\n│ 8   ┆ 5   ┆ [2.0, 1.0] │\n│ 3   ┆ 2   ┆ [2.0, 1.0] │\n└─────┴─────┴────────────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...     }\n... )\n>>> df.with_columns(\n...     pl.concat_list([\"a\", \"b\"]).list.eval(pl.element() * 2).alias(\"a_b_doubled\")\n... )\nshape: (3, 3)\n┌─────┬─────┬─────────────┐\n│ a   ┆ b   ┆ a_b_doubled │\n│ --- ┆ --- ┆ ---         │\n│ i64 ┆ i64 ┆ list[i64]   │\n╞═════╪═════╪═════════════╡\n│ 1   ┆ 4   ┆ [2, 8]      │\n│ 8   ┆ 5   ┆ [16, 10]    │\n│ 3   ┆ 2   ┆ [6, 4]      │\n└─────┴─────┴─────────────┘", ">>> import polars as pl\n>>> df = pl.DataFrame({\"a\": [1, 8, 3], \"b\": [4, 5, 2]})\n>>> df.with_columns(\n...     evens=pl.concat_list(\"a\", \"b\").list.filter(pl.element() % 2 == 0)\n... )\nshape: (3, 3)\n┌─────┬─────┬───────────┐\n│ a   ┆ b   ┆ evens     │\n│ --- ┆ --- ┆ ---       │\n│ i64 ┆ i64 ┆ list[i64] │\n╞═════╪═════╪═══════════╡\n│ 1   ┆ 4   ┆ [4]       │\n│ 8   ┆ 5   ┆ [8]       │\n│ 3   ┆ 2   ┆ [2]       │\n└─────┴─────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 93}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.exclude.html#polars.exclude"], "Title": ["exclude"], "Feature": ["exclude"], "Description": ["Represent all columns except for the given columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"aa\": [1, 2, 3],\n...         \"ba\": [\"a\", \"b\", None],\n...         \"cc\": [None, 2.5, 1.5],\n...     }\n... )\n>>> df.select(pl.exclude(\"ba\"))\nshape: (3, 2)\n┌─────┬──────┐\n│ aa  ┆ cc   │\n│ --- ┆ ---  │\n│ i64 ┆ f64  │\n╞═════╪══════╡\n│ 1   ┆ null │\n│ 2   ┆ 2.5  │\n│ 3   ┆ 1.5  │\n└─────┴──────┘", ">>> df.select(pl.exclude(\"^.*a$\"))\nshape: (3, 1)\n┌──────┐\n│ cc   │\n│ ---  │\n│ f64  │\n╞══════╡\n│ null │\n│ 2.5  │\n│ 1.5  │\n└──────┘", ">>> df.select(pl.exclude([pl.Int64, pl.Float64]))\nshape: (3, 1)\n┌──────┐\n│ ba   │\n│ ---  │\n│ str  │\n╞══════╡\n│ a    │\n│ b    │\n│ null │\n└──────┘"], "Parameters": [["columns", "The name or datatype of the column(s) to exclude. Accepts regular expression\ninput. Regular expressions should start with ^ and end with $ ."], ["*more_columns", "Additional names or datatypes of columns to exclude, specified as positional\narguments."]], "Returns": [], "Category": ["Functions"], "index": 94}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.first.html#polars.first"], "Title": ["first"], "Feature": ["first"], "Description": ["Get the first column or value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"baz\"],\n...     }\n... )", ">>> df.select(pl.first())\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 8   │\n│ 3   │\n└─────┘", ">>> df.select(pl.first(\"b\"))\nshape: (1, 1)\n┌─────┐\n│ b   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 4   │\n└─────┘\n>>> df.select(pl.first(\"a\", \"c\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ c   │\n│ --- ┆ --- │\n│ i64 ┆ str │\n╞═════╪═════╡\n│ 1   ┆ foo │\n└─────┴─────┘"], "Parameters": [["*columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 95}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.fold.html#polars.fold"], "Title": ["fold"], "Feature": ["fold"], "Description": ["Accumulate over multiple columns horizontally/ row wise with a left fold."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [3, 4, 5],\n...         \"c\": [5, 6, 7],\n...     }\n... )\n>>> df\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 3   ┆ 5   │\n│ 2   ┆ 4   ┆ 6   │\n│ 3   ┆ 5   ┆ 7   │\n└─────┴─────┴─────┘", ">>> df.select(\n...     pl.fold(\n...         acc=pl.lit(1), function=lambda acc, x: acc + x, exprs=pl.col(\"*\")\n...     ).alias(\"sum\"),\n... )\nshape: (3, 1)\n┌─────┐\n│ sum │\n│ --- │\n│ i32 │\n╞═════╡\n│ 10  │\n│ 13  │\n│ 16  │\n└─────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [0, 1, 2],\n...     }\n... )\n>>> df\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 0   │\n│ 2   ┆ 1   │\n│ 3   ┆ 2   │\n└─────┴─────┘", ">>> df.filter(\n...     pl.fold(\n...         acc=pl.lit(True),\n...         function=lambda acc, x: acc & x,\n...         exprs=pl.col(\"*\") > 1,\n...     )\n... )\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 3   ┆ 2   │\n└─────┴─────┘"], "Parameters": [["acc", "Accumulator Expression. This is the value that will be initialized when the fold\nstarts. For a sum this could for instance be lit(0)."], ["function", "Function to apply over the accumulator and the value.\nFn(acc, value) -> new_value"], ["exprs", "Expressions to aggregate over. May also be a wildcard expression."], ["returns_scalar", "Whether or not function applied returns a scalar. This must be set correctly\nby the user."], ["return_dtype", "Output datatype.\nIf not set, the dtype will be inferred based on the dtype\nof the accumulator."]], "Returns": [], "Category": ["Functions"], "index": 96}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.format.html#polars.format"], "Title": ["format"], "Feature": ["format"], "Description": ["Format expressions as a string."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"c\"],\n...         \"b\": [1, 2, 3],\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.format(\"foo_{}_bar_{}\", pl.col(\"a\"), \"b\").alias(\"fmt\"),\n...     ]\n... )\nshape: (3, 1)\n┌─────────────┐\n│ fmt         │\n│ ---         │\n│ str         │\n╞═════════════╡\n│ foo_a_bar_1 │\n│ foo_b_bar_2 │\n│ foo_c_bar_3 │\n└─────────────┘"], "Parameters": [["f_string", "A string that with placeholders.\nFor example: “hello_{}” or “{}_world"], ["args", "Expression(s) that fill the placeholders"]], "Returns": [], "Category": ["Functions"], "index": 97}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.from_epoch.html#polars.from_epoch"], "Title": ["from_epoch"], "Feature": ["from_epoch"], "Description": ["Utility function that parses an epoch timestamp (or Unix time) to Polars Date(time)."], "Examples": [">>> df = pl.DataFrame({\"timestamp\": [1666683077, 1666683099]}).lazy()\n>>> df.select(pl.from_epoch(pl.col(\"timestamp\"), time_unit=\"s\")).collect()\nshape: (2, 1)\n┌─────────────────────┐\n│ timestamp           │\n│ ---                 │\n│ datetime[μs]        │\n╞═════════════════════╡\n│ 2022-10-25 07:31:17 │\n│ 2022-10-25 07:31:39 │\n└─────────────────────┘", ">>> s = pl.Series([12345, 12346])\n>>> pl.from_epoch(s, time_unit=\"d\")\nshape: (2,)\nSeries: '' [date]\n[\n        2003-10-20\n        2003-10-21\n]"], "Parameters": [["column", "Series or expression to parse integers to pl.Datetime."], ["time_unit", "The unit of time of the timesteps since epoch time."]], "Returns": [], "Category": ["Functions"], "index": 98}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.groups.html#polars.groups"], "Title": ["groups"], "Feature": ["groups"], "Description": ["Syntactic sugar forpl.col(\"foo\").agg_groups()."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 99}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.head.html#polars.head"], "Title": ["head"], "Feature": ["head"], "Description": ["Get the firstnrows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.head(\"a\"))\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 8   │\n│ 3   │\n└─────┘\n>>> df.select(pl.head(\"a\", 2))\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 8   │\n└─────┘"], "Parameters": [["column", "Column name."], ["n", "Number of rows to return."]], "Returns": [], "Category": ["Functions"], "index": 100}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.nan_max.html#polars.Expr.nan_max"], "Title": ["Expr.nan_max"], "Feature": ["Expr.nan_max"], "Description": ["Get maximum value, but propagate/poison encountered NaN values."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.0, float(\"nan\")]})\n>>> df.select(pl.col(\"a\").nan_max())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ NaN │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 101}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.implode.html#polars.implode"], "Title": ["implode"], "Feature": ["implode"], "Description": ["Aggregate all column values into a list."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [9, 8, 7],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.implode(\"a\"))\nshape: (1, 1)\n┌───────────┐\n│ a         │\n│ ---       │\n│ list[i64] │\n╞═══════════╡\n│ [1, 2, 3] │\n└───────────┘\n>>> df.select(pl.implode(\"b\", \"c\"))\nshape: (1, 2)\n┌───────────┬───────────────────────┐\n│ b         ┆ c                     │\n│ ---       ┆ ---                   │\n│ list[i64] ┆ list[str]             │\n╞═══════════╪═══════════════════════╡\n│ [9, 8, 7] ┆ [\"foo\", \"bar\", \"foo\"] │\n└───────────┴───────────────────────┘"], "Parameters": [["*columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 102}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.int_range.html#polars.int_range"], "Title": ["int_range"], "Feature": ["int_range"], "Description": ["Generate a range of integers."], "Examples": [">>> pl.int_range(0, 3, eager=True)\nshape: (3,)\nSeries: 'literal' [i64]\n[\n        0\n        1\n        2\n]", ">>> pl.int_range(3, eager=True)\nshape: (3,)\nSeries: 'literal' [i64]\n[\n        0\n        1\n        2\n]", ">>> df = pl.DataFrame({\"a\": [1, 3, 5], \"b\": [2, 4, 6]})\n>>> df.select(\n...     pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"index\"),\n...     pl.all(),\n... )\nshape: (3, 3)\n┌───────┬─────┬─────┐\n│ index ┆ a   ┆ b   │\n│ ---   ┆ --- ┆ --- │\n│ u32   ┆ i64 ┆ i64 │\n╞═══════╪═════╪═════╡\n│ 0     ┆ 1   ┆ 2   │\n│ 1     ┆ 3   ┆ 4   │\n│ 2     ┆ 5   ┆ 6   │\n└───────┴─────┴─────┘"], "Parameters": [["start", "Start of the range (inclusive). Defaults to 0."], ["end", "End of the range (exclusive). If set to None (default),\nthe value of start is used and start is set to 0 ."], ["step", "Step size of the range."], ["dtype", "Data type of the range."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of integer data type dtype ."]], "Category": ["Functions"], "index": 103}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.int_ranges.html#polars.int_ranges"], "Title": ["int_ranges"], "Feature": ["int_ranges"], "Description": ["Generate a range of integers for each row of the input columns."], "Examples": [">>> df = pl.DataFrame({\"start\": [1, -1], \"end\": [3, 2]})\n>>> df.with_columns(int_range=pl.int_ranges(\"start\", \"end\"))\nshape: (2, 3)\n┌───────┬─────┬────────────┐\n│ start ┆ end ┆ int_range  │\n│ ---   ┆ --- ┆ ---        │\n│ i64   ┆ i64 ┆ list[i64]  │\n╞═══════╪═════╪════════════╡\n│ 1     ┆ 3   ┆ [1, 2]     │\n│ -1    ┆ 2   ┆ [-1, 0, 1] │\n└───────┴─────┴────────────┘", ">>> df.select(\"end\", int_range=pl.int_ranges(\"end\"))\nshape: (2, 2)\n┌─────┬───────────┐\n│ end ┆ int_range │\n│ --- ┆ ---       │\n│ i64 ┆ list[i64] │\n╞═════╪═══════════╡\n│ 3   ┆ [0, 1, 2] │\n│ 2   ┆ [0, 1]    │\n└─────┴───────────┘"], "Parameters": [["start", "Start of the range (inclusive). Defaults to 0."], ["end", "End of the range (exclusive). If set to None (default),\nthe value of start is used and start is set to 0 ."], ["step", "Step size of the range."], ["dtype", "Integer data type of the ranges. Defaults to Int64 ."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type List(dtype) ."]], "Category": ["Functions"], "index": 104}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.last.html#polars.last"], "Title": ["last"], "Feature": ["last"], "Description": ["Get the last column or value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"baz\"],\n...     }\n... )", ">>> df.select(pl.last())\nshape: (3, 1)\n┌─────┐\n│ c   │\n│ --- │\n│ str │\n╞═════╡\n│ foo │\n│ bar │\n│ baz │\n└─────┘", ">>> df.select(pl.last(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 3   │\n└─────┘\n>>> df.select(pl.last(\"b\", \"c\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ b   ┆ c   │\n│ --- ┆ --- │\n│ i64 ┆ str │\n╞═════╪═════╡\n│ 2   ┆ baz │\n└─────┴─────┘"], "Parameters": [["*columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 105}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.len.html#polars.len"], "Title": ["len"], "Feature": ["len"], "Description": ["Return the number of rows in the context."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None],\n...         \"b\": [3, None, None],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.len())\nshape: (1, 1)\n┌─────┐\n│ len │\n│ --- │\n│ u32 │\n╞═════╡\n│ 3   │\n└─────┘", ">>> df.select(\n...     pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"index\"),\n...     pl.all(),\n... )\nshape: (3, 4)\n┌───────┬──────┬──────┬─────┐\n│ index ┆ a    ┆ b    ┆ c   │\n│ ---   ┆ ---  ┆ ---  ┆ --- │\n│ u32   ┆ i64  ┆ i64  ┆ str │\n╞═══════╪══════╪══════╪═════╡\n│ 0     ┆ 1    ┆ 3    ┆ foo │\n│ 1     ┆ 2    ┆ null ┆ bar │\n│ 2     ┆ null ┆ null ┆ foo │\n└───────┴──────┴──────┴─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Functions"], "index": 106}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.linear_space.html#polars.linear_space"], "Title": ["linear_space"], "Feature": ["linear_space"], "Description": ["Create sequence of evenly-spaced points."], "Examples": [">>> pl.linear_space(start=0, end=1, num_samples=3, eager=True)\nshape: (3,)\nSeries: 'literal' [f64]\n[\n        0.0\n        0.5\n        1.0\n]\n>>> pl.linear_space(start=0, end=1, num_samples=3, closed=\"left\", eager=True)\nshape: (3,)\nSeries: 'literal' [f64]\n[\n        0.0\n        0.333333\n        0.666667\n]\n>>> pl.linear_space(start=0, end=1, num_samples=3, closed=\"right\", eager=True)\nshape: (3,)\nSeries: 'literal' [f64]\n[\n        0.333333\n        0.666667\n        1.0\n]\n>>> pl.linear_space(start=0, end=1, num_samples=3, closed=\"none\", eager=True)\nshape: (3,)\nSeries: 'literal' [f64]\n[\n        0.25\n        0.5\n        0.75\n]\n>>> from datetime import time\n>>> pl.linear_space(\n...     start=time(hour=1), end=time(hour=12), num_samples=3, eager=True\n... )\nshape: (3,)\nSeries: 'literal' [time]\n[\n        01:00:00\n        06:30:00\n        12:00:00\n]", ">>> from datetime import date\n>>> pl.linear_space(\n...     start=date(2025, 1, 1),\n...     end=date(2025, 2, 1),\n...     num_samples=3,\n...     closed=\"right\",\n...     eager=True,\n... )\nshape: (3,)\nSeries: 'literal' [datetime[μs]]\n[\n        2025-01-11 08:00:00\n        2025-01-21 16:00:00\n        2025-02-01 00:00:00\n]", ">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4, 5]})\n>>> df.with_columns(pl.linear_space(0, 1, pl.len()).alias(\"ls\"))\nshape: (5, 2)\n┌─────┬──────┐\n│ a   ┆ ls   │\n│ --- ┆ ---  │\n│ i64 ┆ f64  │\n╞═════╪══════╡\n│ 1   ┆ 0.0  │\n│ 2   ┆ 0.25 │\n│ 3   ┆ 0.5  │\n│ 4   ┆ 0.75 │\n│ 5   ┆ 1.0  │\n└─────┴──────┘"], "Parameters": [["start", "Lower bound of the range."], ["end", "Upper bound of the range."], ["num_samples", "Number of samples in the output sequence."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the interval are closed (inclusive)."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."], [".. warning::", "This functionality is experimental. It may be changed at any point without it\nbeing considered a breaking change."]], "Returns": [["Expr or Series", "Column of data type :class:Time ."]], "Category": ["Functions"], "index": 107}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.linear_spaces.html#polars.linear_spaces"], "Title": ["linear_spaces"], "Feature": ["linear_spaces"], "Description": ["Generate a sequence of evenly-spaced values for each row betweenstartandend."], "Examples": [">>> df = pl.DataFrame({\"start\": [1, -1], \"end\": [3, 2], \"num_samples\": [4, 5]})\n>>> df.with_columns(ls=pl.linear_spaces(\"start\", \"end\", \"num_samples\"))\nshape: (2, 4)\n┌───────┬─────┬─────────────┬────────────────────────┐\n│ start ┆ end ┆ num_samples ┆ ls                     │\n│ ---   ┆ --- ┆ ---         ┆ ---                    │\n│ i64   ┆ i64 ┆ i64         ┆ list[f64]              │\n╞═══════╪═════╪═════════════╪════════════════════════╡\n│ 1     ┆ 3   ┆ 4           ┆ [1.0, 1.666667, … 3.0] │\n│ -1    ┆ 2   ┆ 5           ┆ [-1.0, -0.25, … 2.0]   │\n└───────┴─────┴─────────────┴────────────────────────┘\n>>> df.with_columns(ls=pl.linear_spaces(\"start\", \"end\", 3, as_array=True))\nshape: (2, 4)\n┌───────┬─────┬─────────────┬──────────────────┐\n│ start ┆ end ┆ num_samples ┆ ls               │\n│ ---   ┆ --- ┆ ---         ┆ ---              │\n│ i64   ┆ i64 ┆ i64         ┆ array[f64, 3]    │\n╞═══════╪═════╪═════════════╪══════════════════╡\n│ 1     ┆ 3   ┆ 4           ┆ [1.0, 2.0, 3.0]  │\n│ -1    ┆ 2   ┆ 5           ┆ [-1.0, 0.5, 2.0] │\n└───────┴─────┴─────────────┴──────────────────┘"], "Parameters": [["start", "Lower bound of the range."], ["end", "Upper bound of the range."], ["num_samples", "Number of samples in the output sequence."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the interval are closed (inclusive)."], ["as_array", "Return result as a fixed-length Array . num_samples must be a constant."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."], [".. warning::", "This functionality is experimental. It may be changed at any point without it\nbeing considered a breaking change."]], "Returns": [["Expr or Series", "Column of data type List(dtype) ."]], "Category": ["Functions"], "index": 108}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.lit.html#polars.lit"], "Title": ["lit"], "Feature": ["lit"], "Description": ["Return an expression representing a literal value."], "Examples": [">>> pl.lit(1)  \n>>> pl.lit(5.5)  \n>>> pl.lit(None)  \n>>> pl.lit(\"foo_bar\")  \n>>> pl.lit(date(2021, 1, 20))  \n>>> pl.lit(datetime(2023, 3, 31, 10, 30, 45))", ">>> pl.lit([1, 2, 3])  \n>>> pl.lit(pl.Series(\"x\", [1, 2, 3]))", ">>> pl.lit([[1, 2], [3, 4]])  \n>>> pl.lit(pl.Series(\"y\", [[1, 2], [3, 4]]))"], "Parameters": [["value", "Value that should be used as a literal ."], ["dtype", "The data type of the resulting expression.\nIf set to None (default), the data type is inferred from the value input."], ["allow_object", "If type is unknown use an ‘object’ type.\nBy default, we will raise a ValueException if the type is unknown."]], "Returns": [], "Category": ["Functions"], "index": 109}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.map_batches.html#polars.map_batches"], "Title": ["map_batches"], "Feature": ["map_batches"], "Description": ["Map a custom function over multiple columns/expressions."], "Examples": [">>> def test_func(a, b, c):\n...     return a + b + c\n>>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [4, 5, 6, 7],\n...     }\n... )\n>>>\n>>> df.with_columns(\n...     (\n...         pl.struct([\"a\", \"b\"]).map_batches(\n...             lambda x: test_func(x.struct.field(\"a\"), x.struct.field(\"b\"), 1)\n...         )\n...     ).alias(\"a+b+c\")\n... )\nshape: (4, 3)\n┌─────┬─────┬───────┐\n│ a   ┆ b   ┆ a+b+c │\n│ --- ┆ --- ┆ ---   │\n│ i64 ┆ i64 ┆ i64   │\n╞═════╪═════╪═══════╡\n│ 1   ┆ 4   ┆ 6     │\n│ 2   ┆ 5   ┆ 8     │\n│ 3   ┆ 6   ┆ 10    │\n│ 4   ┆ 7   ┆ 12    │\n└─────┴─────┴───────┘"], "Parameters": [["exprs", "Expression(s) representing the input Series to the function."], ["function", "Function to apply over the input."], ["return_dtype", "Datatype of the output Series. It is recommended to set this whenever possible. If this is None , it tries\nto infer the datatype by calling the function with dummy data and looking at\nthe output."], ["is_elementwise", "Set to true if the operations is elementwise for better performance\nand optimization. An elementwise operations has unit or equal length for all inputs\nand can be ran sequentially on slices without results being affected."], ["returns_scalar", "If the function returns a scalar, by default it will be wrapped in\na list in the output, since the assumption is that the function\nalways returns something Series-like. If you want to keep the\nresult as a scalar, set this argument to True."]], "Returns": [["Expr", "Expression with the data type given by return_dtype ."]], "Category": ["Functions"], "index": 110}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.map_groups.html#polars.map_groups"], "Title": ["map_groups"], "Feature": ["map_groups"], "Description": ["Apply a custom/user-defined function (UDF) in a GroupBy context."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [1, 1, 2],\n...         \"a\": [1, 3, 3],\n...         \"b\": [5, 6, 7],\n...     }\n... )\n>>> df\nshape: (3, 3)\n┌───────┬─────┬─────┐\n│ group ┆ a   ┆ b   │\n│ ---   ┆ --- ┆ --- │\n│ i64   ┆ i64 ┆ i64 │\n╞═══════╪═════╪═════╡\n│ 1     ┆ 1   ┆ 5   │\n│ 1     ┆ 3   ┆ 6   │\n│ 2     ┆ 3   ┆ 7   │\n└───────┴─────┴─────┘\n>>> (\n...     df.group_by(\"group\").agg(\n...         pl.map_groups(\n...             exprs=[\"a\", \"b\"],\n...             function=lambda list_of_series: list_of_series[0]\n...             / list_of_series[0].sum()\n...             + list_of_series[1],\n...             return_dtype=pl.Float64,\n...         ).alias(\"my_custom_aggregation\")\n...     )\n... ).sort(\"group\")\nshape: (2, 2)\n┌───────┬───────────────────────┐\n│ group ┆ my_custom_aggregation │\n│ ---   ┆ ---                   │\n│ i64   ┆ list[f64]             │\n╞═══════╪═══════════════════════╡\n│ 1     ┆ [5.25, 6.75]          │\n│ 2     ┆ [8.0]                 │\n└───────┴───────────────────────┘"], "Parameters": [["exprs", "Expression(s) representing the input Series to the function."], ["function", "Function to apply over the input; should be of type Callable[[Series], Series]."], ["return_dtype", "Datatype of the output Series. It is recommended to set this whenever possible. If this is None , it tries\nto infer the datatype by calling the function with dummy data and looking at\nthe output."], ["is_elementwise", "Set to true if the operations is elementwise for better performance\nand optimization. An elementwise operations has unit or equal length for all inputs\nand can be ran sequentially on slices without results being affected."], ["returns_scalar", "If the function returns a single scalar as output."]], "Returns": [["Expr", "Expression with the data type given by return_dtype ."]], "Category": ["Functions"], "index": 111}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.any.html#polars.Expr.any"], "Title": ["Expr.any"], "Feature": ["Expr.any"], "Description": ["Return whether any of the values in the column areTrue."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, False],\n...         \"b\": [False, False],\n...         \"c\": [None, False],\n...     }\n... )\n>>> df.select(pl.col(\"*\").any())\nshape: (1, 3)\n┌──────┬───────┬───────┐\n│ a    ┆ b     ┆ c     │\n│ ---  ┆ ---   ┆ ---   │\n│ bool ┆ bool  ┆ bool  │\n╞══════╪═══════╪═══════╡\n│ true ┆ false ┆ false │\n└──────┴───────┴───────┘", ">>> df.select(pl.col(\"*\").any(ignore_nulls=False))\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ null │\n└──────┴───────┴──────┘"], "Parameters": [["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is False . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no True values,\nthe output is null."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Aggregation"], "index": 112}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.nan_min.html#polars.Expr.nan_min"], "Title": ["Expr.nan_min"], "Feature": ["Expr.nan_min"], "Description": ["Get minimum value, but propagate/poison encountered NaN values."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.0, float(\"nan\")]})\n>>> df.select(pl.col(\"a\").nan_min())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ NaN │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 113}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.max.html#polars.max"], "Title": ["max"], "Feature": ["max"], "Description": ["Get the maximum value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.max(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 8   │\n└─────┘", ">>> df.select(pl.max(\"^a|b$\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 8   ┆ 5   │\n└─────┴─────┘\n>>> df.select(pl.max(\"a\", \"b\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 8   ┆ 5   │\n└─────┴─────┘"], "Parameters": [["*names", "Name(s) of the columns to use in the aggregation."]], "Returns": [], "Category": ["Functions"], "index": 114}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.max_horizontal.html#polars.max_horizontal"], "Title": ["max_horizontal"], "Feature": ["max_horizontal"], "Description": ["Get the maximum value horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, None],\n...         \"c\": [\"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(max=pl.max_horizontal(\"a\", \"b\"))\nshape: (3, 4)\n┌─────┬──────┬─────┬─────┐\n│ a   ┆ b    ┆ c   ┆ max │\n│ --- ┆ ---  ┆ --- ┆ --- │\n│ i64 ┆ i64  ┆ str ┆ i64 │\n╞═════╪══════╪═════╪═════╡\n│ 1   ┆ 4    ┆ x   ┆ 4   │\n│ 8   ┆ 5    ┆ y   ┆ 8   │\n│ 3   ┆ null ┆ z   ┆ 3   │\n└─────┴──────┴─────┴─────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."]], "Returns": [], "Category": ["Functions"], "index": 115}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.mean.html#polars.mean"], "Title": ["mean"], "Feature": ["mean"], "Description": ["Get the mean value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.mean(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 4.0 │\n└─────┘\n>>> df.select(pl.mean(\"a\", \"b\"))\nshape: (1, 2)\n┌─────┬──────────┐\n│ a   ┆ b        │\n│ --- ┆ ---      │\n│ f64 ┆ f64      │\n╞═════╪══════════╡\n│ 4.0 ┆ 3.666667 │\n└─────┴──────────┘"], "Parameters": [["*columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 116}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.mean_horizontal.html#polars.mean_horizontal"], "Title": ["mean_horizontal"], "Feature": ["mean_horizontal"], "Description": ["Compute the mean of all values horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, None],\n...         \"c\": [\"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(mean=pl.mean_horizontal(\"a\", \"b\"))\nshape: (3, 4)\n┌─────┬──────┬─────┬──────┐\n│ a   ┆ b    ┆ c   ┆ mean │\n│ --- ┆ ---  ┆ --- ┆ ---  │\n│ i64 ┆ i64  ┆ str ┆ f64  │\n╞═════╪══════╪═════╪══════╡\n│ 1   ┆ 4    ┆ x   ┆ 2.5  │\n│ 8   ┆ 5    ┆ y   ┆ 6.5  │\n│ 3   ┆ null ┆ z   ┆ 3.0  │\n└─────┴──────┴─────┴──────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."], ["ignore_nulls", "Ignore null values (default).\nIf set to False , any null value in the input will lead to a null output."]], "Returns": [], "Category": ["Functions"], "index": 117}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.median.html#polars.median"], "Title": ["median"], "Feature": ["median"], "Description": ["Get the median value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.median(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 3.0 │\n└─────┘\n>>> df.select(pl.median(\"a\", \"b\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ f64 ┆ f64 │\n╞═════╪═════╡\n│ 3.0 ┆ 4.0 │\n└─────┴─────┘"], "Parameters": [["columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 118}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.min.html#polars.min"], "Title": ["min"], "Feature": ["min"], "Description": ["Get the minimum value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.min(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n└─────┘", ">>> df.select(pl.min(\"^a|b$\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 2   │\n└─────┴─────┘\n>>> df.select(pl.min(\"a\", \"b\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 2   │\n└─────┴─────┘"], "Parameters": [["*names", "Name(s) of the columns to use in the aggregation."]], "Returns": [], "Category": ["Functions"], "index": 119}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.min_horizontal.html#polars.min_horizontal"], "Title": ["min_horizontal"], "Feature": ["min_horizontal"], "Description": ["Get the minimum value horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, None],\n...         \"c\": [\"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(min=pl.min_horizontal(\"a\", \"b\"))\nshape: (3, 4)\n┌─────┬──────┬─────┬─────┐\n│ a   ┆ b    ┆ c   ┆ min │\n│ --- ┆ ---  ┆ --- ┆ --- │\n│ i64 ┆ i64  ┆ str ┆ i64 │\n╞═════╪══════╪═════╪═════╡\n│ 1   ┆ 4    ┆ x   ┆ 1   │\n│ 8   ┆ 5    ┆ y   ┆ 5   │\n│ 3   ┆ null ┆ z   ┆ 3   │\n└─────┴──────┴─────┴─────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."]], "Returns": [], "Category": ["Functions"], "index": 120}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.n_unique.html#polars.n_unique"], "Title": ["n_unique"], "Feature": ["n_unique"], "Description": ["Count unique values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 1],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.n_unique(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘\n>>> df.select(pl.n_unique(\"b\", \"c\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ b   ┆ c   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 3   ┆ 2   │\n└─────┴─────┘"], "Parameters": [["columns", "One or more column names."]], "Returns": [], "Category": ["Functions"], "index": 121}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.nth.html#polars.nth"], "Title": ["nth"], "Feature": ["nth"], "Description": ["Get the nth column(s) of the context."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"baz\"],\n...     }\n... )\n>>> df.select(pl.nth(1))\nshape: (3, 1)\n┌─────┐\n│ b   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 4   │\n│ 5   │\n│ 2   │\n└─────┘\n>>> df.select(pl.nth(2, 0))\nshape: (3, 2)\n┌─────┬─────┐\n│ c   ┆ a   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ foo ┆ 1   │\n│ bar ┆ 8   │\n│ baz ┆ 3   │\n└─────┴─────┘"], "Parameters": [["indices", "One or more indices representing the columns to retrieve."]], "Returns": [], "Category": ["Functions"], "index": 122}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.ones.html#polars.ones"], "Title": ["ones"], "Feature": ["ones"], "Description": ["Construct a column of lengthnfilled with ones."], "Examples": [">>> pl.ones(3, pl.Int8, eager=True)\nshape: (3,)\nSeries: 'ones' [i8]\n[\n    1\n    1\n    1\n]"], "Parameters": [["n", "Length of the resulting column."], ["dtype", "Data type of the resulting column. Defaults to Float64."], ["eager", "Evaluate immediately and return a Series . If set to False ,\nreturn an expression instead."]], "Returns": [], "Category": ["Functions"], "index": 123}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.null_count.html#polars.Expr.null_count"], "Title": ["Expr.null_count"], "Feature": ["Expr.null_count"], "Description": ["Count null values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [None, 1, None],\n...         \"b\": [10, None, 300],\n...         \"c\": [350, 650, 850],\n...     }\n... )\n>>> df.select(pl.all().null_count())\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ u32 ┆ u32 ┆ u32 │\n╞═════╪═════╪═════╡\n│ 2   ┆ 1   ┆ 0   │\n└─────┴─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 124}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.quantile.html#polars.quantile"], "Title": ["quantile"], "Feature": ["quantile"], "Description": ["Syntactic sugar forpl.col(\"foo\").quantile(..)."], "Examples": [], "Parameters": [["column", "Column name."], ["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."]], "Returns": [], "Category": ["Functions"], "index": 125}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.reduce.html#polars.reduce"], "Title": ["reduce"], "Feature": ["reduce"], "Description": ["Accumulate over multiple columns horizontally/ row wise with a left fold."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [0, 1, 2],\n...     }\n... )\n>>> df\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 0   │\n│ 2   ┆ 1   │\n│ 3   ┆ 2   │\n└─────┴─────┘", ">>> df.select(\n...     pl.reduce(function=lambda acc, x: acc + x, exprs=pl.col(\"*\")).alias(\"sum\")\n... )\nshape: (3, 1)\n┌─────┐\n│ sum │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 3   │\n│ 5   │\n└─────┘"], "Parameters": [["function", "Function to apply over the accumulator and the value.\nFn(acc, value) -> new_value"], ["exprs", "Expressions to aggregate over. May also be a wildcard expression."], ["returns_scalar", "Whether or not function applied returns a scalar. This must be set correctly\nby the user."], ["return_dtype", "Output datatype.\nIf not set, the dtype will be inferred based on the dtype of the input\nexpressions."]], "Returns": [], "Category": ["Functions"], "index": 126}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.repeat.html#polars.repeat"], "Title": ["repeat"], "Feature": ["repeat"], "Description": ["Construct a column of lengthnfilled with the given value."], "Examples": [">>> pl.select(pl.repeat(\"z\", n=3)).to_series()\nshape: (3,)\nSeries: 'repeat' [str]\n[\n        \"z\"\n        \"z\"\n        \"z\"\n]", ">>> pl.repeat(3, n=3, dtype=pl.Int8, eager=True)\nshape: (3,)\nSeries: 'repeat' [i8]\n[\n        3\n        3\n        3\n]"], "Parameters": [["value", "Value to repeat."], ["n", "Length of the resulting column."], ["dtype", "Data type of the resulting column. If set to None (default), data type is\ninferred from the given value. Defaults to Int32 for integer values, unless\nInt64 is required to fit the given value. Defaults to Float64 for float values."], ["eager", "Evaluate immediately and return a Series . If set to False (default),\nreturn an expression instead."]], "Returns": [], "Category": ["Functions"], "index": 127}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.rolling_corr.html#polars.rolling_corr"], "Title": ["rolling_corr"], "Feature": ["rolling_corr"], "Description": ["Compute the rolling correlation between two columns/ expressions."], "Examples": [], "Parameters": [["a", "Column name or Expression."], ["b", "Column name or Expression."], ["window_size", "The length of the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If None, it will be set equal to window size."], ["ddof", "Delta degrees of freedom. The divisor used in calculations\nis N - ddof , where N represents the number of elements."]], "Returns": [], "Category": ["Functions"], "index": 128}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.rolling_cov.html#polars.rolling_cov"], "Title": ["rolling_cov"], "Feature": ["rolling_cov"], "Description": ["Compute the rolling covariance between two columns/ expressions."], "Examples": [], "Parameters": [["a", "Column name or Expression."], ["b", "Column name or Expression."], ["window_size", "The length of the window."], ["min_samples", "The number of values in the window that should be non-null before computing\na result. If None, it will be set equal to window size."], ["ddof", "Delta degrees of freedom. The divisor used in calculations\nis N - ddof , where N represents the number of elements."]], "Returns": [], "Category": ["Functions"], "index": 129}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.row_index.html#polars.row_index"], "Title": ["row_index"], "Feature": ["row_index"], "Description": ["Generates a sequence of integers."], "Examples": [">>> df = pl.DataFrame({\"x\": [\"A\", \"A\", \"B\", \"B\", \"B\"]})\n>>> df.with_columns(pl.row_index(), pl.row_index(\"another_index\"))\nshape: (5, 3)\n┌─────┬───────┬───────────────┐\n│ x   ┆ index ┆ another_index │\n│ --- ┆ ---   ┆ ---           │\n│ str ┆ u32   ┆ u32           │\n╞═════╪═══════╪═══════════════╡\n│ A   ┆ 0     ┆ 0             │\n│ A   ┆ 1     ┆ 1             │\n│ B   ┆ 2     ┆ 2             │\n│ B   ┆ 3     ┆ 3             │\n│ B   ┆ 4     ┆ 4             │\n└─────┴───────┴───────────────┘\n>>> df.group_by(\"x\").agg(pl.row_index()).sort(\"x\")\nshape: (2, 2)\n┌─────┬───────────┐\n│ x   ┆ index     │\n│ --- ┆ ---       │\n│ str ┆ list[u32] │\n╞═════╪═══════════╡\n│ A   ┆ [0, 1]    │\n│ B   ┆ [0, 1, 2] │\n└─────┴───────────┘\n>>> df.select(pl.row_index())\nshape: (5, 1)\n┌───────┐\n│ index │\n│ ---   │\n│ u32   │\n╞═══════╡\n│ 0     │\n│ 1     │\n│ 2     │\n│ 3     │\n│ 4     │\n└───────┘"], "Parameters": [["name", "Name of the returned column."]], "Returns": [["Expr", "Column of integers."]], "Category": ["Functions"], "index": 130}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.select.html#polars.select"], "Title": ["select"], "Feature": ["select"], "Description": ["Run polars expressions without a context."], "Examples": [">>> foo = pl.Series(\"foo\", [1, 2, 3])\n>>> bar = pl.Series(\"bar\", [3, 2, 1])\n>>> pl.select(min=pl.min_horizontal(foo, bar))\nshape: (3, 1)\n┌─────┐\n│ min │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 1   │\n└─────┘", ">>> pl.select(pl.int_range(0, 100_000, 2).alias(\"n\"), eager=False).filter(\n...     pl.col(\"n\") % 22_500 == 0\n... ).collect()\nshape: (5, 1)\n┌───────┐\n│ n     │\n│ ---   │\n│ i64   │\n╞═══════╡\n│ 0     │\n│ 22500 │\n│ 45000 │\n│ 67500 │\n│ 90000 │\n└───────┘"], "Parameters": [["*exprs", "Column(s) to select, specified as positional arguments.\nAccepts expression input. Strings are parsed as column names,\nother non-expression inputs are parsed as literals."], ["eager", "Evaluate immediately and return a DataFrame (default); if set to False ,\nreturn a LazyFrame instead."], ["**named_exprs", "Additional columns to select, specified as keyword arguments.\nThe columns will be renamed to the keyword used."]], "Returns": [["DataFrame or LazyFrame", ""]], "Category": ["Functions"], "index": 131}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.sql.html#polars.sql"], "Title": ["sql"], "Feature": ["sql"], "Description": ["Execute a SQL query against frames in the global namespace."], "Examples": [">>> lf1 = pl.LazyFrame({\"a\": [1, 2, 3], \"b\": [6, 7, 8], \"c\": [\"z\", \"y\", \"x\"]})\n>>> lf2 = pl.LazyFrame({\"a\": [3, 2, 1], \"d\": [125, -654, 888]})", ">>> lf1.sql(\"SELECT c, b FROM self WHERE a > 1\").collect()\nshape: (2, 2)\n┌─────┬─────┐\n│ c   ┆ b   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ y   ┆ 7   │\n│ x   ┆ 8   │\n└─────┴─────┘", ">>> pl.sql(\n...     '''\n...     SELECT lf1.*, d\n...     FROM lf1\n...     INNER JOIN lf2 USING (a)\n...     WHERE a > 1 AND b < 8\n...     '''\n... ).collect()\nshape: (1, 4)\n┌─────┬─────┬─────┬──────┐\n│ a   ┆ b   ┆ c   ┆ d    │\n│ --- ┆ --- ┆ --- ┆ ---  │\n│ i64 ┆ i64 ┆ str ┆ i64  │\n╞═════╪═════╪═════╪══════╡\n│ 2   ┆ 7   ┆ y   ┆ -654 │\n└─────┴─────┴─────┴──────┘", ">>> pl.sql(\n...     query='''\n...         SELECT\n...             a,\n...             (a % 2 == 0) AS a_is_even,\n...             (b::float4 / 2) AS \"b/2\",\n...             CONCAT_WS(':', c, c, c) AS c_c_c\n...         FROM lf1\n...         ORDER BY a\n...     ''',\n... ).filter(~pl.col(\"c_c_c\").str.starts_with(\"x\")).collect()\nshape: (2, 4)\n┌─────┬───────────┬─────┬───────┐\n│ a   ┆ a_is_even ┆ b/2 ┆ c_c_c │\n│ --- ┆ ---       ┆ --- ┆ ---   │\n│ i64 ┆ bool      ┆ f32 ┆ str   │\n╞═════╪═══════════╪═════╪═══════╡\n│ 1   ┆ false     ┆ 3.0 ┆ z:z:z │\n│ 2   ┆ true      ┆ 3.5 ┆ y:y:y │\n└─────┴───────────┴─────┴───────┘", ">>> import pandas as pd\n>>> import pyarrow as pa\n>>> pl_frame = lf1\n>>> pd_frame = pd.DataFrame({\"a\": [2, 3, 4], \"d\": [-0.5, 0.0, 0.5]})\n>>> pa_table = pa.Table.from_arrays(\n...     [pa.array([1, 2, 3]), pa.array([\"x\", \"y\", \"z\"])],\n...     names=[\"a\", \"e\"],\n... )\n>>> pl.sql(\n...     query='''\n...         SELECT pl_frame.*, d, e\n...         FROM pl_frame\n...         JOIN pd_frame USING(a)\n...         JOIN pa_table USING(a)\n...     ''',\n... ).collect()\nshape: (2, 5)\n┌─────┬─────┬─────┬──────┬─────┐\n│ a   ┆ b   ┆ c   ┆ d    ┆ e   │\n│ --- ┆ --- ┆ --- ┆ ---  ┆ --- │\n│ i64 ┆ i64 ┆ str ┆ f64  ┆ str │\n╞═════╪═════╪═════╪══════╪═════╡\n│ 2   ┆ 7   ┆ y   ┆ -0.5 ┆ y   │\n│ 3   ┆ 8   ┆ x   ┆ 0.0  ┆ z   │\n└─────┴─────┴─────┴──────┴─────┘"], "Parameters": [["query", "SQL query to execute."], ["eager", "Automatically collect the result and return a DataFrame instead of a LazyFrame."]], "Returns": [], "Category": ["Functions"], "index": 132}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.sql_expr.html#polars.sql_expr"], "Title": ["sql_expr"], "Feature": ["sql_expr"], "Description": ["Parse one or more SQL expressions to Polars expression(s)."], "Examples": [">>> df = pl.DataFrame({\"a\": [2, 1]})\n>>> expr = pl.sql_expr(\"MAX(a)\")\n>>> df.select(expr)\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n└─────┘", ">>> df.with_columns(\n...     *pl.sql_expr([\"POWER(a,a) AS a_a\", \"CAST(a AS TEXT) AS a_txt\"]),\n... )\nshape: (2, 3)\n┌─────┬─────┬───────┐\n│ a   ┆ a_a ┆ a_txt │\n│ --- ┆ --- ┆ ---   │\n│ i64 ┆ i64 ┆ str   │\n╞═════╪═════╪═══════╡\n│ 2   ┆ 4   ┆ 2     │\n│ 1   ┆ 1   ┆ 1     │\n└─────┴─────┴───────┘"], "Parameters": [["sql", "One or more SQL expressions."]], "Returns": [], "Category": ["Functions"], "index": 133}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.std.html#polars.std"], "Title": ["std"], "Feature": ["std"], "Description": ["Get the standard deviation."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.std(\"a\"))\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 3.605551 │\n└──────────┘\n>>> df[\"a\"].std()\n3.605551275463989"], "Parameters": [["column", "Column name."], ["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Functions"], "index": 134}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.product.html#polars.Expr.product"], "Title": ["Expr.product"], "Feature": ["Expr.product"], "Description": ["Compute the product of an expression."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").product())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 6   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 135}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.struct.html#polars.struct"], "Title": ["struct"], "Feature": ["struct"], "Description": ["Collect columns into a struct column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"int\": [1, 2],\n...         \"str\": [\"a\", \"b\"],\n...         \"bool\": [True, None],\n...         \"list\": [[1, 2], [3]],\n...     }\n... )\n>>> df.select(pl.struct(pl.all()).alias(\"my_struct\"))\nshape: (2, 1)\n┌─────────────────────┐\n│ my_struct           │\n│ ---                 │\n│ struct[4]           │\n╞═════════════════════╡\n│ {1,\"a\",true,[1, 2]} │\n│ {2,\"b\",null,[3]}    │\n└─────────────────────┘", ">>> df.select(pl.struct(\"int\", False).alias(\"my_struct\"))\nshape: (2, 1)\n┌───────────┐\n│ my_struct │\n│ ---       │\n│ struct[2] │\n╞═══════════╡\n│ {1,false} │\n│ {2,false} │\n└───────────┘", ">>> df.select(pl.struct(p=\"int\", q=\"bool\").alias(\"my_struct\")).schema\nSchema({'my_struct': Struct({'p': Int64, 'q': Boolean})})"], "Parameters": [["*exprs", "Column(s) to collect into a struct column, specified as positional arguments.\nAccepts expression input. Strings are parsed as column names,\nother non-expression inputs are parsed as literals."], ["schema", "Optional schema that explicitly defines the struct field dtypes. If no columns\nor expressions are provided, schema keys are used to define columns."], ["eager", "Evaluate immediately and return a Series . If set to False (default),\nreturn an expression instead."], ["**named_exprs", "Additional columns to collect into the struct column, specified as keyword\narguments. The columns will be renamed to the keyword used."]], "Returns": [], "Category": ["Functions"], "index": 136}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.sum.html#polars.sum"], "Title": ["sum"], "Feature": ["sum"], "Description": ["Sum all values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2],\n...         \"b\": [3, 4],\n...         \"c\": [5, 6],\n...     }\n... )\n>>> df.select(pl.sum(\"a\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 3   │\n└─────┘", ">>> df.select(pl.sum(\"a\", \"c\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ c   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 3   ┆ 11  │\n└─────┴─────┘\n>>> df.select(pl.sum(\"^.*[bc]$\"))\nshape: (1, 2)\n┌─────┬─────┐\n│ b   ┆ c   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 7   ┆ 11  │\n└─────┴─────┘"], "Parameters": [["*names", "Name(s) of the columns to use in the aggregation."]], "Returns": [], "Category": ["Functions"], "index": 137}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.sum_horizontal.html#polars.sum_horizontal"], "Title": ["sum_horizontal"], "Feature": ["sum_horizontal"], "Description": ["Sum all values horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, None],\n...         \"c\": [\"x\", \"y\", \"z\"],\n...     }\n... )\n>>> df.with_columns(sum=pl.sum_horizontal(\"a\", \"b\"))\nshape: (3, 4)\n┌─────┬──────┬─────┬─────┐\n│ a   ┆ b    ┆ c   ┆ sum │\n│ --- ┆ ---  ┆ --- ┆ --- │\n│ i64 ┆ i64  ┆ str ┆ i64 │\n╞═════╪══════╪═════╪═════╡\n│ 1   ┆ 4    ┆ x   ┆ 5   │\n│ 8   ┆ 5    ┆ y   ┆ 13  │\n│ 3   ┆ null ┆ z   ┆ 3   │\n└─────┴──────┴─────┴─────┘"], "Parameters": [["*exprs", "Column(s) to use in the aggregation. Accepts expression input. Strings are\nparsed as column names, other non-expression inputs are parsed as literals."], ["ignore_nulls", "Ignore null values (default).\nIf set to False , any null value in the input will lead to a null output."]], "Returns": [], "Category": ["Functions"], "index": 138}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.tail.html#polars.tail"], "Title": ["tail"], "Feature": ["tail"], "Description": ["Get the lastnrows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     }\n... )\n>>> df.select(pl.tail(\"a\"))\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 8   │\n│ 3   │\n└─────┘\n>>> df.select(pl.tail(\"a\", 2))\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 8   │\n│ 3   │\n└─────┘"], "Parameters": [["column", "Column name."], ["n", "Number of rows to return."]], "Returns": [], "Category": ["Functions"], "index": 139}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.time.html#polars.time"], "Title": ["time"], "Feature": ["time"], "Description": ["Create a Polars literal expression of type Time."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"hour\": [12, 13, 14],\n...         \"minute\": [15, 30, 45],\n...     }\n... )", ">>> df.with_columns(pl.time(pl.col(\"hour\"), pl.col(\"minute\")))\nshape: (3, 3)\n┌──────┬────────┬──────────┐\n│ hour ┆ minute ┆ time     │\n│ ---  ┆ ---    ┆ ---      │\n│ i64  ┆ i64    ┆ time     │\n╞══════╪════════╪══════════╡\n│ 12   ┆ 15     ┆ 12:15:00 │\n│ 13   ┆ 30     ┆ 13:30:00 │\n│ 14   ┆ 45     ┆ 14:45:00 │\n└──────┴────────┴──────────┘"], "Parameters": [["hour", "column or literal, ranging from 0-23."], ["minute", "column or literal, ranging from 0-59."], ["second", "column or literal, ranging from 0-59."], ["microsecond", "column or literal, ranging from 0-999999."]], "Returns": [["Expr", "Expression of data type Date ."]], "Category": ["Functions"], "index": 140}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.time_range.html#polars.time_range"], "Title": ["time_range"], "Feature": ["time_range"], "Description": ["Generate a time range."], "Examples": [">>> from datetime import time, timedelta\n>>> pl.time_range(\n...     start=time(14, 0),\n...     interval=timedelta(hours=3, minutes=15),\n...     eager=True,\n... ).alias(\"time\")\nshape: (4,)\nSeries: 'time' [time]\n[\n    14:00:00\n    17:15:00\n    20:30:00\n    23:45:00\n]"], "Parameters": [["start", "Lower bound of the time range.\nIf omitted, defaults to time(0,0,0,0) ."], ["end", "Upper bound of the time range.\nIf omitted, defaults to time(23,59,59,999999) ."], ["interval", "Interval of the range periods, specified as a Python timedelta object\nor using the Polars duration string language (see “Notes” section below)."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the range are closed (inclusive)."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type :class:Time ."]], "Category": ["Functions"], "index": 141}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.time_ranges.html#polars.time_ranges"], "Title": ["time_ranges"], "Feature": ["time_ranges"], "Description": ["Create a column of time ranges."], "Examples": [">>> from datetime import time\n>>> df = pl.DataFrame(\n...     {\n...         \"start\": [time(9, 0), time(10, 0)],\n...         \"end\": time(11, 0),\n...     }\n... )\n>>> df.with_columns(time_range=pl.time_ranges(\"start\", \"end\"))\nshape: (2, 3)\n┌──────────┬──────────┬────────────────────────────────┐\n│ start    ┆ end      ┆ time_range                     │\n│ ---      ┆ ---      ┆ ---                            │\n│ time     ┆ time     ┆ list[time]                     │\n╞══════════╪══════════╪════════════════════════════════╡\n│ 09:00:00 ┆ 11:00:00 ┆ [09:00:00, 10:00:00, 11:00:00] │\n│ 10:00:00 ┆ 11:00:00 ┆ [10:00:00, 11:00:00]           │\n└──────────┴──────────┴────────────────────────────────┘"], "Parameters": [["start", "Lower bound of the time range.\nIf omitted, defaults to time(0, 0, 0, 0) ."], ["end", "Upper bound of the time range.\nIf omitted, defaults to time(23, 59, 59, 999999) ."], ["interval", "Interval of the range periods, specified as a Python timedelta object\nor using the Polars duration string language (see “Notes” section below)."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the range are closed (inclusive)."], ["eager", "Evaluate immediately and return a Series .\nIf set to False (default), return an expression instead."]], "Returns": [["Expr or Series", "Column of data type List(Time) ."]], "Category": ["Functions"], "index": 142}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.var.html#polars.var"], "Title": ["var"], "Feature": ["var"], "Description": ["Get the variance."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 8, 3],\n...         \"b\": [4, 5, 2],\n...         \"c\": [\"foo\", \"bar\", \"foo\"],\n...     },\n... )\n>>> df.select(pl.var(\"a\"))\nshape: (1, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ 13.0 │\n└──────┘\n>>> df[\"a\"].var()\n13.0"], "Parameters": [["column", "Column name."], ["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Functions"], "index": 143}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.when.html#polars.when"], "Title": ["when"], "Feature": ["when"], "Description": ["Start awhen-then-otherwiseexpression."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 3, 4], \"bar\": [3, 4, 0]})\n>>> df.with_columns(\n...     pl.when(pl.col.foo > 2).then(1).otherwise(1 + pl.col.bar).alias(\"val\")\n... )\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ val │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 3   ┆ 4   │\n│ 3   ┆ 4   ┆ 1   │\n│ 4   ┆ 0   ┆ 1   │\n└─────┴─────┴─────┘", ">>> df.with_columns(\n...     when = pl.col.foo > 2,\n...     then = 1,\n...     otherwise = 1 + pl.col.bar\n... ).with_columns(\n...     pl.when(\"when\").then(\"then\").otherwise(\"otherwise\").alias(\"val\")\n... )\nshape: (3, 6)\n┌─────┬─────┬───────┬──────┬───────────┬─────┐\n│ foo ┆ bar ┆ when  ┆ then ┆ otherwise ┆ val │\n│ --- ┆ --- ┆ ---   ┆ ---  ┆ ---       ┆ --- │\n│ i64 ┆ i64 ┆ bool  ┆ i32  ┆ i64       ┆ i64 │\n╞═════╪═════╪═══════╪══════╪═══════════╪═════╡\n│ 1   ┆ 3   ┆ false ┆ 1    ┆ 4         ┆ 4   │\n│ 3   ┆ 4   ┆ true  ┆ 1    ┆ 5         ┆ 1   │\n│ 4   ┆ 0   ┆ true  ┆ 1    ┆ 1         ┆ 1   │\n└─────┴─────┴───────┴──────┴───────────┴─────┘", ">>> df.with_columns(\n...     when = pl.col.foo > 2,\n...     then = \"foo\",\n...     otherwise = \"bar\"\n... )\nshape: (3, 5)\n┌─────┬─────┬───────┬──────┬───────────┐\n│ foo ┆ bar ┆ when  ┆ then ┆ otherwise │\n│ --- ┆ --- ┆ ---   ┆ ---  ┆ ---       │\n│ i64 ┆ i64 ┆ bool  ┆ i64  ┆ i64       │\n╞═════╪═════╪═══════╪══════╪═══════════╡\n│ 1   ┆ 3   ┆ false ┆ 1    ┆ 3         │\n│ 3   ┆ 4   ┆ true  ┆ 3    ┆ 4         │\n│ 4   ┆ 0   ┆ true  ┆ 4    ┆ 0         │\n└─────┴─────┴───────┴──────┴───────────┘", ">>> df.with_columns(\n...     pl.when(pl.col.foo > 2).then(\"foo\").otherwise(\"bar\").alias(\"val\")\n... )\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ val │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 3   ┆ 3   │\n│ 3   ┆ 4   ┆ 3   │\n│ 4   ┆ 0   ┆ 4   │\n└─────┴─────┴─────┘", ">>> df.with_columns(\n...     pl.when(pl.col.foo > 2)\n...     .then(pl.lit(\"foo\"))\n...     .otherwise(pl.lit(\"bar\"))\n...     .alias(\"val\")\n... )\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ val │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 3   ┆ bar │\n│ 3   ┆ 4   ┆ foo │\n│ 4   ┆ 0   ┆ foo │\n└─────┴─────┴─────┘", ">>> df.with_columns(\n...     pl.when(pl.col.foo > 2)\n...     .then(1)\n...     .when(pl.col.bar > 2)\n...     .then(4)\n...     .otherwise(-1)\n...     .alias(\"val\")\n... )\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ val │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i32 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 3   ┆ 4   │\n│ 3   ┆ 4   ┆ 1   │\n│ 4   ┆ 0   ┆ 1   │\n└─────┴─────┴─────┘", ">>> df.with_columns(\n...     when1 = pl.col.foo > 2,\n...     then1 = 1,\n...     when2 = pl.col.bar > 2,\n...     then2 = 4,\n...     otherwise = -1\n... )\nshape: (3, 7)\n┌─────┬─────┬───────┬───────┬───────┬───────┬───────────┐\n│ foo ┆ bar ┆ when1 ┆ then1 ┆ when2 ┆ then2 ┆ otherwise │\n│ --- ┆ --- ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---       │\n│ i64 ┆ i64 ┆ bool  ┆ i32   ┆ bool  ┆ i32   ┆ i32       │\n╞═════╪═════╪═══════╪═══════╪═══════╪═══════╪═══════════╡\n│ 1   ┆ 3   ┆ false ┆ 1     ┆ true  ┆ 4     ┆ -1        │\n│ 3   ┆ 4   ┆ true  ┆ 1     ┆ true  ┆ 4     ┆ -1        │\n│ 4   ┆ 0   ┆ true  ┆ 1     ┆ false ┆ 4     ┆ -1        │\n└─────┴─────┴───────┴───────┴───────┴───────┴───────────┘", ">>> df.with_columns(pl.when(pl.col.foo == 3).then(\"bar\"))\nshape: (3, 2)\n┌─────┬──────┐\n│ foo ┆ bar  │\n│ --- ┆ ---  │\n│ i64 ┆ i64  │\n╞═════╪══════╡\n│ 1   ┆ null │\n│ 3   ┆ 4    │\n│ 4   ┆ null │\n└─────┴──────┘", ">>> df.with_columns(pl.when(foo=3).then(\"bar\"))\nshape: (3, 2)\n┌─────┬──────┐\n│ foo ┆ bar  │\n│ --- ┆ ---  │\n│ i64 ┆ i64  │\n╞═════╪══════╡\n│ 1   ┆ null │\n│ 3   ┆ 4    │\n│ 4   ┆ null │\n└─────┴──────┘", ">>> df.with_columns(\n...     pl.when(pl.col.foo > 2, pl.col.bar < 3) # when((pred1) & (pred2))\n...     .then(pl.lit(\"Yes\"))\n...     .otherwise(pl.lit(\"No\"))\n...     .alias(\"val\")\n... )\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ val │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 3   ┆ No  │\n│ 3   ┆ 4   ┆ No  │\n│ 4   ┆ 0   ┆ Yes │\n└─────┴─────┴─────┘", ">>> df.with_columns(\n...     when = pl.all_horizontal(pl.col.foo > 2, pl.col.bar < 3)\n... )\nshape: (3, 3)\n┌─────┬─────┬───────┐\n│ foo ┆ bar ┆ when  │\n│ --- ┆ --- ┆ ---   │\n│ i64 ┆ i64 ┆ bool  │\n╞═════╪═════╪═══════╡\n│ 1   ┆ 3   ┆ false │\n│ 3   ┆ 4   ┆ false │\n│ 4   ┆ 0   ┆ true  │\n└─────┴─────┴───────┘", ">>> df.with_columns(\n...     pl.when(pl.col.foo > 2)\n...     .then(pl.struct(foo=\"bar\", bar=\"foo\"))\n...     .otherwise(pl.struct(\"foo\", \"bar\"))\n...     .struct.unnest()\n... )\nshape: (3, 2)\n┌─────┬─────┐\n│ foo ┆ bar │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 3   │\n│ 4   ┆ 3   │\n│ 0   ┆ 4   │\n└─────┴─────┘", ">>> df.with_columns(\n...     when = pl.col.foo > 2,\n...     then = pl.struct(foo=\"bar\", bar=\"foo\"),\n...     otherwise = pl.struct(\"foo\", \"bar\")\n... )\nshape: (3, 5)\n┌─────┬─────┬───────┬───────────┬───────────┐\n│ foo ┆ bar ┆ when  ┆ then      ┆ otherwise │\n│ --- ┆ --- ┆ ---   ┆ ---       ┆ ---       │\n│ i64 ┆ i64 ┆ bool  ┆ struct[2] ┆ struct[2] │\n╞═════╪═════╪═══════╪═══════════╪═══════════╡\n│ 1   ┆ 3   ┆ false ┆ {3,1}     ┆ {1,3}     │\n│ 3   ┆ 4   ┆ true  ┆ {4,3}     ┆ {3,4}     │\n│ 4   ┆ 0   ┆ true  ┆ {0,4}     ┆ {4,0}     │\n└─────┴─────┴───────┴───────────┴───────────┘", ">>> df.with_columns( \n...    pl.when(pl.any_horizontal(pl.all() < 2))\n...    .then(0)\n...    .otherwise(pl.all())\n... )\n# ComputeError: the name 'literal' passed to `LazyFrame.with_columns` is duplicate", ">>> df.with_columns(\n...    pl.when(pl.any_horizontal(pl.all() < 2))\n...    .then(0)\n...    .otherwise(pl.all())\n...    .name.keep()\n... )\nshape: (3, 2)\n┌─────┬─────┐\n│ foo ┆ bar │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 0   ┆ 0   │\n│ 3   ┆ 4   │\n│ 0   ┆ 0   │\n└─────┴─────┘", ">>> df.with_columns(\n...     pl.when(pl.any_horizontal(pl.all() < 2).not_())\n...     .then(pl.all())\n...     .otherwise(0)\n... )\nshape: (3, 2)\n┌─────┬─────┐\n│ foo ┆ bar │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 0   ┆ 0   │\n│ 3   ┆ 4   │\n│ 0   ┆ 0   │\n└─────┴─────┘"], "Parameters": [["predicates", "Condition(s) that must be met in order to apply the subsequent statement.\nAccepts one or more boolean expressions, which are implicitly combined with & ."], ["constraints", "Apply conditions as col_name = value keyword arguments that are treated as\nequality matches, such as x = 123 . As with the predicates parameter, multiple\nconditions are implicitly combined using & ."]], "Returns": [], "Category": ["Functions"], "index": 144}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.zeros.html#polars.zeros"], "Title": ["zeros"], "Feature": ["zeros"], "Description": ["Construct a column of lengthnfilled with zeros."], "Examples": [">>> pl.zeros(3, pl.Int8, eager=True)\nshape: (3,)\nSeries: 'zeros' [i8]\n[\n    0\n    0\n    0\n]"], "Parameters": [["n", "Length of the resulting column."], ["dtype", "Data type of the resulting column. Defaults to Float64."], ["eager", "Evaluate immediately and return a Series . If set to False ,\nreturn an expression instead."]], "Returns": [], "Category": ["Functions"], "index": 145}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.quantile.html#polars.Expr.quantile"], "Title": ["Expr.quantile"], "Feature": ["Expr.quantile"], "Description": ["Get quantile value."], "Examples": [">>> df = pl.DataFrame({\"a\": [0, 1, 2, 3, 4, 5]})\n>>> df.select(pl.col(\"a\").quantile(0.3))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 2.0 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"higher\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 2.0 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"lower\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"midpoint\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.5 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"linear\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.5 │\n└─────┘"], "Parameters": [["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."]], "Returns": [], "Category": ["Aggregation"], "index": 146}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.all.html#polars.Expr.all"], "Title": ["Expr.all"], "Feature": ["Expr.all"], "Description": ["Return whether all values in the column areTrue."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, True],\n...         \"b\": [False, True],\n...         \"c\": [None, True],\n...     }\n... )\n>>> df.select(pl.col(\"*\").all())\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ true │\n└──────┴───────┴──────┘", ">>> df.select(pl.col(\"*\").all(ignore_nulls=False))\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ null │\n└──────┴───────┴──────┘"], "Parameters": [["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is True . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no False values,\nthe output is null."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Functions"], "index": 147}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.any.html#polars.Expr.any"], "Title": ["Expr.any"], "Feature": ["Expr.any"], "Description": ["Return whether any of the values in the column areTrue."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, False],\n...         \"b\": [False, False],\n...         \"c\": [None, False],\n...     }\n... )\n>>> df.select(pl.col(\"*\").any())\nshape: (1, 3)\n┌──────┬───────┬───────┐\n│ a    ┆ b     ┆ c     │\n│ ---  ┆ ---   ┆ ---   │\n│ bool ┆ bool  ┆ bool  │\n╞══════╪═══════╪═══════╡\n│ true ┆ false ┆ false │\n└──────┴───────┴───────┘", ">>> df.select(pl.col(\"*\").any(ignore_nulls=False))\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ null │\n└──────┴───────┴──────┘"], "Parameters": [["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is False . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no True values,\nthe output is null."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Functions"], "index": 148}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.approx_n_unique.html#polars.Expr.approx_n_unique"], "Title": ["Expr.approx_n_unique"], "Feature": ["Expr.approx_n_unique"], "Description": ["Approximate count of unique values."], "Examples": [">>> df = pl.DataFrame({\"n\": [1, 1, 2]})\n>>> df.select(pl.col(\"n\").approx_n_unique())\nshape: (1, 1)\n┌─────┐\n│ n   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘\n>>> df = pl.DataFrame({\"n\": range(1000)})\n>>> df.select(\n...     exact=pl.col(\"n\").n_unique(),\n...     approx=pl.col(\"n\").approx_n_unique(),\n... )  \nshape: (1, 2)\n┌───────┬────────┐\n│ exact ┆ approx │\n│ ---   ┆ ---    │\n│ u32   ┆ u32    │\n╞═══════╪════════╡\n│ 1000  ┆ 1005   │\n└───────┴────────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 149}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.count.html#polars.Expr.count"], "Title": ["Expr.count"], "Feature": ["Expr.count"], "Description": ["Return the number of non-null elements in the column."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [None, 4, 4]})\n>>> df.select(pl.all().count())\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 3   ┆ 2   │\n└─────┴─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Functions"], "index": 150}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.first.html#polars.Expr.first"], "Title": ["Expr.first"], "Feature": ["Expr.first"], "Description": ["Get the first value."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2]})\n>>> df.select(pl.col(\"a\").first())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 151}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.head.html#polars.Expr.head"], "Title": ["Expr.head"], "Feature": ["Expr.head"], "Description": ["Get the firstnrows."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7]})\n>>> df.select(pl.col(\"foo\").head(3))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n└─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["Functions"], "index": 152}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.implode.html#polars.Expr.implode"], "Title": ["Expr.implode"], "Feature": ["Expr.implode"], "Description": ["Aggregate values into a list."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [4, 5, 6],\n...     }\n... )\n>>> df.select(pl.all().implode())\nshape: (1, 2)\n┌───────────┬───────────┐\n│ a         ┆ b         │\n│ ---       ┆ ---       │\n│ list[i64] ┆ list[i64] │\n╞═══════════╪═══════════╡\n│ [1, 2, 3] ┆ [4, 5, 6] │\n└───────────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 153}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.map_batches.html#polars.Expr.map_batches"], "Title": ["Expr.map_batches"], "Feature": ["Expr.map_batches"], "Description": ["Apply a custom python function to a whole Series or sequence of Series."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"sine\": [0.0, 1.0, 0.0, -1.0],\n...         \"cosine\": [1.0, 0.0, -1.0, 0.0],\n...     }\n... )\n>>> df.select(\n...     pl.all().map_batches(\n...         lambda x: x.to_numpy().argmax(),\n...         returns_scalar=True,\n...     )\n... )\nshape: (1, 2)\n┌──────┬────────┐\n│ sine ┆ cosine │\n│ ---  ┆ ---    │\n│ i64  ┆ i64    │\n╞══════╪════════╡\n│ 1    ┆ 0      │\n└──────┴────────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [0, 1, 0, 1],\n...         \"b\": [1, 2, 3, 4],\n...     }\n... )\n>>> df.group_by(\"a\").agg(\n...     pl.col(\"b\").map_batches(\n...         lambda x: x.max(), returns_scalar=True, return_dtype=pl.self_dtype()\n...     )\n... )  \nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 4   │\n│ 0   ┆ 3   │\n└─────┴─────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [5, 1, 0, 3],\n...         \"b\": [4, 2, 3, 4],\n...     }\n... )\n>>> df.with_columns(\n...     a_times_b=pl.struct(\"a\", \"b\").map_batches(\n...         lambda x: np.multiply(x.struct.field(\"a\"), x.struct.field(\"b\")),\n...         return_dtype=pl.Int64,\n...     )\n... )\nshape: (4, 3)\n┌─────┬─────┬───────────┐\n│ a   ┆ b   ┆ a_times_b │\n│ --- ┆ --- ┆ ---       │\n│ i64 ┆ i64 ┆ i64       │\n╞═════╪═════╪═══════════╡\n│ 5   ┆ 4   ┆ 20        │\n│ 1   ┆ 2   ┆ 2         │\n│ 0   ┆ 3   ┆ 0         │\n│ 3   ┆ 4   ┆ 12        │\n└─────┴─────┴───────────┘"], "Parameters": [["function", "Lambda/function to apply."], ["return_dtype", "Datatype of the output Series. It is recommended to set this whenever possible. If this is None , it tries\nto infer the datatype by calling the function with dummy data and looking at\nthe output."], ["agg_list", "First implode when in a group-by aggregation. Deprecated since version 1.32.0: Use expr.implode().map_batches(..) instead."], ["is_elementwise", "Set to true if the operations is elementwise for better performance\nand optimization. An elementwise operations has unit or equal length for all inputs\nand can be ran sequentially on slices without results being affected."], ["returns_scalar", "If the function returns a scalar, by default it will be wrapped in\na list in the output, since the assumption is that the function\nalways returns something Series-like. If you want to keep the\nresult as a scalar, set this argument to True."]], "Returns": [], "Category": ["Functions"], "index": 154}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.map_elements.html#polars.Expr.map_elements"], "Title": ["Expr.map_elements"], "Feature": ["Expr.map_elements"], "Description": ["Map a custom/user-defined function (UDF) to each element of a column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 1],\n...         \"b\": [\"a\", \"b\", \"c\", \"c\"],\n...     }\n... )", ">>> df.with_columns(  \n...     pl.col(\"a\")\n...     .map_elements(lambda x: x * 2, return_dtype=pl.self_dtype())\n...     .alias(\"a_times_2\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬───────────┐\n│ a   ┆ b   ┆ a_times_2 │\n│ --- ┆ --- ┆ ---       │\n│ i64 ┆ str ┆ i64       │\n╞═════╪═════╪═══════════╡\n│ 1   ┆ a   ┆ 2         │\n│ 2   ┆ b   ┆ 4         │\n│ 3   ┆ c   ┆ 6         │\n│ 1   ┆ c   ┆ 2         │\n└─────┴─────┴───────────┘", ">>> df.with_columns(\n...     (pl.col(\"a\") * 2).alias(\"a_times_2\"),\n... )", ">>> (\n...     df.lazy()\n...     .group_by(\"b\")\n...     .agg(\n...         pl.col(\"a\")\n...         .implode()\n...         .map_elements(lambda x: x.sum(), return_dtype=pl.Int64)\n...     )\n...     .collect()\n... )  \nshape: (3, 2)\n┌─────┬─────┐\n│ b   ┆ a   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ a   ┆ 1   │\n│ b   ┆ 2   │\n│ c   ┆ 4   │\n└─────┴─────┘", ">>> (\n...     df.lazy()\n...     .group_by(\"b\", maintain_order=True)\n...     .agg(pl.col(\"a\").sum())\n...     .collect()\n... )", ">>> df = pl.DataFrame(\n...     {\n...         \"key\": [\"x\", \"x\", \"y\", \"x\", \"y\", \"z\"],\n...         \"val\": [1, 1, 1, 1, 1, 1],\n...     }\n... )\n>>> df.with_columns(\n...     scaled=pl.col(\"val\")\n...     .implode()\n...     .map_elements(lambda s: s * len(s), return_dtype=pl.List(pl.Int64))\n...     .explode()\n...     .over(\"key\"),\n... ).sort(\"key\")\nshape: (6, 3)\n┌─────┬─────┬────────┐\n│ key ┆ val ┆ scaled │\n│ --- ┆ --- ┆ ---    │\n│ str ┆ i64 ┆ i64    │\n╞═════╪═════╪════════╡\n│ x   ┆ 1   ┆ 3      │\n│ x   ┆ 1   ┆ 3      │\n│ x   ┆ 1   ┆ 3      │\n│ y   ┆ 1   ┆ 2      │\n│ y   ┆ 1   ┆ 2      │\n│ z   ┆ 1   ┆ 1      │\n└─────┴─────┴────────┘", ">>> df.with_columns(\n...     scaled=(pl.col(\"val\") * pl.col(\"val\").count()).over(\"key\"),\n... ).sort(\"key\")"], "Parameters": [["function", "Lambda/function to map."], ["return_dtype", "Datatype of the output Series. It is recommended to set this whenever possible. If this is None , it tries\nto infer the datatype by calling the function with dummy data and looking at\nthe output."], ["skip_nulls", "Don’t map the function over values that contain nulls (this is faster)."], ["pass_name", "Pass the Series name to the custom function (this is more expensive)."], ["returns_scalar", "Deprecated since version 1.32.0: Is ignored and will be removed in 2.0."], ["strategy {‘thread_local’, ‘threading’}", "The threading strategy to use. ‘thread_local’: run the python function on a single thread. ‘threading’: run the python function on separate threads. Use with\ncare as this can slow performance. This might only speed up\nyour code if the amount of work per element is significant\nand the python function releases the GIL (e.g. via calling\na c function) Warning This functionality is considered unstable . It may be changed\nat any point without it being considered a breaking change."]], "Returns": [], "Category": ["Functions"], "index": 155}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.max.html#polars.Expr.max"], "Title": ["Expr.max"], "Feature": ["Expr.max"], "Description": ["Get maximum value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1.0, float(\"nan\"), 1.0]})\n>>> df.select(pl.col(\"a\").max())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 156}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.std.html#polars.Expr.std"], "Title": ["Expr.std"], "Feature": ["Expr.std"], "Description": ["Get standard deviation."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").std())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Aggregation"], "index": 157}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.mean.html#polars.Expr.mean"], "Title": ["Expr.mean"], "Feature": ["Expr.mean"], "Description": ["Get mean value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").mean())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 158}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.median.html#polars.Expr.median"], "Title": ["Expr.median"], "Feature": ["Expr.median"], "Description": ["Get median value using linear interpolation."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").median())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 159}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.min.html#polars.Expr.min"], "Title": ["Expr.min"], "Feature": ["Expr.min"], "Description": ["Get minimum value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1.0, float(\"nan\"), 1.0]})\n>>> df.select(pl.col(\"a\").min())\nshape: (1, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ -1.0 │\n└──────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 160}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.n_unique.html#polars.Expr.n_unique"], "Title": ["Expr.n_unique"], "Feature": ["Expr.n_unique"], "Description": ["Count unique values."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 1, 2, 2, 3], \"y\": [1, 1, 1, None, None]})\n>>> df.select(\n...     x_unique=pl.col(\"x\").n_unique(),\n...     y_unique=pl.col(\"y\").n_unique(),\n... )\nshape: (1, 2)\n┌──────────┬──────────┐\n│ x_unique ┆ y_unique │\n│ ---      ┆ ---      │\n│ u32      ┆ u32      │\n╞══════════╪══════════╡\n│ 3        ┆ 2        │\n└──────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 161}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.quantile.html#polars.Expr.quantile"], "Title": ["Expr.quantile"], "Feature": ["Expr.quantile"], "Description": ["Get quantile value."], "Examples": [">>> df = pl.DataFrame({\"a\": [0, 1, 2, 3, 4, 5]})\n>>> df.select(pl.col(\"a\").quantile(0.3))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 2.0 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"higher\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 2.0 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"lower\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"midpoint\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.5 │\n└─────┘\n>>> df.select(pl.col(\"a\").quantile(0.3, interpolation=\"linear\"))\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.5 │\n└─────┘"], "Parameters": [["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."]], "Returns": [], "Category": ["Functions"], "index": 162}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.std.html#polars.Expr.std"], "Title": ["Expr.std"], "Feature": ["Expr.std"], "Description": ["Get standard deviation."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").std())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Functions"], "index": 163}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sum.html#polars.Expr.sum"], "Title": ["Expr.sum"], "Feature": ["Expr.sum"], "Description": ["Get sum value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").sum())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│  0  │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Functions"], "index": 164}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.tail.html#polars.Expr.tail"], "Title": ["Expr.tail"], "Feature": ["Expr.tail"], "Description": ["Get the lastnrows."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7]})\n>>> df.select(pl.col(\"foo\").tail(3))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 5   │\n│ 6   │\n│ 7   │\n└─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["Functions"], "index": 165}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.var.html#polars.Expr.var"], "Title": ["Expr.var"], "Feature": ["Expr.var"], "Description": ["Get variance."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").var())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Functions"], "index": 166}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.all.html#polars.Expr.list.all"], "Title": ["Expr.list.all"], "Feature": ["Expr.list.all"], "Description": ["Evaluate whether all boolean values in a list are true."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[True, True], [False, True], [False, False], [None], [], None]}\n... )\n>>> df.with_columns(all=pl.col(\"a\").list.all())\nshape: (6, 2)\n┌────────────────┬───────┐\n│ a              ┆ all   │\n│ ---            ┆ ---   │\n│ list[bool]     ┆ bool  │\n╞════════════════╪═══════╡\n│ [true, true]   ┆ true  │\n│ [false, true]  ┆ false │\n│ [false, false] ┆ false │\n│ [null]         ┆ true  │\n│ []             ┆ true  │\n│ null           ┆ null  │\n└────────────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 167}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sum.html#polars.Expr.sum"], "Title": ["Expr.sum"], "Feature": ["Expr.sum"], "Description": ["Get sum value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").sum())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│  0  │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 168}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.any.html#polars.Expr.list.any"], "Title": ["Expr.list.any"], "Feature": ["Expr.list.any"], "Description": ["Evaluate whether any boolean value in a list is true."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[True, True], [False, True], [False, False], [None], [], None]}\n... )\n>>> df.with_columns(any=pl.col(\"a\").list.any())\nshape: (6, 2)\n┌────────────────┬───────┐\n│ a              ┆ any   │\n│ ---            ┆ ---   │\n│ list[bool]     ┆ bool  │\n╞════════════════╪═══════╡\n│ [true, true]   ┆ true  │\n│ [false, true]  ┆ true  │\n│ [false, false] ┆ false │\n│ [null]         ┆ false │\n│ []             ┆ false │\n│ null           ┆ null  │\n└────────────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 169}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.arg_max.html#polars.Expr.list.arg_max"], "Title": ["Expr.list.arg_max"], "Feature": ["Expr.list.arg_max"], "Description": ["Retrieve the index of the maximum value in every sublist."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2], [2, 1]],\n...     }\n... )\n>>> df.with_columns(arg_max=pl.col(\"a\").list.arg_max())\nshape: (2, 2)\n┌───────────┬─────────┐\n│ a         ┆ arg_max │\n│ ---       ┆ ---     │\n│ list[i64] ┆ u32     │\n╞═══════════╪═════════╡\n│ [1, 2]    ┆ 1       │\n│ [2, 1]    ┆ 0       │\n└───────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 or UInt64 (depending on compilation)."]], "Category": ["List"], "index": 170}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.arg_min.html#polars.Expr.list.arg_min"], "Title": ["Expr.list.arg_min"], "Feature": ["Expr.list.arg_min"], "Description": ["Retrieve the index of the minimal value in every sublist."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2], [2, 1]],\n...     }\n... )\n>>> df.with_columns(arg_min=pl.col(\"a\").list.arg_min())\nshape: (2, 2)\n┌───────────┬─────────┐\n│ a         ┆ arg_min │\n│ ---       ┆ ---     │\n│ list[i64] ┆ u32     │\n╞═══════════╪═════════╡\n│ [1, 2]    ┆ 0       │\n│ [2, 1]    ┆ 1       │\n└───────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 or UInt64 (depending on compilation)."]], "Category": ["List"], "index": 171}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.concat.html#polars.Expr.list.concat"], "Title": ["Expr.list.concat"], "Feature": ["Expr.list.concat"], "Description": ["Concat the arrays in a Series dtype List in linear time."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[\"a\"], [\"x\"]],\n...         \"b\": [[\"b\", \"c\"], [\"y\", \"z\"]],\n...     }\n... )\n>>> df.with_columns(concat=pl.col(\"a\").list.concat(\"b\"))\nshape: (2, 3)\n┌───────────┬────────────┬─────────────────┐\n│ a         ┆ b          ┆ concat          │\n│ ---       ┆ ---        ┆ ---             │\n│ list[str] ┆ list[str]  ┆ list[str]       │\n╞═══════════╪════════════╪═════════════════╡\n│ [\"a\"]     ┆ [\"b\", \"c\"] ┆ [\"a\", \"b\", \"c\"] │\n│ [\"x\"]     ┆ [\"y\", \"z\"] ┆ [\"x\", \"y\", \"z\"] │\n└───────────┴────────────┴─────────────────┘"], "Parameters": [["other", "Columns to concat into a List Series"]], "Returns": [], "Category": ["List"], "index": 172}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.contains.html#polars.Expr.list.contains"], "Title": ["Expr.list.contains"], "Feature": ["Expr.list.contains"], "Description": ["Check if sublists contain the given item."], "Examples": [">>> df = pl.DataFrame({\"a\": [[3, 2, 1], [], [1, 2]]})\n>>> df.with_columns(contains=pl.col(\"a\").list.contains(1))\nshape: (3, 2)\n┌───────────┬──────────┐\n│ a         ┆ contains │\n│ ---       ┆ ---      │\n│ list[i64] ┆ bool     │\n╞═══════════╪══════════╡\n│ [3, 2, 1] ┆ true     │\n│ []        ┆ false    │\n│ [1, 2]    ┆ true     │\n└───────────┴──────────┘"], "Parameters": [["item", "Item that will be checked for membership"], ["nulls_equal bool, default True", "If True, treat null as a distinct value. Null values will not propagate."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["List"], "index": 173}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.count_matches.html#polars.Expr.list.count_matches"], "Title": ["Expr.list.count_matches"], "Feature": ["Expr.list.count_matches"], "Description": ["Count how often the value produced byelementoccurs."], "Examples": [">>> df = pl.DataFrame({\"a\": [[0], [1], [1, 2, 3, 2], [1, 2, 1], [4, 4]]})\n>>> df.with_columns(number_of_twos=pl.col(\"a\").list.count_matches(2))\nshape: (5, 2)\n┌─────────────┬────────────────┐\n│ a           ┆ number_of_twos │\n│ ---         ┆ ---            │\n│ list[i64]   ┆ u32            │\n╞═════════════╪════════════════╡\n│ [0]         ┆ 0              │\n│ [1]         ┆ 0              │\n│ [1, 2, … 2] ┆ 2              │\n│ [1, 2, 1]   ┆ 1              │\n│ [4, 4]      ┆ 0              │\n└─────────────┴────────────────┘"], "Parameters": [["element", "An expression that produces a single value"]], "Returns": [], "Category": ["List"], "index": 174}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.diff.html#polars.Expr.list.diff"], "Title": ["Expr.list.diff"], "Feature": ["Expr.list.diff"], "Description": ["Calculate the first discrete difference between shifted items of every sublist."], "Examples": [">>> df = pl.DataFrame({\"n\": [[1, 2, 3, 4], [10, 2, 1]]})\n>>> df.with_columns(diff=pl.col(\"n\").list.diff())\nshape: (2, 2)\n┌─────────────┬────────────────┐\n│ n           ┆ diff           │\n│ ---         ┆ ---            │\n│ list[i64]   ┆ list[i64]      │\n╞═════════════╪════════════════╡\n│ [1, 2, … 4] ┆ [null, 1, … 1] │\n│ [10, 2, 1]  ┆ [null, -8, -1] │\n└─────────────┴────────────────┘", ">>> df.with_columns(diff=pl.col(\"n\").list.diff(n=2))\nshape: (2, 2)\n┌─────────────┬───────────────────┐\n│ n           ┆ diff              │\n│ ---         ┆ ---               │\n│ list[i64]   ┆ list[i64]         │\n╞═════════════╪═══════════════════╡\n│ [1, 2, … 4] ┆ [null, null, … 2] │\n│ [10, 2, 1]  ┆ [null, null, -9]  │\n└─────────────┴───────────────────┘", ">>> df.with_columns(diff=pl.col(\"n\").list.diff(n=2, null_behavior=\"drop\"))\nshape: (2, 2)\n┌─────────────┬───────────┐\n│ n           ┆ diff      │\n│ ---         ┆ ---       │\n│ list[i64]   ┆ list[i64] │\n╞═════════════╪═══════════╡\n│ [1, 2, … 4] ┆ [2, 2]    │\n│ [10, 2, 1]  ┆ [-9]      │\n└─────────────┴───────────┘"], "Parameters": [["n", "Number of slots to shift."], ["null_behavior {‘ignore’, ‘drop’}", "How to handle null values."]], "Returns": [], "Category": ["List"], "index": 175}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.drop_nulls.html#polars.Expr.list.drop_nulls"], "Title": ["Expr.list.drop_nulls"], "Feature": ["Expr.list.drop_nulls"], "Description": ["Drop all null values in the list."], "Examples": [">>> df = pl.DataFrame({\"values\": [[None, 1, None, 2], [None], [3, 4]]})\n>>> df.with_columns(drop_nulls=pl.col(\"values\").list.drop_nulls())\nshape: (3, 2)\n┌────────────────┬────────────┐\n│ values         ┆ drop_nulls │\n│ ---            ┆ ---        │\n│ list[i64]      ┆ list[i64]  │\n╞════════════════╪════════════╡\n│ [null, 1, … 2] ┆ [1, 2]     │\n│ [null]         ┆ []         │\n│ [3, 4]         ┆ [3, 4]     │\n└────────────────┴────────────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 176}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.eval.html#polars.Expr.list.eval"], "Title": ["Expr.list.eval"], "Feature": ["Expr.list.eval"], "Description": ["Run any polars expression against the lists' elements."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 8, 3], \"b\": [4, 5, 2]})\n>>> df.with_columns(\n...     rank=pl.concat_list(\"a\", \"b\").list.eval(pl.element().rank())\n... )\nshape: (3, 3)\n┌─────┬─────┬────────────┐\n│ a   ┆ b   ┆ rank       │\n│ --- ┆ --- ┆ ---        │\n│ i64 ┆ i64 ┆ list[f64]  │\n╞═════╪═════╪════════════╡\n│ 1   ┆ 4   ┆ [1.0, 2.0] │\n│ 8   ┆ 5   ┆ [2.0, 1.0] │\n│ 3   ┆ 2   ┆ [2.0, 1.0] │\n└─────┴─────┴────────────┘"], "Parameters": [["expr", "Expression to run. Note that you can select an element with pl.first() , or pl.col()"], ["parallel", "Run all expression parallel. Don’t activate this blindly.\nParallelism is worth it if there is enough work to do per thread. This likely should not be used in the group by context, because we already\nparallel execution per group"]], "Returns": [], "Category": ["List"], "index": 177}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.explode.html#polars.Expr.list.explode"], "Title": ["Expr.list.explode"], "Feature": ["Expr.list.explode"], "Description": ["Returns a column with a separate row for every list element."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2, 3], [4, 5, 6]]})\n>>> df.select(pl.col(\"a\").list.explode())\nshape: (6, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n│ 4   │\n│ 5   │\n│ 6   │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression with the data type of the list elements."]], "Category": ["List"], "index": 178}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.var.html#polars.Expr.var"], "Title": ["Expr.var"], "Feature": ["Expr.var"], "Description": ["Get variance."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 1]})\n>>> df.select(pl.col(\"a\").var())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Aggregation"], "index": 179}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.filter.html#polars.Expr.list.filter"], "Title": ["Expr.list.filter"], "Feature": ["Expr.list.filter"], "Description": ["Filter elements in each list by a boolean expression."], "Examples": [">>> import polars as pl\n>>> df = pl.DataFrame({\"a\": [1, 8, 3], \"b\": [4, 5, 2]})\n>>> df.with_columns(\n...     evens=pl.concat_list(\"a\", \"b\").list.filter(pl.element() % 2 == 0)\n... )\nshape: (3, 3)\n┌─────┬─────┬───────────┐\n│ a   ┆ b   ┆ evens     │\n│ --- ┆ --- ┆ ---       │\n│ i64 ┆ i64 ┆ list[i64] │\n╞═════╪═════╪═══════════╡\n│ 1   ┆ 4   ┆ [4]       │\n│ 8   ┆ 5   ┆ [8]       │\n│ 3   ┆ 2   ┆ [2]       │\n└─────┴─────┴───────────┘"], "Parameters": [["predicate", "A boolean expression that is evaluated per list element.\nYou can refer to the current element with pl.element() ."]], "Returns": [], "Category": ["List"], "index": 180}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.first.html#polars.Expr.list.first"], "Title": ["Expr.list.first"], "Feature": ["Expr.list.first"], "Description": ["Get the first value of the sublists."], "Examples": [">>> df = pl.DataFrame({\"a\": [[3, 2, 1], [], [1, 2]]})\n>>> df.with_columns(first=pl.col(\"a\").list.first())\nshape: (3, 2)\n┌───────────┬───────┐\n│ a         ┆ first │\n│ ---       ┆ ---   │\n│ list[i64] ┆ i64   │\n╞═══════════╪═══════╡\n│ [3, 2, 1] ┆ 3     │\n│ []        ┆ null  │\n│ [1, 2]    ┆ 1     │\n└───────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 181}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.gather.html#polars.Expr.list.gather"], "Title": ["Expr.list.gather"], "Feature": ["Expr.list.gather"], "Description": ["Take sublists by multiple indices."], "Examples": [">>> df = pl.DataFrame({\"a\": [[3, 2, 1], [], [1, 2, 3, 4, 5]]})\n>>> df.with_columns(gather=pl.col(\"a\").list.gather([0, 4], null_on_oob=True))\nshape: (3, 2)\n┌─────────────┬──────────────┐\n│ a           ┆ gather       │\n│ ---         ┆ ---          │\n│ list[i64]   ┆ list[i64]    │\n╞═════════════╪══════════════╡\n│ [3, 2, 1]   ┆ [3, null]    │\n│ []          ┆ [null, null] │\n│ [1, 2, … 5] ┆ [1, 5]       │\n└─────────────┴──────────────┘"], "Parameters": [["indices", "Indices to return per sublist"], ["null_on_oob", "Behavior if an index is out of bounds:\nTrue -> set as null\nFalse -> raise an error\nNote that defaulting to raising an error is much cheaper"]], "Returns": [], "Category": ["List"], "index": 182}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.gather_every.html#polars.Expr.list.gather_every"], "Title": ["Expr.list.gather_every"], "Feature": ["Expr.list.gather_every"], "Description": ["Take every n-th value start from offset in sublists."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2, 3, 4, 5], [6, 7, 8], [9, 10, 11, 12]],\n...         \"n\": [2, 1, 3],\n...         \"offset\": [0, 1, 0],\n...     }\n... )\n>>> df.with_columns(\n...     gather_every=pl.col(\"a\").list.gather_every(\n...         n=pl.col(\"n\"), offset=pl.col(\"offset\")\n...     )\n... )\nshape: (3, 4)\n┌───────────────┬─────┬────────┬──────────────┐\n│ a             ┆ n   ┆ offset ┆ gather_every │\n│ ---           ┆ --- ┆ ---    ┆ ---          │\n│ list[i64]     ┆ i64 ┆ i64    ┆ list[i64]    │\n╞═══════════════╪═════╪════════╪══════════════╡\n│ [1, 2, … 5]   ┆ 2   ┆ 0      ┆ [1, 3, 5]    │\n│ [6, 7, 8]     ┆ 1   ┆ 1      ┆ [7, 8]       │\n│ [9, 10, … 12] ┆ 3   ┆ 0      ┆ [9, 12]      │\n└───────────────┴─────┴────────┴──────────────┘"], "Parameters": [["n", "Gather every n-th element."], ["offset", "Starting index."]], "Returns": [], "Category": ["List"], "index": 183}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.get.html#polars.Expr.list.get"], "Title": ["Expr.list.get"], "Feature": ["Expr.list.get"], "Description": ["Get the value by index in the sublists."], "Examples": [">>> df = pl.DataFrame({\"a\": [[3, 2, 1], [], [1, 2]]})\n>>> df.with_columns(get=pl.col(\"a\").list.get(0, null_on_oob=True))\nshape: (3, 2)\n┌───────────┬──────┐\n│ a         ┆ get  │\n│ ---       ┆ ---  │\n│ list[i64] ┆ i64  │\n╞═══════════╪══════╡\n│ [3, 2, 1] ┆ 3    │\n│ []        ┆ null │\n│ [1, 2]    ┆ 1    │\n└───────────┴──────┘"], "Parameters": [["index", "Index to return per sublist"], ["null_on_oob", "Behavior if an index is out of bounds: True -> set as null False -> raise an error"]], "Returns": [], "Category": ["List"], "index": 184}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.head.html#polars.Expr.list.head"], "Title": ["Expr.list.head"], "Feature": ["Expr.list.head"], "Description": ["Slice the firstnvalues of every sublist."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2, 3, 4], [10, 2, 1]]})\n>>> df.with_columns(head=pl.col(\"a\").list.head(2))\nshape: (2, 2)\n┌─────────────┬───────────┐\n│ a           ┆ head      │\n│ ---         ┆ ---       │\n│ list[i64]   ┆ list[i64] │\n╞═════════════╪═══════════╡\n│ [1, 2, … 4] ┆ [1, 2]    │\n│ [10, 2, 1]  ┆ [10, 2]   │\n└─────────────┴───────────┘"], "Parameters": [["n", "Number of values to return for each sublist."]], "Returns": [], "Category": ["List"], "index": 185}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.join.html#polars.Expr.list.join"], "Title": ["Expr.list.join"], "Feature": ["Expr.list.join"], "Description": ["Join all string items in a sublist and place a separator between them."], "Examples": [">>> df = pl.DataFrame({\"s\": [[\"a\", \"b\", \"c\"], [\"x\", \"y\"]]})\n>>> df.with_columns(join=pl.col(\"s\").list.join(\" \"))\nshape: (2, 2)\n┌─────────────────┬───────┐\n│ s               ┆ join  │\n│ ---             ┆ ---   │\n│ list[str]       ┆ str   │\n╞═════════════════╪═══════╡\n│ [\"a\", \"b\", \"c\"] ┆ a b c │\n│ [\"x\", \"y\"]      ┆ x y   │\n└─────────────────┴───────┘", ">>> df = pl.DataFrame(\n...     {\"s\": [[\"a\", \"b\", \"c\"], [\"x\", \"y\"]], \"separator\": [\"*\", \"_\"]}\n... )\n>>> df.with_columns(join=pl.col(\"s\").list.join(pl.col(\"separator\")))\nshape: (2, 3)\n┌─────────────────┬───────────┬───────┐\n│ s               ┆ separator ┆ join  │\n│ ---             ┆ ---       ┆ ---   │\n│ list[str]       ┆ str       ┆ str   │\n╞═════════════════╪═══════════╪═══════╡\n│ [\"a\", \"b\", \"c\"] ┆ *         ┆ a*b*c │\n│ [\"x\", \"y\"]      ┆ _         ┆ x_y   │\n└─────────────────┴───────────┴───────┘"], "Parameters": [["separator", "string to separate the items with"], ["ignore_nulls", "Ignore null values (default). If set to False , null values will be propagated.\nIf the sub-list contains any null values, the output is None ."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["List"], "index": 186}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.last.html#polars.Expr.list.last"], "Title": ["Expr.list.last"], "Feature": ["Expr.list.last"], "Description": ["Get the last value of the sublists."], "Examples": [">>> df = pl.DataFrame({\"a\": [[3, 2, 1], [], [1, 2]]})\n>>> df.with_columns(last=pl.col(\"a\").list.last())\nshape: (3, 2)\n┌───────────┬──────┐\n│ a         ┆ last │\n│ ---       ┆ ---  │\n│ list[i64] ┆ i64  │\n╞═══════════╪══════╡\n│ [3, 2, 1] ┆ 1    │\n│ []        ┆ null │\n│ [1, 2]    ┆ 2    │\n└───────────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 187}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.len.html#polars.Expr.list.len"], "Title": ["Expr.list.len"], "Feature": ["Expr.list.len"], "Description": ["Return the number of elements in each list."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2, None], [5]]})\n>>> df.with_columns(len=pl.col(\"a\").list.len())\nshape: (2, 2)\n┌──────────────┬─────┐\n│ a            ┆ len │\n│ ---          ┆ --- │\n│ list[i64]    ┆ u32 │\n╞══════════════╪═════╡\n│ [1, 2, null] ┆ 3   │\n│ [5]          ┆ 1   │\n└──────────────┴─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["List"], "index": 188}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.max.html#polars.Expr.list.max"], "Title": ["Expr.list.max"], "Feature": ["Expr.list.max"], "Description": ["Compute the max value of the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[1], [2, 3]]})\n>>> df.with_columns(max=pl.col(\"values\").list.max())\nshape: (2, 2)\n┌───────────┬─────┐\n│ values    ┆ max │\n│ ---       ┆ --- │\n│ list[i64] ┆ i64 │\n╞═══════════╪═════╡\n│ [1]       ┆ 1   │\n│ [2, 3]    ┆ 3   │\n└───────────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 189}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.all.html#polars.Expr.arr.all"], "Title": ["Expr.arr.all"], "Feature": ["Expr.arr.all"], "Description": ["Evaluate whether all boolean values are true for every subarray."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"a\": [\n...             [True, True],\n...             [False, True],\n...             [False, False],\n...             [None, None],\n...             None,\n...         ]\n...     },\n...     schema={\"a\": pl.Array(pl.Boolean, 2)},\n... )\n>>> df.with_columns(all=pl.col(\"a\").arr.all())\nshape: (5, 2)\n┌────────────────┬───────┐\n│ a              ┆ all   │\n│ ---            ┆ ---   │\n│ array[bool, 2] ┆ bool  │\n╞════════════════╪═══════╡\n│ [true, true]   ┆ true  │\n│ [false, true]  ┆ false │\n│ [false, false] ┆ false │\n│ [null, null]   ┆ true  │\n│ null           ┆ null  │\n└────────────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 190}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.mean.html#polars.Expr.list.mean"], "Title": ["Expr.list.mean"], "Feature": ["Expr.list.mean"], "Description": ["Compute the mean value of the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[1], [2, 3]]})\n>>> df.with_columns(mean=pl.col(\"values\").list.mean())\nshape: (2, 2)\n┌───────────┬──────┐\n│ values    ┆ mean │\n│ ---       ┆ ---  │\n│ list[i64] ┆ f64  │\n╞═══════════╪══════╡\n│ [1]       ┆ 1.0  │\n│ [2, 3]    ┆ 2.5  │\n└───────────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 191}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.median.html#polars.Expr.list.median"], "Title": ["Expr.list.median"], "Feature": ["Expr.list.median"], "Description": ["Compute the median value of the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[-1, 0, 1], [1, 10]]})\n>>> df.with_columns(pl.col(\"values\").list.median().alias(\"median\"))\nshape: (2, 2)\n┌────────────┬────────┐\n│ values     ┆ median │\n│ ---        ┆ ---    │\n│ list[i64]  ┆ f64    │\n╞════════════╪════════╡\n│ [-1, 0, 1] ┆ 0.0    │\n│ [1, 10]    ┆ 5.5    │\n└────────────┴────────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 192}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.min.html#polars.Expr.list.min"], "Title": ["Expr.list.min"], "Feature": ["Expr.list.min"], "Description": ["Compute the min value of the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[1], [2, 3]]})\n>>> df.with_columns(min=pl.col(\"values\").list.min())\nshape: (2, 2)\n┌───────────┬─────┐\n│ values    ┆ min │\n│ ---       ┆ --- │\n│ list[i64] ┆ i64 │\n╞═══════════╪═════╡\n│ [1]       ┆ 1   │\n│ [2, 3]    ┆ 2   │\n└───────────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 193}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.n_unique.html#polars.Expr.list.n_unique"], "Title": ["Expr.list.n_unique"], "Feature": ["Expr.list.n_unique"], "Description": ["Count the number of unique values in every sub-lists."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 1, 2], [2, 3, 4]],\n...     }\n... )\n>>> df.with_columns(n_unique=pl.col(\"a\").list.n_unique())\nshape: (2, 2)\n┌───────────┬──────────┐\n│ a         ┆ n_unique │\n│ ---       ┆ ---      │\n│ list[i64] ┆ u32      │\n╞═══════════╪══════════╡\n│ [1, 1, 2] ┆ 2        │\n│ [2, 3, 4] ┆ 3        │\n└───────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 194}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.reverse.html#polars.Expr.list.reverse"], "Title": ["Expr.list.reverse"], "Feature": ["Expr.list.reverse"], "Description": ["Reverse the arrays in the list."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[3, 2, 1], [9, 1, 2]],\n...     }\n... )\n>>> df.with_columns(reverse=pl.col(\"a\").list.reverse())\nshape: (2, 2)\n┌───────────┬───────────┐\n│ a         ┆ reverse   │\n│ ---       ┆ ---       │\n│ list[i64] ┆ list[i64] │\n╞═══════════╪═══════════╡\n│ [3, 2, 1] ┆ [1, 2, 3] │\n│ [9, 1, 2] ┆ [2, 1, 9] │\n└───────────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 195}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.sample.html#polars.Expr.list.sample"], "Title": ["Expr.list.sample"], "Feature": ["Expr.list.sample"], "Description": ["Sample from this list."], "Examples": [">>> df = pl.DataFrame({\"values\": [[1, 2, 3], [4, 5]], \"n\": [2, 1]})\n>>> df.with_columns(sample=pl.col(\"values\").list.sample(n=pl.col(\"n\"), seed=1))\nshape: (2, 3)\n┌───────────┬─────┬───────────┐\n│ values    ┆ n   ┆ sample    │\n│ ---       ┆ --- ┆ ---       │\n│ list[i64] ┆ i64 ┆ list[i64] │\n╞═══════════╪═════╪═══════════╡\n│ [1, 2, 3] ┆ 2   ┆ [2, 3]    │\n│ [4, 5]    ┆ 1   ┆ [5]       │\n└───────────┴─────┴───────────┘"], "Parameters": [["n", "Number of items to return. Cannot be used with fraction . Defaults to 1 if fraction is None."], ["fraction", "Fraction of items to return. Cannot be used with n ."], ["with_replacement", "Allow values to be sampled more than once."], ["shuffle", "Shuffle the order of sampled data points."], ["seed", "Seed for the random number generator. If set to None (default), a\nrandom seed is generated for each sample operation."]], "Returns": [], "Category": ["List"], "index": 196}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.set_difference.html#polars.Expr.list.set_difference"], "Title": ["Expr.list.set_difference"], "Feature": ["Expr.list.set_difference"], "Description": ["Compute the SET DIFFERENCE between the elements in this list and the elements ofother."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2, 3], [], [None, 3], [5, 6, 7]],\n...         \"b\": [[2, 3, 4], [3], [3, 4, None], [6, 8]],\n...     }\n... )\n>>> df.with_columns(difference=pl.col(\"a\").list.set_difference(\"b\"))\nshape: (4, 3)\n┌───────────┬──────────────┬────────────┐\n│ a         ┆ b            ┆ difference │\n│ ---       ┆ ---          ┆ ---        │\n│ list[i64] ┆ list[i64]    ┆ list[i64]  │\n╞═══════════╪══════════════╪════════════╡\n│ [1, 2, 3] ┆ [2, 3, 4]    ┆ [1]        │\n│ []        ┆ [3]          ┆ []         │\n│ [null, 3] ┆ [3, 4, null] ┆ []         │\n│ [5, 6, 7] ┆ [6, 8]       ┆ [5, 7]     │\n└───────────┴──────────────┴────────────┘"], "Parameters": [["other", "Right hand side of the set operation."]], "Returns": [], "Category": ["List"], "index": 197}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.set_intersection.html#polars.Expr.list.set_intersection"], "Title": ["Expr.list.set_intersection"], "Feature": ["Expr.list.set_intersection"], "Description": ["Compute the SET INTERSECTION between the elements in this list and the elements ofother."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2, 3], [], [None, 3], [5, 6, 7]],\n...         \"b\": [[2, 3, 4], [3], [3, 4, None], [6, 8]],\n...     }\n... )\n>>> df.with_columns(intersection=pl.col(\"a\").list.set_intersection(\"b\"))\nshape: (4, 3)\n┌───────────┬──────────────┬──────────────┐\n│ a         ┆ b            ┆ intersection │\n│ ---       ┆ ---          ┆ ---          │\n│ list[i64] ┆ list[i64]    ┆ list[i64]    │\n╞═══════════╪══════════════╪══════════════╡\n│ [1, 2, 3] ┆ [2, 3, 4]    ┆ [2, 3]       │\n│ []        ┆ [3]          ┆ []           │\n│ [null, 3] ┆ [3, 4, null] ┆ [null, 3]    │\n│ [5, 6, 7] ┆ [6, 8]       ┆ [6]          │\n└───────────┴──────────────┴──────────────┘"], "Parameters": [["other", "Right hand side of the set operation."]], "Returns": [], "Category": ["List"], "index": 198}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.set_symmetric_difference.html#polars.Expr.list.set_symmetric_difference"], "Title": ["Expr.list.set_symmetric_difference"], "Feature": ["Expr.list.set_symmetric_difference"], "Description": ["Compute the SET SYMMETRIC DIFFERENCE between the elements in this list and the elements ofother."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2, 3], [], [None, 3], [5, 6, 7]],\n...         \"b\": [[2, 3, 4], [3], [3, 4, None], [6, 8]],\n...     }\n... )\n>>> df.with_columns(sdiff=pl.col(\"b\").list.set_symmetric_difference(\"a\"))\nshape: (4, 3)\n┌───────────┬──────────────┬───────────┐\n│ a         ┆ b            ┆ sdiff     │\n│ ---       ┆ ---          ┆ ---       │\n│ list[i64] ┆ list[i64]    ┆ list[i64] │\n╞═══════════╪══════════════╪═══════════╡\n│ [1, 2, 3] ┆ [2, 3, 4]    ┆ [4, 1]    │\n│ []        ┆ [3]          ┆ [3]       │\n│ [null, 3] ┆ [3, 4, null] ┆ [4]       │\n│ [5, 6, 7] ┆ [6, 8]       ┆ [8, 5, 7] │\n└───────────┴──────────────┴───────────┘"], "Parameters": [["other", "Right hand side of the set operation."]], "Returns": [], "Category": ["List"], "index": 199}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.set_union.html#polars.Expr.list.set_union"], "Title": ["Expr.list.set_union"], "Feature": ["Expr.list.set_union"], "Description": ["Compute the SET UNION between the elements in this list and the elements ofother."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2, 3], [], [None, 3], [5, 6, 7]],\n...         \"b\": [[2, 3, 4], [3], [3, 4, None], [6, 8]],\n...     }\n... )\n>>> df.with_columns(\n...     union=pl.col(\"a\").list.set_union(\"b\")\n... )  \nshape: (4, 3)\n┌───────────┬──────────────┬───────────────┐\n│ a         ┆ b            ┆ union         │\n│ ---       ┆ ---          ┆ ---           │\n│ list[i64] ┆ list[i64]    ┆ list[i64]     │\n╞═══════════╪══════════════╪═══════════════╡\n│ [1, 2, 3] ┆ [2, 3, 4]    ┆ [1, 2, 3, 4]  │\n│ []        ┆ [3]          ┆ [3]           │\n│ [null, 3] ┆ [3, 4, null] ┆ [null, 3, 4]  │\n│ [5, 6, 7] ┆ [6, 8]       ┆ [5, 6, 7, 8]  │\n└───────────┴──────────────┴───────────────┘"], "Parameters": [["other", "Right hand side of the set operation."]], "Returns": [], "Category": ["List"], "index": 200}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.any.html#polars.Expr.arr.any"], "Title": ["Expr.arr.any"], "Feature": ["Expr.arr.any"], "Description": ["Evaluate whether any boolean value is true for every subarray."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"a\": [\n...             [True, True],\n...             [False, True],\n...             [False, False],\n...             [None, None],\n...             None,\n...         ]\n...     },\n...     schema={\"a\": pl.Array(pl.Boolean, 2)},\n... )\n>>> df.with_columns(any=pl.col(\"a\").arr.any())\nshape: (5, 2)\n┌────────────────┬───────┐\n│ a              ┆ any   │\n│ ---            ┆ ---   │\n│ array[bool, 2] ┆ bool  │\n╞════════════════╪═══════╡\n│ [true, true]   ┆ true  │\n│ [false, true]  ┆ true  │\n│ [false, false] ┆ false │\n│ [null, null]   ┆ false │\n│ null           ┆ null  │\n└────────────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 201}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.shift.html#polars.Expr.list.shift"], "Title": ["Expr.list.shift"], "Feature": ["Expr.list.shift"], "Description": ["Shift list values by the given number of indices."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2, 3], [4, 5]]})\n>>> df.with_columns(shift=pl.col(\"a\").list.shift())\nshape: (2, 2)\n┌───────────┬──────────────┐\n│ a         ┆ shift        │\n│ ---       ┆ ---          │\n│ list[i64] ┆ list[i64]    │\n╞═══════════╪══════════════╡\n│ [1, 2, 3] ┆ [null, 1, 2] │\n│ [4, 5]    ┆ [null, 4]    │\n└───────────┴──────────────┘", ">>> df.with_columns(shift=pl.col(\"a\").list.shift(-2))\nshape: (2, 2)\n┌───────────┬─────────────────┐\n│ a         ┆ shift           │\n│ ---       ┆ ---             │\n│ list[i64] ┆ list[i64]       │\n╞═══════════╪═════════════════╡\n│ [1, 2, 3] ┆ [3, null, null] │\n│ [4, 5]    ┆ [null, null]    │\n└───────────┴─────────────────┘"], "Parameters": [["n", "Number of indices to shift forward. If a negative value is passed, values\nare shifted in the opposite direction instead."]], "Returns": [], "Category": ["List"], "index": 202}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.slice.html#polars.Expr.list.slice"], "Title": ["Expr.list.slice"], "Feature": ["Expr.list.slice"], "Description": ["Slice every sublist."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2, 3, 4], [10, 2, 1]]})\n>>> df.with_columns(slice=pl.col(\"a\").list.slice(1, 2))\nshape: (2, 2)\n┌─────────────┬───────────┐\n│ a           ┆ slice     │\n│ ---         ┆ ---       │\n│ list[i64]   ┆ list[i64] │\n╞═════════════╪═══════════╡\n│ [1, 2, … 4] ┆ [2, 3]    │\n│ [10, 2, 1]  ┆ [2, 1]    │\n└─────────────┴───────────┘"], "Parameters": [["offset", "Start index. Negative indexing is supported."], ["length", "Length of the slice. If set to None (default), the slice is taken to the\nend of the list."]], "Returns": [], "Category": ["List"], "index": 203}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.sort.html#polars.Expr.list.sort"], "Title": ["Expr.list.sort"], "Feature": ["Expr.list.sort"], "Description": ["Sort the lists in this column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[3, 2, 1], [9, 1, 2]],\n...     }\n... )\n>>> df.with_columns(sort=pl.col(\"a\").list.sort())\nshape: (2, 2)\n┌───────────┬───────────┐\n│ a         ┆ sort      │\n│ ---       ┆ ---       │\n│ list[i64] ┆ list[i64] │\n╞═══════════╪═══════════╡\n│ [3, 2, 1] ┆ [1, 2, 3] │\n│ [9, 1, 2] ┆ [1, 2, 9] │\n└───────────┴───────────┘\n>>> df.with_columns(sort=pl.col(\"a\").list.sort(descending=True))\nshape: (2, 2)\n┌───────────┬───────────┐\n│ a         ┆ sort      │\n│ ---       ┆ ---       │\n│ list[i64] ┆ list[i64] │\n╞═══════════╪═══════════╡\n│ [3, 2, 1] ┆ [3, 2, 1] │\n│ [9, 1, 2] ┆ [9, 2, 1] │\n└───────────┴───────────┘"], "Parameters": [["descending", "Sort in descending order."], ["nulls_last", "Place null values last."]], "Returns": [], "Category": ["List"], "index": 204}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.std.html#polars.Expr.list.std"], "Title": ["Expr.list.std"], "Feature": ["Expr.list.std"], "Description": ["Compute the std value of the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[-1, 0, 1], [1, 10]]})\n>>> df.with_columns(pl.col(\"values\").list.std().alias(\"std\"))\nshape: (2, 2)\n┌────────────┬──────────┐\n│ values     ┆ std      │\n│ ---        ┆ ---      │\n│ list[i64]  ┆ f64      │\n╞════════════╪══════════╡\n│ [-1, 0, 1] ┆ 1.0      │\n│ [1, 10]    ┆ 6.363961 │\n└────────────┴──────────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["List"], "index": 205}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.sum.html#polars.Expr.list.sum"], "Title": ["Expr.list.sum"], "Feature": ["Expr.list.sum"], "Description": ["Sum all the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[1], [2, 3]]})\n>>> df.with_columns(sum=pl.col(\"values\").list.sum())\nshape: (2, 2)\n┌───────────┬─────┐\n│ values    ┆ sum │\n│ ---       ┆ --- │\n│ list[i64] ┆ i64 │\n╞═══════════╪═════╡\n│ [1]       ┆ 1   │\n│ [2, 3]    ┆ 5   │\n└───────────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["List"], "index": 206}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.tail.html#polars.Expr.list.tail"], "Title": ["Expr.list.tail"], "Feature": ["Expr.list.tail"], "Description": ["Slice the lastnvalues of every sublist."], "Examples": [">>> df = pl.DataFrame({\"a\": [[1, 2, 3, 4], [10, 2, 1]]})\n>>> df.with_columns(tail=pl.col(\"a\").list.tail(2))\nshape: (2, 2)\n┌─────────────┬───────────┐\n│ a           ┆ tail      │\n│ ---         ┆ ---       │\n│ list[i64]   ┆ list[i64] │\n╞═════════════╪═══════════╡\n│ [1, 2, … 4] ┆ [3, 4]    │\n│ [10, 2, 1]  ┆ [2, 1]    │\n└─────────────┴───────────┘"], "Parameters": [["n", "Number of values to return for each sublist."]], "Returns": [], "Category": ["List"], "index": 207}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.to_array.html#polars.Expr.list.to_array"], "Title": ["Expr.list.to_array"], "Feature": ["Expr.list.to_array"], "Description": ["Convert a List column into an Array column with the same inner data type."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [3, 4]]},\n...     schema={\"a\": pl.List(pl.Int8)},\n... )\n>>> df.with_columns(array=pl.col(\"a\").list.to_array(2))\nshape: (2, 2)\n┌──────────┬──────────────┐\n│ a        ┆ array        │\n│ ---      ┆ ---          │\n│ list[i8] ┆ array[i8, 2] │\n╞══════════╪══════════════╡\n│ [1, 2]   ┆ [1, 2]       │\n│ [3, 4]   ┆ [3, 4]       │\n└──────────┴──────────────┘"], "Parameters": [["width", "Width of the resulting Array column."]], "Returns": [["Expr", "Expression of data type Array ."]], "Category": ["List"], "index": 208}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.to_struct.html#polars.Expr.list.to_struct"], "Title": ["Expr.list.to_struct"], "Feature": ["Expr.list.to_struct"], "Description": ["Convert the Series of typeListto a Series of typeStruct."], "Examples": [">>> df = pl.DataFrame({\"n\": [[0, 1], [0, 1, 2]]})\n>>> df.with_columns(\n...     struct=pl.col(\"n\").list.to_struct(upper_bound=2)\n... )  \nshape: (2, 2)\n┌───────────┬───────────┐\n│ n         ┆ struct    │\n│ ---       ┆ ---       │\n│ list[i64] ┆ struct[2] │ # <- struct with 2 fields\n╞═══════════╪═══════════╡\n│ [0, 1]    ┆ {0,1}     │ # OK\n│ [0, 1, 2] ┆ {0,1}     │ # NOT OK - last value missing\n└───────────┴───────────┘", ">>> df = pl.DataFrame({\"n\": [[0, 1], [2, 3]]})\n>>> df.select(\n...     pl.col(\"n\").list.to_struct(fields=lambda idx: f\"n{idx}\", upper_bound=2)\n... ).rows(named=True)  \n[{'n': {'n0': 0, 'n1': 1}}, {'n': {'n0': 2, 'n1': 3}}]", ">>> df.select(pl.col(\"n\").list.to_struct(fields=[\"one\", \"two\"])).rows(\n...     named=True\n... )\n[{'n': {'one': 0, 'two': 1}}, {'n': {'one': 2, 'two': 3}}]"], "Parameters": [["n_field_strategy {‘first_non_null’, ‘max_width’}", "Deprecated and ignored."], ["fields", "If the name and number of the desired fields is known in advance\na list of field names can be given, which will be assigned by index.\nOtherwise, to dynamically assign field names, a custom function can be\nused; if neither are set, fields will be field_0, field_1 .. field_n ."], ["upper_bound", "A polars expression needs to be able to evaluate the output datatype at all\ntimes, so the caller must provide an upper bound of the number of struct\nfields that will be created if fields is not a sequence of field names."], [".. versionchanged: 1.33.0", "The n_field_strategy parameter is ignored and deprecated. The fields needs to be a sequence of field names or the upper bound is regarded as\nground truth."]], "Returns": [], "Category": ["List"], "index": 209}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.unique.html#polars.Expr.list.unique"], "Title": ["Expr.list.unique"], "Feature": ["Expr.list.unique"], "Description": ["Get the unique/distinct values in the list."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 1, 2]],\n...     }\n... )\n>>> df.with_columns(unique=pl.col(\"a\").list.unique())\nshape: (1, 2)\n┌───────────┬───────────┐\n│ a         ┆ unique    │\n│ ---       ┆ ---       │\n│ list[i64] ┆ list[i64] │\n╞═══════════╪═══════════╡\n│ [1, 1, 2] ┆ [1, 2]    │\n└───────────┴───────────┘"], "Parameters": [["maintain_order", "Maintain order of data. This requires more work."]], "Returns": [], "Category": ["List"], "index": 210}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.var.html#polars.Expr.list.var"], "Title": ["Expr.list.var"], "Feature": ["Expr.list.var"], "Description": ["Compute the var value of the lists in the array."], "Examples": [">>> df = pl.DataFrame({\"values\": [[-1, 0, 1], [1, 10]]})\n>>> df.with_columns(pl.col(\"values\").list.var().alias(\"var\"))\nshape: (2, 2)\n┌────────────┬──────┐\n│ values     ┆ var  │\n│ ---        ┆ ---  │\n│ list[i64]  ┆ f64  │\n╞════════════╪══════╡\n│ [-1, 0, 1] ┆ 1.0  │\n│ [1, 10]    ┆ 40.5 │\n└────────────┴──────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["List"], "index": 211}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.arg_max.html#polars.Expr.arr.arg_max"], "Title": ["Expr.arr.arg_max"], "Feature": ["Expr.arr.arg_max"], "Description": ["Retrieve the index of the maximum value in every sub-array."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2], [2, 1]],\n...     },\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.with_columns(arg_max=pl.col(\"a\").arr.arg_max())\nshape: (2, 2)\n┌───────────────┬─────────┐\n│ a             ┆ arg_max │\n│ ---           ┆ ---     │\n│ array[i64, 2] ┆ u32     │\n╞═══════════════╪═════════╡\n│ [1, 2]        ┆ 1       │\n│ [2, 1]        ┆ 0       │\n└───────────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 or UInt64 (depending on compilation)."]], "Category": ["Array"], "index": 212}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.append.html#polars.Expr.append"], "Title": ["Expr.append"], "Feature": ["Expr.append"], "Description": ["Append expressions."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [8, 9, 10],\n...         \"b\": [None, 4, 4],\n...     }\n... )\n>>> df.select(pl.all().head(1).append(pl.all().tail(1)))\nshape: (2, 2)\n┌─────┬──────┐\n│ a   ┆ b    │\n│ --- ┆ ---  │\n│ i64 ┆ i64  │\n╞═════╪══════╡\n│ 8   ┆ null │\n│ 10  ┆ 4    │\n└─────┴──────┘"], "Parameters": [["other", "Expression to append."], ["upcast", "Cast both Series to the same supertype."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 213}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arg_sort.html#polars.Expr.arg_sort"], "Title": ["Expr.arg_sort"], "Feature": ["Expr.arg_sort"], "Description": ["Get the index values that would sort this column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [20, 10, 30],\n...         \"b\": [1, 2, 3],\n...     }\n... )\n>>> df.select(pl.col(\"a\").arg_sort())\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 1   │\n│ 0   │\n│ 2   │\n└─────┘", ">>> df.select(pl.col(\"b\").gather(pl.col(\"a\").arg_sort()))\nshape: (3, 1)\n┌─────┐\n│ b   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n│ 1   │\n│ 3   │\n└─────┘"], "Parameters": [["descending", "Sort in descending (descending) order."], ["nulls_last", "Place null values last instead of first."]], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Manipulation_selection"], "index": 214}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arg_true.html#polars.Expr.arg_true"], "Title": ["Expr.arg_true"], "Feature": ["Expr.arg_true"], "Description": ["Return indices where expression evaluatesTrue."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2, 1]})\n>>> df.select((pl.col(\"a\") == 1).arg_true())\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 0   │\n│ 1   │\n│ 3   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 215}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.backward_fill.html#polars.Expr.backward_fill"], "Title": ["Expr.backward_fill"], "Feature": ["Expr.backward_fill"], "Description": ["Fill missing values with the next non-null value."], "Examples": [], "Parameters": [["limit", "The number of consecutive null values to backward fill."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 216}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bottom_k.html#polars.Expr.bottom_k"], "Title": ["Expr.bottom_k"], "Feature": ["Expr.bottom_k"], "Description": ["Return theksmallest elements."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"value\": [1, 98, 2, 3, 99, 4],\n...     }\n... )\n>>> df.select(\n...     pl.col(\"value\").top_k().alias(\"top_k\"),\n...     pl.col(\"value\").bottom_k().alias(\"bottom_k\"),\n... )\nshape: (5, 2)\n┌───────┬──────────┐\n│ top_k ┆ bottom_k │\n│ ---   ┆ ---      │\n│ i64   ┆ i64      │\n╞═══════╪══════════╡\n│ 4     ┆ 1        │\n│ 98    ┆ 98       │\n│ 2     ┆ 2        │\n│ 3     ┆ 3        │\n│ 99    ┆ 4        │\n└───────┴──────────┘"], "Parameters": [["k", "Number of elements to return."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 217}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bottom_k_by.html#polars.Expr.bottom_k_by"], "Title": ["Expr.bottom_k_by"], "Feature": ["Expr.bottom_k_by"], "Description": ["Return the elements corresponding to theksmallest elements of thebycolumn(s)."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4, 5, 6],\n...         \"b\": [6, 5, 4, 3, 2, 1],\n...         \"c\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df\nshape: (6, 3)\n┌─────┬─────┬────────┐\n│ a   ┆ b   ┆ c      │\n│ --- ┆ --- ┆ ---    │\n│ i64 ┆ i64 ┆ str    │\n╞═════╪═════╪════════╡\n│ 1   ┆ 6   ┆ Apple  │\n│ 2   ┆ 5   ┆ Orange │\n│ 3   ┆ 4   ┆ Apple  │\n│ 4   ┆ 3   ┆ Apple  │\n│ 5   ┆ 2   ┆ Banana │\n│ 6   ┆ 1   ┆ Banana │\n└─────┴─────┴────────┘", ">>> df.select(\n...     pl.all().bottom_k_by(\"a\", 2).name.suffix(\"_btm_by_a\"),\n...     pl.all().bottom_k_by(\"b\", 2).name.suffix(\"_btm_by_b\"),\n... )\nshape: (2, 6)\n┌────────────┬────────────┬────────────┬────────────┬────────────┬────────────┐\n│ a_btm_by_a ┆ b_btm_by_a ┆ c_btm_by_a ┆ a_btm_by_b ┆ b_btm_by_b ┆ c_btm_by_b │\n│ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n│ i64        ┆ i64        ┆ str        ┆ i64        ┆ i64        ┆ str        │\n╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n│ 1          ┆ 6          ┆ Apple      ┆ 6          ┆ 1          ┆ Banana     │\n│ 2          ┆ 5          ┆ Orange     ┆ 5          ┆ 2          ┆ Banana     │\n└────────────┴────────────┴────────────┴────────────┴────────────┴────────────┘", ">>> df.select(\n...     pl.all()\n...     .bottom_k_by([\"c\", \"a\"], 2, reverse=[False, True])\n...     .name.suffix(\"_by_ca\"),\n...     pl.all()\n...     .bottom_k_by([\"c\", \"b\"], 2, reverse=[False, True])\n...     .name.suffix(\"_by_cb\"),\n... )\nshape: (2, 6)\n┌─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐\n│ a_by_ca ┆ b_by_ca ┆ c_by_ca ┆ a_by_cb ┆ b_by_cb ┆ c_by_cb │\n│ ---     ┆ ---     ┆ ---     ┆ ---     ┆ ---     ┆ ---     │\n│ i64     ┆ i64     ┆ str     ┆ i64     ┆ i64     ┆ str     │\n╞═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n│ 4       ┆ 3       ┆ Apple   ┆ 1       ┆ 6       ┆ Apple   │\n│ 3       ┆ 4       ┆ Apple   ┆ 3       ┆ 4       ┆ Apple   │\n└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘", ">>> (\n...     df.group_by(\"c\", maintain_order=True)\n...     .agg(pl.all().bottom_k_by(\"a\", 2))\n...     .explode(pl.all().exclude(\"c\"))\n... )\nshape: (5, 3)\n┌────────┬─────┬─────┐\n│ c      ┆ a   ┆ b   │\n│ ---    ┆ --- ┆ --- │\n│ str    ┆ i64 ┆ i64 │\n╞════════╪═════╪═════╡\n│ Apple  ┆ 1   ┆ 6   │\n│ Apple  ┆ 3   ┆ 4   │\n│ Orange ┆ 2   ┆ 5   │\n│ Banana ┆ 5   ┆ 2   │\n│ Banana ┆ 6   ┆ 1   │\n└────────┴─────┴─────┘"], "Parameters": [["by", "Column(s) used to determine the smallest elements.\nAccepts expression input. Strings are parsed as column names."], ["k", "Number of elements to return."], ["reverse", "Consider the k largest elements of the by column(s) (instead of the k smallest). This can be specified per column by passing a sequence of\nbooleans."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 218}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cast.html#polars.Expr.cast"], "Title": ["Expr.cast"], "Feature": ["Expr.cast"], "Description": ["Cast between data types."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [\"4\", \"5\", \"6\"],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"a\").cast(pl.Float64),\n...     pl.col(\"b\").cast(pl.Int32),\n... )\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ f64 ┆ i32 │\n╞═════╪═════╡\n│ 1.0 ┆ 4   │\n│ 2.0 ┆ 5   │\n│ 3.0 ┆ 6   │\n└─────┴─────┘"], "Parameters": [["dtype", "DataType to cast to."], ["strict", "Raise if cast is invalid on rows after predicates are pushed down.\nIf False , invalid casts will produce null values."], ["wrap_numerical", "If True numeric casts wrap overflowing values instead of\nmarking the cast as invalid."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 219}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ceil.html#polars.Expr.ceil"], "Title": ["Expr.ceil"], "Feature": ["Expr.ceil"], "Description": ["Rounds up to the nearest integer value."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.3, 0.5, 1.0, 1.1]})\n>>> df.select(pl.col(\"a\").ceil())\nshape: (4, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n│ 1.0 │\n│ 1.0 │\n│ 2.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 220}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.clip.html#polars.Expr.clip"], "Title": ["Expr.clip"], "Feature": ["Expr.clip"], "Description": ["Set values outside the given boundaries to the boundary value."], "Examples": [">>> df = pl.DataFrame({\"a\": [-50, 5, 50, None]})\n>>> df.with_columns(clip=pl.col(\"a\").clip(1, 10))\nshape: (4, 2)\n┌──────┬──────┐\n│ a    ┆ clip │\n│ ---  ┆ ---  │\n│ i64  ┆ i64  │\n╞══════╪══════╡\n│ -50  ┆ 1    │\n│ 5    ┆ 5    │\n│ 50   ┆ 10   │\n│ null ┆ null │\n└──────┴──────┘", ">>> df.with_columns(clip=pl.col(\"a\").clip(upper_bound=10))\nshape: (4, 2)\n┌──────┬──────┐\n│ a    ┆ clip │\n│ ---  ┆ ---  │\n│ i64  ┆ i64  │\n╞══════╪══════╡\n│ -50  ┆ -50  │\n│ 5    ┆ 5    │\n│ 50   ┆ 10   │\n│ null ┆ null │\n└──────┴──────┘", ">>> df = pl.DataFrame(\n...     {\"a\": [-50, 5, 50, None], \"low\": [10, 1, 0, 0], \"up\": [20, 4, 3, 2]}\n... )\n>>> df.with_columns(clip=pl.col(\"a\").clip(\"low\", \"up\"))\nshape: (4, 4)\n┌──────┬─────┬─────┬──────┐\n│ a    ┆ low ┆ up  ┆ clip │\n│ ---  ┆ --- ┆ --- ┆ ---  │\n│ i64  ┆ i64 ┆ i64 ┆ i64  │\n╞══════╪═════╪═════╪══════╡\n│ -50  ┆ 10  ┆ 20  ┆ 10   │\n│ 5    ┆ 1   ┆ 4   ┆ 4    │\n│ 50   ┆ 0   ┆ 3   ┆ 3    │\n│ null ┆ 0   ┆ 2   ┆ null │\n└──────┴─────┴─────┴──────┘"], "Parameters": [["lower_bound", "Lower bound. Accepts expression input. Non-expression inputs are\nparsed as literals. Strings are parsed as column names."], ["upper_bound", "Upper bound. Accepts expression input. Non-expression inputs are\nparsed as literals. Strings are parsed as column names."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 221}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cut.html#polars.Expr.cut"], "Title": ["Expr.cut"], "Feature": ["Expr.cut"], "Description": ["Bin continuous values into discrete categories."], "Examples": [">>> df = pl.DataFrame({\"foo\": [-2, -1, 0, 1, 2]})\n>>> df.with_columns(\n...     pl.col(\"foo\").cut([-1, 1], labels=[\"a\", \"b\", \"c\"]).alias(\"cut\")\n... )\nshape: (5, 2)\n┌─────┬─────┐\n│ foo ┆ cut │\n│ --- ┆ --- │\n│ i64 ┆ cat │\n╞═════╪═════╡\n│ -2  ┆ a   │\n│ -1  ┆ a   │\n│ 0   ┆ b   │\n│ 1   ┆ b   │\n│ 2   ┆ c   │\n└─────┴─────┘", ">>> df.with_columns(\n...     pl.col(\"foo\").cut([-1, 1], include_breaks=True).alias(\"cut\")\n... ).unnest(\"cut\")\nshape: (5, 3)\n┌─────┬────────────┬────────────┐\n│ foo ┆ breakpoint ┆ category   │\n│ --- ┆ ---        ┆ ---        │\n│ i64 ┆ f64        ┆ cat        │\n╞═════╪════════════╪════════════╡\n│ -2  ┆ -1.0       ┆ (-inf, -1] │\n│ -1  ┆ -1.0       ┆ (-inf, -1] │\n│ 0   ┆ 1.0        ┆ (-1, 1]    │\n│ 1   ┆ 1.0        ┆ (-1, 1]    │\n│ 2   ┆ inf        ┆ (1, inf]   │\n└─────┴────────────┴────────────┘"], "Parameters": [["breaks", "List of unique cut points."], ["labels", "Names of the categories. The number of labels must be equal to the number\nof cut points plus one."], ["left_closed", "Set the intervals to be left-closed instead of right-closed."], ["include_breaks", "Include a column with the right endpoint of the bin each observation falls\nin. This will change the data type of the output from a Categorical to a Struct ."]], "Returns": [["Expr", "Expression of data type Categorical if include_breaks is set to False (default), otherwise an expression of data type Struct ."]], "Category": ["Manipulation_selection"], "index": 222}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.approx_n_unique.html#polars.Expr.approx_n_unique"], "Title": ["Expr.approx_n_unique"], "Feature": ["Expr.approx_n_unique"], "Description": ["Approximate count of unique values."], "Examples": [">>> df = pl.DataFrame({\"n\": [1, 1, 2]})\n>>> df.select(pl.col(\"n\").approx_n_unique())\nshape: (1, 1)\n┌─────┐\n│ n   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘\n>>> df = pl.DataFrame({\"n\": range(1000)})\n>>> df.select(\n...     exact=pl.col(\"n\").n_unique(),\n...     approx=pl.col(\"n\").approx_n_unique(),\n... )  \nshape: (1, 2)\n┌───────┬────────┐\n│ exact ┆ approx │\n│ ---   ┆ ---    │\n│ u32   ┆ u32    │\n╞═══════╪════════╡\n│ 1000  ┆ 1005   │\n└───────┴────────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 223}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.arg_min.html#polars.Expr.arr.arg_min"], "Title": ["Expr.arr.arg_min"], "Feature": ["Expr.arr.arg_min"], "Description": ["Retrieve the index of the minimal value in every sub-array."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 2], [2, 1]],\n...     },\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.with_columns(arg_min=pl.col(\"a\").arr.arg_min())\nshape: (2, 2)\n┌───────────────┬─────────┐\n│ a             ┆ arg_min │\n│ ---           ┆ ---     │\n│ array[i64, 2] ┆ u32     │\n╞═══════════════╪═════════╡\n│ [1, 2]        ┆ 0       │\n│ [2, 1]        ┆ 1       │\n└───────────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 or UInt64 (depending on compilation)."]], "Category": ["Array"], "index": 224}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.drop_nans.html#polars.Expr.drop_nans"], "Title": ["Expr.drop_nans"], "Feature": ["Expr.drop_nans"], "Description": ["Drop all floating point NaN values."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0, None, 3.0, float(\"nan\")]})\n>>> df.select(pl.col(\"a\").drop_nans())\nshape: (3, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ 1.0  │\n│ null │\n│ 3.0  │\n└──────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 225}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.drop_nulls.html#polars.Expr.drop_nulls"], "Title": ["Expr.drop_nulls"], "Feature": ["Expr.drop_nulls"], "Description": ["Drop all null values."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0, None, 3.0, float(\"nan\")]})\n>>> df.select(pl.col(\"a\").drop_nulls())\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n│ 3.0 │\n│ NaN │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 226}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.explode.html#polars.Expr.explode"], "Title": ["Expr.explode"], "Feature": ["Expr.explode"], "Description": ["Explode a list expression."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\"a\", \"b\"],\n...         \"values\": [\n...             [1, 2],\n...             [3, 4],\n...         ],\n...     }\n... )\n>>> df.select(pl.col(\"values\").explode())\nshape: (4, 1)\n┌────────┐\n│ values │\n│ ---    │\n│ i64    │\n╞════════╡\n│ 1      │\n│ 2      │\n│ 3      │\n│ 4      │\n└────────┘"], "Parameters": [], "Returns": [["Expr", "Expression with the data type of the list elements."]], "Category": ["Manipulation_selection"], "index": 227}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.extend_constant.html#polars.Expr.extend_constant"], "Title": ["Expr.extend_constant"], "Feature": ["Expr.extend_constant"], "Description": ["Extremely fast method for extending the Series with 'n' copies of a value."], "Examples": [">>> df = pl.DataFrame({\"values\": [1, 2, 3]})\n>>> df.select((pl.col(\"values\") - 1).extend_constant(99, n=2))\nshape: (5, 1)\n┌────────┐\n│ values │\n│ ---    │\n│ i64    │\n╞════════╡\n│ 0      │\n│ 1      │\n│ 2      │\n│ 99     │\n│ 99     │\n└────────┘"], "Parameters": [["value", "A constant literal value or a unit expression with which to extend the\nexpression result Series; can pass None to extend with nulls."], ["n", "The number of additional values that will be added."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 228}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.fill_nan.html#polars.Expr.fill_nan"], "Title": ["Expr.fill_nan"], "Feature": ["Expr.fill_nan"], "Description": ["Fill floating point NaN value with a fill value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1.0, None, float(\"nan\")],\n...         \"b\": [4.0, float(\"nan\"), 6],\n...     }\n... )\n>>> df.with_columns(pl.col(\"b\").fill_nan(0))\nshape: (3, 2)\n┌──────┬─────┐\n│ a    ┆ b   │\n│ ---  ┆ --- │\n│ f64  ┆ f64 │\n╞══════╪═════╡\n│ 1.0  ┆ 4.0 │\n│ null ┆ 0.0 │\n│ NaN  ┆ 6.0 │\n└──────┴─────┘"], "Parameters": [["value", "Value used to fill NaN values."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 229}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.fill_null.html#polars.Expr.fill_null"], "Title": ["Expr.fill_null"], "Feature": ["Expr.fill_null"], "Description": ["Fill null values using the specified value or strategy."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None],\n...         \"b\": [4, None, 6],\n...     }\n... )\n>>> df.with_columns(pl.col(\"b\").fill_null(strategy=\"zero\"))\nshape: (3, 2)\n┌──────┬─────┐\n│ a    ┆ b   │\n│ ---  ┆ --- │\n│ i64  ┆ i64 │\n╞══════╪═════╡\n│ 1    ┆ 4   │\n│ 2    ┆ 0   │\n│ null ┆ 6   │\n└──────┴─────┘\n>>> df.with_columns(pl.col(\"b\").fill_null(99))\nshape: (3, 2)\n┌──────┬─────┐\n│ a    ┆ b   │\n│ ---  ┆ --- │\n│ i64  ┆ i64 │\n╞══════╪═════╡\n│ 1    ┆ 4   │\n│ 2    ┆ 99  │\n│ null ┆ 6   │\n└──────┴─────┘\n>>> df.with_columns(pl.col(\"b\").fill_null(strategy=\"forward\"))\nshape: (3, 2)\n┌──────┬─────┐\n│ a    ┆ b   │\n│ ---  ┆ --- │\n│ i64  ┆ i64 │\n╞══════╪═════╡\n│ 1    ┆ 4   │\n│ 2    ┆ 4   │\n│ null ┆ 6   │\n└──────┴─────┘\n>>> df.with_columns(pl.col(\"b\").fill_null(pl.col(\"b\").median()))\nshape: (3, 2)\n┌──────┬─────┐\n│ a    ┆ b   │\n│ ---  ┆ --- │\n│ i64  ┆ f64 │\n╞══════╪═════╡\n│ 1    ┆ 4.0 │\n│ 2    ┆ 5.0 │\n│ null ┆ 6.0 │\n└──────┴─────┘\n>>> df.with_columns(pl.all().fill_null(pl.all().median()))\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ f64 ┆ f64 │\n╞═════╪═════╡\n│ 1.0 ┆ 4.0 │\n│ 2.0 ┆ 5.0 │\n│ 1.5 ┆ 6.0 │\n└─────┴─────┘"], "Parameters": [["value", "Value used to fill null values."], ["strategy {None, ‘forward’, ‘backward’, ‘min’, ‘max’, ‘mean’, ‘zero’, ‘one’}", "Strategy used to fill null values."], ["limit", "Number of consecutive null values to fill when using the ‘forward’ or\n‘backward’ strategy."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 230}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.filter.html#polars.Expr.filter"], "Title": ["Expr.filter"], "Feature": ["Expr.filter"], "Description": ["Filter the expression based on one or more predicate expressions."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group_col\": [\"g1\", \"g1\", \"g2\"],\n...         \"b\": [1, 2, 3],\n...     }\n... )\n>>> df.group_by(\"group_col\").agg(\n...     lt=pl.col(\"b\").filter(pl.col(\"b\") < 2).sum(),\n...     gte=pl.col(\"b\").filter(pl.col(\"b\") >= 2).sum(),\n... ).sort(\"group_col\")\nshape: (2, 3)\n┌───────────┬─────┬─────┐\n│ group_col ┆ lt  ┆ gte │\n│ ---       ┆ --- ┆ --- │\n│ str       ┆ i64 ┆ i64 │\n╞═══════════╪═════╪═════╡\n│ g1        ┆ 1   ┆ 2   │\n│ g2        ┆ 0   ┆ 3   │\n└───────────┴─────┴─────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"key\": [\"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"b\"],\n...         \"n\": [1, 2, 2, 3, 1, 3, 3, 2, 3],\n...     },\n... )\n>>> df.group_by(\"key\").agg(\n...     n_1=pl.col(\"n\").filter(n=1).sum(),\n...     n_2=pl.col(\"n\").filter(n=2).sum(),\n...     n_3=pl.col(\"n\").filter(n=3).sum(),\n... ).sort(by=\"key\")\nshape: (2, 4)\n┌─────┬─────┬─────┬─────┐\n│ key ┆ n_1 ┆ n_2 ┆ n_3 │\n│ --- ┆ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╪═════╡\n│ a   ┆ 1   ┆ 4   ┆ 3   │\n│ b   ┆ 1   ┆ 2   ┆ 9   │\n└─────┴─────┴─────┴─────┘"], "Parameters": [["predicates", "Expression(s) that evaluates to a boolean Series."], ["constraints", "Column filters; use name = value to filter columns by the supplied value.\nEach constraint will behave the same as pl.col(name).eq(value) , and\nbe implicitly joined with the other filter conditions using & ."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 231}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.flatten.html#polars.Expr.flatten"], "Title": ["Expr.flatten"], "Feature": ["Expr.flatten"], "Description": ["Flatten a list or string column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\"a\", \"b\", \"b\"],\n...         \"values\": [[1, 2], [2, 3], [4]],\n...     }\n... )\n>>> df.group_by(\"group\").agg(pl.col(\"values\").flatten())  \nshape: (2, 2)\n┌───────┬───────────┐\n│ group ┆ values    │\n│ ---   ┆ ---       │\n│ str   ┆ list[i64] │\n╞═══════╪═══════════╡\n│ a     ┆ [1, 2]    │\n│ b     ┆ [2, 3, 4] │\n└───────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 232}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.floor.html#polars.Expr.floor"], "Title": ["Expr.floor"], "Feature": ["Expr.floor"], "Description": ["Rounds down to the nearest integer value."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.3, 0.5, 1.0, 1.1]})\n>>> df.select(pl.col(\"a\").floor())\nshape: (4, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n│ 0.0 │\n│ 1.0 │\n│ 1.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 233}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.forward_fill.html#polars.Expr.forward_fill"], "Title": ["Expr.forward_fill"], "Feature": ["Expr.forward_fill"], "Description": ["Fill missing values with the last non-null value."], "Examples": [], "Parameters": [["limit", "The number of consecutive null values to forward fill."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 234}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.contains.html#polars.Expr.arr.contains"], "Title": ["Expr.arr.contains"], "Feature": ["Expr.arr.contains"], "Description": ["Check if sub-arrays contain the given item."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[\"a\", \"b\"], [\"x\", \"y\"], [\"a\", \"c\"]]},\n...     schema={\"a\": pl.Array(pl.String, 2)},\n... )\n>>> df.with_columns(contains=pl.col(\"a\").arr.contains(\"a\"))\nshape: (3, 2)\n┌───────────────┬──────────┐\n│ a             ┆ contains │\n│ ---           ┆ ---      │\n│ array[str, 2] ┆ bool     │\n╞═══════════════╪══════════╡\n│ [\"a\", \"b\"]    ┆ true     │\n│ [\"x\", \"y\"]    ┆ false    │\n│ [\"a\", \"c\"]    ┆ true     │\n└───────────────┴──────────┘"], "Parameters": [["item", "Item that will be checked for membership"], ["nulls_equal bool, default True", "If True, treat null as a distinct value. Null values will not propagate."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Array"], "index": 235}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.gather.html#polars.Expr.gather"], "Title": ["Expr.gather"], "Feature": ["Expr.gather"], "Description": ["Take values by index."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\n...             \"one\",\n...             \"one\",\n...             \"one\",\n...             \"two\",\n...             \"two\",\n...             \"two\",\n...         ],\n...         \"value\": [1, 98, 2, 3, 99, 4],\n...     }\n... )\n>>> df.group_by(\"group\", maintain_order=True).agg(\n...     pl.col(\"value\").gather([2, 1])\n... )\nshape: (2, 2)\n┌───────┬───────────┐\n│ group ┆ value     │\n│ ---   ┆ ---       │\n│ str   ┆ list[i64] │\n╞═══════╪═══════════╡\n│ one   ┆ [2, 98]   │\n│ two   ┆ [4, 99]   │\n└───────┴───────────┘"], "Parameters": [["indices", "An expression that leads to a UInt32 dtyped Series."]], "Returns": [["Expr", "Expression of the same data type."]], "Category": ["Manipulation_selection"], "index": 236}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.gather_every.html#polars.Expr.gather_every"], "Title": ["Expr.gather_every"], "Feature": ["Expr.gather_every"], "Description": ["Take every nth value in the Series and return as a new Series."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7, 8, 9]})\n>>> df.select(pl.col(\"foo\").gather_every(3))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 4   │\n│ 7   │\n└─────┘", ">>> df.select(pl.col(\"foo\").gather_every(3, offset=1))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n│ 5   │\n│ 8   │\n└─────┘"], "Parameters": [["n", "Gather every n -th row."], ["offset", "Starting index."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 237}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.get.html#polars.Expr.get"], "Title": ["Expr.get"], "Feature": ["Expr.get"], "Description": ["Return a single value by index."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\n...             \"one\",\n...             \"one\",\n...             \"one\",\n...             \"two\",\n...             \"two\",\n...             \"two\",\n...         ],\n...         \"value\": [1, 98, 2, 3, 99, 4],\n...     }\n... )\n>>> df.group_by(\"group\", maintain_order=True).agg(pl.col(\"value\").get(1))\nshape: (2, 2)\n┌───────┬───────┐\n│ group ┆ value │\n│ ---   ┆ ---   │\n│ str   ┆ i64   │\n╞═══════╪═══════╡\n│ one   ┆ 98    │\n│ two   ┆ 99    │\n└───────┴───────┘"], "Parameters": [["index", "An expression that leads to a UInt32 index."]], "Returns": [["Expr", "Expression of the same data type."]], "Category": ["Manipulation_selection"], "index": 238}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.head.html#polars.Expr.head"], "Title": ["Expr.head"], "Feature": ["Expr.head"], "Description": ["Get the firstnrows."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7]})\n>>> df.select(pl.col(\"foo\").head(3))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n└─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 239}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.inspect.html#polars.Expr.inspect"], "Title": ["Expr.inspect"], "Feature": ["Expr.inspect"], "Description": ["Print the value that this expression evaluates to and pass on the value."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 1, 2]})\n>>> df.select(pl.col(\"foo\").cum_sum().inspect(\"value is: {}\").alias(\"bar\"))\nvalue is: shape: (3,)\nSeries: 'foo' [i64]\n[\n    1\n    2\n    4\n]\nshape: (3, 1)\n┌─────┐\n│ bar │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 4   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 240}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.interpolate.html#polars.Expr.interpolate"], "Title": ["Expr.interpolate"], "Feature": ["Expr.interpolate"], "Description": ["Interpolate intermediate values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, None, 3],\n...         \"b\": [1.0, float(\"nan\"), 3.0],\n...     }\n... )\n>>> df.select(pl.all().interpolate())\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ f64 ┆ f64 │\n╞═════╪═════╡\n│ 1.0 ┆ 1.0 │\n│ 2.0 ┆ NaN │\n│ 3.0 ┆ 3.0 │\n└─────┴─────┘", ">>> df.select(pl.all().interpolate(\"nearest\"))\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ f64 │\n╞═════╪═════╡\n│ 1   ┆ 1.0 │\n│ 3   ┆ NaN │\n│ 3   ┆ 3.0 │\n└─────┴─────┘", ">>> df_original_grid = pl.DataFrame(\n...     {\n...         \"grid_points\": [1, 3, 10],\n...         \"values\": [2.0, 6.0, 20.0],\n...     }\n... )  # Interpolate from this to the new grid\n>>> df_new_grid = pl.DataFrame({\"grid_points\": range(1, 11)})\n>>> df_new_grid.join(\n...     df_original_grid, on=\"grid_points\", how=\"left\", coalesce=True\n... ).with_columns(pl.col(\"values\").interpolate())\nshape: (10, 2)\n┌─────────────┬────────┐\n│ grid_points ┆ values │\n│ ---         ┆ ---    │\n│ i64         ┆ f64    │\n╞═════════════╪════════╡\n│ 1           ┆ 2.0    │\n│ 2           ┆ 4.0    │\n│ 3           ┆ 6.0    │\n│ 4           ┆ 8.0    │\n│ 5           ┆ 10.0   │\n│ 6           ┆ 12.0   │\n│ 7           ┆ 14.0   │\n│ 8           ┆ 16.0   │\n│ 9           ┆ 18.0   │\n│ 10          ┆ 20.0   │\n└─────────────┴────────┘"], "Parameters": [["method {‘linear’, ‘nearest’}", "Interpolation method."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 241}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.interpolate_by.html#polars.Expr.interpolate_by"], "Title": ["Expr.interpolate_by"], "Feature": ["Expr.interpolate_by"], "Description": ["Fill null values using interpolation based on another column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, None, None, 3],\n...         \"b\": [1, 2, 7, 8],\n...     }\n... )\n>>> df.with_columns(a_interpolated=pl.col(\"a\").interpolate_by(\"b\"))\nshape: (4, 3)\n┌──────┬─────┬────────────────┐\n│ a    ┆ b   ┆ a_interpolated │\n│ ---  ┆ --- ┆ ---            │\n│ i64  ┆ i64 ┆ f64            │\n╞══════╪═════╪════════════════╡\n│ 1    ┆ 1   ┆ 1.0            │\n│ null ┆ 2   ┆ 1.285714       │\n│ null ┆ 7   ┆ 2.714286       │\n│ 3    ┆ 8   ┆ 3.0            │\n└──────┴─────┴────────────────┘"], "Parameters": [["by", "Column to interpolate values based on."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 242}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.limit.html#polars.Expr.limit"], "Title": ["Expr.limit"], "Feature": ["Expr.limit"], "Description": ["Get the firstnrows (alias forExpr.head())."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7]})\n>>> df.select(pl.col(\"foo\").limit(3))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n└─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 243}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.lower_bound.html#polars.Expr.lower_bound"], "Title": ["Expr.lower_bound"], "Feature": ["Expr.lower_bound"], "Description": ["Calculate the lower bound."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 2, 1]})\n>>> df.select(pl.col(\"a\").lower_bound())\nshape: (1, 1)\n┌──────────────────────┐\n│ a                    │\n│ ---                  │\n│ i64                  │\n╞══════════════════════╡\n│ -9223372036854775808 │\n└──────────────────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 244}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.pipe.html#polars.Expr.pipe"], "Title": ["Expr.pipe"], "Feature": ["Expr.pipe"], "Description": ["Offers a structured way to apply a sequence of user-defined functions (UDFs)."], "Examples": [">>> def extract_number(expr: pl.Expr) -> pl.Expr:\n...     \"\"\"Extract the digits from a string.\"\"\"\n...     return expr.str.extract(r\"\\d+\", 0).cast(pl.Int64)\n>>>\n>>> def scale_negative_even(expr: pl.Expr, *, n: int = 1) -> pl.Expr:\n...     \"\"\"Set even numbers negative, and scale by a user-supplied value.\"\"\"\n...     expr = pl.when(expr % 2 == 0).then(-expr).otherwise(expr)\n...     return expr * n\n>>>\n>>> df = pl.DataFrame({\"val\": [\"a: 1\", \"b: 2\", \"c: 3\", \"d: 4\"]})\n>>> df.with_columns(\n...     udfs=(\n...         pl.col(\"val\").pipe(extract_number).pipe(scale_negative_even, n=5)\n...     ),\n... )\nshape: (4, 2)\n┌──────┬──────┐\n│ val  ┆ udfs │\n│ ---  ┆ ---  │\n│ str  ┆ i64  │\n╞══════╪══════╡\n│ a: 1 ┆ 5    │\n│ b: 2 ┆ -10  │\n│ c: 3 ┆ 15   │\n│ d: 4 ┆ -20  │\n└──────┴──────┘"], "Parameters": [["function", "Callable; will receive the expression as the first parameter,\nfollowed by any given args/kwargs."], ["*args", "Arguments to pass to the UDF."], ["**kwargs", "Keyword arguments to pass to the UDF."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 245}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.count_matches.html#polars.Expr.arr.count_matches"], "Title": ["Expr.arr.count_matches"], "Feature": ["Expr.arr.count_matches"], "Description": ["Count how often the value produced byelementoccurs."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[1, 2], [1, 1], [2, 2]]}, schema={\"a\": pl.Array(pl.Int64, 2)}\n... )\n>>> df.with_columns(number_of_twos=pl.col(\"a\").arr.count_matches(2))\nshape: (3, 2)\n┌───────────────┬────────────────┐\n│ a             ┆ number_of_twos │\n│ ---           ┆ ---            │\n│ array[i64, 2] ┆ u32            │\n╞═══════════════╪════════════════╡\n│ [1, 2]        ┆ 1              │\n│ [1, 1]        ┆ 0              │\n│ [2, 2]        ┆ 2              │\n└───────────────┴────────────────┘"], "Parameters": [["element", "An expression that produces a single value"]], "Returns": [], "Category": ["Array"], "index": 246}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.qcut.html#polars.Expr.qcut"], "Title": ["Expr.qcut"], "Feature": ["Expr.qcut"], "Description": ["Bin continuous values into discrete categories based on their quantiles."], "Examples": [">>> df = pl.DataFrame({\"foo\": [-2, -1, 0, 1, 2]})\n>>> df.with_columns(\n...     pl.col(\"foo\").qcut([0.25, 0.75], labels=[\"a\", \"b\", \"c\"]).alias(\"qcut\")\n... )\nshape: (5, 2)\n┌─────┬──────┐\n│ foo ┆ qcut │\n│ --- ┆ ---  │\n│ i64 ┆ cat  │\n╞═════╪══════╡\n│ -2  ┆ a    │\n│ -1  ┆ a    │\n│ 0   ┆ b    │\n│ 1   ┆ b    │\n│ 2   ┆ c    │\n└─────┴──────┘", ">>> df.with_columns(\n...     pl.col(\"foo\")\n...     .qcut(2, labels=[\"low\", \"high\"], left_closed=True)\n...     .alias(\"qcut\")\n... )\nshape: (5, 2)\n┌─────┬──────┐\n│ foo ┆ qcut │\n│ --- ┆ ---  │\n│ i64 ┆ cat  │\n╞═════╪══════╡\n│ -2  ┆ low  │\n│ -1  ┆ low  │\n│ 0   ┆ high │\n│ 1   ┆ high │\n│ 2   ┆ high │\n└─────┴──────┘", ">>> df.with_columns(\n...     pl.col(\"foo\").qcut([0.25, 0.75], include_breaks=True).alias(\"qcut\")\n... ).unnest(\"qcut\")\nshape: (5, 3)\n┌─────┬────────────┬────────────┐\n│ foo ┆ breakpoint ┆ category   │\n│ --- ┆ ---        ┆ ---        │\n│ i64 ┆ f64        ┆ cat        │\n╞═════╪════════════╪════════════╡\n│ -2  ┆ -1.0       ┆ (-inf, -1] │\n│ -1  ┆ -1.0       ┆ (-inf, -1] │\n│ 0   ┆ 1.0        ┆ (-1, 1]    │\n│ 1   ┆ 1.0        ┆ (-1, 1]    │\n│ 2   ┆ inf        ┆ (1, inf]   │\n└─────┴────────────┴────────────┘"], "Parameters": [["quantiles", "Either a list of quantile probabilities between 0 and 1 or a positive\ninteger determining the number of bins with uniform probability."], ["labels", "Names of the categories. The number of labels must be equal to the number\nof categories."], ["left_closed", "Set the intervals to be left-closed instead of right-closed."], ["allow_duplicates", "If set to True , duplicates in the resulting quantiles are dropped,\nrather than raising a DuplicateError . This can happen even with unique\nprobabilities, depending on the data."], ["include_breaks", "Include a column with the right endpoint of the bin each observation falls\nin. This will change the data type of the output from a Categorical to a Struct ."]], "Returns": [["Expr", "Expression of data type Categorical if include_breaks is set to False (default), otherwise an expression of data type Struct ."]], "Category": ["Manipulation_selection"], "index": 247}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rechunk.html#polars.Expr.rechunk"], "Title": ["Expr.rechunk"], "Feature": ["Expr.rechunk"], "Description": ["Create a single chunk of memory for this Series."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2]})", ">>> df.select(pl.repeat(None, 3).append(pl.col(\"a\")).rechunk())\nshape: (6, 1)\n┌────────┐\n│ repeat │\n│ ---    │\n│ i64    │\n╞════════╡\n│ null   │\n│ null   │\n│ null   │\n│ 1      │\n│ 1      │\n│ 2      │\n└────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 248}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.reinterpret.html#polars.Expr.reinterpret"], "Title": ["Expr.reinterpret"], "Feature": ["Expr.reinterpret"], "Description": ["Reinterpret the underlying bits as a signed/unsigned integer."], "Examples": [">>> s = pl.Series(\"a\", [1, 1, 2], dtype=pl.UInt64)\n>>> df = pl.DataFrame([s])\n>>> df.select(\n...     [\n...         pl.col(\"a\").reinterpret(signed=True).alias(\"reinterpreted\"),\n...         pl.col(\"a\").alias(\"original\"),\n...     ]\n... )\nshape: (3, 2)\n┌───────────────┬──────────┐\n│ reinterpreted ┆ original │\n│ ---           ┆ ---      │\n│ i64           ┆ u64      │\n╞═══════════════╪══════════╡\n│ 1             ┆ 1        │\n│ 1             ┆ 1        │\n│ 2             ┆ 2        │\n└───────────────┴──────────┘"], "Parameters": [["signed", "If True, reinterpret as pl.Int64 . Otherwise, reinterpret as pl.UInt64 ."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 249}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.repeat_by.html#polars.Expr.repeat_by"], "Title": ["Expr.repeat_by"], "Feature": ["Expr.repeat_by"], "Description": ["Repeat the elements in this Series as specified in the given expression."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"x\", \"y\", \"z\"],\n...         \"n\": [1, 2, 3],\n...     }\n... )\n>>> df.select(pl.col(\"a\").repeat_by(\"n\"))\nshape: (3, 1)\n┌─────────────────┐\n│ a               │\n│ ---             │\n│ list[str]       │\n╞═════════════════╡\n│ [\"x\"]           │\n│ [\"y\", \"y\"]      │\n│ [\"z\", \"z\", \"z\"] │\n└─────────────────┘"], "Parameters": [["by", "Numeric column that determines how often the values will be repeated.\nThe column will be coerced to UInt32. Give this dtype to make the coercion a\nno-op."]], "Returns": [["Expr", "Expression of data type List , where the inner data type is equal\nto the original data type."]], "Category": ["Manipulation_selection"], "index": 250}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.replace.html#polars.Expr.replace"], "Title": ["Expr.replace"], "Feature": ["Expr.replace"], "Description": ["Replace the given values by different values of the same data type."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 2, 3]})\n>>> df.with_columns(replaced=pl.col(\"a\").replace(2, 100))\nshape: (4, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ i64 ┆ i64      │\n╞═════╪══════════╡\n│ 1   ┆ 1        │\n│ 2   ┆ 100      │\n│ 2   ┆ 100      │\n│ 3   ┆ 3        │\n└─────┴──────────┘", ">>> df.with_columns(replaced=pl.col(\"a\").replace([2, 3], [100, 200]))\nshape: (4, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ i64 ┆ i64      │\n╞═════╪══════════╡\n│ 1   ┆ 1        │\n│ 2   ┆ 100      │\n│ 2   ┆ 100      │\n│ 3   ┆ 200      │\n└─────┴──────────┘", ">>> mapping = {2: 100, 3: 200}\n>>> df.with_columns(replaced=pl.col(\"a\").replace(mapping))\nshape: (4, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ i64 ┆ i64      │\n╞═════╪══════════╡\n│ 1   ┆ 1        │\n│ 2   ┆ 100      │\n│ 2   ┆ 100      │\n│ 3   ┆ 200      │\n└─────┴──────────┘", ">>> df = pl.DataFrame({\"a\": [\"x\", \"y\", \"z\"]})\n>>> mapping = {\"x\": 1, \"y\": 2, \"z\": 3}\n>>> df.with_columns(replaced=pl.col(\"a\").replace(mapping))\nshape: (3, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ str ┆ str      │\n╞═════╪══════════╡\n│ x   ┆ 1        │\n│ y   ┆ 2        │\n│ z   ┆ 3        │\n└─────┴──────────┘", ">>> df = pl.DataFrame({\"a\": [1, 2, 2, 3], \"b\": [1.5, 2.5, 5.0, 1.0]})\n>>> df.with_columns(\n...     replaced=pl.col(\"a\").replace(\n...         old=pl.col(\"a\").max(),\n...         new=pl.col(\"b\").sum(),\n...     )\n... )\nshape: (4, 3)\n┌─────┬─────┬──────────┐\n│ a   ┆ b   ┆ replaced │\n│ --- ┆ --- ┆ ---      │\n│ i64 ┆ f64 ┆ i64      │\n╞═════╪═════╪══════════╡\n│ 1   ┆ 1.5 ┆ 1        │\n│ 2   ┆ 2.5 ┆ 2        │\n│ 2   ┆ 5.0 ┆ 2        │\n│ 3   ┆ 1.0 ┆ 10       │\n└─────┴─────┴──────────┘"], "Parameters": [["old", "Value or sequence of values to replace.\nAccepts expression input. Sequences are parsed as Series,\nother non-expression inputs are parsed as literals.\nAlso accepts a mapping of values to their replacement as syntactic sugar for replace(old=Series(mapping.keys()), new=Series(mapping.values())) ."], ["new", "Value or sequence of values to replace by.\nAccepts expression input. Sequences are parsed as Series,\nother non-expression inputs are parsed as literals.\nLength must match the length of old or have length 1."], ["default", "Set values that were not replaced to this value.\nDefaults to keeping the original value.\nAccepts expression input. Non-expression inputs are parsed as literals. Deprecated since version 1.0.0: Use replace_strict() instead to set a default while replacing\nvalues."], ["return_dtype", "The data type of the resulting expression. If set to None (default),\nthe data type of the original column is preserved. Deprecated since version 1.0.0: Use replace_strict() instead to set a return data type while\nreplacing values, or explicitly call cast() on the output."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 251}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.replace_strict.html#polars.Expr.replace_strict"], "Title": ["Expr.replace_strict"], "Feature": ["Expr.replace_strict"], "Description": ["Replace all values by different values."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 2, 3]})\n>>> df.with_columns(\n...     replaced=pl.col(\"a\").replace_strict([1, 2, 3], [100, 200, 300])\n... )\nshape: (4, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ i64 ┆ i64      │\n╞═════╪══════════╡\n│ 1   ┆ 100      │\n│ 2   ┆ 200      │\n│ 2   ┆ 200      │\n│ 3   ┆ 300      │\n└─────┴──────────┘", ">>> mapping = {1: 100, 2: 200, 3: 300}\n>>> df.with_columns(replaced=pl.col(\"a\").replace_strict(mapping))\nshape: (4, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ i64 ┆ i64      │\n╞═════╪══════════╡\n│ 1   ┆ 100      │\n│ 2   ┆ 200      │\n│ 2   ┆ 200      │\n│ 3   ┆ 300      │\n└─────┴──────────┘", ">>> mapping = {2: 200, 3: 300}\n>>> df.with_columns(\n...     replaced=pl.col(\"a\").replace_strict(mapping)\n... )  \nTraceback (most recent call last):\n...\npolars.exceptions.InvalidOperationError: incomplete mapping specified for `replace_strict`\n>>> df.with_columns(replaced=pl.col(\"a\").replace_strict(mapping, default=-1))\nshape: (4, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ i64 ┆ i64      │\n╞═════╪══════════╡\n│ 1   ┆ -1       │\n│ 2   ┆ 200      │\n│ 2   ┆ 200      │\n│ 3   ┆ 300      │\n└─────┴──────────┘", ">>> df = pl.DataFrame({\"a\": [\"x\", \"y\", \"z\"]})\n>>> mapping = {\"x\": 1, \"y\": 2, \"z\": 3}\n>>> df.with_columns(replaced=pl.col(\"a\").replace_strict(mapping))\nshape: (3, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ str ┆ i64      │\n╞═════╪══════════╡\n│ x   ┆ 1        │\n│ y   ┆ 2        │\n│ z   ┆ 3        │\n└─────┴──────────┘\n>>> df.with_columns(replaced=pl.col(\"a\").replace_strict(mapping, default=\"x\"))\nshape: (3, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ str ┆ str      │\n╞═════╪══════════╡\n│ x   ┆ 1        │\n│ y   ┆ 2        │\n│ z   ┆ 3        │\n└─────┴──────────┘", ">>> df.with_columns(\n...     replaced=pl.col(\"a\").replace_strict(mapping, return_dtype=pl.UInt8)\n... )\nshape: (3, 2)\n┌─────┬──────────┐\n│ a   ┆ replaced │\n│ --- ┆ ---      │\n│ str ┆ u8       │\n╞═════╪══════════╡\n│ x   ┆ 1        │\n│ y   ┆ 2        │\n│ z   ┆ 3        │\n└─────┴──────────┘", ">>> df = pl.DataFrame({\"a\": [1, 2, 2, 3], \"b\": [1.5, 2.5, 5.0, 1.0]})\n>>> df.with_columns(\n...     replaced=pl.col(\"a\").replace_strict(\n...         old=pl.col(\"a\").max(),\n...         new=pl.col(\"b\").sum(),\n...         default=pl.col(\"b\"),\n...     )\n... )\nshape: (4, 3)\n┌─────┬─────┬──────────┐\n│ a   ┆ b   ┆ replaced │\n│ --- ┆ --- ┆ ---      │\n│ i64 ┆ f64 ┆ f64      │\n╞═════╪═════╪══════════╡\n│ 1   ┆ 1.5 ┆ 1.5      │\n│ 2   ┆ 2.5 ┆ 2.5      │\n│ 2   ┆ 5.0 ┆ 5.0      │\n│ 3   ┆ 1.0 ┆ 10.0     │\n└─────┴─────┴──────────┘"], "Parameters": [["old", "Value or sequence of values to replace.\nAccepts expression input. Sequences are parsed as Series,\nother non-expression inputs are parsed as literals.\nAlso accepts a mapping of values to their replacement as syntactic sugar for replace_strict(old=Series(mapping.keys()), new=Series(mapping.values())) ."], ["new", "Value or sequence of values to replace by.\nAccepts expression input. Sequences are parsed as Series,\nother non-expression inputs are parsed as literals.\nLength must match the length of old or have length 1."], ["default", "Set values that were not replaced to this value. If no default is specified,\n(default), an error is raised if any values were not replaced.\nAccepts expression input. Non-expression inputs are parsed as literals."], ["return_dtype", "The data type of the resulting expression. If set to None (default),\nthe data type is determined automatically based on the other inputs."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 252}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.reshape.html#polars.Expr.reshape"], "Title": ["Expr.reshape"], "Feature": ["Expr.reshape"], "Description": ["Reshape this Expr to a flat column or an Array column."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7, 8, 9]})\n>>> square = df.select(pl.col(\"foo\").reshape((3, 3)))\n>>> square\nshape: (3, 1)\n┌───────────────┐\n│ foo           │\n│ ---           │\n│ array[i64, 3] │\n╞═══════════════╡\n│ [1, 2, 3]     │\n│ [4, 5, 6]     │\n│ [7, 8, 9]     │\n└───────────────┘\n>>> square.select(pl.col(\"foo\").reshape((9,)))\nshape: (9, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n│ 4   │\n│ 5   │\n│ 6   │\n│ 7   │\n│ 8   │\n│ 9   │\n└─────┘"], "Parameters": [["dimensions", "Tuple of the dimension sizes. If a -1 is used in any of the dimensions, that\ndimension is inferred."]], "Returns": [["Expr", "If a single dimension is given, results in an expression of the original\ndata type.\nIf a multiple dimensions are given, results in an expression of data type Array with shape dimensions ."]], "Category": ["Manipulation_selection"], "index": 253}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.reverse.html#polars.Expr.reverse"], "Title": ["Expr.reverse"], "Feature": ["Expr.reverse"], "Description": ["Reverse the selection."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"A\": [1, 2, 3, 4, 5],\n...         \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n...         \"B\": [5, 4, 3, 2, 1],\n...         \"cars\": [\"beetle\", \"audi\", \"beetle\", \"beetle\", \"beetle\"],\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.all(),\n...         pl.all().reverse().name.suffix(\"_reverse\"),\n...     ]\n... )\nshape: (5, 8)\n┌─────┬────────┬─────┬────────┬───────────┬────────────────┬───────────┬──────────────┐\n│ A   ┆ fruits ┆ B   ┆ cars   ┆ A_reverse ┆ fruits_reverse ┆ B_reverse ┆ cars_reverse │\n│ --- ┆ ---    ┆ --- ┆ ---    ┆ ---       ┆ ---            ┆ ---       ┆ ---          │\n│ i64 ┆ str    ┆ i64 ┆ str    ┆ i64       ┆ str            ┆ i64       ┆ str          │\n╞═════╪════════╪═════╪════════╪═══════════╪════════════════╪═══════════╪══════════════╡\n│ 1   ┆ banana ┆ 5   ┆ beetle ┆ 5         ┆ banana         ┆ 1         ┆ beetle       │\n│ 2   ┆ banana ┆ 4   ┆ audi   ┆ 4         ┆ apple          ┆ 2         ┆ beetle       │\n│ 3   ┆ apple  ┆ 3   ┆ beetle ┆ 3         ┆ apple          ┆ 3         ┆ beetle       │\n│ 4   ┆ apple  ┆ 2   ┆ beetle ┆ 2         ┆ banana         ┆ 4         ┆ audi         │\n│ 5   ┆ banana ┆ 1   ┆ beetle ┆ 1         ┆ banana         ┆ 5         ┆ beetle       │\n└─────┴────────┴─────┴────────┴───────────┴────────────────┴───────────┴──────────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 254}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rle.html#polars.Expr.rle"], "Title": ["Expr.rle"], "Feature": ["Expr.rle"], "Description": ["Compress the column data using run-length encoding."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2, 1, None, 1, 3, 3]})\n>>> df.select(pl.col(\"a\").rle()).unnest(\"a\")\nshape: (6, 2)\n┌─────┬───────┐\n│ len ┆ value │\n│ --- ┆ ---   │\n│ u32 ┆ i64   │\n╞═════╪═══════╡\n│ 2   ┆ 1     │\n│ 1   ┆ 2     │\n│ 1   ┆ 1     │\n│ 1   ┆ null  │\n│ 1   ┆ 1     │\n│ 2   ┆ 3     │\n└─────┴───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Struct with fields len of data type UInt32 and value of the original data type."]], "Category": ["Manipulation_selection"], "index": 255}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rle_id.html#polars.Expr.rle_id"], "Title": ["Expr.rle_id"], "Feature": ["Expr.rle_id"], "Description": ["Get a distinct integer ID for each run of identical values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 1, 1, 1],\n...         \"b\": [\"x\", \"x\", None, \"y\", \"y\"],\n...     }\n... )\n>>> df.with_columns(\n...     rle_id_a=pl.col(\"a\").rle_id(),\n...     rle_id_ab=pl.struct(\"a\", \"b\").rle_id(),\n... )\nshape: (5, 4)\n┌─────┬──────┬──────────┬───────────┐\n│ a   ┆ b    ┆ rle_id_a ┆ rle_id_ab │\n│ --- ┆ ---  ┆ ---      ┆ ---       │\n│ i64 ┆ str  ┆ u32      ┆ u32       │\n╞═════╪══════╪══════════╪═══════════╡\n│ 1   ┆ x    ┆ 0        ┆ 0         │\n│ 2   ┆ x    ┆ 1        ┆ 1         │\n│ 1   ┆ null ┆ 2        ┆ 2         │\n│ 1   ┆ y    ┆ 2        ┆ 3         │\n│ 1   ┆ y    ┆ 2        ┆ 3         │\n└─────┴──────┴──────────┴───────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Manipulation_selection"], "index": 256}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.explode.html#polars.Expr.arr.explode"], "Title": ["Expr.arr.explode"], "Feature": ["Expr.arr.explode"], "Description": ["Returns a column with a separate row for every array element."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[1, 2, 3], [4, 5, 6]]}, schema={\"a\": pl.Array(pl.Int64, 3)}\n... )\n>>> df.select(pl.col(\"a\").arr.explode())\nshape: (6, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n│ 4   │\n│ 5   │\n│ 6   │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression with the data type of the array elements."]], "Category": ["Array"], "index": 257}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.round.html#polars.Expr.round"], "Title": ["Expr.round"], "Feature": ["Expr.round"], "Description": ["Round underlying floating point data bydecimalsdigits."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.33, 0.52, 1.02, 1.17]})\n>>> df.select(pl.col(\"a\").round(1))\nshape: (4, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.3 │\n│ 0.5 │\n│ 1.0 │\n│ 1.2 │\n└─────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"f64\": [-3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5],\n...         \"d\": [\"-3.5\", \"-2.5\", \"-1.5\", \"-0.5\", \"0.5\", \"1.5\", \"2.5\", \"3.5\"],\n...     },\n...     schema_overrides={\"d\": pl.Decimal(scale=1)},\n... )\n>>> df.with_columns(\n...     pl.all().round(mode=\"half_away_from_zero\").name.suffix(\"_away\"),\n...     pl.all().round(mode=\"half_to_even\").name.suffix(\"_to_even\"),\n... )\nshape: (8, 6)\n┌──────┬──────────────┬──────────┬──────────────┬─────────────┬──────────────┐\n│ f64  ┆ d            ┆ f64_away ┆ d_away       ┆ f64_to_even ┆ d_to_even    │\n│ ---  ┆ ---          ┆ ---      ┆ ---          ┆ ---         ┆ ---          │\n│ f64  ┆ decimal[*,1] ┆ f64      ┆ decimal[*,1] ┆ f64         ┆ decimal[*,1] │\n╞══════╪══════════════╪══════════╪══════════════╪═════════════╪══════════════╡\n│ -3.5 ┆ -3.5         ┆ -4.0     ┆ -4.0         ┆ -4.0        ┆ -4.0         │\n│ -2.5 ┆ -2.5         ┆ -3.0     ┆ -3.0         ┆ -2.0        ┆ -2.0         │\n│ -1.5 ┆ -1.5         ┆ -2.0     ┆ -2.0         ┆ -2.0        ┆ -2.0         │\n│ -0.5 ┆ -0.5         ┆ -1.0     ┆ -1.0         ┆ -0.0        ┆ 0.0          │\n│ 0.5  ┆ 0.5          ┆ 1.0      ┆ 1.0          ┆ 0.0         ┆ 0.0          │\n│ 1.5  ┆ 1.5          ┆ 2.0      ┆ 2.0          ┆ 2.0         ┆ 2.0          │\n│ 2.5  ┆ 2.5          ┆ 3.0      ┆ 3.0          ┆ 2.0         ┆ 2.0          │\n│ 3.5  ┆ 3.5          ┆ 4.0      ┆ 4.0          ┆ 4.0         ┆ 4.0          │\n└──────┴──────────────┴──────────┴──────────────┴─────────────┴──────────────┘"], "Parameters": [["decimals", "Number of decimals to round by."], ["mode {‘half_to_even’, ‘half_away_from_zero’}", "RoundMode. half_to_even round to the nearest even number half_away_from_zero round to the nearest number away from zero"], ["half_to_even", "round to the nearest even number"], ["half_away_from_zero", "round to the nearest number away from zero"]], "Returns": [], "Category": ["Manipulation_selection"], "index": 258}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.round_sig_figs.html#polars.Expr.round_sig_figs"], "Title": ["Expr.round_sig_figs"], "Feature": ["Expr.round_sig_figs"], "Description": ["Round to a number of significant figures."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.01234, 3.333, 1234.0]})\n>>> df.with_columns(pl.col(\"a\").round_sig_figs(2).alias(\"round_sig_figs\"))\nshape: (3, 2)\n┌─────────┬────────────────┐\n│ a       ┆ round_sig_figs │\n│ ---     ┆ ---            │\n│ f64     ┆ f64            │\n╞═════════╪════════════════╡\n│ 0.01234 ┆ 0.012          │\n│ 3.333   ┆ 3.3            │\n│ 1234.0  ┆ 1200.0         │\n└─────────┴────────────────┘"], "Parameters": [["digits", "Number of significant figures to round to."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 259}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sample.html#polars.Expr.sample"], "Title": ["Expr.sample"], "Feature": ["Expr.sample"], "Description": ["Sample from this expression."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").sample(fraction=1.0, with_replacement=True, seed=1))\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 3   │\n│ 3   │\n│ 1   │\n└─────┘"], "Parameters": [["n", "Number of items to return. Cannot be used with fraction . Defaults to 1 if fraction is None."], ["fraction", "Fraction of items to return. Cannot be used with n ."], ["with_replacement", "Allow values to be sampled more than once."], ["shuffle", "Shuffle the order of sampled data points."], ["seed", "Seed for the random number generator. If set to None (default), a\nrandom seed is generated for each sample operation."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 260}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.shift.html#polars.Expr.shift"], "Title": ["Expr.shift"], "Feature": ["Expr.shift"], "Description": ["Shift values by the given number of indices."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4]})\n>>> df.with_columns(shift=pl.col(\"a\").shift())\nshape: (4, 2)\n┌─────┬───────┐\n│ a   ┆ shift │\n│ --- ┆ ---   │\n│ i64 ┆ i64   │\n╞═════╪═══════╡\n│ 1   ┆ null  │\n│ 2   ┆ 1     │\n│ 3   ┆ 2     │\n│ 4   ┆ 3     │\n└─────┴───────┘", ">>> df.with_columns(shift=pl.col(\"a\").shift(-2))\nshape: (4, 2)\n┌─────┬───────┐\n│ a   ┆ shift │\n│ --- ┆ ---   │\n│ i64 ┆ i64   │\n╞═════╪═══════╡\n│ 1   ┆ 3     │\n│ 2   ┆ 4     │\n│ 3   ┆ null  │\n│ 4   ┆ null  │\n└─────┴───────┘", ">>> df.with_columns(shift=pl.col(\"a\").shift(-2, fill_value=100))\nshape: (4, 2)\n┌─────┬───────┐\n│ a   ┆ shift │\n│ --- ┆ ---   │\n│ i64 ┆ i64   │\n╞═════╪═══════╡\n│ 1   ┆ 3     │\n│ 2   ┆ 4     │\n│ 3   ┆ 100   │\n│ 4   ┆ 100   │\n└─────┴───────┘"], "Parameters": [["n", "Number of indices to shift forward. If a negative value is passed, values\nare shifted in the opposite direction instead."], ["fill_value", "Fill the resulting null values with this scalar value."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 261}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.shrink_dtype.html#polars.Expr.shrink_dtype"], "Title": ["Expr.shrink_dtype"], "Feature": ["Expr.shrink_dtype"], "Description": ["Shrink numeric columns to the minimal required datatype."], "Examples": [">>> pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [1, 2, 2 << 32],\n...         \"c\": [-1, 2, 1 << 30],\n...         \"d\": [-112, 2, 112],\n...         \"e\": [-112, 2, 129],\n...         \"f\": [\"a\", \"b\", \"c\"],\n...         \"g\": [0.1, 1.32, 0.12],\n...         \"h\": [True, None, False],\n...     }\n... ).select(pl.all().shrink_dtype())  \nshape: (3, 8)\n┌─────┬────────────┬────────────┬──────┬──────┬─────┬──────┬───────┐\n│ a   ┆ b          ┆ c          ┆ d    ┆ e    ┆ f   ┆ g    ┆ h     │\n│ --- ┆ ---        ┆ ---        ┆ ---  ┆ ---  ┆ --- ┆ ---  ┆ ---   │\n│ i8  ┆ i64        ┆ i32        ┆ i8   ┆ i16  ┆ str ┆ f32  ┆ bool  │\n╞═════╪════════════╪════════════╪══════╪══════╪═════╪══════╪═══════╡\n│ 1   ┆ 1          ┆ -1         ┆ -112 ┆ -112 ┆ a   ┆ 0.1  ┆ true  │\n│ 2   ┆ 2          ┆ 2          ┆ 2    ┆ 2    ┆ b   ┆ 1.32 ┆ null  │\n│ 3   ┆ 8589934592 ┆ 1073741824 ┆ 112  ┆ 129  ┆ c   ┆ 0.12 ┆ false │\n└─────┴────────────┴────────────┴──────┴──────┴─────┴──────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 262}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.shuffle.html#polars.Expr.shuffle"], "Title": ["Expr.shuffle"], "Feature": ["Expr.shuffle"], "Description": ["Shuffle the contents of this expression."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3]})\n>>> df.select(pl.col(\"a\").shuffle(seed=1))\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n│ 3   │\n│ 1   │\n└─────┘"], "Parameters": [["seed", "Seed for the random number generator. If set to None (default), a\nrandom seed is generated each time the shuffle is called."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 263}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.slice.html#polars.Expr.slice"], "Title": ["Expr.slice"], "Feature": ["Expr.slice"], "Description": ["Get a slice of this expression."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [8, 9, 10, 11],\n...         \"b\": [None, 4, 4, 4],\n...     }\n... )\n>>> df.select(pl.all().slice(1, 2))\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 9   ┆ 4   │\n│ 10  ┆ 4   │\n└─────┴─────┘"], "Parameters": [["offset", "Start index. Negative indexing is supported."], ["length", "Length of the slice. If set to None , all rows starting at the offset\nwill be selected."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 264}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sort.html#polars.Expr.sort"], "Title": ["Expr.sort"], "Feature": ["Expr.sort"], "Description": ["Sort this column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, None, 3, 2],\n...     }\n... )\n>>> df.select(pl.col(\"a\").sort())\nshape: (4, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ null │\n│ 1    │\n│ 2    │\n│ 3    │\n└──────┘\n>>> df.select(pl.col(\"a\").sort(descending=True))\nshape: (4, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ null │\n│ 3    │\n│ 2    │\n│ 1    │\n└──────┘\n>>> df.select(pl.col(\"a\").sort(nulls_last=True))\nshape: (4, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ 1    │\n│ 2    │\n│ 3    │\n│ null │\n└──────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\"one\", \"one\", \"one\", \"two\", \"two\", \"two\"],\n...         \"value\": [1, 98, 2, 3, 99, 4],\n...     }\n... )\n>>> df.group_by(\"group\").agg(pl.col(\"value\").sort())  \nshape: (2, 2)\n┌───────┬────────────┐\n│ group ┆ value      │\n│ ---   ┆ ---        │\n│ str   ┆ list[i64]  │\n╞═══════╪════════════╡\n│ two   ┆ [3, 4, 99] │\n│ one   ┆ [1, 2, 98] │\n└───────┴────────────┘"], "Parameters": [["descending", "Sort in descending order."], ["nulls_last", "Place null values last."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 265}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sort_by.html#polars.Expr.sort_by"], "Title": ["Expr.sort_by"], "Feature": ["Expr.sort_by"], "Description": ["Sort this column by the ordering of other columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group\": [\"a\", \"a\", \"b\", \"b\"],\n...         \"value1\": [1, 3, 4, 2],\n...         \"value2\": [8, 7, 6, 5],\n...     }\n... )\n>>> df.select(pl.col(\"group\").sort_by(\"value1\"))\nshape: (4, 1)\n┌───────┐\n│ group │\n│ ---   │\n│ str   │\n╞═══════╡\n│ a     │\n│ b     │\n│ a     │\n│ b     │\n└───────┘", ">>> df.select(pl.col(\"group\").sort_by(pl.col(\"value1\") + pl.col(\"value2\")))\nshape: (4, 1)\n┌───────┐\n│ group │\n│ ---   │\n│ str   │\n╞═══════╡\n│ b     │\n│ a     │\n│ a     │\n│ b     │\n└───────┘", ">>> df.select(pl.col(\"group\").sort_by([\"value1\", \"value2\"], descending=True))\nshape: (4, 1)\n┌───────┐\n│ group │\n│ ---   │\n│ str   │\n╞═══════╡\n│ b     │\n│ a     │\n│ b     │\n│ a     │\n└───────┘", ">>> df.select(pl.col(\"group\").sort_by(\"value1\", \"value2\"))\nshape: (4, 1)\n┌───────┐\n│ group │\n│ ---   │\n│ str   │\n╞═══════╡\n│ a     │\n│ b     │\n│ a     │\n│ b     │\n└───────┘", ">>> df.group_by(\"group\").agg(\n...     pl.col(\"value1\").sort_by(\"value2\")\n... )  \nshape: (2, 2)\n┌───────┬───────────┐\n│ group ┆ value1    │\n│ ---   ┆ ---       │\n│ str   ┆ list[i64] │\n╞═══════╪═══════════╡\n│ a     ┆ [3, 1]    │\n│ b     ┆ [2, 4]    │\n└───────┴───────────┘", ">>> df.group_by(\"group\").agg(\n...     pl.all().sort_by(\"value2\").first()\n... )  \nshape: (2, 3)\n┌───────┬────────┬────────┐\n│ group ┆ value1 ┆ value2 |\n│ ---   ┆ ---    ┆ ---    │\n│ str   ┆ i64    ┆ i64    |\n╞═══════╪════════╪════════╡\n│ a     ┆ 3      ┆ 7      |\n│ b     ┆ 2      ┆ 5      |\n└───────┴────────┴────────┘"], "Parameters": [["by", "Column(s) to sort by. Accepts expression input. Strings are parsed as column\nnames."], ["*more_by", "Additional columns to sort by, specified as positional arguments."], ["descending", "Sort in descending order. When sorting by multiple columns, can be specified\nper column by passing a sequence of booleans."], ["nulls_last", "Place null values last; can specify a single boolean applying to all columns\nor a sequence of booleans for per-column control."], ["multithreaded", "Sort using multiple threads."], ["maintain_order", "Whether the order should be maintained if elements are equal."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 266}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.tail.html#polars.Expr.tail"], "Title": ["Expr.tail"], "Feature": ["Expr.tail"], "Description": ["Get the lastnrows."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5, 6, 7]})\n>>> df.select(pl.col(\"foo\").tail(3))\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 5   │\n│ 6   │\n│ 7   │\n└─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 267}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.first.html#polars.Expr.arr.first"], "Title": ["Expr.arr.first"], "Feature": ["Expr.arr.first"], "Description": ["Get the first value of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[1, 2, 3], [4, 5, 6], [7, 8, 9]]},\n...     schema={\"a\": pl.Array(pl.Int32, 3)},\n... )\n>>> df.with_columns(first=pl.col(\"a\").arr.first())\nshape: (3, 2)\n┌───────────────┬───────┐\n│ a             ┆ first │\n│ ---           ┆ ---   │\n│ array[i32, 3] ┆ i32   │\n╞═══════════════╪═══════╡\n│ [1, 2, 3]     ┆ 1     │\n│ [4, 5, 6]     ┆ 4     │\n│ [7, 8, 9]     ┆ 7     │\n└───────────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 268}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.to_physical.html#polars.Expr.to_physical"], "Title": ["Expr.to_physical"], "Feature": ["Expr.to_physical"], "Description": ["Cast to physical representation of the logical dtype."], "Examples": [">>> pl.DataFrame({\"vals\": [\"a\", \"x\", None, \"a\"]}).with_columns(\n...     pl.col(\"vals\").cast(pl.Categorical),\n...     pl.col(\"vals\")\n...     .cast(pl.Categorical)\n...     .to_physical()\n...     .alias(\"vals_physical\"),\n... )\nshape: (4, 2)\n┌──────┬───────────────┐\n│ vals ┆ vals_physical │\n│ ---  ┆ ---           │\n│ cat  ┆ u32           │\n╞══════╪═══════════════╡\n│ a    ┆ 0             │\n│ x    ┆ 1             │\n│ null ┆ null          │\n│ a    ┆ 0             │\n└──────┴───────────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 269}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.top_k.html#polars.Expr.top_k"], "Title": ["Expr.top_k"], "Feature": ["Expr.top_k"], "Description": ["Return theklargest elements."], "Examples": [">>> df = pl.DataFrame({\"value\": [1, 98, 2, 3, 99, 4]})\n>>> df.select(\n...     pl.col(\"value\").top_k().alias(\"top_k\"),\n...     pl.col(\"value\").bottom_k().alias(\"bottom_k\"),\n... )\nshape: (5, 2)\n┌───────┬──────────┐\n│ top_k ┆ bottom_k │\n│ ---   ┆ ---      │\n│ i64   ┆ i64      │\n╞═══════╪══════════╡\n│ 4     ┆ 1        │\n│ 98    ┆ 98       │\n│ 2     ┆ 2        │\n│ 3     ┆ 3        │\n│ 99    ┆ 4        │\n└───────┴──────────┘"], "Parameters": [["k", "Number of elements to return."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 270}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.top_k_by.html#polars.Expr.top_k_by"], "Title": ["Expr.top_k_by"], "Feature": ["Expr.top_k_by"], "Description": ["Return the elements corresponding to theklargest elements of thebycolumn(s)."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4, 5, 6],\n...         \"b\": [6, 5, 4, 3, 2, 1],\n...         \"c\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df\nshape: (6, 3)\n┌─────┬─────┬────────┐\n│ a   ┆ b   ┆ c      │\n│ --- ┆ --- ┆ ---    │\n│ i64 ┆ i64 ┆ str    │\n╞═════╪═════╪════════╡\n│ 1   ┆ 6   ┆ Apple  │\n│ 2   ┆ 5   ┆ Orange │\n│ 3   ┆ 4   ┆ Apple  │\n│ 4   ┆ 3   ┆ Apple  │\n│ 5   ┆ 2   ┆ Banana │\n│ 6   ┆ 1   ┆ Banana │\n└─────┴─────┴────────┘", ">>> df.select(\n...     pl.all().top_k_by(\"a\", 2).name.suffix(\"_top_by_a\"),\n...     pl.all().top_k_by(\"b\", 2).name.suffix(\"_top_by_b\"),\n... )\nshape: (2, 6)\n┌────────────┬────────────┬────────────┬────────────┬────────────┬────────────┐\n│ a_top_by_a ┆ b_top_by_a ┆ c_top_by_a ┆ a_top_by_b ┆ b_top_by_b ┆ c_top_by_b │\n│ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n│ i64        ┆ i64        ┆ str        ┆ i64        ┆ i64        ┆ str        │\n╞════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n│ 6          ┆ 1          ┆ Banana     ┆ 1          ┆ 6          ┆ Apple      │\n│ 5          ┆ 2          ┆ Banana     ┆ 2          ┆ 5          ┆ Orange     │\n└────────────┴────────────┴────────────┴────────────┴────────────┴────────────┘", ">>> df.select(\n...     pl.all()\n...     .top_k_by([\"c\", \"a\"], 2, reverse=[False, True])\n...     .name.suffix(\"_by_ca\"),\n...     pl.all()\n...     .top_k_by([\"c\", \"b\"], 2, reverse=[False, True])\n...     .name.suffix(\"_by_cb\"),\n... )\nshape: (2, 6)\n┌─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐\n│ a_by_ca ┆ b_by_ca ┆ c_by_ca ┆ a_by_cb ┆ b_by_cb ┆ c_by_cb │\n│ ---     ┆ ---     ┆ ---     ┆ ---     ┆ ---     ┆ ---     │\n│ i64     ┆ i64     ┆ str     ┆ i64     ┆ i64     ┆ str     │\n╞═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n│ 2       ┆ 5       ┆ Orange  ┆ 2       ┆ 5       ┆ Orange  │\n│ 5       ┆ 2       ┆ Banana  ┆ 6       ┆ 1       ┆ Banana  │\n└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘", ">>> (\n...     df.group_by(\"c\", maintain_order=True)\n...     .agg(pl.all().top_k_by(\"a\", 2))\n...     .explode(pl.all().exclude(\"c\"))\n... )\nshape: (5, 3)\n┌────────┬─────┬─────┐\n│ c      ┆ a   ┆ b   │\n│ ---    ┆ --- ┆ --- │\n│ str    ┆ i64 ┆ i64 │\n╞════════╪═════╪═════╡\n│ Apple  ┆ 4   ┆ 3   │\n│ Apple  ┆ 3   ┆ 4   │\n│ Orange ┆ 2   ┆ 5   │\n│ Banana ┆ 6   ┆ 1   │\n│ Banana ┆ 5   ┆ 2   │\n└────────┴─────┴─────┘"], "Parameters": [["by", "Column(s) used to determine the largest elements.\nAccepts expression input. Strings are parsed as column names."], ["k", "Number of elements to return."], ["reverse", "Consider the k smallest elements of the by column(s) (instead of the k largest). This can be specified per column by passing a sequence of\nbooleans."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 271}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.upper_bound.html#polars.Expr.upper_bound"], "Title": ["Expr.upper_bound"], "Feature": ["Expr.upper_bound"], "Description": ["Calculate the upper bound."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 2, 1]})\n>>> df.select(pl.col(\"a\").upper_bound())\nshape: (1, 1)\n┌─────────────────────┐\n│ a                   │\n│ ---                 │\n│ i64                 │\n╞═════════════════════╡\n│ 9223372036854775807 │\n└─────────────────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 272}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.where.html#polars.Expr.where"], "Title": ["Expr.where"], "Feature": ["Expr.where"], "Description": ["Filter a single column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"group_col\": [\"g1\", \"g1\", \"g2\"],\n...         \"b\": [1, 2, 3],\n...     }\n... )\n>>> df.group_by(\"group_col\").agg(  \n...     [\n...         pl.col(\"b\").where(pl.col(\"b\") < 2).sum().alias(\"lt\"),\n...         pl.col(\"b\").where(pl.col(\"b\") >= 2).sum().alias(\"gte\"),\n...     ]\n... ).sort(\"group_col\")\nshape: (2, 3)\n┌───────────┬─────┬─────┐\n│ group_col ┆ lt  ┆ gte │\n│ ---       ┆ --- ┆ --- │\n│ str       ┆ i64 ┆ i64 │\n╞═══════════╪═════╪═════╡\n│ g1        ┆ 1   ┆ 2   │\n│ g2        ┆ 0   ┆ 3   │\n└───────────┴─────┴─────┘"], "Parameters": [["predicate", "Boolean expression."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 273}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.and_.html#polars.Expr.and_"], "Title": ["Expr.and_"], "Feature": ["Expr.and_"], "Description": ["Method equivalent of bitwise \"and\" operatorexpr&other&...."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Operators"], "index": 274}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.or_.html#polars.Expr.or_"], "Title": ["Expr.or_"], "Feature": ["Expr.or_"], "Description": ["Method equivalent of bitwise \"or\" operatorexpr|other|...."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Operators"], "index": 275}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.eq.html#polars.Expr.eq"], "Title": ["Expr.eq"], "Feature": ["Expr.eq"], "Description": ["Method equivalent of equality operatorexpr==other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [1.0, 2.0, float(\"nan\"), 4.0],\n...         \"y\": [2.0, 2.0, float(\"nan\"), 4.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").eq(pl.col(\"y\")).alias(\"x == y\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬────────┐\n│ x   ┆ y   ┆ x == y │\n│ --- ┆ --- ┆ ---    │\n│ f64 ┆ f64 ┆ bool   │\n╞═════╪═════╪════════╡\n│ 1.0 ┆ 2.0 ┆ false  │\n│ 2.0 ┆ 2.0 ┆ true   │\n│ NaN ┆ NaN ┆ true   │\n│ 4.0 ┆ 4.0 ┆ true   │\n└─────┴─────┴────────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 276}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.eq_missing.html#polars.Expr.eq_missing"], "Title": ["Expr.eq_missing"], "Feature": ["Expr.eq_missing"], "Description": ["Method equivalent of equality operatorexpr==otherwhereNone==None."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [1.0, 2.0, float(\"nan\"), 4.0, None, None],\n...         \"y\": [2.0, 2.0, float(\"nan\"), 4.0, 5.0, None],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").eq(pl.col(\"y\")).alias(\"x eq y\"),\n...     pl.col(\"x\").eq_missing(pl.col(\"y\")).alias(\"x eq_missing y\"),\n... )\nshape: (6, 4)\n┌──────┬──────┬────────┬────────────────┐\n│ x    ┆ y    ┆ x eq y ┆ x eq_missing y │\n│ ---  ┆ ---  ┆ ---    ┆ ---            │\n│ f64  ┆ f64  ┆ bool   ┆ bool           │\n╞══════╪══════╪════════╪════════════════╡\n│ 1.0  ┆ 2.0  ┆ false  ┆ false          │\n│ 2.0  ┆ 2.0  ┆ true   ┆ true           │\n│ NaN  ┆ NaN  ┆ true   ┆ true           │\n│ 4.0  ┆ 4.0  ┆ true   ┆ true           │\n│ null ┆ 5.0  ┆ null   ┆ false          │\n│ null ┆ null ┆ null   ┆ true           │\n└──────┴──────┴────────┴────────────────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 277}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ge.html#polars.Expr.ge"], "Title": ["Expr.ge"], "Feature": ["Expr.ge"], "Description": ["Method equivalent of \"greater than or equal\" operatorexpr>=other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [5.0, 4.0, float(\"nan\"), 2.0],\n...         \"y\": [5.0, 3.0, float(\"nan\"), 1.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").ge(pl.col(\"y\")).alias(\"x >= y\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬────────┐\n│ x   ┆ y   ┆ x >= y │\n│ --- ┆ --- ┆ ---    │\n│ f64 ┆ f64 ┆ bool   │\n╞═════╪═════╪════════╡\n│ 5.0 ┆ 5.0 ┆ true   │\n│ 4.0 ┆ 3.0 ┆ true   │\n│ NaN ┆ NaN ┆ true   │\n│ 2.0 ┆ 1.0 ┆ true   │\n└─────┴─────┴────────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 278}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.get.html#polars.Expr.arr.get"], "Title": ["Expr.arr.get"], "Feature": ["Expr.arr.get"], "Description": ["Get the value by index in the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     {\"arr\": [[1, 2, 3], [4, 5, 6], [7, 8, 9]], \"idx\": [1, -2, 0]},\n...     schema={\"arr\": pl.Array(pl.Int32, 3), \"idx\": pl.Int32},\n... )\n>>> df.with_columns(get=pl.col(\"arr\").arr.get(\"idx\", null_on_oob=True))\nshape: (3, 3)\n┌───────────────┬─────┬─────┐\n│ arr           ┆ idx ┆ get │\n│ ---           ┆ --- ┆ --- │\n│ array[i32, 3] ┆ i32 ┆ i32 │\n╞═══════════════╪═════╪═════╡\n│ [1, 2, 3]     ┆ 1   ┆ 2   │\n│ [4, 5, 6]     ┆ -2  ┆ 5   │\n│ [7, 8, 9]     ┆ 0   ┆ 7   │\n└───────────────┴─────┴─────┘"], "Parameters": [["index", "Index to return per sub-array"], ["null_on_oob", "Behavior if an index is out of bounds:\nTrue -> set as null\nFalse -> raise an error"]], "Returns": [], "Category": ["Array"], "index": 279}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.gt.html#polars.Expr.gt"], "Title": ["Expr.gt"], "Feature": ["Expr.gt"], "Description": ["Method equivalent of \"greater than\" operatorexpr>other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [5.0, 4.0, float(\"nan\"), 2.0],\n...         \"y\": [5.0, 3.0, float(\"nan\"), 1.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").gt(pl.col(\"y\")).alias(\"x > y\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬───────┐\n│ x   ┆ y   ┆ x > y │\n│ --- ┆ --- ┆ ---   │\n│ f64 ┆ f64 ┆ bool  │\n╞═════╪═════╪═══════╡\n│ 5.0 ┆ 5.0 ┆ false │\n│ 4.0 ┆ 3.0 ┆ true  │\n│ NaN ┆ NaN ┆ false │\n│ 2.0 ┆ 1.0 ┆ true  │\n└─────┴─────┴───────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 280}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.le.html#polars.Expr.le"], "Title": ["Expr.le"], "Feature": ["Expr.le"], "Description": ["Method equivalent of \"less than or equal\" operatorexpr<=other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [5.0, 4.0, float(\"nan\"), 0.5],\n...         \"y\": [5.0, 3.5, float(\"nan\"), 2.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").le(pl.col(\"y\")).alias(\"x <= y\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬────────┐\n│ x   ┆ y   ┆ x <= y │\n│ --- ┆ --- ┆ ---    │\n│ f64 ┆ f64 ┆ bool   │\n╞═════╪═════╪════════╡\n│ 5.0 ┆ 5.0 ┆ true   │\n│ 4.0 ┆ 3.5 ┆ false  │\n│ NaN ┆ NaN ┆ true   │\n│ 0.5 ┆ 2.0 ┆ true   │\n└─────┴─────┴────────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 281}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.lt.html#polars.Expr.lt"], "Title": ["Expr.lt"], "Feature": ["Expr.lt"], "Description": ["Method equivalent of \"less than\" operatorexpr<other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [1.0, 2.0, float(\"nan\"), 3.0],\n...         \"y\": [2.0, 2.0, float(\"nan\"), 4.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").lt(pl.col(\"y\")).alias(\"x < y\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬───────┐\n│ x   ┆ y   ┆ x < y │\n│ --- ┆ --- ┆ ---   │\n│ f64 ┆ f64 ┆ bool  │\n╞═════╪═════╪═══════╡\n│ 1.0 ┆ 2.0 ┆ true  │\n│ 2.0 ┆ 2.0 ┆ false │\n│ NaN ┆ NaN ┆ false │\n│ 3.0 ┆ 4.0 ┆ true  │\n└─────┴─────┴───────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 282}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ne.html#polars.Expr.ne"], "Title": ["Expr.ne"], "Feature": ["Expr.ne"], "Description": ["Method equivalent of inequality operatorexpr!=other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [1.0, 2.0, float(\"nan\"), 4.0],\n...         \"y\": [2.0, 2.0, float(\"nan\"), 4.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").ne(pl.col(\"y\")).alias(\"x != y\"),\n... )\nshape: (4, 3)\n┌─────┬─────┬────────┐\n│ x   ┆ y   ┆ x != y │\n│ --- ┆ --- ┆ ---    │\n│ f64 ┆ f64 ┆ bool   │\n╞═════╪═════╪════════╡\n│ 1.0 ┆ 2.0 ┆ true   │\n│ 2.0 ┆ 2.0 ┆ false  │\n│ NaN ┆ NaN ┆ false  │\n│ 4.0 ┆ 4.0 ┆ false  │\n└─────┴─────┴────────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 283}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.ne_missing.html#polars.Expr.ne_missing"], "Title": ["Expr.ne_missing"], "Feature": ["Expr.ne_missing"], "Description": ["Method equivalent of equality operatorexpr!=otherwhereNone==None."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"x\": [1.0, 2.0, float(\"nan\"), 4.0, None, None],\n...         \"y\": [2.0, 2.0, float(\"nan\"), 4.0, 5.0, None],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").ne(pl.col(\"y\")).alias(\"x ne y\"),\n...     pl.col(\"x\").ne_missing(pl.col(\"y\")).alias(\"x ne_missing y\"),\n... )\nshape: (6, 4)\n┌──────┬──────┬────────┬────────────────┐\n│ x    ┆ y    ┆ x ne y ┆ x ne_missing y │\n│ ---  ┆ ---  ┆ ---    ┆ ---            │\n│ f64  ┆ f64  ┆ bool   ┆ bool           │\n╞══════╪══════╪════════╪════════════════╡\n│ 1.0  ┆ 2.0  ┆ true   ┆ true           │\n│ 2.0  ┆ 2.0  ┆ false  ┆ false          │\n│ NaN  ┆ NaN  ┆ false  ┆ false          │\n│ 4.0  ┆ 4.0  ┆ false  ┆ false          │\n│ null ┆ 5.0  ┆ null   ┆ true           │\n│ null ┆ null ┆ null   ┆ false          │\n└──────┴──────┴────────┴────────────────┘"], "Parameters": [["other", "A literal or expression value to compare with."]], "Returns": [], "Category": ["Operators"], "index": 284}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.add.html#polars.Expr.add"], "Title": ["Expr.add"], "Feature": ["Expr.add"], "Description": ["Method equivalent of addition operatorexpr+other."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 2, 3, 4, 5]})\n>>> df.with_columns(\n...     pl.col(\"x\").add(2).alias(\"x+int\"),\n...     pl.col(\"x\").add(pl.col(\"x\").cum_prod()).alias(\"x+expr\"),\n... )\nshape: (5, 3)\n┌─────┬───────┬────────┐\n│ x   ┆ x+int ┆ x+expr │\n│ --- ┆ ---   ┆ ---    │\n│ i64 ┆ i64   ┆ i64    │\n╞═════╪═══════╪════════╡\n│ 1   ┆ 3     ┆ 2      │\n│ 2   ┆ 4     ┆ 4      │\n│ 3   ┆ 5     ┆ 9      │\n│ 4   ┆ 6     ┆ 28     │\n│ 5   ┆ 7     ┆ 125    │\n└─────┴───────┴────────┘", ">>> df = pl.DataFrame(\n...     {\"x\": [\"a\", \"d\", \"g\"], \"y\": [\"b\", \"e\", \"h\"], \"z\": [\"c\", \"f\", \"i\"]}\n... )\n>>> df.with_columns(pl.col(\"x\").add(pl.col(\"y\")).add(pl.col(\"z\")).alias(\"xyz\"))\nshape: (3, 4)\n┌─────┬─────┬─────┬─────┐\n│ x   ┆ y   ┆ z   ┆ xyz │\n│ --- ┆ --- ┆ --- ┆ --- │\n│ str ┆ str ┆ str ┆ str │\n╞═════╪═════╪═════╪═════╡\n│ a   ┆ b   ┆ c   ┆ abc │\n│ d   ┆ e   ┆ f   ┆ def │\n│ g   ┆ h   ┆ i   ┆ ghi │\n└─────┴─────┴─────┴─────┘"], "Parameters": [["other", "numeric or string value; accepts expression input."]], "Returns": [], "Category": ["Operators"], "index": 285}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.floordiv.html#polars.Expr.floordiv"], "Title": ["Expr.floordiv"], "Feature": ["Expr.floordiv"], "Description": ["Method equivalent of integer division operatorexpr//other."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 2, 3, 4, 5]})\n>>> df.with_columns(\n...     pl.col(\"x\").truediv(2).alias(\"x/2\"),\n...     pl.col(\"x\").floordiv(2).alias(\"x//2\"),\n... )\nshape: (5, 3)\n┌─────┬─────┬──────┐\n│ x   ┆ x/2 ┆ x//2 │\n│ --- ┆ --- ┆ ---  │\n│ i64 ┆ f64 ┆ i64  │\n╞═════╪═════╪══════╡\n│ 1   ┆ 0.5 ┆ 0    │\n│ 2   ┆ 1.0 ┆ 1    │\n│ 3   ┆ 1.5 ┆ 1    │\n│ 4   ┆ 2.0 ┆ 2    │\n│ 5   ┆ 2.5 ┆ 2    │\n└─────┴─────┴──────┘", ">>> 6.0 // 0.1\n59.0", ">>> df = pl.DataFrame({\"x\": [6.0, 6.03]})\n>>> df.with_columns(\n...     pl.col(\"x\").truediv(0.1).alias(\"x/0.1\"),\n... ).with_columns(\n...     pl.col(\"x/0.1\").floor().alias(\"x/0.1 floor\"),\n... )\nshape: (2, 3)\n┌──────┬───────┬─────────────┐\n│ x    ┆ x/0.1 ┆ x/0.1 floor │\n│ ---  ┆ ---   ┆ ---         │\n│ f64  ┆ f64   ┆ f64         │\n╞══════╪═══════╪═════════════╡\n│ 6.0  ┆ 60.0  ┆ 60.0        │\n│ 6.03 ┆ 60.3  ┆ 60.0        │\n└──────┴───────┴─────────────┘", ">>> df.with_columns(\n...     pl.col(\"x\").floordiv(0.1).alias(\"x//0.1\"),\n... )\nshape: (2, 2)\n┌──────┬────────┐\n│ x    ┆ x//0.1 │\n│ ---  ┆ ---    │\n│ f64  ┆ f64    │\n╞══════╪════════╡\n│ 6.0  ┆ 60.0   │\n│ 6.03 ┆ 60.0   │\n└──────┴────────┘"], "Parameters": [["other", "Numeric literal or expression value."]], "Returns": [], "Category": ["Operators"], "index": 286}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.mod.html#polars.Expr.mod"], "Title": ["Expr.mod"], "Feature": ["Expr.mod"], "Description": ["Method equivalent of modulus operatorexpr%other."], "Examples": [">>> df = pl.DataFrame({\"x\": [0, 1, 2, 3, 4]})\n>>> df.with_columns(pl.col(\"x\").mod(2).alias(\"x%2\"))\nshape: (5, 2)\n┌─────┬─────┐\n│ x   ┆ x%2 │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 0   ┆ 0   │\n│ 1   ┆ 1   │\n│ 2   ┆ 0   │\n│ 3   ┆ 1   │\n│ 4   ┆ 0   │\n└─────┴─────┘"], "Parameters": [["other", "Numeric literal or expression value."]], "Returns": [], "Category": ["Operators"], "index": 287}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.mul.html#polars.Expr.mul"], "Title": ["Expr.mul"], "Feature": ["Expr.mul"], "Description": ["Method equivalent of multiplication operatorexpr*other."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 2, 4, 8, 16]})\n>>> df.with_columns(\n...     pl.col(\"x\").mul(2).alias(\"x*2\"),\n...     pl.col(\"x\").mul(pl.col(\"x\").log(2)).alias(\"x * xlog2\"),\n... )\nshape: (5, 3)\n┌─────┬─────┬───────────┐\n│ x   ┆ x*2 ┆ x * xlog2 │\n│ --- ┆ --- ┆ ---       │\n│ i64 ┆ i64 ┆ f64       │\n╞═════╪═════╪═══════════╡\n│ 1   ┆ 2   ┆ 0.0       │\n│ 2   ┆ 4   ┆ 2.0       │\n│ 4   ┆ 8   ┆ 8.0       │\n│ 8   ┆ 16  ┆ 24.0      │\n│ 16  ┆ 32  ┆ 64.0      │\n└─────┴─────┴───────────┘"], "Parameters": [["other", "Numeric literal or expression value."]], "Returns": [], "Category": ["Operators"], "index": 288}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.neg.html#polars.Expr.neg"], "Title": ["Expr.neg"], "Feature": ["Expr.neg"], "Description": ["Method equivalent of unary minus operator-expr."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 0, 2, None]})\n>>> df.with_columns(pl.col(\"a\").neg())\nshape: (4, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ 1    │\n│ 0    │\n│ -2   │\n│ null │\n└──────┘"], "Parameters": [], "Returns": [], "Category": ["Operators"], "index": 289}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.join.html#polars.Expr.arr.join"], "Title": ["Expr.arr.join"], "Feature": ["Expr.arr.join"], "Description": ["Join all string items in a sub-array and place a separator between them."], "Examples": [">>> df = pl.DataFrame(\n...     {\"s\": [[\"a\", \"b\"], [\"x\", \"y\"]], \"separator\": [\"*\", \"_\"]},\n...     schema={\n...         \"s\": pl.Array(pl.String, 2),\n...         \"separator\": pl.String,\n...     },\n... )\n>>> df.with_columns(join=pl.col(\"s\").arr.join(pl.col(\"separator\")))\nshape: (2, 3)\n┌───────────────┬───────────┬──────┐\n│ s             ┆ separator ┆ join │\n│ ---           ┆ ---       ┆ ---  │\n│ array[str, 2] ┆ str       ┆ str  │\n╞═══════════════╪═══════════╪══════╡\n│ [\"a\", \"b\"]    ┆ *         ┆ a*b  │\n│ [\"x\", \"y\"]    ┆ _         ┆ x_y  │\n└───────────────┴───────────┴──────┘"], "Parameters": [["separator", "string to separate the items with"], ["ignore_nulls", "Ignore null values (default). If set to False , null values will be propagated.\nIf the sub-list contains any null values, the output is None ."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["Array"], "index": 290}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.pow.html#polars.Expr.pow"], "Title": ["Expr.pow"], "Feature": ["Expr.pow"], "Description": ["Method equivalent of exponentiation operatorexpr**exponent."], "Examples": [">>> df = pl.DataFrame({\"x\": [1, 2, 4, 8]})\n>>> df.with_columns(\n...     pl.col(\"x\").pow(3).alias(\"cube\"),\n...     pl.col(\"x\").pow(pl.col(\"x\").log(2)).alias(\"x ** xlog2\"),\n... )\nshape: (4, 3)\n┌─────┬──────┬────────────┐\n│ x   ┆ cube ┆ x ** xlog2 │\n│ --- ┆ ---  ┆ ---        │\n│ i64 ┆ i64  ┆ f64        │\n╞═════╪══════╪════════════╡\n│ 1   ┆ 1    ┆ 1.0        │\n│ 2   ┆ 8    ┆ 2.0        │\n│ 4   ┆ 64   ┆ 16.0       │\n│ 8   ┆ 512  ┆ 512.0      │\n└─────┴──────┴────────────┘", ">>> df.with_columns(\n...     x_squared=pl.col(\"x\").pow(2),\n...     x_inverse=pl.col(\"x\").pow(-1.0),\n... )\nshape: (4, 3)\n┌─────┬───────────┬───────────┐\n│ x   ┆ x_squared ┆ x_inverse │\n│ --- ┆ ---       ┆ ---       │\n│ i64 ┆ i64       ┆ f64       │\n╞═════╪═══════════╪═══════════╡\n│ 1   ┆ 1         ┆ 1.0       │\n│ 2   ┆ 4         ┆ 0.5       │\n│ 4   ┆ 16        ┆ 0.25      │\n│ 8   ┆ 64        ┆ 0.125     │\n└─────┴───────────┴───────────┘"], "Parameters": [["exponent", "Numeric literal or expression exponent value."]], "Returns": [], "Category": ["Operators"], "index": 291}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.sub.html#polars.Expr.sub"], "Title": ["Expr.sub"], "Feature": ["Expr.sub"], "Description": ["Method equivalent of subtraction operatorexpr-other."], "Examples": [">>> df = pl.DataFrame({\"x\": [0, 1, 2, 3, 4]})\n>>> df.with_columns(\n...     pl.col(\"x\").sub(2).alias(\"x-2\"),\n...     pl.col(\"x\").sub(pl.col(\"x\").cum_sum()).alias(\"x-expr\"),\n... )\nshape: (5, 3)\n┌─────┬─────┬────────┐\n│ x   ┆ x-2 ┆ x-expr │\n│ --- ┆ --- ┆ ---    │\n│ i64 ┆ i64 ┆ i64    │\n╞═════╪═════╪════════╡\n│ 0   ┆ -2  ┆ 0      │\n│ 1   ┆ -1  ┆ 0      │\n│ 2   ┆ 0   ┆ -1     │\n│ 3   ┆ 1   ┆ -3     │\n│ 4   ┆ 2   ┆ -6     │\n└─────┴─────┴────────┘"], "Parameters": [["other", "Numeric literal or expression value."]], "Returns": [], "Category": ["Operators"], "index": 292}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.truediv.html#polars.Expr.truediv"], "Title": ["Expr.truediv"], "Feature": ["Expr.truediv"], "Description": ["Method equivalent of float division operatorexpr/other."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"x\": [-2, -1, 0, 1, 2], \"y\": [0.5, 0.0, 0.0, -4.0, -0.5]}\n... )\n>>> df.with_columns(\n...     pl.col(\"x\").truediv(2).alias(\"x/2\"),\n...     pl.col(\"x\").truediv(pl.col(\"y\")).alias(\"x/y\"),\n... )\nshape: (5, 4)\n┌─────┬──────┬──────┬───────┐\n│ x   ┆ y    ┆ x/2  ┆ x/y   │\n│ --- ┆ ---  ┆ ---  ┆ ---   │\n│ i64 ┆ f64  ┆ f64  ┆ f64   │\n╞═════╪══════╪══════╪═══════╡\n│ -2  ┆ 0.5  ┆ -1.0 ┆ -4.0  │\n│ -1  ┆ 0.0  ┆ -0.5 ┆ -inf  │\n│ 0   ┆ 0.0  ┆ 0.0  ┆ NaN   │\n│ 1   ┆ -4.0 ┆ 0.5  ┆ -0.25 │\n│ 2   ┆ -0.5 ┆ 1.0  ┆ -4.0  │\n└─────┴──────┴──────┴───────┘"], "Parameters": [["other", "Numeric literal or expression value."]], "Returns": [], "Category": ["Operators"], "index": 293}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.xor.html#polars.Expr.xor"], "Title": ["Expr.xor"], "Feature": ["Expr.xor"], "Description": ["Method equivalent of bitwise exclusive-or operatorexpr^other."], "Examples": [">>> df = pl.DataFrame(\n...     {\"x\": [True, False, True, False], \"y\": [True, True, False, False]}\n... )\n>>> df.with_columns(pl.col(\"x\").xor(pl.col(\"y\")).alias(\"x ^ y\"))\nshape: (4, 3)\n┌───────┬───────┬───────┐\n│ x     ┆ y     ┆ x ^ y │\n│ ---   ┆ ---   ┆ ---   │\n│ bool  ┆ bool  ┆ bool  │\n╞═══════╪═══════╪═══════╡\n│ true  ┆ true  ┆ false │\n│ false ┆ true  ┆ true  │\n│ true  ┆ false ┆ true  │\n│ false ┆ false ┆ false │\n└───────┴───────┴───────┘", ">>> def binary_string(n: int) -> str:\n...     return bin(n)[2:].zfill(8)\n>>>\n>>> df = pl.DataFrame(\n...     data={\"x\": [10, 8, 250, 66], \"y\": [1, 2, 3, 4]},\n...     schema={\"x\": pl.UInt8, \"y\": pl.UInt8},\n... )\n>>> df.with_columns(\n...     pl.col(\"x\")\n...     .map_elements(binary_string, return_dtype=pl.String)\n...     .alias(\"bin_x\"),\n...     pl.col(\"y\")\n...     .map_elements(binary_string, return_dtype=pl.String)\n...     .alias(\"bin_y\"),\n...     pl.col(\"x\").xor(pl.col(\"y\")).alias(\"xor_xy\"),\n...     pl.col(\"x\")\n...     .xor(pl.col(\"y\"))\n...     .map_elements(binary_string, return_dtype=pl.String)\n...     .alias(\"bin_xor_xy\"),\n... )\nshape: (4, 6)\n┌─────┬─────┬──────────┬──────────┬────────┬────────────┐\n│ x   ┆ y   ┆ bin_x    ┆ bin_y    ┆ xor_xy ┆ bin_xor_xy │\n│ --- ┆ --- ┆ ---      ┆ ---      ┆ ---    ┆ ---        │\n│ u8  ┆ u8  ┆ str      ┆ str      ┆ u8     ┆ str        │\n╞═════╪═════╪══════════╪══════════╪════════╪════════════╡\n│ 10  ┆ 1   ┆ 00001010 ┆ 00000001 ┆ 11     ┆ 00001011   │\n│ 8   ┆ 2   ┆ 00001000 ┆ 00000010 ┆ 10     ┆ 00001010   │\n│ 250 ┆ 3   ┆ 11111010 ┆ 00000011 ┆ 249    ┆ 11111001   │\n│ 66  ┆ 4   ┆ 01000010 ┆ 00000100 ┆ 70     ┆ 01000110   │\n└─────┴─────┴──────────┴──────────┴────────┴────────────┘"], "Parameters": [["other", "Integer or boolean value; accepts expression input."]], "Returns": [], "Category": ["Operators"], "index": 294}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.concat.html#polars.Expr.str.concat"], "Title": ["Expr.str.concat"], "Feature": ["Expr.str.concat"], "Description": ["Vertically concatenate the string values in the column to a single string value."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, None, 2]})\n>>> df.select(pl.col(\"foo\").str.concat(\"-\"))  \nshape: (1, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ str │\n╞═════╡\n│ 1-2 │\n└─────┘\n>>> df.select(\n...     pl.col(\"foo\").str.concat(\"-\", ignore_nulls=False)\n... )  \nshape: (1, 1)\n┌──────┐\n│ foo  │\n│ ---  │\n│ str  │\n╞══════╡\n│ null │\n└──────┘"], "Parameters": [["delimiter", "The delimiter to insert between consecutive string values."], ["ignore_nulls", "Ignore null values (default).\nIf set to False , null values will be propagated. This means that\nif the column contains any null values, the output is null."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 295}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.contains.html#polars.Expr.str.contains"], "Title": ["Expr.str.contains"], "Feature": ["Expr.str.contains"], "Description": ["Check if the string contains a substring that matches a pattern."], "Examples": [">>> df = pl.DataFrame({\"txt\": [\"Crab\", \"cat and dog\", \"rab$bit\", None]})\n>>> df.select(\n...     pl.col(\"txt\"),\n...     pl.col(\"txt\").str.contains(\"cat|bit\").alias(\"regex\"),\n...     pl.col(\"txt\").str.contains(\"rab$\", literal=True).alias(\"literal\"),\n... )\nshape: (4, 3)\n┌─────────────┬───────┬─────────┐\n│ txt         ┆ regex ┆ literal │\n│ ---         ┆ ---   ┆ ---     │\n│ str         ┆ bool  ┆ bool    │\n╞═════════════╪═══════╪═════════╡\n│ Crab        ┆ false ┆ false   │\n│ cat and dog ┆ true  ┆ false   │\n│ rab$bit     ┆ true  ┆ true    │\n│ null        ┆ null  ┆ null    │\n└─────────────┴───────┴─────────┘"], "Parameters": [["pattern", "A valid regular expression pattern, compatible with the regex crate ."], ["literal", "Treat pattern as a literal string, not as a regular expression."], ["strict", "Raise an error if the underlying pattern is not a valid regex,\notherwise mask out with a null value."]], "Returns": [], "Category": ["String"], "index": 296}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.contains_any.html#polars.Expr.str.contains_any"], "Title": ["Expr.str.contains_any"], "Feature": ["Expr.str.contains_any"], "Description": ["Use the Aho-Corasick algorithm to find matches."], "Examples": [">>> _ = pl.Config.set_fmt_str_lengths(100)\n>>> df = pl.DataFrame(\n...     {\n...         \"lyrics\": [\n...             \"Everybody wants to rule the world\",\n...             \"Tell me what you want, what you really really want\",\n...             \"Can you feel the love tonight\",\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"lyrics\").str.contains_any([\"you\", \"me\"]).alias(\"contains_any\")\n... )\nshape: (3, 2)\n┌────────────────────────────────────────────────────┬──────────────┐\n│ lyrics                                             ┆ contains_any │\n│ ---                                                ┆ ---          │\n│ str                                                ┆ bool         │\n╞════════════════════════════════════════════════════╪══════════════╡\n│ Everybody wants to rule the world                  ┆ false        │\n│ Tell me what you want, what you really really want ┆ true         │\n│ Can you feel the love tonight                      ┆ true         │\n└────────────────────────────────────────────────────┴──────────────┘"], "Parameters": [["patterns", "String patterns to search."], ["ascii_case_insensitive", "Enable ASCII-aware case-insensitive matching.\nWhen this option is enabled, searching will be performed without respect\nto case for ASCII letters (a-z and A-Z) only."]], "Returns": [], "Category": ["String"], "index": 297}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.count_matches.html#polars.Expr.str.count_matches"], "Title": ["Expr.str.count_matches"], "Feature": ["Expr.str.count_matches"], "Description": ["Count all successive non-overlapping regex matches."], "Examples": [">>> df = pl.DataFrame({\"foo\": [\"123 bla 45 asd\", \"xyz 678 910t\", \"bar\", None]})\n>>> df.with_columns(\n...     pl.col(\"foo\").str.count_matches(r\"\\d\").alias(\"count_digits\"),\n... )\nshape: (4, 2)\n┌────────────────┬──────────────┐\n│ foo            ┆ count_digits │\n│ ---            ┆ ---          │\n│ str            ┆ u32          │\n╞════════════════╪══════════════╡\n│ 123 bla 45 asd ┆ 5            │\n│ xyz 678 910t   ┆ 6            │\n│ bar            ┆ 0            │\n│ null           ┆ null         │\n└────────────────┴──────────────┘", ">>> df = pl.DataFrame({\"bar\": [\"12 dbc 3xy\", \"cat\\\\w\", \"1zy3\\\\d\\\\d\", None]})\n>>> df.with_columns(\n...     pl.col(\"bar\")\n...     .str.count_matches(r\"\\d\", literal=True)\n...     .alias(\"count_digits\"),\n... )\nshape: (4, 2)\n┌────────────┬──────────────┐\n│ bar        ┆ count_digits │\n│ ---        ┆ ---          │\n│ str        ┆ u32          │\n╞════════════╪══════════════╡\n│ 12 dbc 3xy ┆ 0            │\n│ cat\\w      ┆ 0            │\n│ 1zy3\\d\\d   ┆ 2            │\n│ null       ┆ null         │\n└────────────┴──────────────┘"], "Parameters": [["pattern", "A valid regular expression pattern, compatible with the regex crate ."], ["literal", "Treat pattern as a literal string, not as a regular expression."]], "Returns": [["Expr", "Expression of data type UInt32 . Returns null if the\noriginal value is null."]], "Category": ["String"], "index": 298}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.decode.html#polars.Expr.str.decode"], "Title": ["Expr.str.decode"], "Feature": ["Expr.str.decode"], "Description": ["Decode values using the provided encoding."], "Examples": [">>> df = pl.DataFrame({\"color\": [\"000000\", \"ffff00\", \"0000ff\"]})\n>>> df.with_columns(pl.col(\"color\").str.decode(\"hex\").alias(\"decoded\"))\nshape: (3, 2)\n┌────────┬─────────────────┐\n│ color  ┆ decoded         │\n│ ---    ┆ ---             │\n│ str    ┆ binary          │\n╞════════╪═════════════════╡\n│ 000000 ┆ b\"\\x00\\x00\\x00\" │\n│ ffff00 ┆ b\"\\xff\\xff\\x00\" │\n│ 0000ff ┆ b\"\\x00\\x00\\xff\" │\n└────────┴─────────────────┘"], "Parameters": [["encoding {‘hex’, ‘base64’}", "The encoding to use."], ["strict", "Raise an error if the underlying value cannot be decoded,\notherwise mask out with a null value."]], "Returns": [["Expr", "Expression of data type Binary ."]], "Category": ["String"], "index": 299}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.encode.html#polars.Expr.str.encode"], "Title": ["Expr.str.encode"], "Feature": ["Expr.str.encode"], "Description": ["Encode values using the provided encoding."], "Examples": [">>> df = pl.DataFrame({\"strings\": [\"foo\", \"bar\", None]})\n>>> df.with_columns(strings_hex=pl.col(\"strings\").str.encode(\"hex\"))\nshape: (3, 2)\n┌─────────┬─────────────┐\n│ strings ┆ strings_hex │\n│ ---     ┆ ---         │\n│ str     ┆ str         │\n╞═════════╪═════════════╡\n│ foo     ┆ 666f6f      │\n│ bar     ┆ 626172      │\n│ null    ┆ null        │\n└─────────┴─────────────┘"], "Parameters": [["encoding {‘hex’, ‘base64’}", "The encoding to use."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 300}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.last.html#polars.Expr.arr.last"], "Title": ["Expr.arr.last"], "Feature": ["Expr.arr.last"], "Description": ["Get the last value of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[1, 2, 3], [4, 5, 6], [7, 9, 8]]},\n...     schema={\"a\": pl.Array(pl.Int32, 3)},\n... )\n>>> df.with_columns(last=pl.col(\"a\").arr.last())\nshape: (3, 2)\n┌───────────────┬──────┐\n│ a             ┆ last │\n│ ---           ┆ ---  │\n│ array[i32, 3] ┆ i32  │\n╞═══════════════╪══════╡\n│ [1, 2, 3]     ┆ 3    │\n│ [4, 5, 6]     ┆ 6    │\n│ [7, 9, 8]     ┆ 8    │\n└───────────────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 301}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.ends_with.html#polars.Expr.str.ends_with"], "Title": ["Expr.str.ends_with"], "Feature": ["Expr.str.ends_with"], "Description": ["Check if string values end with a substring."], "Examples": [">>> df = pl.DataFrame({\"fruits\": [\"apple\", \"mango\", None]})\n>>> df.with_columns(\n...     pl.col(\"fruits\").str.ends_with(\"go\").alias(\"has_suffix\"),\n... )\nshape: (3, 2)\n┌────────┬────────────┐\n│ fruits ┆ has_suffix │\n│ ---    ┆ ---        │\n│ str    ┆ bool       │\n╞════════╪════════════╡\n│ apple  ┆ false      │\n│ mango  ┆ true       │\n│ null   ┆ null       │\n└────────┴────────────┘", ">>> df = pl.DataFrame(\n...     {\"fruits\": [\"apple\", \"mango\", \"banana\"], \"suffix\": [\"le\", \"go\", \"nu\"]}\n... )\n>>> df.with_columns(\n...     pl.col(\"fruits\").str.ends_with(pl.col(\"suffix\")).alias(\"has_suffix\"),\n... )\nshape: (3, 3)\n┌────────┬────────┬────────────┐\n│ fruits ┆ suffix ┆ has_suffix │\n│ ---    ┆ ---    ┆ ---        │\n│ str    ┆ str    ┆ bool       │\n╞════════╪════════╪════════════╡\n│ apple  ┆ le     ┆ true       │\n│ mango  ┆ go     ┆ true       │\n│ banana ┆ nu     ┆ false      │\n└────────┴────────┴────────────┘", ">>> df.filter(pl.col(\"fruits\").str.ends_with(\"go\"))\nshape: (1, 2)\n┌────────┬────────┐\n│ fruits ┆ suffix │\n│ ---    ┆ ---    │\n│ str    ┆ str    │\n╞════════╪════════╡\n│ mango  ┆ go     │\n└────────┴────────┘"], "Parameters": [["suffix", "Suffix substring."]], "Returns": [], "Category": ["String"], "index": 302}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.escape_regex.html#polars.Expr.str.escape_regex"], "Title": ["Expr.str.escape_regex"], "Feature": ["Expr.str.escape_regex"], "Description": ["Returns string values with all regular expression meta characters escaped."], "Examples": [">>> df = pl.DataFrame({\"text\": [\"abc\", \"def\", None, \"abc(\\\\w+)\"]})\n>>> df.with_columns(pl.col(\"text\").str.escape_regex().alias(\"escaped\"))\n shape: (4, 2)\n┌──────────┬──────────────┐\n│ text     ┆ escaped      │\n│ ---      ┆ ---          │\n│ str      ┆ str          │\n╞══════════╪══════════════╡\n│ abc      ┆ abc          │\n│ def      ┆ def          │\n│ null     ┆ null         │\n│ abc(\\w+) ┆ abc\\(\\\\w\\+\\) │\n└──────────┴──────────────┘"], "Parameters": [], "Returns": [], "Category": ["String"], "index": 303}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.explode.html#polars.Expr.str.explode"], "Title": ["Expr.str.explode"], "Feature": ["Expr.str.explode"], "Description": ["Returns a column with a separate row for every string character."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"foo\", \"bar\"]})\n>>> df.select(pl.col(\"a\").str.explode())  \nshape: (6, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ str │\n╞═════╡\n│ f   │\n│ o   │\n│ o   │\n│ b   │\n│ a   │\n│ r   │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 304}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.extract.html#polars.Expr.str.extract"], "Title": ["Expr.str.extract"], "Feature": ["Expr.str.extract"], "Description": ["Extract the target capture group from provided patterns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"url\": [\n...             \"http://vote.com/ballon_dor?error=404&ref=unknown\",\n...             \"http://vote.com/ballon_dor?ref=polars&candidate=messi\",\n...             \"http://vote.com/ballon_dor?candidate=ronaldo&ref=polars\",\n...         ]\n...     }\n... )\n>>> df.select(\n...     pl.col(\"url\").str.extract(r\"candidate=(\\w+)\", 1).alias(\"candidate\"),\n...     pl.col(\"url\").str.extract(r\"ref=(\\w+)\", 1).alias(\"referer\"),\n...     pl.col(\"url\").str.extract(r\"error=(\\w+)\", 1).alias(\"error\"),\n... )\nshape: (3, 3)\n┌───────────┬─────────┬───────┐\n│ candidate ┆ referer ┆ error │\n│ ---       ┆ ---     ┆ ---   │\n│ str       ┆ str     ┆ str   │\n╞═══════════╪═════════╪═══════╡\n│ null      ┆ unknown ┆ 404   │\n│ messi     ┆ polars  ┆ null  │\n│ ronaldo   ┆ polars  ┆ null  │\n└───────────┴─────────┴───────┘"], "Parameters": [["pattern", "A valid regular expression pattern containing at least one capture group,\ncompatible with the regex crate ."], ["group_index", "Index of the targeted capture group.\nGroup 0 means the whole pattern, the first group begins at index 1.\nDefaults to the first capture group."]], "Returns": [["Expr", "Expression of data type String . Contains null values if original\nvalue is null or the regex captures nothing."]], "Category": ["String"], "index": 305}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.extract_all.html#polars.Expr.str.extract_all"], "Title": ["Expr.str.extract_all"], "Feature": ["Expr.str.extract_all"], "Description": ["Extract all matches for the given regex pattern."], "Examples": [">>> df = pl.DataFrame({\"foo\": [\"123 bla 45 asd\", \"xyz 678 910t\", \"bar\", None]})\n>>> df.select(\n...     pl.col(\"foo\").str.extract_all(r\"\\d+\").alias(\"extracted_nrs\"),\n... )\nshape: (4, 1)\n┌────────────────┐\n│ extracted_nrs  │\n│ ---            │\n│ list[str]      │\n╞════════════════╡\n│ [\"123\", \"45\"]  │\n│ [\"678\", \"910\"] │\n│ []             │\n│ null           │\n└────────────────┘"], "Parameters": [["pattern", "A valid regular expression pattern, compatible with the regex crate ."]], "Returns": [["Expr", "Expression of data type List(String) ."]], "Category": ["String"], "index": 306}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.extract_groups.html#polars.Expr.str.extract_groups"], "Title": ["Expr.str.extract_groups"], "Feature": ["Expr.str.extract_groups"], "Description": ["Extract all capture groups for the given regex pattern."], "Examples": [">>> df = pl.DataFrame(\n...     data={\n...         \"url\": [\n...             \"http://vote.com/ballon_dor?candidate=messi&ref=python\",\n...             \"http://vote.com/ballon_dor?candidate=weghorst&ref=polars\",\n...             \"http://vote.com/ballon_dor?error=404&ref=rust\",\n...         ]\n...     }\n... )\n>>> pattern = r\"candidate=(?<candidate>\\w+)&ref=(?<ref>\\w+)\"\n>>> df.select(captures=pl.col(\"url\").str.extract_groups(pattern)).unnest(\n...     \"captures\"\n... )\nshape: (3, 2)\n┌───────────┬────────┐\n│ candidate ┆ ref    │\n│ ---       ┆ ---    │\n│ str       ┆ str    │\n╞═══════════╪════════╡\n│ messi     ┆ python │\n│ weghorst  ┆ polars │\n│ null      ┆ null   │\n└───────────┴────────┘", ">>> pattern = r\"candidate=(\\w+)&ref=(\\w+)\"\n>>> (\n...     df.with_columns(\n...         captures=pl.col(\"url\").str.extract_groups(pattern)\n...     ).with_columns(name=pl.col(\"captures\").struct[\"1\"].str.to_uppercase())\n... )\nshape: (3, 3)\n┌─────────────────────────────────┬───────────────────────┬──────────┐\n│ url                             ┆ captures              ┆ name     │\n│ ---                             ┆ ---                   ┆ ---      │\n│ str                             ┆ struct[2]             ┆ str      │\n╞═════════════════════════════════╪═══════════════════════╪══════════╡\n│ http://vote.com/ballon_dor?can… ┆ {\"messi\",\"python\"}    ┆ MESSI    │\n│ http://vote.com/ballon_dor?can… ┆ {\"weghorst\",\"polars\"} ┆ WEGHORST │\n│ http://vote.com/ballon_dor?err… ┆ {null,null}           ┆ null     │\n└─────────────────────────────────┴───────────────────────┴──────────┘"], "Parameters": [["pattern", "A valid regular expression pattern containing at least one capture group,\ncompatible with the regex crate ."]], "Returns": [["Expr", "Expression of data type Struct with fields of data type String ."]], "Category": ["String"], "index": 307}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.extract_many.html#polars.Expr.str.extract_many"], "Title": ["Expr.str.extract_many"], "Feature": ["Expr.str.extract_many"], "Description": ["Use the Aho-Corasick algorithm to extract many matches."], "Examples": [">>> _ = pl.Config.set_fmt_str_lengths(100)\n>>> df = pl.DataFrame({\"values\": [\"discontent\"]})\n>>> patterns = [\"winter\", \"disco\", \"onte\", \"discontent\"]\n>>> df.with_columns(\n...     pl.col(\"values\")\n...     .str.extract_many(patterns, overlapping=False)\n...     .alias(\"matches\"),\n...     pl.col(\"values\")\n...     .str.extract_many(patterns, overlapping=True)\n...     .alias(\"matches_overlapping\"),\n... )\nshape: (1, 3)\n┌────────────┬───────────┬─────────────────────────────────┐\n│ values     ┆ matches   ┆ matches_overlapping             │\n│ ---        ┆ ---       ┆ ---                             │\n│ str        ┆ list[str] ┆ list[str]                       │\n╞════════════╪═══════════╪═════════════════════════════════╡\n│ discontent ┆ [\"disco\"] ┆ [\"disco\", \"onte\", \"discontent\"] │\n└────────────┴───────────┴─────────────────────────────────┘\n>>> df = pl.DataFrame(\n...     {\n...         \"values\": [\"discontent\", \"rhapsody\"],\n...         \"patterns\": [\n...             [\"winter\", \"disco\", \"onte\", \"discontent\"],\n...             [\"rhap\", \"ody\", \"coalesce\"],\n...         ],\n...     }\n... )\n>>> df.select(pl.col(\"values\").str.extract_many(\"patterns\"))\nshape: (2, 1)\n┌─────────────────┐\n│ values          │\n│ ---             │\n│ list[str]       │\n╞═════════════════╡\n│ [\"disco\"]       │\n│ [\"rhap\", \"ody\"] │\n└─────────────────┘"], "Parameters": [["patterns", "String patterns to search."], ["ascii_case_insensitive", "Enable ASCII-aware case-insensitive matching.\nWhen this option is enabled, searching will be performed without respect\nto case for ASCII letters (a-z and A-Z) only."], ["overlapping", "Whether matches may overlap."]], "Returns": [], "Category": ["String"], "index": 308}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.find.html#polars.Expr.str.find"], "Title": ["Expr.str.find"], "Feature": ["Expr.str.find"], "Description": ["Return the bytes offset of the first substring matching a pattern."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"txt\": [\"Crab\", \"Lobster\", None, \"Crustacean\"],\n...         \"pat\": [\"a[bc]\", \"b.t\", \"[aeiuo]\", \"(?i)A[BC]\"],\n...     }\n... )", ">>> df.select(\n...     pl.col(\"txt\"),\n...     pl.col(\"txt\").str.find(\"a|e\").alias(\"a|e (regex)\"),\n...     pl.col(\"txt\").str.find(\"e\", literal=True).alias(\"e (lit)\"),\n... )\nshape: (4, 3)\n┌────────────┬─────────────┬─────────┐\n│ txt        ┆ a|e (regex) ┆ e (lit) │\n│ ---        ┆ ---         ┆ ---     │\n│ str        ┆ u32         ┆ u32     │\n╞════════════╪═════════════╪═════════╡\n│ Crab       ┆ 2           ┆ null    │\n│ Lobster    ┆ 5           ┆ 5       │\n│ null       ┆ null        ┆ null    │\n│ Crustacean ┆ 5           ┆ 7       │\n└────────────┴─────────────┴─────────┘", ">>> df.with_columns(pl.col(\"txt\").str.find(pl.col(\"pat\")).alias(\"find_pat\"))\nshape: (4, 3)\n┌────────────┬───────────┬──────────┐\n│ txt        ┆ pat       ┆ find_pat │\n│ ---        ┆ ---       ┆ ---      │\n│ str        ┆ str       ┆ u32      │\n╞════════════╪═══════════╪══════════╡\n│ Crab       ┆ a[bc]     ┆ 2        │\n│ Lobster    ┆ b.t       ┆ 2        │\n│ null       ┆ [aeiuo]   ┆ null     │\n│ Crustacean ┆ (?i)A[BC] ┆ 5        │\n└────────────┴───────────┴──────────┘"], "Parameters": [["pattern", "A valid regular expression pattern, compatible with the regex crate ."], ["literal", "Treat pattern as a literal string, not as a regular expression."], ["strict", "Raise an error if the underlying pattern is not a valid regex,\notherwise mask out with a null value."]], "Returns": [], "Category": ["String"], "index": 309}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.find_many.html#polars.Expr.str.find_many"], "Title": ["Expr.str.find_many"], "Feature": ["Expr.str.find_many"], "Description": ["Use the Aho-Corasick algorithm to find many matches."], "Examples": [">>> _ = pl.Config.set_fmt_str_lengths(100)\n>>> df = pl.DataFrame({\"values\": [\"discontent\"]})\n>>> patterns = [\"winter\", \"disco\", \"onte\", \"discontent\"]\n>>> df.with_columns(\n...     pl.col(\"values\")\n...     .str.find_many(patterns, overlapping=False)\n...     .alias(\"matches\"),\n...     pl.col(\"values\")\n...     .str.find_many(patterns, overlapping=True)\n...     .alias(\"matches_overlapping\"),\n... )\nshape: (1, 3)\n┌────────────┬───────────┬─────────────────────┐\n│ values     ┆ matches   ┆ matches_overlapping │\n│ ---        ┆ ---       ┆ ---                 │\n│ str        ┆ list[u32] ┆ list[u32]           │\n╞════════════╪═══════════╪═════════════════════╡\n│ discontent ┆ [0]       ┆ [0, 4, 0]           │\n└────────────┴───────────┴─────────────────────┘\n>>> df = pl.DataFrame(\n...     {\n...         \"values\": [\"discontent\", \"rhapsody\"],\n...         \"patterns\": [\n...             [\"winter\", \"disco\", \"onte\", \"discontent\"],\n...             [\"rhap\", \"ody\", \"coalesce\"],\n...         ],\n...     }\n... )\n>>> df.select(pl.col(\"values\").str.find_many(\"patterns\"))\nshape: (2, 1)\n┌───────────┐\n│ values    │\n│ ---       │\n│ list[u32] │\n╞═══════════╡\n│ [0]       │\n│ [0, 5]    │\n└───────────┘"], "Parameters": [["patterns", "String patterns to search."], ["ascii_case_insensitive", "Enable ASCII-aware case-insensitive matching.\nWhen this option is enabled, searching will be performed without respect\nto case for ASCII letters (a-z and A-Z) only."], ["overlapping", "Whether matches may overlap."]], "Returns": [], "Category": ["String"], "index": 310}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.head.html#polars.Expr.str.head"], "Title": ["Expr.str.head"], "Feature": ["Expr.str.head"], "Description": ["Return the first n characters of each string in a String Series."], "Examples": [">>> df = pl.DataFrame({\"s\": [\"pear\", None, \"papaya\", \"dragonfruit\"]})\n>>> df.with_columns(pl.col(\"s\").str.head(5).alias(\"s_head_5\"))\nshape: (4, 2)\n┌─────────────┬──────────┐\n│ s           ┆ s_head_5 │\n│ ---         ┆ ---      │\n│ str         ┆ str      │\n╞═════════════╪══════════╡\n│ pear        ┆ pear     │\n│ null        ┆ null     │\n│ papaya      ┆ papay    │\n│ dragonfruit ┆ drago    │\n└─────────────┴──────────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"s\": [\"pear\", None, \"papaya\", \"dragonfruit\"],\n...         \"n\": [3, 4, -2, -5],\n...     }\n... )\n>>> df.with_columns(pl.col(\"s\").str.head(\"n\").alias(\"s_head_n\"))\nshape: (4, 3)\n┌─────────────┬─────┬──────────┐\n│ s           ┆ n   ┆ s_head_n │\n│ ---         ┆ --- ┆ ---      │\n│ str         ┆ i64 ┆ str      │\n╞═════════════╪═════╪══════════╡\n│ pear        ┆ 3   ┆ pea      │\n│ null        ┆ 4   ┆ null     │\n│ papaya      ┆ -2  ┆ papa     │\n│ dragonfruit ┆ -5  ┆ dragon   │\n└─────────────┴─────┴──────────┘"], "Parameters": [["n", "Length of the slice (integer or expression). Negative indexing is supported;\nsee note (2) below."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 311}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.max.html#polars.Expr.arr.max"], "Title": ["Expr.arr.max"], "Feature": ["Expr.arr.max"], "Description": ["Compute the max values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [4, 3]]},\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.max())\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 2   │\n│ 4   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 312}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.join.html#polars.Expr.str.join"], "Title": ["Expr.str.join"], "Feature": ["Expr.str.join"], "Description": ["Vertically concatenate the string values in the column to a single string value."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, None, 3]})\n>>> df.select(pl.col(\"foo\").str.join(\"-\"))\nshape: (1, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ str │\n╞═════╡\n│ 1-3 │\n└─────┘\n>>> df.select(pl.col(\"foo\").str.join(ignore_nulls=False))\nshape: (1, 1)\n┌──────┐\n│ foo  │\n│ ---  │\n│ str  │\n╞══════╡\n│ null │\n└──────┘"], "Parameters": [["delimiter", "The delimiter to insert between consecutive string values."], ["ignore_nulls", "Ignore null values (default).\nIf set to False , null values will be propagated. This means that\nif the column contains any null values, the output is null."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 313}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.json_decode.html#polars.Expr.str.json_decode"], "Title": ["Expr.str.json_decode"], "Feature": ["Expr.str.json_decode"], "Description": ["Parse string values as JSON."], "Examples": [">>> df = pl.DataFrame(\n...     {\"json\": ['{\"a\":1, \"b\": true}', None, '{\"a\":2, \"b\": false}']}\n... )\n>>> dtype = pl.Struct([pl.Field(\"a\", pl.Int64), pl.Field(\"b\", pl.Boolean)])\n>>> df.with_columns(decoded=pl.col(\"json\").str.json_decode(dtype))\nshape: (3, 2)\n┌─────────────────────┬───────────┐\n│ json                ┆ decoded   │\n│ ---                 ┆ ---       │\n│ str                 ┆ struct[2] │\n╞═════════════════════╪═══════════╡\n│ {\"a\":1, \"b\": true}  ┆ {1,true}  │\n│ null                ┆ null      │\n│ {\"a\":2, \"b\": false} ┆ {2,false} │\n└─────────────────────┴───────────┘"], "Parameters": [["dtype", "The dtype to cast the extracted value to."], ["infer_schema_length", "Deprecated and ignored."], [".. versionchanged: 1.33.0", "Deprecate infer_schema_length and make dtype non-optional to\nensure that the planner can determine the output datatype."]], "Returns": [], "Category": ["String"], "index": 314}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.json_path_match.html#polars.Expr.str.json_path_match"], "Title": ["Expr.str.json_path_match"], "Feature": ["Expr.str.json_path_match"], "Description": ["Extract the first match from a JSON string using the provided JSONPath."], "Examples": [">>> df = pl.DataFrame(\n...     {\"json_val\": ['{\"a\":\"1\"}', None, '{\"a\":2}', '{\"a\":2.1}', '{\"a\":true}']}\n... )\n>>> df.with_columns(matched=pl.col(\"json_val\").str.json_path_match(\"$.a\"))\nshape: (5, 2)\n┌────────────┬─────────┐\n│ json_val   ┆ matched │\n│ ---        ┆ ---     │\n│ str        ┆ str     │\n╞════════════╪═════════╡\n│ {\"a\":\"1\"}  ┆ 1       │\n│ null       ┆ null    │\n│ {\"a\":2}    ┆ 2       │\n│ {\"a\":2.1}  ┆ 2.1     │\n│ {\"a\":true} ┆ true    │\n└────────────┴─────────┘"], "Parameters": [["json_path", "A valid JSONPath query string."]], "Returns": [["Expr", "Expression of data type String . Contains null values if original\nvalue is null or the json_path returns nothing."]], "Category": ["String"], "index": 315}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.len_bytes.html#polars.Expr.str.len_bytes"], "Title": ["Expr.str.len_bytes"], "Feature": ["Expr.str.len_bytes"], "Description": ["Return the length of each string as the number of bytes."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"Café\", \"345\", \"東京\", None]})\n>>> df.with_columns(\n...     pl.col(\"a\").str.len_bytes().alias(\"n_bytes\"),\n...     pl.col(\"a\").str.len_chars().alias(\"n_chars\"),\n... )\nshape: (4, 3)\n┌──────┬─────────┬─────────┐\n│ a    ┆ n_bytes ┆ n_chars │\n│ ---  ┆ ---     ┆ ---     │\n│ str  ┆ u32     ┆ u32     │\n╞══════╪═════════╪═════════╡\n│ Café ┆ 5       ┆ 4       │\n│ 345  ┆ 3       ┆ 3       │\n│ 東京 ┆ 6       ┆ 2       │\n│ null ┆ null    ┆ null    │\n└──────┴─────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["String"], "index": 316}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.len_chars.html#polars.Expr.str.len_chars"], "Title": ["Expr.str.len_chars"], "Feature": ["Expr.str.len_chars"], "Description": ["Return the length of each string as the number of characters."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"Café\", \"345\", \"東京\", None]})\n>>> df.with_columns(\n...     pl.col(\"a\").str.len_chars().alias(\"n_chars\"),\n...     pl.col(\"a\").str.len_bytes().alias(\"n_bytes\"),\n... )\nshape: (4, 3)\n┌──────┬─────────┬─────────┐\n│ a    ┆ n_chars ┆ n_bytes │\n│ ---  ┆ ---     ┆ ---     │\n│ str  ┆ u32     ┆ u32     │\n╞══════╪═════════╪═════════╡\n│ Café ┆ 4       ┆ 5       │\n│ 345  ┆ 3       ┆ 3       │\n│ 東京 ┆ 2       ┆ 6       │\n│ null ┆ null    ┆ null    │\n└──────┴─────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["String"], "index": 317}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.normalize.html#polars.Expr.str.normalize"], "Title": ["Expr.str.normalize"], "Feature": ["Expr.str.normalize"], "Description": ["Returns the Unicode normal form of the string values."], "Examples": [">>> df = pl.DataFrame({\"text\": [\"01²\", \"ＫＡＤＯＫＡＷＡ\"]})\n>>> new = df.with_columns(\n...     nfc=pl.col(\"text\").str.normalize(\"NFC\"),\n...     nfkc=pl.col(\"text\").str.normalize(\"NFKC\"),\n... )\n>>> new\nshape: (2, 3)\n┌──────────────────┬──────────────────┬──────────┐\n│ text             ┆ nfc              ┆ nfkc     │\n│ ---              ┆ ---              ┆ ---      │\n│ str              ┆ str              ┆ str      │\n╞══════════════════╪══════════════════╪══════════╡\n│ 01²              ┆ 01²              ┆ 012      │\n│ ＫＡＤＯＫＡＷＡ    ┆ ＫＡＤＯＫＡＷＡ    ┆ KADOKAWA │\n└──────────────────┴──────────────────┴──────────┘\n>>> new.select(pl.all().str.len_bytes())\nshape: (2, 3)\n┌──────┬─────┬──────┐\n│ text ┆ nfc ┆ nfkc │\n│ ---  ┆ --- ┆ ---  │\n│ u32  ┆ u32 ┆ u32  │\n╞══════╪═════╪══════╡\n│ 4    ┆ 4   ┆ 3    │\n│ 24   ┆ 24  ┆ 8    │\n└──────┴─────┴──────┘"], "Parameters": [["form {‘NFC’, ‘NFKC’, ‘NFD’, ‘NFKD’}", "Unicode form to use."]], "Returns": [], "Category": ["String"], "index": 318}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.pad_end.html#polars.Expr.str.pad_end"], "Title": ["Expr.str.pad_end"], "Feature": ["Expr.str.pad_end"], "Description": ["Pad the end of the string until it reaches the given length."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"cow\", \"monkey\", \"hippopotamus\", None]})\n>>> df.with_columns(padded=pl.col(\"a\").str.pad_end(8, \"*\"))\nshape: (4, 2)\n┌──────────────┬──────────────┐\n│ a            ┆ padded       │\n│ ---          ┆ ---          │\n│ str          ┆ str          │\n╞══════════════╪══════════════╡\n│ cow          ┆ cow*****     │\n│ monkey       ┆ monkey**     │\n│ hippopotamus ┆ hippopotamus │\n│ null         ┆ null         │\n└──────────────┴──────────────┘"], "Parameters": [["length", "Pad the string until it reaches this length. Strings with length equal to or\ngreater than this value are returned as-is. Can be int or expression."], ["fill_char", "The character to pad the string with."]], "Returns": [], "Category": ["String"], "index": 319}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.pad_start.html#polars.Expr.str.pad_start"], "Title": ["Expr.str.pad_start"], "Feature": ["Expr.str.pad_start"], "Description": ["Pad the start of the string until it reaches the given length."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"cow\", \"monkey\", \"hippopotamus\", None]})\n>>> df.with_columns(padded=pl.col(\"a\").str.pad_start(8, \"*\"))\nshape: (4, 2)\n┌──────────────┬──────────────┐\n│ a            ┆ padded       │\n│ ---          ┆ ---          │\n│ str          ┆ str          │\n╞══════════════╪══════════════╡\n│ cow          ┆ *****cow     │\n│ monkey       ┆ **monkey     │\n│ hippopotamus ┆ hippopotamus │\n│ null         ┆ null         │\n└──────────────┴──────────────┘"], "Parameters": [["length", "Pad the string until it reaches this length. Strings with length equal to or\ngreater than this value are returned as-is."], ["fill_char", "The character to pad the string with."]], "Returns": [], "Category": ["String"], "index": 320}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.replace.html#polars.Expr.str.replace"], "Title": ["Expr.str.replace"], "Feature": ["Expr.str.replace"], "Description": ["Replace first matching regex/literal substring with a new string value."], "Examples": [">>> df = pl.DataFrame({\"id\": [1, 2], \"text\": [\"123abc\", \"abc456\"]})\n>>> df.with_columns(pl.col(\"text\").str.replace(r\"abc\\b\", \"ABC\"))\nshape: (2, 2)\n┌─────┬────────┐\n│ id  ┆ text   │\n│ --- ┆ ---    │\n│ i64 ┆ str    │\n╞═════╪════════╡\n│ 1   ┆ 123ABC │\n│ 2   ┆ abc456 │\n└─────┴────────┘", ">>> df = pl.DataFrame({\"word\": [\"hat\", \"hut\"]})\n>>> df.with_columns(\n...     positional=pl.col.word.str.replace(\"h(.)t\", \"b${1}d\"),\n...     named=pl.col.word.str.replace(\"h(?<vowel>.)t\", \"b${vowel}d\"),\n... )\nshape: (2, 3)\n┌──────┬────────────┬───────┐\n│ word ┆ positional ┆ named │\n│ ---  ┆ ---        ┆ ---   │\n│ str  ┆ str        ┆ str   │\n╞══════╪════════════╪═══════╡\n│ hat  ┆ bad        ┆ bad   │\n│ hut  ┆ bud        ┆ bud   │\n└──────┴────────────┴───────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"city\": \"Philadelphia\",\n...         \"season\": [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"],\n...         \"weather\": [\"Rainy\", \"Sunny\", \"Cloudy\", \"Snowy\"],\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"weather\").str.replace(r\"(?i)foggy|rainy|cloudy|snowy\", \"Sunny\")\n... )\nshape: (4, 3)\n┌──────────────┬────────┬─────────┐\n│ city         ┆ season ┆ weather │\n│ ---          ┆ ---    ┆ ---     │\n│ str          ┆ str    ┆ str     │\n╞══════════════╪════════╪═════════╡\n│ Philadelphia ┆ Spring ┆ Sunny   │\n│ Philadelphia ┆ Summer ┆ Sunny   │\n│ Philadelphia ┆ Autumn ┆ Sunny   │\n│ Philadelphia ┆ Winter ┆ Sunny   │\n└──────────────┴────────┴─────────┘"], "Parameters": [["pattern", "A valid regular expression pattern, compatible with the regex crate ."], ["value", "String that will replace the matched substring."], ["literal", "Treat pattern as a literal string."], ["n", "Number of matches to replace."]], "Returns": [], "Category": ["String"], "index": 321}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.replace_all.html#polars.Expr.str.replace_all"], "Title": ["Expr.str.replace_all"], "Feature": ["Expr.str.replace_all"], "Description": ["Replace all matching regex/literal substrings with a new string value."], "Examples": [">>> df = pl.DataFrame({\"id\": [1, 2], \"text\": [\"abcabc\", \"123a123\"]})\n>>> df.with_columns(pl.col(\"text\").str.replace_all(\"a\", \"-\"))\nshape: (2, 2)\n┌─────┬─────────┐\n│ id  ┆ text    │\n│ --- ┆ ---     │\n│ i64 ┆ str     │\n╞═════╪═════════╡\n│ 1   ┆ -bc-bc  │\n│ 2   ┆ 123-123 │\n└─────┴─────────┘", ">>> df = pl.DataFrame({\"word\": [\"hat\", \"hut\"]})\n>>> df.with_columns(\n...     positional=pl.col.word.str.replace_all(\"h(.)t\", \"b${1}d\"),\n...     named=pl.col.word.str.replace_all(\"h(?<vowel>.)t\", \"b${vowel}d\"),\n... )\nshape: (2, 3)\n┌──────┬────────────┬───────┐\n│ word ┆ positional ┆ named │\n│ ---  ┆ ---        ┆ ---   │\n│ str  ┆ str        ┆ str   │\n╞══════╪════════════╪═══════╡\n│ hat  ┆ bad        ┆ bad   │\n│ hut  ┆ bud        ┆ bud   │\n└──────┴────────────┴───────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"city\": \"Philadelphia\",\n...         \"season\": [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"],\n...         \"weather\": [\"Rainy\", \"Sunny\", \"Cloudy\", \"Snowy\"],\n...     }\n... )\n>>> df.with_columns(\n...     # apply case-insensitive string replacement\n...     pl.col(\"weather\").str.replace_all(\n...         r\"(?i)foggy|rainy|cloudy|snowy\", \"Sunny\"\n...     )\n... )\nshape: (4, 3)\n┌──────────────┬────────┬─────────┐\n│ city         ┆ season ┆ weather │\n│ ---          ┆ ---    ┆ ---     │\n│ str          ┆ str    ┆ str     │\n╞══════════════╪════════╪═════════╡\n│ Philadelphia ┆ Spring ┆ Sunny   │\n│ Philadelphia ┆ Summer ┆ Sunny   │\n│ Philadelphia ┆ Autumn ┆ Sunny   │\n│ Philadelphia ┆ Winter ┆ Sunny   │\n└──────────────┴────────┴─────────┘"], "Parameters": [["pattern", "A valid regular expression pattern, compatible with the regex crate ."], ["value", "String that will replace the matched substring."], ["literal", "Treat pattern as a literal string."]], "Returns": [], "Category": ["String"], "index": 322}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.mean.html#polars.Expr.arr.mean"], "Title": ["Expr.arr.mean"], "Feature": ["Expr.arr.mean"], "Description": ["Compute the mean of the values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2, 3], [1, 1, 16]]},\n...     schema={\"a\": pl.Array(pl.Int64, 3)},\n... )\n>>> df.select(pl.col(\"a\").arr.mean())\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 2.0 │\n│ 6.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 323}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.replace_many.html#polars.Expr.str.replace_many"], "Title": ["Expr.str.replace_many"], "Feature": ["Expr.str.replace_many"], "Description": ["Use the Aho-Corasick algorithm to replace many matches."], "Examples": [">>> _ = pl.Config.set_fmt_str_lengths(100)\n>>> _ = pl.Config.set_tbl_width_chars(110)\n>>> df = pl.DataFrame(\n...     {\n...         \"lyrics\": [\n...             \"Everybody wants to rule the world\",\n...             \"Tell me what you want, what you really really want\",\n...             \"Can you feel the love tonight\",\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"lyrics\")\n...     .str.replace_many(\n...         [\"me\", \"you\"],\n...         [\"you\", \"me\"],\n...     )\n...     .alias(\"confusing\")\n... )\nshape: (3, 2)\n┌────────────────────────────────────────────────────┬───────────────────────────────────────────────────┐\n│ lyrics                                             ┆ confusing                                         │\n│ ---                                                ┆ ---                                               │\n│ str                                                ┆ str                                               │\n╞════════════════════════════════════════════════════╪═══════════════════════════════════════════════════╡\n│ Everybody wants to rule the world                  ┆ Everybody wants to rule the world                 │\n│ Tell me what you want, what you really really want ┆ Tell you what me want, what me really really want │\n│ Can you feel the love tonight                      ┆ Can me feel the love tonight                      │\n└────────────────────────────────────────────────────┴───────────────────────────────────────────────────┘", ">>> _ = pl.Config.set_fmt_str_lengths(100)\n>>> df = pl.DataFrame(\n...     {\n...         \"lyrics\": [\n...             \"Everybody wants to rule the world\",\n...             \"Tell me what you want, what you really really want\",\n...             \"Can you feel the love tonight\",\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"lyrics\")\n...     .str.replace_many(\n...         [\"me\", \"you\", \"they\"],\n...         [\"\"],\n...     )\n...     .alias(\"removes_pronouns\")\n... )\nshape: (3, 2)\n┌────────────────────────────────────────────────────┬────────────────────────────────────────────┐\n│ lyrics                                             ┆ removes_pronouns                           │\n│ ---                                                ┆ ---                                        │\n│ str                                                ┆ str                                        │\n╞════════════════════════════════════════════════════╪════════════════════════════════════════════╡\n│ Everybody wants to rule the world                  ┆ Everybody wants to rule the world          │\n│ Tell me what you want, what you really really want ┆ Tell  what  want, what  really really want │\n│ Can you feel the love tonight                      ┆ Can  feel the love tonight                 │\n└────────────────────────────────────────────────────┴────────────────────────────────────────────┘", ">>> _ = pl.Config.set_fmt_str_lengths(100)\n>>> _ = pl.Config.set_tbl_width_chars(110)\n>>> df = pl.DataFrame(\n...     {\n...         \"lyrics\": [\n...             \"Everybody wants to rule the world\",\n...             \"Tell me what you want, what you really really want\",\n...             \"Can you feel the love tonight\",\n...         ]\n...     }\n... )\n>>> mapping = {\"me\": \"you\", \"you\": \"me\", \"want\": \"need\"}\n>>> df.with_columns(\n...     pl.col(\"lyrics\").str.replace_many(mapping).alias(\"confusing\")\n... )\nshape: (3, 2)\n┌────────────────────────────────────────────────────┬───────────────────────────────────────────────────┐\n│ lyrics                                             ┆ confusing                                         │\n│ ---                                                ┆ ---                                               │\n│ str                                                ┆ str                                               │\n╞════════════════════════════════════════════════════╪═══════════════════════════════════════════════════╡\n│ Everybody wants to rule the world                  ┆ Everybody needs to rule the world                 │\n│ Tell me what you want, what you really really want ┆ Tell you what me need, what me really really need │\n│ Can you feel the love tonight                      ┆ Can me feel the love tonight                      │\n└────────────────────────────────────────────────────┴───────────────────────────────────────────────────┘"], "Parameters": [["patterns", "String patterns to search and replace.\nAccepts expression input. Strings are parsed as column names, and other\nnon-expression inputs are parsed as literals. Also accepts a mapping of\npatterns to their replacement as syntactic sugar for replace_many(pl.Series(mapping.keys()), pl.Series(mapping.values())) ."], ["replace_with", "Strings to replace where a pattern was a match.\nAccepts expression input. Non-expression inputs are parsed as literals.\nLength must match the length of patterns or have length 1. This can be\nbroadcasted, so it supports many:one and many:many."], ["ascii_case_insensitive", "Enable ASCII-aware case-insensitive matching.\nWhen this option is enabled, searching will be performed without respect\nto case for ASCII letters (a-z and A-Z) only."]], "Returns": [], "Category": ["String"], "index": 324}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.reverse.html#polars.Expr.str.reverse"], "Title": ["Expr.str.reverse"], "Feature": ["Expr.str.reverse"], "Description": ["Returns string values in reversed order."], "Examples": [">>> df = pl.DataFrame({\"text\": [\"foo\", \"bar\", \"mañana\"]})\n>>> df.with_columns(pl.col(\"text\").str.reverse().alias(\"reversed\"))\nshape: (3, 2)\n┌────────┬──────────┐\n│ text   ┆ reversed │\n│ ---    ┆ ---      │\n│ str    ┆ str      │\n╞════════╪══════════╡\n│ foo    ┆ oof      │\n│ bar    ┆ rab      │\n│ mañana ┆ anañam   │\n└────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["String"], "index": 325}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.slice.html#polars.Expr.str.slice"], "Title": ["Expr.str.slice"], "Feature": ["Expr.str.slice"], "Description": ["Extract a substring from each string value."], "Examples": [">>> df = pl.DataFrame({\"s\": [\"pear\", None, \"papaya\", \"dragonfruit\"]})\n>>> df.with_columns(pl.col(\"s\").str.slice(-3).alias(\"slice\"))\nshape: (4, 2)\n┌─────────────┬───────┐\n│ s           ┆ slice │\n│ ---         ┆ ---   │\n│ str         ┆ str   │\n╞═════════════╪═══════╡\n│ pear        ┆ ear   │\n│ null        ┆ null  │\n│ papaya      ┆ aya   │\n│ dragonfruit ┆ uit   │\n└─────────────┴───────┘", ">>> df.with_columns(pl.col(\"s\").str.slice(4, length=3).alias(\"slice\"))\nshape: (4, 2)\n┌─────────────┬───────┐\n│ s           ┆ slice │\n│ ---         ┆ ---   │\n│ str         ┆ str   │\n╞═════════════╪═══════╡\n│ pear        ┆       │\n│ null        ┆ null  │\n│ papaya      ┆ ya    │\n│ dragonfruit ┆ onf   │\n└─────────────┴───────┘"], "Parameters": [["offset", "Start index. Negative indexing is supported."], ["length", "Length of the slice. If set to None (default), the slice is taken to the\nend of the string."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 326}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.split.html#polars.Expr.str.split"], "Title": ["Expr.str.split"], "Feature": ["Expr.str.split"], "Description": ["Split the string by a substring."], "Examples": [">>> df = pl.DataFrame({\"s\": [\"foo bar\", \"foo_bar\", \"foo_bar_baz\"]})\n>>> df.with_columns(\n...     pl.col(\"s\").str.split(by=\"_\").alias(\"split\"),\n...     pl.col(\"s\").str.split(by=\"_\", inclusive=True).alias(\"split_inclusive\"),\n... )\nshape: (3, 3)\n┌─────────────┬───────────────────────┬─────────────────────────┐\n│ s           ┆ split                 ┆ split_inclusive         │\n│ ---         ┆ ---                   ┆ ---                     │\n│ str         ┆ list[str]             ┆ list[str]               │\n╞═════════════╪═══════════════════════╪═════════════════════════╡\n│ foo bar     ┆ [\"foo bar\"]           ┆ [\"foo bar\"]             │\n│ foo_bar     ┆ [\"foo\", \"bar\"]        ┆ [\"foo_\", \"bar\"]         │\n│ foo_bar_baz ┆ [\"foo\", \"bar\", \"baz\"] ┆ [\"foo_\", \"bar_\", \"baz\"] │\n└─────────────┴───────────────────────┴─────────────────────────┘", ">>> df = pl.DataFrame(\n...     {\"s\": [\"foo^bar\", \"foo_bar\", \"foo*bar*baz\"], \"by\": [\"_\", \"_\", \"*\"]}\n... )\n>>> df.with_columns(\n...     pl.col(\"s\").str.split(by=pl.col(\"by\")).alias(\"split\"),\n...     pl.col(\"s\")\n...     .str.split(by=pl.col(\"by\"), inclusive=True)\n...     .alias(\"split_inclusive\"),\n... )\nshape: (3, 4)\n┌─────────────┬─────┬───────────────────────┬─────────────────────────┐\n│ s           ┆ by  ┆ split                 ┆ split_inclusive         │\n│ ---         ┆ --- ┆ ---                   ┆ ---                     │\n│ str         ┆ str ┆ list[str]             ┆ list[str]               │\n╞═════════════╪═════╪═══════════════════════╪═════════════════════════╡\n│ foo^bar     ┆ _   ┆ [\"foo^bar\"]           ┆ [\"foo^bar\"]             │\n│ foo_bar     ┆ _   ┆ [\"foo\", \"bar\"]        ┆ [\"foo_\", \"bar\"]         │\n│ foo*bar*baz ┆ *   ┆ [\"foo\", \"bar\", \"baz\"] ┆ [\"foo*\", \"bar*\", \"baz\"] │\n└─────────────┴─────┴───────────────────────┴─────────────────────────┘"], "Parameters": [["by", "Substring to split by."], ["inclusive", "If True, include the split character/string in the results."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 327}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.split_exact.html#polars.Expr.str.split_exact"], "Title": ["Expr.str.split_exact"], "Feature": ["Expr.str.split_exact"], "Description": ["Split the string by a substring usingnsplits."], "Examples": [">>> df = pl.DataFrame({\"x\": [\"a_1\", None, \"c\", \"d_4\"]})\n>>> df.with_columns(\n...     extracted=pl.col(\"x\").str.split_exact(\"_\", 1).alias(\"fields\"),\n... )\nshape: (4, 2)\n┌──────┬─────────────┐\n│ x    ┆ extracted   │\n│ ---  ┆ ---         │\n│ str  ┆ struct[2]   │\n╞══════╪═════════════╡\n│ a_1  ┆ {\"a\",\"1\"}   │\n│ null ┆ {null,null} │\n│ c    ┆ {\"c\",null}  │\n│ d_4  ┆ {\"d\",\"4\"}   │\n└──────┴─────────────┘", ">>> df.with_columns(\n...     pl.col(\"x\")\n...     .str.split_exact(\"_\", 1)\n...     .struct.rename_fields([\"first_part\", \"second_part\"])\n...     .alias(\"fields\")\n... ).unnest(\"fields\")\nshape: (4, 3)\n┌──────┬────────────┬─────────────┐\n│ x    ┆ first_part ┆ second_part │\n│ ---  ┆ ---        ┆ ---         │\n│ str  ┆ str        ┆ str         │\n╞══════╪════════════╪═════════════╡\n│ a_1  ┆ a          ┆ 1           │\n│ null ┆ null       ┆ null        │\n│ c    ┆ c          ┆ null        │\n│ d_4  ┆ d          ┆ 4           │\n└──────┴────────────┴─────────────┘"], "Parameters": [["by", "Substring to split by."], ["n", "Number of splits to make."], ["inclusive", "If True, include the split character/string in the results."]], "Returns": [["Expr", "Expression of data type Struct with fields of data type String ."]], "Category": ["String"], "index": 328}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.splitn.html#polars.Expr.str.splitn"], "Title": ["Expr.str.splitn"], "Feature": ["Expr.str.splitn"], "Description": ["Split the string by a substring, restricted to returning at mostnitems."], "Examples": [">>> df = pl.DataFrame({\"s\": [\"foo bar\", None, \"foo-bar\", \"foo bar baz\"]})\n>>> df.with_columns(pl.col(\"s\").str.splitn(\" \", 2).alias(\"fields\"))\nshape: (4, 2)\n┌─────────────┬───────────────────┐\n│ s           ┆ fields            │\n│ ---         ┆ ---               │\n│ str         ┆ struct[2]         │\n╞═════════════╪═══════════════════╡\n│ foo bar     ┆ {\"foo\",\"bar\"}     │\n│ null        ┆ {null,null}       │\n│ foo-bar     ┆ {\"foo-bar\",null}  │\n│ foo bar baz ┆ {\"foo\",\"bar baz\"} │\n└─────────────┴───────────────────┘", ">>> df.with_columns(\n...     pl.col(\"s\")\n...     .str.splitn(\" \", 2)\n...     .struct.rename_fields([\"first_part\", \"second_part\"])\n...     .alias(\"fields\")\n... ).unnest(\"fields\")\nshape: (4, 3)\n┌─────────────┬────────────┬─────────────┐\n│ s           ┆ first_part ┆ second_part │\n│ ---         ┆ ---        ┆ ---         │\n│ str         ┆ str        ┆ str         │\n╞═════════════╪════════════╪═════════════╡\n│ foo bar     ┆ foo        ┆ bar         │\n│ null        ┆ null       ┆ null        │\n│ foo-bar     ┆ foo-bar    ┆ null        │\n│ foo bar baz ┆ foo        ┆ bar baz     │\n└─────────────┴────────────┴─────────────┘"], "Parameters": [["by", "Substring to split by."], ["n", "Max number of items to return."]], "Returns": [["Expr", "Expression of data type Struct with fields of data type String ."]], "Category": ["String"], "index": 329}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.starts_with.html#polars.Expr.str.starts_with"], "Title": ["Expr.str.starts_with"], "Feature": ["Expr.str.starts_with"], "Description": ["Check if string values start with a substring."], "Examples": [">>> df = pl.DataFrame({\"fruits\": [\"apple\", \"mango\", None]})\n>>> df.with_columns(\n...     pl.col(\"fruits\").str.starts_with(\"app\").alias(\"has_prefix\"),\n... )\nshape: (3, 2)\n┌────────┬────────────┐\n│ fruits ┆ has_prefix │\n│ ---    ┆ ---        │\n│ str    ┆ bool       │\n╞════════╪════════════╡\n│ apple  ┆ true       │\n│ mango  ┆ false      │\n│ null   ┆ null       │\n└────────┴────────────┘", ">>> df = pl.DataFrame(\n...     {\"fruits\": [\"apple\", \"mango\", \"banana\"], \"prefix\": [\"app\", \"na\", \"ba\"]}\n... )\n>>> df.with_columns(\n...     pl.col(\"fruits\").str.starts_with(pl.col(\"prefix\")).alias(\"has_prefix\"),\n... )\nshape: (3, 3)\n┌────────┬────────┬────────────┐\n│ fruits ┆ prefix ┆ has_prefix │\n│ ---    ┆ ---    ┆ ---        │\n│ str    ┆ str    ┆ bool       │\n╞════════╪════════╪════════════╡\n│ apple  ┆ app    ┆ true       │\n│ mango  ┆ na     ┆ false      │\n│ banana ┆ ba     ┆ true       │\n└────────┴────────┴────────────┘", ">>> df.filter(pl.col(\"fruits\").str.starts_with(\"app\"))\nshape: (1, 2)\n┌────────┬────────┐\n│ fruits ┆ prefix │\n│ ---    ┆ ---    │\n│ str    ┆ str    │\n╞════════╪════════╡\n│ apple  ┆ app    │\n└────────┴────────┘"], "Parameters": [["prefix", "Prefix substring."]], "Returns": [], "Category": ["String"], "index": 330}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.strip_chars.html#polars.Expr.str.strip_chars"], "Title": ["Expr.str.strip_chars"], "Feature": ["Expr.str.strip_chars"], "Description": ["Remove leading and trailing characters."], "Examples": [">>> df = pl.DataFrame({\"foo\": [\" hello\", \"\\nworld\"]})\n>>> df\nshape: (2, 1)\n┌────────┐\n│ foo    │\n│ ---    │\n│ str    │\n╞════════╡\n│  hello │\n│        │\n│ world  │\n└────────┘", ">>> df.with_columns(foo_stripped=pl.col(\"foo\").str.strip_chars())\nshape: (2, 2)\n┌────────┬──────────────┐\n│ foo    ┆ foo_stripped │\n│ ---    ┆ ---          │\n│ str    ┆ str          │\n╞════════╪══════════════╡\n│  hello ┆ hello        │\n│        ┆ world        │\n│ world  ┆              │\n└────────┴──────────────┘", ">>> df.with_columns(foo_stripped=pl.col(\"foo\").str.strip_chars(\"ow\\n\"))\nshape: (2, 2)\n┌────────┬──────────────┐\n│ foo    ┆ foo_stripped │\n│ ---    ┆ ---          │\n│ str    ┆ str          │\n╞════════╪══════════════╡\n│  hello ┆  hell        │\n│        ┆ rld          │\n│ world  ┆              │\n└────────┴──────────────┘"], "Parameters": [["characters", "The set of characters to be removed. All combinations of this set of\ncharacters will be stripped from the start and end of the string. If set to\nNone (default), all leading and trailing whitespace is removed instead."]], "Returns": [], "Category": ["String"], "index": 331}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.strip_chars_start.html#polars.Expr.str.strip_chars_start"], "Title": ["Expr.str.strip_chars_start"], "Feature": ["Expr.str.strip_chars_start"], "Description": ["Remove leading characters."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["String"], "index": 332}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.strip_chars_end.html#polars.Expr.str.strip_chars_end"], "Title": ["Expr.str.strip_chars_end"], "Feature": ["Expr.str.strip_chars_end"], "Description": ["Remove trailing characters."], "Examples": [">>> df = pl.DataFrame({\"foo\": [\" hello\", \"world\\n\"]})\n>>> df\nshape: (2, 1)\n┌────────┐\n│ foo    │\n│ ---    │\n│ str    │\n╞════════╡\n│  hello │\n│ world  │\n│        │\n└────────┘\n>>> df.with_columns(foo_strip_end=pl.col(\"foo\").str.strip_chars_end())\nshape: (2, 2)\n┌────────┬───────────────┐\n│ foo    ┆ foo_strip_end │\n│ ---    ┆ ---           │\n│ str    ┆ str           │\n╞════════╪═══════════════╡\n│  hello ┆  hello        │\n│ world  ┆ world         │\n│        ┆               │\n└────────┴───────────────┘", ">>> df.with_columns(foo_strip_end=pl.col(\"foo\").str.strip_chars_end(\"oldw \"))\nshape: (2, 2)\n┌────────┬───────────────┐\n│ foo    ┆ foo_strip_end │\n│ ---    ┆ ---           │\n│ str    ┆ str           │\n╞════════╪═══════════════╡\n│  hello ┆  he           │\n│ world  ┆ world         │\n│        ┆               │\n└────────┴───────────────┘", ">>> pl.DataFrame({\"foo\": [\"abcdeff\"]}).with_columns(\n...     foo_strip_end=pl.col(\"foo\").str.strip_chars_end(\"fed\")\n... )\nshape: (1, 2)\n┌─────────┬───────────────┐\n│ foo     ┆ foo_strip_end │\n│ ---     ┆ ---           │\n│ str     ┆ str           │\n╞═════════╪═══════════════╡\n│ abcdeff ┆ abc           │\n└─────────┴───────────────┘"], "Parameters": [["characters", "The set of characters to be removed. All combinations of this set of\ncharacters will be stripped from the end of the string. If set to None\n(default), all trailing whitespace is removed instead."]], "Returns": [], "Category": ["String"], "index": 333}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arg_max.html#polars.Expr.arg_max"], "Title": ["Expr.arg_max"], "Feature": ["Expr.arg_max"], "Description": ["Get the index of the maximal value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [20, 10, 30],\n...     }\n... )\n>>> df.select(pl.col(\"a\").arg_max())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 334}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.median.html#polars.Expr.arr.median"], "Title": ["Expr.arr.median"], "Feature": ["Expr.arr.median"], "Description": ["Compute the median of the values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [4, 3]]},\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.median())\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.5 │\n│ 3.5 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 335}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.strip_prefix.html#polars.Expr.str.strip_prefix"], "Title": ["Expr.str.strip_prefix"], "Feature": ["Expr.str.strip_prefix"], "Description": ["Remove prefix."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"foobar\", \"foofoobar\", \"foo\", \"bar\"]})\n>>> df.with_columns(pl.col(\"a\").str.strip_prefix(\"foo\").alias(\"stripped\"))\nshape: (4, 2)\n┌───────────┬──────────┐\n│ a         ┆ stripped │\n│ ---       ┆ ---      │\n│ str       ┆ str      │\n╞═══════════╪══════════╡\n│ foobar    ┆ bar      │\n│ foofoobar ┆ foobar   │\n│ foo       ┆          │\n│ bar       ┆ bar      │\n└───────────┴──────────┘"], "Parameters": [["prefix", "The prefix to be removed."]], "Returns": [], "Category": ["String"], "index": 336}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.strip_suffix.html#polars.Expr.str.strip_suffix"], "Title": ["Expr.str.strip_suffix"], "Feature": ["Expr.str.strip_suffix"], "Description": ["Remove suffix."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"foobar\", \"foobarbar\", \"foo\", \"bar\"]})\n>>> df.with_columns(pl.col(\"a\").str.strip_suffix(\"bar\").alias(\"stripped\"))\nshape: (4, 2)\n┌───────────┬──────────┐\n│ a         ┆ stripped │\n│ ---       ┆ ---      │\n│ str       ┆ str      │\n╞═══════════╪══════════╡\n│ foobar    ┆ foo      │\n│ foobarbar ┆ foobar   │\n│ foo       ┆ foo      │\n│ bar       ┆          │\n└───────────┴──────────┘"], "Parameters": [["suffix", "The suffix to be removed."]], "Returns": [], "Category": ["String"], "index": 337}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.strptime.html#polars.Expr.str.strptime"], "Title": ["Expr.str.strptime"], "Feature": ["Expr.str.strptime"], "Description": ["Convert a String column into a Date/Datetime/Time column."], "Examples": [">>> s = pl.Series([\"2020-01-01 01:00Z\", \"2020-01-01 02:00Z\"])\n>>> s.str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M%#z\")\nshape: (2,)\nSeries: '' [datetime[μs, UTC]]\n[\n        2020-01-01 01:00:00 UTC\n        2020-01-01 02:00:00 UTC\n]", ">>> s = pl.Series(\n...     \"date\",\n...     [\n...         \"2021-04-22\",\n...         \"2022-01-04 00:00:00\",\n...         \"01/31/22\",\n...         \"Sun Jul  8 00:34:60 2001\",\n...     ],\n... )\n>>> s.to_frame().select(\n...     pl.coalesce(\n...         pl.col(\"date\").str.strptime(pl.Date, \"%F\", strict=False),\n...         pl.col(\"date\").str.strptime(pl.Date, \"%F %T\", strict=False),\n...         pl.col(\"date\").str.strptime(pl.Date, \"%D\", strict=False),\n...         pl.col(\"date\").str.strptime(pl.Date, \"%c\", strict=False),\n...     )\n... ).to_series()\nshape: (4,)\nSeries: 'date' [date]\n[\n        2021-04-22\n        2022-01-04\n        2022-01-31\n        2001-07-08\n]"], "Parameters": [["dtype", "The data type to convert into. Can be either Date, Datetime, or Time."], ["format", "Format to use for conversion. Refer to the chrono crate documentation for the full specification. Example: \"%Y-%m-%d %H:%M:%S\" .\nIf set to None (default), the format is inferred from the data."], ["strict", "Raise an error if any conversion fails."], ["exact", "Require an exact format match. If False, allow the format to match anywhere\nin the target string. Conversion to the Time type is always exact. Note Using exact=False introduces a performance penalty - cleaning your\ndata beforehand will almost certainly be more performant."], ["cache", "Use a cache of unique, converted dates to apply the datetime conversion."], ["ambiguous", "Determine how to deal with ambiguous datetimes: 'raise' (default): raise 'earliest' : use the earliest datetime 'latest' : use the latest datetime 'null' : set to null"]], "Returns": [], "Category": ["String"], "index": 338}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.tail.html#polars.Expr.str.tail"], "Title": ["Expr.str.tail"], "Feature": ["Expr.str.tail"], "Description": ["Return the last n characters of each string in a String Series."], "Examples": [">>> df = pl.DataFrame({\"s\": [\"pear\", None, \"papaya\", \"dragonfruit\"]})\n>>> df.with_columns(pl.col(\"s\").str.tail(5).alias(\"s_tail_5\"))\nshape: (4, 2)\n┌─────────────┬──────────┐\n│ s           ┆ s_tail_5 │\n│ ---         ┆ ---      │\n│ str         ┆ str      │\n╞═════════════╪══════════╡\n│ pear        ┆ pear     │\n│ null        ┆ null     │\n│ papaya      ┆ apaya    │\n│ dragonfruit ┆ fruit    │\n└─────────────┴──────────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"s\": [\"pear\", None, \"papaya\", \"dragonfruit\"],\n...         \"n\": [3, 4, -2, -5],\n...     }\n... )\n>>> df.with_columns(pl.col(\"s\").str.tail(\"n\").alias(\"s_tail_n\"))\nshape: (4, 3)\n┌─────────────┬─────┬──────────┐\n│ s           ┆ n   ┆ s_tail_n │\n│ ---         ┆ --- ┆ ---      │\n│ str         ┆ i64 ┆ str      │\n╞═════════════╪═════╪══════════╡\n│ pear        ┆ 3   ┆ ear      │\n│ null        ┆ 4   ┆ null     │\n│ papaya      ┆ -2  ┆ paya     │\n│ dragonfruit ┆ -5  ┆ nfruit   │\n└─────────────┴─────┴──────────┘"], "Parameters": [["n", "Length of the slice (integer or expression). Negative indexing is supported;\nsee note (2) below."]], "Returns": [["Expr", "Expression of data type String ."]], "Category": ["String"], "index": 339}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_date.html#polars.Expr.str.to_date"], "Title": ["Expr.str.to_date"], "Feature": ["Expr.str.to_date"], "Description": ["Convert a String column into a Date column."], "Examples": [">>> s = pl.Series([\"2020/01/01\", \"2020/02/01\", \"2020/03/01\"])\n>>> s.str.to_date()\nshape: (3,)\nSeries: '' [date]\n[\n        2020-01-01\n        2020-02-01\n        2020-03-01\n]"], "Parameters": [["format", "Format to use for conversion. Refer to the chrono crate documentation for the full specification. Example: \"%Y-%m-%d\" .\nIf set to None (default), the format is inferred from the data."], ["strict", "Raise an error if any conversion fails."], ["exact", "Require an exact format match. If False, allow the format to match anywhere\nin the target string. Note Using exact=False introduces a performance penalty - cleaning your\ndata beforehand will almost certainly be more performant."], ["cache", "Use a cache of unique, converted dates to apply the conversion."]], "Returns": [], "Category": ["String"], "index": 340}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_datetime.html#polars.Expr.str.to_datetime"], "Title": ["Expr.str.to_datetime"], "Feature": ["Expr.str.to_datetime"], "Description": ["Convert a String column into a Datetime column."], "Examples": [">>> s = pl.Series([\"2020-01-01 01:00Z\", \"2020-01-01 02:00Z\"])\n>>> s.str.to_datetime(\"%Y-%m-%d %H:%M%#z\")\nshape: (2,)\nSeries: '' [datetime[μs, UTC]]\n[\n        2020-01-01 01:00:00 UTC\n        2020-01-01 02:00:00 UTC\n]"], "Parameters": [["format", "Format to use for conversion. Refer to the chrono crate documentation for the full specification. Example: \"%Y-%m-%d %H:%M:%S\" .\nIf set to None (default), the format is inferred from the data."], ["time_unit {None, ‘us’, ‘ns’, ‘ms’}", "Unit of time for the resulting Datetime column. If set to None (default),\nthe time unit is inferred from the format string if given, eg: \"%F %T%.3f\" => Datetime(\"ms\") . If no fractional second component is\nfound, the default is \"us\" ."], ["time_zone", "Time zone for the resulting Datetime column. Rules are: If inputs are tz-naive and time_zone is None, the result time zone is None . If inputs are offset-aware and time_zone is None, inputs are converted\nto 'UTC' and the result time zone is 'UTC' . If inputs are offset-aware and time_zone is given, inputs are converted\nto time_zone and the result time zone is time_zone . If inputs are tz-naive and time_zone is given, input time zones are\nreplaced with (not converted to!) time_zone , and the result time zone\nis time_zone ."], ["strict", "Raise an error if any conversion fails."], ["exact", "Require an exact format match. If False, allow the format to match anywhere\nin the target string. Note Using exact=False introduces a performance penalty - cleaning your\ndata beforehand will almost certainly be more performant."], ["cache", "Use a cache of unique, converted datetimes to apply the conversion."], ["ambiguous", "Determine how to deal with ambiguous datetimes: 'raise' (default): raise 'earliest' : use the earliest datetime 'latest' : use the latest datetime 'null' : set to null"]], "Returns": [], "Category": ["String"], "index": 341}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_decimal.html#polars.Expr.str.to_decimal"], "Title": ["Expr.str.to_decimal"], "Feature": ["Expr.str.to_decimal"], "Description": ["Convert a String column into a Decimal column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"numbers\": [\n...             \"40.12\",\n...             \"3420.13\",\n...             \"120134.19\",\n...             \"3212.98\",\n...             \"12.90\",\n...             \"143.09\",\n...             \"143.9\",\n...         ]\n...     }\n... )\n>>> df.with_columns(numbers_decimal=pl.col(\"numbers\").str.to_decimal(scale=2))\nshape: (7, 2)\n┌───────────┬─────────────────┐\n│ numbers   ┆ numbers_decimal │\n│ ---       ┆ ---             │\n│ str       ┆ decimal[*,2]    │\n╞═══════════╪═════════════════╡\n│ 40.12     ┆ 40.12           │\n│ 3420.13   ┆ 3420.13         │\n│ 120134.19 ┆ 120134.19       │\n│ 3212.98   ┆ 3212.98         │\n│ 12.90     ┆ 12.90           │\n│ 143.09    ┆ 143.09          │\n│ 143.9     ┆ 143.90          │\n└───────────┴─────────────────┘"], "Parameters": [["scale", "Number of digits after the comma to use for the decimals."]], "Returns": [], "Category": ["String"], "index": 342}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_integer.html#polars.Expr.str.to_integer"], "Title": ["Expr.str.to_integer"], "Feature": ["Expr.str.to_integer"], "Description": ["Convert a String column into an Int64 column with base radix."], "Examples": [">>> df = pl.DataFrame({\"bin\": [\"110\", \"101\", \"010\", \"invalid\"]})\n>>> df.with_columns(\n...     parsed=pl.col(\"bin\").str.to_integer(\n...         base=2, dtype=pl.Int32, strict=False\n...     )\n... )\nshape: (4, 2)\n┌─────────┬────────┐\n│ bin     ┆ parsed │\n│ ---     ┆ ---    │\n│ str     ┆ i32    │\n╞═════════╪════════╡\n│ 110     ┆ 6      │\n│ 101     ┆ 5      │\n│ 010     ┆ 2      │\n│ invalid ┆ null   │\n└─────────┴────────┘", ">>> df = pl.DataFrame({\"hex\": [\"fa1e\", \"ff00\", \"cafe\", None]})\n>>> df.with_columns(parsed=pl.col(\"hex\").str.to_integer(base=16, strict=True))\nshape: (4, 2)\n┌──────┬────────┐\n│ hex  ┆ parsed │\n│ ---  ┆ ---    │\n│ str  ┆ i64    │\n╞══════╪════════╡\n│ fa1e ┆ 64030  │\n│ ff00 ┆ 65280  │\n│ cafe ┆ 51966  │\n│ null ┆ null   │\n└──────┴────────┘"], "Parameters": [["base", "Positive integer or expression which is the base of the string\nwe are parsing.\nDefault: 10."], ["strict", "Bool, Default=True will raise any ParseError or overflow as ComputeError.\nFalse silently convert to Null."]], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["String"], "index": 343}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_lowercase.html#polars.Expr.str.to_lowercase"], "Title": ["Expr.str.to_lowercase"], "Feature": ["Expr.str.to_lowercase"], "Description": ["Modify strings to their lowercase equivalent."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["String"], "index": 344}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_time.html#polars.Expr.str.to_time"], "Title": ["Expr.str.to_time"], "Feature": ["Expr.str.to_time"], "Description": ["Convert a String column into a Time column."], "Examples": [">>> s = pl.Series([\"01:00\", \"02:00\", \"03:00\"])\n>>> s.str.to_time(\"%H:%M\")\nshape: (3,)\nSeries: '' [time]\n[\n        01:00:00\n        02:00:00\n        03:00:00\n]"], "Parameters": [["format", "Format to use for conversion. Refer to the chrono crate documentation for the full specification. Example: \"%H:%M:%S\" .\nIf set to None (default), the format is inferred from the data."], ["strict", "Raise an error if any conversion fails."], ["cache", "Use a cache of unique, converted times to apply the conversion."]], "Returns": [], "Category": ["String"], "index": 345}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.min.html#polars.Expr.arr.min"], "Title": ["Expr.arr.min"], "Feature": ["Expr.arr.min"], "Description": ["Compute the min values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [4, 3]]},\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.min())\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 3   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 346}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_titlecase.html#polars.Expr.str.to_titlecase"], "Title": ["Expr.str.to_titlecase"], "Feature": ["Expr.str.to_titlecase"], "Description": ["Modify strings to their titlecase equivalent."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"quotes\": [\n...             \"'e.t. phone home'\",\n...             \"you talkin' to me?\",\n...             \"to infinity,and BEYOND!\",\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     quotes_title=pl.col(\"quotes\").str.to_titlecase(),\n... )\nshape: (3, 2)\n┌─────────────────────────┬─────────────────────────┐\n│ quotes                  ┆ quotes_title            │\n│ ---                     ┆ ---                     │\n│ str                     ┆ str                     │\n╞═════════════════════════╪═════════════════════════╡\n│ 'e.t. phone home'       ┆ 'E.T. Phone Home'       │\n│ you talkin' to me?      ┆ You Talkin' To Me?      │\n│ to infinity,and BEYOND! ┆ To Infinity,And Beyond! │\n└─────────────────────────┴─────────────────────────┘"], "Parameters": [], "Returns": [], "Category": ["String"], "index": 347}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.to_uppercase.html#polars.Expr.str.to_uppercase"], "Title": ["Expr.str.to_uppercase"], "Feature": ["Expr.str.to_uppercase"], "Description": ["Modify strings to their uppercase equivalent."], "Examples": [">>> df = pl.DataFrame({\"foo\": [\"cat\", \"dog\"]})\n>>> df.with_columns(foo_upper=pl.col(\"foo\").str.to_uppercase())\nshape: (2, 2)\n┌─────┬───────────┐\n│ foo ┆ foo_upper │\n│ --- ┆ ---       │\n│ str ┆ str       │\n╞═════╪═══════════╡\n│ cat ┆ CAT       │\n│ dog ┆ DOG       │\n└─────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["String"], "index": 348}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.str.zfill.html#polars.Expr.str.zfill"], "Title": ["Expr.str.zfill"], "Feature": ["Expr.str.zfill"], "Description": ["Pad the start of the string with zeros until it reaches the given length."], "Examples": [">>> df = pl.DataFrame({\"a\": [-1, 123, 999999, None]})\n>>> df.with_columns(zfill=pl.col(\"a\").cast(pl.String).str.zfill(4))\nshape: (4, 2)\n┌────────┬────────┐\n│ a      ┆ zfill  │\n│ ---    ┆ ---    │\n│ i64    ┆ str    │\n╞════════╪════════╡\n│ -1     ┆ -001   │\n│ 123    ┆ 0123   │\n│ 999999 ┆ 999999 │\n│ null   ┆ null   │\n└────────┴────────┘\n>>> df = pl.DataFrame(\n...     {\n...         \"a\": [-1, 123, 999999, None],\n...         \"length\": [8, 4, 1, 2],\n...     }\n... )\n>>> df.with_columns(zfill=pl.col(\"a\").cast(pl.String).str.zfill(\"length\"))\nshape: (4, 3)\n┌────────┬────────┬──────────┐\n│ a      ┆ length ┆ zfill    │\n│ ---    ┆ ---    ┆ ---      │\n│ i64    ┆ i64    ┆ str      │\n╞════════╪════════╪══════════╡\n│ -1     ┆ 8      ┆ -0000001 │\n│ 123    ┆ 4      ┆ 0123     │\n│ 999999 ┆ 1      ┆ 999999   │\n│ null   ┆ 2      ┆ null     │\n└────────┴────────┴──────────┘"], "Parameters": [["length", "Pad the string until it reaches this length. Strings with length equal to\nor greater than this value are returned as-is."]], "Returns": [], "Category": ["String"], "index": 349}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.add_business_days.html#polars.Expr.dt.add_business_days"], "Title": ["Expr.dt.add_business_days"], "Feature": ["Expr.dt.add_business_days"], "Description": ["Offset bynbusiness days."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame({\"start\": [date(2020, 1, 1), date(2020, 1, 2)]})\n>>> df.with_columns(result=pl.col(\"start\").dt.add_business_days(5))\nshape: (2, 2)\n┌────────────┬────────────┐\n│ start      ┆ result     │\n│ ---        ┆ ---        │\n│ date       ┆ date       │\n╞════════════╪════════════╡\n│ 2020-01-01 ┆ 2020-01-08 │\n│ 2020-01-02 ┆ 2020-01-09 │\n└────────────┴────────────┘", ">>> week_mask = (True, True, True, True, True, True, False)\n>>> df.with_columns(\n...     result=pl.col(\"start\").dt.add_business_days(5, week_mask=week_mask)\n... )\nshape: (2, 2)\n┌────────────┬────────────┐\n│ start      ┆ result     │\n│ ---        ┆ ---        │\n│ date       ┆ date       │\n╞════════════╪════════════╡\n│ 2020-01-01 ┆ 2020-01-07 │\n│ 2020-01-02 ┆ 2020-01-08 │\n└────────────┴────────────┘", ">>> from datetime import date\n>>> holidays = [date(2020, 1, 3), date(2020, 1, 6)]\n>>> df.with_columns(\n...     result=pl.col(\"start\").dt.add_business_days(5, holidays=holidays)\n... )\nshape: (2, 2)\n┌────────────┬────────────┐\n│ start      ┆ result     │\n│ ---        ┆ ---        │\n│ date       ┆ date       │\n╞════════════╪════════════╡\n│ 2020-01-01 ┆ 2020-01-10 │\n│ 2020-01-02 ┆ 2020-01-13 │\n└────────────┴────────────┘", ">>> df = pl.DataFrame({\"start\": [date(2020, 1, 5), date(2020, 1, 6)]})\n>>> df.with_columns(\n...     rolled_forwards=pl.col(\"start\").dt.add_business_days(0, roll=\"forward\")\n... )\nshape: (2, 2)\n┌────────────┬─────────────────┐\n│ start      ┆ rolled_forwards │\n│ ---        ┆ ---             │\n│ date       ┆ date            │\n╞════════════╪═════════════════╡\n│ 2020-01-05 ┆ 2020-01-06      │\n│ 2020-01-06 ┆ 2020-01-06      │\n└────────────┴─────────────────┘"], "Parameters": [["n", "Number of business days to offset by. Can be a single number of an\nexpression."], ["week_mask", "Which days of the week to count. The default is Monday to Friday.\nIf you wanted to count only Monday to Thursday, you would pass (True, True, True, True, False, False, False) ."], ["holidays", "Holidays to exclude from the count. The Python package python-holidays may come in handy here. You can install it with pip install holidays ,\nand then, to get all Dutch holidays for years 2020-2024: import holidays my_holidays = holidays . country_holidays ( \"NL\" , years = range ( 2020 , 2025 )) Copy to clipboard and pass holidays=my_holidays when you call add_business_days ."], ["roll", "What to do when the start date lands on a non-business day. Options are: 'raise' : raise an error 'forward' : move to the next business day 'backward' : move to the previous business day"]], "Returns": [["Expr", "Data type is preserved."]], "Category": ["Temporal"], "index": 350}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.base_utc_offset.html#polars.Expr.dt.base_utc_offset"], "Title": ["Expr.dt.base_utc_offset"], "Feature": ["Expr.dt.base_utc_offset"], "Description": ["Base offset from UTC."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"ts\": [datetime(2011, 12, 29), datetime(2012, 1, 1)],\n...     }\n... )\n>>> df = df.with_columns(pl.col(\"ts\").dt.replace_time_zone(\"Pacific/Apia\"))\n>>> df.with_columns(pl.col(\"ts\").dt.base_utc_offset().alias(\"base_utc_offset\"))\nshape: (2, 2)\n┌────────────────────────────┬─────────────────┐\n│ ts                         ┆ base_utc_offset │\n│ ---                        ┆ ---             │\n│ datetime[μs, Pacific/Apia] ┆ duration[ms]    │\n╞════════════════════════════╪═════════════════╡\n│ 2011-12-29 00:00:00 -10    ┆ -11h            │\n│ 2012-01-01 00:00:00 +14    ┆ 13h             │\n└────────────────────────────┴─────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Duration ."]], "Category": ["Temporal"], "index": 351}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.cast_time_unit.html#polars.Expr.dt.cast_time_unit"], "Title": ["Expr.dt.cast_time_unit"], "Feature": ["Expr.dt.cast_time_unit"], "Description": ["Cast the underlying data to another time unit."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2001, 1, 1), datetime(2001, 1, 3), \"1d\", eager=True\n...         )\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"date\"),\n...         pl.col(\"date\").dt.cast_time_unit(\"ms\").alias(\"time_unit_ms\"),\n...         pl.col(\"date\").dt.cast_time_unit(\"ns\").alias(\"time_unit_ns\"),\n...     ]\n... )\nshape: (3, 3)\n┌─────────────────────┬─────────────────────┬─────────────────────┐\n│ date                ┆ time_unit_ms        ┆ time_unit_ns        │\n│ ---                 ┆ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[ms]        ┆ datetime[ns]        │\n╞═════════════════════╪═════════════════════╪═════════════════════╡\n│ 2001-01-01 00:00:00 ┆ 2001-01-01 00:00:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-02 00:00:00 ┆ 2001-01-02 00:00:00 ┆ 2001-01-02 00:00:00 │\n│ 2001-01-03 00:00:00 ┆ 2001-01-03 00:00:00 ┆ 2001-01-03 00:00:00 │\n└─────────────────────┴─────────────────────┴─────────────────────┘"], "Parameters": [["time_unit {‘ns’, ‘us’, ‘ms’}", "Time unit for the Datetime expression."]], "Returns": [], "Category": ["Temporal"], "index": 352}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.century.html#polars.Expr.dt.century"], "Title": ["Expr.dt.century"], "Feature": ["Expr.dt.century"], "Description": ["Extract the century from underlying representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": [\n...             date(999, 12, 31),\n...             date(1897, 5, 7),\n...             date(2000, 1, 1),\n...             date(2001, 7, 5),\n...             date(3002, 10, 20),\n...         ]\n...     }\n... )\n>>> df.with_columns(cent=pl.col(\"date\").dt.century())\nshape: (5, 2)\n┌────────────┬──────┐\n│ date       ┆ cent │\n│ ---        ┆ ---  │\n│ date       ┆ i32  │\n╞════════════╪══════╡\n│ 0999-12-31 ┆ 10   │\n│ 1897-05-07 ┆ 19   │\n│ 2000-01-01 ┆ 20   │\n│ 2001-07-05 ┆ 21   │\n│ 3002-10-20 ┆ 31   │\n└────────────┴──────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 353}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.combine.html#polars.Expr.dt.combine"], "Title": ["Expr.dt.combine"], "Feature": ["Expr.dt.combine"], "Description": ["Create a naive Datetime from an existing Date/Datetime expression and a Time."], "Examples": [">>> from datetime import datetime, date, time\n>>> df = pl.DataFrame(\n...     {\n...         \"dtm\": [\n...             datetime(2022, 12, 31, 10, 30, 45),\n...             datetime(2023, 7, 5, 23, 59, 59),\n...         ],\n...         \"dt\": [date(2022, 10, 10), date(2022, 7, 5)],\n...         \"tm\": [time(1, 2, 3, 456000), time(7, 8, 9, 101000)],\n...     }\n... )\n>>> df\nshape: (2, 3)\n┌─────────────────────┬────────────┬──────────────┐\n│ dtm                 ┆ dt         ┆ tm           │\n│ ---                 ┆ ---        ┆ ---          │\n│ datetime[μs]        ┆ date       ┆ time         │\n╞═════════════════════╪════════════╪══════════════╡\n│ 2022-12-31 10:30:45 ┆ 2022-10-10 ┆ 01:02:03.456 │\n│ 2023-07-05 23:59:59 ┆ 2022-07-05 ┆ 07:08:09.101 │\n└─────────────────────┴────────────┴──────────────┘\n>>> df.select(\n...     [\n...         pl.col(\"dtm\").dt.combine(pl.col(\"tm\")).alias(\"d1\"),\n...         pl.col(\"dt\").dt.combine(pl.col(\"tm\")).alias(\"d2\"),\n...         pl.col(\"dt\").dt.combine(time(4, 5, 6)).alias(\"d3\"),\n...     ]\n... )\nshape: (2, 3)\n┌─────────────────────────┬─────────────────────────┬─────────────────────┐\n│ d1                      ┆ d2                      ┆ d3                  │\n│ ---                     ┆ ---                     ┆ ---                 │\n│ datetime[μs]            ┆ datetime[μs]            ┆ datetime[μs]        │\n╞═════════════════════════╪═════════════════════════╪═════════════════════╡\n│ 2022-12-31 01:02:03.456 ┆ 2022-10-10 01:02:03.456 ┆ 2022-10-10 04:05:06 │\n│ 2023-07-05 07:08:09.101 ┆ 2022-07-05 07:08:09.101 ┆ 2022-07-05 04:05:06 │\n└─────────────────────────┴─────────────────────────┴─────────────────────┘"], "Parameters": [["time", "A python time literal or polars expression/column that resolves to a time."], ["time_unit {‘ns’, ‘us’, ‘ms’}", "Unit of time."]], "Returns": [], "Category": ["Temporal"], "index": 354}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.convert_time_zone.html#polars.Expr.dt.convert_time_zone"], "Title": ["Expr.dt.convert_time_zone"], "Feature": ["Expr.dt.convert_time_zone"], "Description": ["Convert to given time zone for an expression of type Datetime."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 3, 1),\n...             datetime(2020, 5, 1),\n...             \"1mo\",\n...             time_zone=\"UTC\",\n...             eager=True,\n...         ),\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"date\"),\n...         pl.col(\"date\")\n...         .dt.convert_time_zone(time_zone=\"Europe/London\")\n...         .alias(\"London\"),\n...     ]\n... )\nshape: (3, 2)\n┌─────────────────────────┬─────────────────────────────┐\n│ date                    ┆ London                      │\n│ ---                     ┆ ---                         │\n│ datetime[μs, UTC]       ┆ datetime[μs, Europe/London] │\n╞═════════════════════════╪═════════════════════════════╡\n│ 2020-03-01 00:00:00 UTC ┆ 2020-03-01 00:00:00 GMT     │\n│ 2020-04-01 00:00:00 UTC ┆ 2020-04-01 01:00:00 BST     │\n│ 2020-05-01 00:00:00 UTC ┆ 2020-05-01 01:00:00 BST     │\n└─────────────────────────┴─────────────────────────────┘"], "Parameters": [["time_zone", "Time zone for the Datetime expression."]], "Returns": [], "Category": ["Temporal"], "index": 355}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.date.html#polars.Expr.dt.date"], "Title": ["Expr.dt.date"], "Feature": ["Expr.dt.date"], "Description": ["Extract date from date(time)."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(pl.col(\"datetime\").dt.date().alias(\"date\"))\nshape: (3, 2)\n┌─────────────────────────┬────────────┐\n│ datetime                ┆ date       │\n│ ---                     ┆ ---        │\n│ datetime[μs]            ┆ date       │\n╞═════════════════════════╪════════════╡\n│ 1978-01-01 01:01:01     ┆ 1978-01-01 │\n│ 2024-10-13 05:30:14.500 ┆ 2024-10-13 │\n│ 2065-01-01 10:20:30.060 ┆ 2065-01-01 │\n└─────────────────────────┴────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Date ."]], "Category": ["Temporal"], "index": 356}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.n_unique.html#polars.Expr.arr.n_unique"], "Title": ["Expr.arr.n_unique"], "Feature": ["Expr.arr.n_unique"], "Description": ["Count the number of unique values in every sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 1, 2], [2, 3, 4]],\n...     },\n...     schema={\"a\": pl.Array(pl.Int64, 3)},\n... )\n>>> df.with_columns(n_unique=pl.col(\"a\").arr.n_unique())\nshape: (2, 2)\n┌───────────────┬──────────┐\n│ a             ┆ n_unique │\n│ ---           ┆ ---      │\n│ array[i64, 3] ┆ u32      │\n╞═══════════════╪══════════╡\n│ [1, 1, 2]     ┆ 2        │\n│ [2, 3, 4]     ┆ 3        │\n└───────────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 357}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.datetime.html#polars.Expr.dt.datetime"], "Title": ["Expr.dt.datetime"], "Feature": ["Expr.dt.datetime"], "Description": ["Return datetime."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime UTC\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     },\n...     schema={\"datetime UTC\": pl.Datetime(time_zone=\"UTC\")},\n... )\n>>> df.with_columns(  \n...     pl.col(\"datetime UTC\").dt.datetime().alias(\"datetime (no timezone)\"),\n... )\nshape: (3, 2)\n┌─────────────────────────────┬─────────────────────────┐\n│ datetime UTC                ┆ datetime (no timezone)  │\n│ ---                         ┆ ---                     │\n│ datetime[μs, UTC]           ┆ datetime[μs]            │\n╞═════════════════════════════╪═════════════════════════╡\n│ 1978-01-01 01:01:01 UTC     ┆ 1978-01-01 01:01:01     │\n│ 2024-10-13 05:30:14.500 UTC ┆ 2024-10-13 05:30:14.500 │\n│ 2065-01-01 10:20:30.060 UTC ┆ 2065-01-01 10:20:30.060 │\n└─────────────────────────────┴─────────────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Datetime ."]], "Category": ["Temporal"], "index": 358}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.day.html#polars.Expr.dt.day"], "Title": ["Expr.dt.day"], "Feature": ["Expr.dt.day"], "Description": ["Extract day from underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.date_range(\n...             date(2001, 12, 22), date(2001, 12, 25), eager=True\n...         )\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"date\").dt.weekday().alias(\"weekday\"),\n...     pl.col(\"date\").dt.day().alias(\"day_of_month\"),\n...     pl.col(\"date\").dt.ordinal_day().alias(\"day_of_year\"),\n... )\nshape: (4, 4)\n┌────────────┬─────────┬──────────────┬─────────────┐\n│ date       ┆ weekday ┆ day_of_month ┆ day_of_year │\n│ ---        ┆ ---     ┆ ---          ┆ ---         │\n│ date       ┆ i8      ┆ i8           ┆ i16         │\n╞════════════╪═════════╪══════════════╪═════════════╡\n│ 2001-12-22 ┆ 6       ┆ 22           ┆ 356         │\n│ 2001-12-23 ┆ 7       ┆ 23           ┆ 357         │\n│ 2001-12-24 ┆ 1       ┆ 24           ┆ 358         │\n│ 2001-12-25 ┆ 2       ┆ 25           ┆ 359         │\n└────────────┴─────────┴──────────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 359}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.dst_offset.html#polars.Expr.dt.dst_offset"], "Title": ["Expr.dt.dst_offset"], "Feature": ["Expr.dt.dst_offset"], "Description": ["Additional offset currently in effect (typically due to daylight saving time)."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"ts\": [datetime(2020, 10, 25), datetime(2020, 10, 26)],\n...     }\n... )\n>>> df = df.with_columns(pl.col(\"ts\").dt.replace_time_zone(\"Europe/London\"))\n>>> df.with_columns(pl.col(\"ts\").dt.dst_offset().alias(\"dst_offset\"))\nshape: (2, 2)\n┌─────────────────────────────┬──────────────┐\n│ ts                          ┆ dst_offset   │\n│ ---                         ┆ ---          │\n│ datetime[μs, Europe/London] ┆ duration[ms] │\n╞═════════════════════════════╪══════════════╡\n│ 2020-10-25 00:00:00 BST     ┆ 1h           │\n│ 2020-10-26 00:00:00 GMT     ┆ 0ms          │\n└─────────────────────────────┴──────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Duration ."]], "Category": ["Temporal"], "index": 360}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.epoch.html#polars.Expr.dt.epoch"], "Title": ["Expr.dt.epoch"], "Feature": ["Expr.dt.epoch"], "Description": ["Get the time passed since the Unix EPOCH in the give time unit."], "Examples": [">>> from datetime import date\n>>> df = (\n...     pl.date_range(date(2001, 1, 1), date(2001, 1, 3), eager=True)\n...     .alias(\"date\")\n...     .to_frame()\n... )\n>>> df.with_columns(\n...     pl.col(\"date\").dt.epoch().alias(\"epoch_ns\"),\n...     pl.col(\"date\").dt.epoch(time_unit=\"s\").alias(\"epoch_s\"),\n... )\nshape: (3, 3)\n┌────────────┬─────────────────┬───────────┐\n│ date       ┆ epoch_ns        ┆ epoch_s   │\n│ ---        ┆ ---             ┆ ---       │\n│ date       ┆ i64             ┆ i64       │\n╞════════════╪═════════════════╪═══════════╡\n│ 2001-01-01 ┆ 978307200000000 ┆ 978307200 │\n│ 2001-01-02 ┆ 978393600000000 ┆ 978393600 │\n│ 2001-01-03 ┆ 978480000000000 ┆ 978480000 │\n└────────────┴─────────────────┴───────────┘"], "Parameters": [["time_unit {‘ns’, ‘us’, ‘ms’, ‘s’, ‘d’}", "Time unit."]], "Returns": [], "Category": ["Temporal"], "index": 361}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.hour.html#polars.Expr.dt.hour"], "Title": ["Expr.dt.hour"], "Feature": ["Expr.dt.hour"], "Description": ["Extract hour from underlying DateTime representation."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second().alias(\"second\"),\n...     pl.col(\"datetime\").dt.millisecond().alias(\"millisecond\"),\n... )\nshape: (3, 5)\n┌─────────────────────────┬──────┬────────┬────────┬─────────────┐\n│ datetime                ┆ hour ┆ minute ┆ second ┆ millisecond │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    ┆ ---         │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ i8     ┆ i32         │\n╞═════════════════════════╪══════╪════════╪════════╪═════════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1      ┆ 0           │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14     ┆ 500         │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30     ┆ 60          │\n└─────────────────────────┴──────┴────────┴────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 362}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.is_business_day.html#polars.Expr.dt.is_business_day"], "Title": ["Expr.dt.is_business_day"], "Feature": ["Expr.dt.is_business_day"], "Description": ["Determine whether each day lands on a business day."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame({\"start\": [date(2020, 1, 3), date(2020, 1, 5)]})\n>>> df.with_columns(is_business_day=pl.col(\"start\").dt.is_business_day())\nshape: (2, 2)\n┌────────────┬─────────────────┐\n│ start      ┆ is_business_day │\n│ ---        ┆ ---             │\n│ date       ┆ bool            │\n╞════════════╪═════════════════╡\n│ 2020-01-03 ┆ true            │\n│ 2020-01-05 ┆ false           │\n└────────────┴─────────────────┘", ">>> week_mask = (True, True, True, True, True, True, False)\n>>> df.with_columns(\n...     is_business_day=pl.col(\"start\").dt.is_business_day(week_mask=week_mask)\n... )\nshape: (2, 2)\n┌────────────┬─────────────────┐\n│ start      ┆ is_business_day │\n│ ---        ┆ ---             │\n│ date       ┆ bool            │\n╞════════════╪═════════════════╡\n│ 2020-01-03 ┆ true            │\n│ 2020-01-05 ┆ false           │\n└────────────┴─────────────────┘", ">>> from datetime import date\n>>> holidays = [date(2020, 1, 3), date(2020, 1, 6)]\n>>> df.with_columns(\n...     is_business_day=pl.col(\"start\").dt.is_business_day(holidays=holidays)\n... )\nshape: (2, 2)\n┌────────────┬─────────────────┐\n│ start      ┆ is_business_day │\n│ ---        ┆ ---             │\n│ date       ┆ bool            │\n╞════════════╪═════════════════╡\n│ 2020-01-03 ┆ false           │\n│ 2020-01-05 ┆ false           │\n└────────────┴─────────────────┘"], "Parameters": [["week_mask", "Which days of the week to count. The default is Monday to Friday.\nIf you wanted to count only Monday to Thursday, you would pass (True, True, True, True, False, False, False) ."], ["holidays", "Holidays to exclude from the count. The Python package python-holidays may come in handy here. You can install it with pip install holidays ,\nand then, to get all Dutch holidays for years 2020-2024: import holidays my_holidays = holidays . country_holidays ( \"NL\" , years = range ( 2020 , 2025 )) Copy to clipboard and pass holidays=my_holidays when you call is_business_day ."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Temporal"], "index": 363}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.is_leap_year.html#polars.Expr.dt.is_leap_year"], "Title": ["Expr.dt.is_leap_year"], "Feature": ["Expr.dt.is_leap_year"], "Description": ["Determine whether the year of the underlying date is a leap year."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\"date\": [date(2000, 1, 1), date(2001, 1, 1), date(2002, 1, 1)]}\n... )\n>>> df.with_columns(\n...     leap_year=pl.col(\"date\").dt.is_leap_year(),\n... )\nshape: (3, 2)\n┌────────────┬───────────┐\n│ date       ┆ leap_year │\n│ ---        ┆ ---       │\n│ date       ┆ bool      │\n╞════════════╪═══════════╡\n│ 2000-01-01 ┆ true      │\n│ 2001-01-01 ┆ false     │\n│ 2002-01-01 ┆ false     │\n└────────────┴───────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Temporal"], "index": 364}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.iso_year.html#polars.Expr.dt.iso_year"], "Title": ["Expr.dt.iso_year"], "Feature": ["Expr.dt.iso_year"], "Description": ["Extract ISO year from underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\"date\": [date(1977, 1, 1), date(1978, 1, 1), date(1979, 1, 1)]}\n... )\n>>> df.select(\n...     \"date\",\n...     pl.col(\"date\").dt.year().alias(\"calendar_year\"),\n...     pl.col(\"date\").dt.iso_year().alias(\"iso_year\"),\n... )\nshape: (3, 3)\n┌────────────┬───────────────┬──────────┐\n│ date       ┆ calendar_year ┆ iso_year │\n│ ---        ┆ ---           ┆ ---      │\n│ date       ┆ i32           ┆ i32      │\n╞════════════╪═══════════════╪══════════╡\n│ 1977-01-01 ┆ 1977          ┆ 1976     │\n│ 1978-01-01 ┆ 1978          ┆ 1977     │\n│ 1979-01-01 ┆ 1979          ┆ 1979     │\n└────────────┴───────────────┴──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 365}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.microsecond.html#polars.Expr.dt.microsecond"], "Title": ["Expr.dt.microsecond"], "Feature": ["Expr.dt.microsecond"], "Description": ["Extract microseconds from underlying DateTime representation."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second().alias(\"second\"),\n...     pl.col(\"datetime\").dt.microsecond().alias(\"microsecond\"),\n... )\nshape: (3, 5)\n┌─────────────────────────┬──────┬────────┬────────┬─────────────┐\n│ datetime                ┆ hour ┆ minute ┆ second ┆ microsecond │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    ┆ ---         │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ i8     ┆ i32         │\n╞═════════════════════════╪══════╪════════╪════════╪═════════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1      ┆ 0           │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14     ┆ 500000      │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30     ┆ 60000       │\n└─────────────────────────┴──────┴────────┴────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 366}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.millennium.html#polars.Expr.dt.millennium"], "Title": ["Expr.dt.millennium"], "Feature": ["Expr.dt.millennium"], "Description": ["Extract the millennium from underlying representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": [\n...             date(999, 12, 31),\n...             date(1897, 5, 7),\n...             date(2000, 1, 1),\n...             date(2001, 7, 5),\n...             date(3002, 10, 20),\n...         ]\n...     }\n... )\n>>> df.with_columns(mlnm=pl.col(\"date\").dt.millennium())\nshape: (5, 2)\n┌────────────┬──────┐\n│ date       ┆ mlnm │\n│ ---        ┆ ---  │\n│ date       ┆ i32  │\n╞════════════╪══════╡\n│ 0999-12-31 ┆ 1    │\n│ 1897-05-07 ┆ 2    │\n│ 2000-01-01 ┆ 2    │\n│ 2001-07-05 ┆ 3    │\n│ 3002-10-20 ┆ 4    │\n└────────────┴──────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 367}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.reverse.html#polars.Expr.arr.reverse"], "Title": ["Expr.arr.reverse"], "Feature": ["Expr.arr.reverse"], "Description": ["Reverse the arrays in this column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[3, 2, 1], [9, 1, 2]],\n...     },\n...     schema={\"a\": pl.Array(pl.Int64, 3)},\n... )\n>>> df.with_columns(reverse=pl.col(\"a\").arr.reverse())\nshape: (2, 2)\n┌───────────────┬───────────────┐\n│ a             ┆ reverse       │\n│ ---           ┆ ---           │\n│ array[i64, 3] ┆ array[i64, 3] │\n╞═══════════════╪═══════════════╡\n│ [3, 2, 1]     ┆ [1, 2, 3]     │\n│ [9, 1, 2]     ┆ [2, 1, 9]     │\n└───────────────┴───────────────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 368}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.millisecond.html#polars.Expr.dt.millisecond"], "Title": ["Expr.dt.millisecond"], "Feature": ["Expr.dt.millisecond"], "Description": ["Extract milliseconds from underlying DateTime representation."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second().alias(\"second\"),\n...     pl.col(\"datetime\").dt.millisecond().alias(\"millisecond\"),\n... )\nshape: (3, 5)\n┌─────────────────────────┬──────┬────────┬────────┬─────────────┐\n│ datetime                ┆ hour ┆ minute ┆ second ┆ millisecond │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    ┆ ---         │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ i8     ┆ i32         │\n╞═════════════════════════╪══════╪════════╪════════╪═════════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1      ┆ 0           │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14     ┆ 500         │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30     ┆ 60          │\n└─────────────────────────┴──────┴────────┴────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 369}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.minute.html#polars.Expr.dt.minute"], "Title": ["Expr.dt.minute"], "Feature": ["Expr.dt.minute"], "Description": ["Extract minutes from underlying DateTime representation."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second().alias(\"second\"),\n...     pl.col(\"datetime\").dt.millisecond().alias(\"millisecond\"),\n... )\nshape: (3, 5)\n┌─────────────────────────┬──────┬────────┬────────┬─────────────┐\n│ datetime                ┆ hour ┆ minute ┆ second ┆ millisecond │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    ┆ ---         │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ i8     ┆ i32         │\n╞═════════════════════════╪══════╪════════╪════════╪═════════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1      ┆ 0           │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14     ┆ 500         │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30     ┆ 60          │\n└─────────────────────────┴──────┴────────┴────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 370}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.month.html#polars.Expr.dt.month"], "Title": ["Expr.dt.month"], "Feature": ["Expr.dt.month"], "Description": ["Extract month from underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\"date\": [date(2001, 1, 1), date(2001, 6, 30), date(2001, 12, 27)]}\n... )\n>>> df.with_columns(pl.col(\"date\").dt.month().alias(\"month\"))\nshape: (3, 2)\n┌────────────┬───────┐\n│ date       ┆ month │\n│ ---        ┆ ---   │\n│ date       ┆ i8    │\n╞════════════╪═══════╡\n│ 2001-01-01 ┆ 1     │\n│ 2001-06-30 ┆ 6     │\n│ 2001-12-27 ┆ 12    │\n└────────────┴───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 371}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.month_end.html#polars.Expr.dt.month_end"], "Title": ["Expr.dt.month_end"], "Feature": ["Expr.dt.month_end"], "Description": ["Roll forward to the last day of the month."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"dates\": pl.datetime_range(\n...             datetime(2000, 1, 1, 2),\n...             datetime(2000, 12, 1, 2),\n...             \"1mo\",\n...             eager=True,\n...         )\n...     }\n... )\n>>> df.select(pl.col(\"dates\").dt.month_end())\nshape: (12, 1)\n┌─────────────────────┐\n│ dates               │\n│ ---                 │\n│ datetime[μs]        │\n╞═════════════════════╡\n│ 2000-01-31 02:00:00 │\n│ 2000-02-29 02:00:00 │\n│ 2000-03-31 02:00:00 │\n│ 2000-04-30 02:00:00 │\n│ 2000-05-31 02:00:00 │\n│ …                   │\n│ 2000-08-31 02:00:00 │\n│ 2000-09-30 02:00:00 │\n│ 2000-10-31 02:00:00 │\n│ 2000-11-30 02:00:00 │\n│ 2000-12-31 02:00:00 │\n└─────────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Date or Datetime ."]], "Category": ["Temporal"], "index": 372}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.month_start.html#polars.Expr.dt.month_start"], "Title": ["Expr.dt.month_start"], "Feature": ["Expr.dt.month_start"], "Description": ["Roll backward to the first day of the month."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"dates\": pl.datetime_range(\n...             datetime(2000, 1, 15, 2),\n...             datetime(2000, 12, 15, 2),\n...             \"1mo\",\n...             eager=True,\n...         )\n...     }\n... )\n>>> df.select(pl.col(\"dates\").dt.month_start())\nshape: (12, 1)\n┌─────────────────────┐\n│ dates               │\n│ ---                 │\n│ datetime[μs]        │\n╞═════════════════════╡\n│ 2000-01-01 02:00:00 │\n│ 2000-02-01 02:00:00 │\n│ 2000-03-01 02:00:00 │\n│ 2000-04-01 02:00:00 │\n│ 2000-05-01 02:00:00 │\n│ …                   │\n│ 2000-08-01 02:00:00 │\n│ 2000-09-01 02:00:00 │\n│ 2000-10-01 02:00:00 │\n│ 2000-11-01 02:00:00 │\n│ 2000-12-01 02:00:00 │\n└─────────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Date or Datetime ."]], "Category": ["Temporal"], "index": 373}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.nanosecond.html#polars.Expr.dt.nanosecond"], "Title": ["Expr.dt.nanosecond"], "Feature": ["Expr.dt.nanosecond"], "Description": ["Extract nanoseconds from underlying DateTime representation."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second().alias(\"second\"),\n...     pl.col(\"datetime\").dt.nanosecond().alias(\"nanosecond\"),\n... )\nshape: (3, 5)\n┌─────────────────────────┬──────┬────────┬────────┬────────────┐\n│ datetime                ┆ hour ┆ minute ┆ second ┆ nanosecond │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    ┆ ---        │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ i8     ┆ i32        │\n╞═════════════════════════╪══════╪════════╪════════╪════════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1      ┆ 0          │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14     ┆ 500000000  │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30     ┆ 60000000   │\n└─────────────────────────┴──────┴────────┴────────┴────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 374}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.offset_by.html#polars.Expr.dt.offset_by"], "Title": ["Expr.dt.offset_by"], "Feature": ["Expr.dt.offset_by"], "Description": ["Offset this date by a relative time offset."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"dates\": pl.datetime_range(\n...             datetime(2000, 1, 1), datetime(2005, 1, 1), \"1y\", eager=True\n...         ),\n...         \"offset\": [\"1d\", \"2d\", \"-1d\", \"1mo\", None, \"1y\"],\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"dates\").dt.offset_by(\"1y\").alias(\"date_plus_1y\"),\n...         pl.col(\"dates\").dt.offset_by(\"-1y2mo\").alias(\"date_min\"),\n...     ]\n... )\nshape: (6, 2)\n┌─────────────────────┬─────────────────────┐\n│ date_plus_1y        ┆ date_min            │\n│ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╡\n│ 2001-01-01 00:00:00 ┆ 1998-11-01 00:00:00 │\n│ 2002-01-01 00:00:00 ┆ 1999-11-01 00:00:00 │\n│ 2003-01-01 00:00:00 ┆ 2000-11-01 00:00:00 │\n│ 2004-01-01 00:00:00 ┆ 2001-11-01 00:00:00 │\n│ 2005-01-01 00:00:00 ┆ 2002-11-01 00:00:00 │\n│ 2006-01-01 00:00:00 ┆ 2003-11-01 00:00:00 │\n└─────────────────────┴─────────────────────┘", ">>> df.with_columns(new_dates=pl.col(\"dates\").dt.offset_by(pl.col(\"offset\")))\nshape: (6, 3)\n┌─────────────────────┬────────┬─────────────────────┐\n│ dates               ┆ offset ┆ new_dates           │\n│ ---                 ┆ ---    ┆ ---                 │\n│ datetime[μs]        ┆ str    ┆ datetime[μs]        │\n╞═════════════════════╪════════╪═════════════════════╡\n│ 2000-01-01 00:00:00 ┆ 1d     ┆ 2000-01-02 00:00:00 │\n│ 2001-01-01 00:00:00 ┆ 2d     ┆ 2001-01-03 00:00:00 │\n│ 2002-01-01 00:00:00 ┆ -1d    ┆ 2001-12-31 00:00:00 │\n│ 2003-01-01 00:00:00 ┆ 1mo    ┆ 2003-02-01 00:00:00 │\n│ 2004-01-01 00:00:00 ┆ null   ┆ null                │\n│ 2005-01-01 00:00:00 ┆ 1y     ┆ 2006-01-01 00:00:00 │\n└─────────────────────┴────────┴─────────────────────┘"], "Parameters": [["by", "The offset is dictated by the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) By “calendar day”, we mean the corresponding time on the next day (which may\nnot be 24 hours, due to daylight savings). Similarly for “calendar week”,\n“calendar month”, “calendar quarter”, and “calendar year”."]], "Returns": [["Expr", "Expression of data type Date or Datetime ."]], "Category": ["Temporal"], "index": 375}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.ordinal_day.html#polars.Expr.dt.ordinal_day"], "Title": ["Expr.dt.ordinal_day"], "Feature": ["Expr.dt.ordinal_day"], "Description": ["Extract ordinal day from underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.date_range(\n...             date(2001, 12, 22), date(2001, 12, 25), eager=True\n...         )\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"date\").dt.weekday().alias(\"weekday\"),\n...     pl.col(\"date\").dt.day().alias(\"day_of_month\"),\n...     pl.col(\"date\").dt.ordinal_day().alias(\"day_of_year\"),\n... )\nshape: (4, 4)\n┌────────────┬─────────┬──────────────┬─────────────┐\n│ date       ┆ weekday ┆ day_of_month ┆ day_of_year │\n│ ---        ┆ ---     ┆ ---          ┆ ---         │\n│ date       ┆ i8      ┆ i8           ┆ i16         │\n╞════════════╪═════════╪══════════════╪═════════════╡\n│ 2001-12-22 ┆ 6       ┆ 22           ┆ 356         │\n│ 2001-12-23 ┆ 7       ┆ 23           ┆ 357         │\n│ 2001-12-24 ┆ 1       ┆ 24           ┆ 358         │\n│ 2001-12-25 ┆ 2       ┆ 25           ┆ 359         │\n└────────────┴─────────┴──────────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int16 ."]], "Category": ["Temporal"], "index": 376}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.quarter.html#polars.Expr.dt.quarter"], "Title": ["Expr.dt.quarter"], "Feature": ["Expr.dt.quarter"], "Description": ["Extract quarter from underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\"date\": [date(2001, 1, 1), date(2001, 6, 30), date(2001, 12, 27)]}\n... )\n>>> df.with_columns(pl.col(\"date\").dt.quarter().alias(\"quarter\"))\nshape: (3, 2)\n┌────────────┬─────────┐\n│ date       ┆ quarter │\n│ ---        ┆ ---     │\n│ date       ┆ i8      │\n╞════════════╪═════════╡\n│ 2001-01-01 ┆ 1       │\n│ 2001-06-30 ┆ 2       │\n│ 2001-12-27 ┆ 4       │\n└────────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 377}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.replace.html#polars.Expr.dt.replace"], "Title": ["Expr.dt.replace"], "Feature": ["Expr.dt.replace"], "Description": ["Replace time unit."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": [date(2024, 4, 1), date(2025, 3, 16)],\n...         \"new_day\": [10, 15],\n...     }\n... )\n>>> df.with_columns(pl.col(\"date\").dt.replace(day=\"new_day\").alias(\"replaced\"))\nshape: (2, 3)\n┌────────────┬─────────┬────────────┐\n│ date       ┆ new_day ┆ replaced   │\n│ ---        ┆ ---     ┆ ---        │\n│ date       ┆ i64     ┆ date       │\n╞════════════╪═════════╪════════════╡\n│ 2024-04-01 ┆ 10      ┆ 2024-04-10 │\n│ 2025-03-16 ┆ 15      ┆ 2025-03-15 │\n└────────────┴─────────┴────────────┘\n>>> df.with_columns(pl.col(\"date\").dt.replace(year=1800).alias(\"replaced\"))\nshape: (2, 3)\n┌────────────┬─────────┬────────────┐\n│ date       ┆ new_day ┆ replaced   │\n│ ---        ┆ ---     ┆ ---        │\n│ date       ┆ i64     ┆ date       │\n╞════════════╪═════════╪════════════╡\n│ 2024-04-01 ┆ 10      ┆ 1800-04-01 │\n│ 2025-03-16 ┆ 15      ┆ 1800-03-16 │\n└────────────┴─────────┴────────────┘"], "Parameters": [["year", "Column or literal."], ["month", "Column or literal, ranging from 1-12."], ["day", "Column or literal, ranging from 1-31."], ["hour", "Column or literal, ranging from 0-23."], ["minute", "Column or literal, ranging from 0-59."], ["second", "Column or literal, ranging from 0-59."], ["microsecond", "Column or literal, ranging from 0-999999."], ["ambiguous", "Determine how to deal with ambiguous datetimes: 'raise' (default): raise 'earliest' : use the earliest datetime 'latest' : use the latest datetime 'null' : set to null"]], "Returns": [["Expr", "Expression of data type Date or Datetime with the\nspecified time units replaced."]], "Category": ["Temporal"], "index": 378}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.shift.html#polars.Expr.arr.shift"], "Title": ["Expr.arr.shift"], "Feature": ["Expr.arr.shift"], "Description": ["Shift array values by the given number of indices."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [[1, 2, 3], [4, 5, 6]]}, schema={\"a\": pl.Array(pl.Int64, 3)}\n... )\n>>> df.with_columns(shift=pl.col(\"a\").arr.shift())\nshape: (2, 2)\n┌───────────────┬───────────────┐\n│ a             ┆ shift         │\n│ ---           ┆ ---           │\n│ array[i64, 3] ┆ array[i64, 3] │\n╞═══════════════╪═══════════════╡\n│ [1, 2, 3]     ┆ [null, 1, 2]  │\n│ [4, 5, 6]     ┆ [null, 4, 5]  │\n└───────────────┴───────────────┘", ">>> df.with_columns(shift=pl.col(\"a\").arr.shift(-2))\nshape: (2, 2)\n┌───────────────┬─────────────────┐\n│ a             ┆ shift           │\n│ ---           ┆ ---             │\n│ array[i64, 3] ┆ array[i64, 3]   │\n╞═══════════════╪═════════════════╡\n│ [1, 2, 3]     ┆ [3, null, null] │\n│ [4, 5, 6]     ┆ [6, null, null] │\n└───────────────┴─────────────────┘"], "Parameters": [["n", "Number of indices to shift forward. If a negative value is passed, values\nare shifted in the opposite direction instead."]], "Returns": [], "Category": ["Array"], "index": 379}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.replace_time_zone.html#polars.Expr.dt.replace_time_zone"], "Title": ["Expr.dt.replace_time_zone"], "Feature": ["Expr.dt.replace_time_zone"], "Description": ["Replace time zone for an expression of type Datetime."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"london_timezone\": pl.datetime_range(\n...             datetime(2020, 3, 1),\n...             datetime(2020, 7, 1),\n...             \"1mo\",\n...             time_zone=\"UTC\",\n...             eager=True,\n...         ).dt.convert_time_zone(time_zone=\"Europe/London\"),\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"london_timezone\"),\n...         pl.col(\"london_timezone\")\n...         .dt.replace_time_zone(time_zone=\"Europe/Amsterdam\")\n...         .alias(\"London_to_Amsterdam\"),\n...     ]\n... )\nshape: (5, 2)\n┌─────────────────────────────┬────────────────────────────────┐\n│ london_timezone             ┆ London_to_Amsterdam            │\n│ ---                         ┆ ---                            │\n│ datetime[μs, Europe/London] ┆ datetime[μs, Europe/Amsterdam] │\n╞═════════════════════════════╪════════════════════════════════╡\n│ 2020-03-01 00:00:00 GMT     ┆ 2020-03-01 00:00:00 CET        │\n│ 2020-04-01 01:00:00 BST     ┆ 2020-04-01 01:00:00 CEST       │\n│ 2020-05-01 01:00:00 BST     ┆ 2020-05-01 01:00:00 CEST       │\n│ 2020-06-01 01:00:00 BST     ┆ 2020-06-01 01:00:00 CEST       │\n│ 2020-07-01 01:00:00 BST     ┆ 2020-07-01 01:00:00 CEST       │\n└─────────────────────────────┴────────────────────────────────┘", ">>> dates = [\n...     \"2018-10-28 01:30\",\n...     \"2018-10-28 02:00\",\n...     \"2018-10-28 02:30\",\n...     \"2018-10-28 02:00\",\n... ]\n>>> df = pl.DataFrame(\n...     {\n...         \"ts\": pl.Series(dates).str.strptime(pl.Datetime),\n...         \"ambiguous\": [\"earliest\", \"earliest\", \"latest\", \"latest\"],\n...     }\n... )\n>>> df.with_columns(\n...     ts_localized=pl.col(\"ts\").dt.replace_time_zone(\n...         \"Europe/Brussels\", ambiguous=pl.col(\"ambiguous\")\n...     )\n... )\nshape: (4, 3)\n┌─────────────────────┬───────────┬───────────────────────────────┐\n│ ts                  ┆ ambiguous ┆ ts_localized                  │\n│ ---                 ┆ ---       ┆ ---                           │\n│ datetime[μs]        ┆ str       ┆ datetime[μs, Europe/Brussels] │\n╞═════════════════════╪═══════════╪═══════════════════════════════╡\n│ 2018-10-28 01:30:00 ┆ earliest  ┆ 2018-10-28 01:30:00 CEST      │\n│ 2018-10-28 02:00:00 ┆ earliest  ┆ 2018-10-28 02:00:00 CEST      │\n│ 2018-10-28 02:30:00 ┆ latest    ┆ 2018-10-28 02:30:00 CET       │\n│ 2018-10-28 02:00:00 ┆ latest    ┆ 2018-10-28 02:00:00 CET       │\n└─────────────────────┴───────────┴───────────────────────────────┘"], "Parameters": [["time_zone", "Time zone for the Datetime expression. Pass None to unset time zone."], ["ambiguous", "Determine how to deal with ambiguous datetimes: 'raise' (default): raise 'earliest' : use the earliest datetime 'latest' : use the latest datetime 'null' : set to null"], ["non_existent", "Determine how to deal with non-existent datetimes: 'raise' (default): raise 'null' : set to null"]], "Returns": [], "Category": ["Temporal"], "index": 380}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.round.html#polars.Expr.dt.round"], "Title": ["Expr.dt.round"], "Feature": ["Expr.dt.round"], "Description": ["Divide the date/datetime range into buckets."], "Examples": [">>> from datetime import timedelta, datetime\n>>> df = (\n...     pl.datetime_range(\n...         datetime(2001, 1, 1),\n...         datetime(2001, 1, 2),\n...         timedelta(minutes=225),\n...         eager=True,\n...     )\n...     .alias(\"datetime\")\n...     .to_frame()\n... )\n>>> df.with_columns(pl.col(\"datetime\").dt.round(\"1h\").alias(\"round\"))\nshape: (7, 2)\n┌─────────────────────┬─────────────────────┐\n│ datetime            ┆ round               │\n│ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╡\n│ 2001-01-01 00:00:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-01 03:45:00 ┆ 2001-01-01 04:00:00 │\n│ 2001-01-01 07:30:00 ┆ 2001-01-01 08:00:00 │\n│ 2001-01-01 11:15:00 ┆ 2001-01-01 11:00:00 │\n│ 2001-01-01 15:00:00 ┆ 2001-01-01 15:00:00 │\n│ 2001-01-01 18:45:00 ┆ 2001-01-01 19:00:00 │\n│ 2001-01-01 22:30:00 ┆ 2001-01-01 23:00:00 │\n└─────────────────────┴─────────────────────┘", ">>> df = (\n...     pl.datetime_range(\n...         datetime(2001, 1, 1), datetime(2001, 1, 1, 1), \"10m\", eager=True\n...     )\n...     .alias(\"datetime\")\n...     .to_frame()\n... )\n>>> df.with_columns(pl.col(\"datetime\").dt.round(\"30m\").alias(\"round\"))\nshape: (7, 2)\n┌─────────────────────┬─────────────────────┐\n│ datetime            ┆ round               │\n│ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╡\n│ 2001-01-01 00:00:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-01 00:10:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-01 00:20:00 ┆ 2001-01-01 00:30:00 │\n│ 2001-01-01 00:30:00 ┆ 2001-01-01 00:30:00 │\n│ 2001-01-01 00:40:00 ┆ 2001-01-01 00:30:00 │\n│ 2001-01-01 00:50:00 ┆ 2001-01-01 01:00:00 │\n│ 2001-01-01 01:00:00 ┆ 2001-01-01 01:00:00 │\n└─────────────────────┴─────────────────────┘"], "Parameters": [["every", "Every interval start and period length"]], "Returns": [["Expr", "Expression of data type Date or Datetime ."]], "Category": ["Temporal"], "index": 381}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.second.html#polars.Expr.dt.second"], "Title": ["Expr.dt.second"], "Feature": ["Expr.dt.second"], "Description": ["Extract seconds from underlying DateTime representation."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second().alias(\"second\"),\n... )\nshape: (3, 4)\n┌─────────────────────────┬──────┬────────┬────────┐\n│ datetime                ┆ hour ┆ minute ┆ second │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ i8     │\n╞═════════════════════════╪══════╪════════╪════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1      │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14     │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30     │\n└─────────────────────────┴──────┴────────┴────────┘\n>>> df.with_columns(\n...     pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n...     pl.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     pl.col(\"datetime\").dt.second(fractional=True).alias(\"second\"),\n... )\nshape: (3, 4)\n┌─────────────────────────┬──────┬────────┬────────┐\n│ datetime                ┆ hour ┆ minute ┆ second │\n│ ---                     ┆ ---  ┆ ---    ┆ ---    │\n│ datetime[μs]            ┆ i8   ┆ i8     ┆ f64    │\n╞═════════════════════════╪══════╪════════╪════════╡\n│ 1978-01-01 01:01:01     ┆ 1    ┆ 1      ┆ 1.0    │\n│ 2024-10-13 05:30:14.500 ┆ 5    ┆ 30     ┆ 14.5   │\n│ 2065-01-01 10:20:30.060 ┆ 10   ┆ 20     ┆ 30.06  │\n└─────────────────────────┴──────┴────────┴────────┘"], "Parameters": [["fractional", "Whether to include the fractional component of the second."]], "Returns": [["Expr", "Expression of data type Int8 or Float64 ."]], "Category": ["Temporal"], "index": 382}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.strftime.html#polars.Expr.dt.strftime"], "Title": ["Expr.dt.strftime"], "Feature": ["Expr.dt.strftime"], "Description": ["Convert a Date/Time/Datetime column into a String column with the given format."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(2020, 3, 1),\n...             datetime(2020, 4, 1),\n...             datetime(2020, 5, 1),\n...         ]\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"datetime\")\n...     .dt.strftime(\"%Y/%m/%d %H:%M:%S\")\n...     .alias(\"datetime_string\")\n... )\nshape: (3, 2)\n┌─────────────────────┬─────────────────────┐\n│ datetime            ┆ datetime_string     │\n│ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ str                 │\n╞═════════════════════╪═════════════════════╡\n│ 2020-03-01 00:00:00 ┆ 2020/03/01 00:00:00 │\n│ 2020-04-01 00:00:00 ┆ 2020/04/01 00:00:00 │\n│ 2020-05-01 00:00:00 ┆ 2020/05/01 00:00:00 │\n└─────────────────────┴─────────────────────┘", ">>> df.with_columns(\n...     day_name=pl.col(\"datetime\").dt.strftime(\"%A\"),\n...     month_name=pl.col(\"datetime\").dt.strftime(\"%B\"),\n... )\nshape: (3, 3)\n┌─────────────────────┬───────────┬────────────┐\n│ datetime            ┆ day_name  ┆ month_name │\n│ ---                 ┆ ---       ┆ ---        │\n│ datetime[μs]        ┆ str       ┆ str        │\n╞═════════════════════╪═══════════╪════════════╡\n│ 2020-03-01 00:00:00 ┆ Sunday    ┆ March      │\n│ 2020-04-01 00:00:00 ┆ Wednesday ┆ April      │\n│ 2020-05-01 00:00:00 ┆ Friday    ┆ May        │\n└─────────────────────┴───────────┴────────────┘"], "Parameters": [["format", "Format to use, refer to the chrono strftime documentation for specification. Example: \"%y-%m-%d\" ."]], "Returns": [], "Category": ["Temporal"], "index": 383}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.time.html#polars.Expr.dt.time"], "Title": ["Expr.dt.time"], "Feature": ["Expr.dt.time"], "Description": ["Extract time."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"datetime\": [\n...             datetime(1978, 1, 1, 1, 1, 1, 0),\n...             datetime(2024, 10, 13, 5, 30, 14, 500_000),\n...             datetime(2065, 1, 1, 10, 20, 30, 60_000),\n...         ]\n...     }\n... )\n>>> df.with_columns(pl.col(\"datetime\").dt.time().alias(\"time\"))\nshape: (3, 2)\n┌─────────────────────────┬──────────────┐\n│ datetime                ┆ time         │\n│ ---                     ┆ ---          │\n│ datetime[μs]            ┆ time         │\n╞═════════════════════════╪══════════════╡\n│ 1978-01-01 01:01:01     ┆ 01:01:01     │\n│ 2024-10-13 05:30:14.500 ┆ 05:30:14.500 │\n│ 2065-01-01 10:20:30.060 ┆ 10:20:30.060 │\n└─────────────────────────┴──────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Time ."]], "Category": ["Temporal"], "index": 384}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.timestamp.html#polars.Expr.dt.timestamp"], "Title": ["Expr.dt.timestamp"], "Feature": ["Expr.dt.timestamp"], "Description": ["Return a timestamp in the given time unit."], "Examples": [">>> from datetime import date\n>>> df = (\n...     pl.date_range(date(2001, 1, 1), date(2001, 1, 3), eager=True)\n...     .alias(\"date\")\n...     .to_frame()\n... )\n>>> df.with_columns(\n...     pl.col(\"date\").dt.timestamp().alias(\"timestamp_us\"),\n...     pl.col(\"date\").dt.timestamp(\"ms\").alias(\"timestamp_ms\"),\n... )\nshape: (3, 3)\n┌────────────┬─────────────────┬──────────────┐\n│ date       ┆ timestamp_us    ┆ timestamp_ms │\n│ ---        ┆ ---             ┆ ---          │\n│ date       ┆ i64             ┆ i64          │\n╞════════════╪═════════════════╪══════════════╡\n│ 2001-01-01 ┆ 978307200000000 ┆ 978307200000 │\n│ 2001-01-02 ┆ 978393600000000 ┆ 978393600000 │\n│ 2001-01-03 ┆ 978480000000000 ┆ 978480000000 │\n└────────────┴─────────────────┴──────────────┘"], "Parameters": [["time_unit {‘ns’, ‘us’, ‘ms’}", "Time unit."]], "Returns": [], "Category": ["Temporal"], "index": 385}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.to_string.html#polars.Expr.dt.to_string"], "Title": ["Expr.dt.to_string"], "Feature": ["Expr.dt.to_string"], "Description": ["Convert a Date/Time/Datetime column into a String column with the given format."], "Examples": [">>> from datetime import datetime, date, timedelta, time\n>>> df = pl.DataFrame(\n...     {\n...         \"dt\": [\n...             date(1999, 3, 1),\n...             date(2020, 5, 3),\n...             date(2077, 7, 5),\n...         ],\n...         \"dtm\": [\n...             datetime(1980, 8, 10, 0, 10, 20),\n...             datetime(2010, 10, 20, 8, 25, 35),\n...             datetime(2040, 12, 30, 16, 40, 50),\n...         ],\n...         \"tm\": [\n...             time(1, 2, 3, 456789),\n...             time(23, 59, 9, 101),\n...             time(0, 0, 0, 100),\n...         ],\n...         \"td\": [\n...             timedelta(days=-1, seconds=-42),\n...             timedelta(days=14, hours=-10, microseconds=100),\n...             timedelta(seconds=0),\n...         ],\n...     }\n... )", ">>> import polars.selectors as cs\n>>> df.select(cs.temporal().dt.to_string().name.prefix(\"s_\"))\nshape: (3, 4)\n┌────────────┬────────────────────────────┬─────────────────┬─────────────────┐\n│ s_dt       ┆ s_dtm                      ┆ s_tm            ┆ s_td            │\n│ ---        ┆ ---                        ┆ ---             ┆ ---             │\n│ str        ┆ str                        ┆ str             ┆ str             │\n╞════════════╪════════════════════════════╪═════════════════╪═════════════════╡\n│ 1999-03-01 ┆ 1980-08-10 00:10:20.000000 ┆ 01:02:03.456789 ┆ -P1DT42S        │\n│ 2020-05-03 ┆ 2010-10-20 08:25:35.000000 ┆ 23:59:09.000101 ┆ P13DT14H0.0001S │\n│ 2077-07-05 ┆ 2040-12-30 16:40:50.000000 ┆ 00:00:00.000100 ┆ PT0S            │\n└────────────┴────────────────────────────┴─────────────────┴─────────────────┘", ">>> df.select(\n...     pl.col(\"dtm\").dt.to_string(\"iso\").alias(\"dtm_iso\"),\n...     pl.col(\"dtm\").dt.to_string(\"iso:strict\").alias(\"dtm_iso_strict\"),\n... )\nshape: (3, 2)\n┌────────────────────────────┬────────────────────────────┐\n│ dtm_iso                    ┆ dtm_iso_strict             │\n│ ---                        ┆ ---                        │\n│ str                        ┆ str                        │\n╞════════════════════════════╪════════════════════════════╡\n│ 1980-08-10 00:10:20.000000 ┆ 1980-08-10T00:10:20.000000 │\n│ 2010-10-20 08:25:35.000000 ┆ 2010-10-20T08:25:35.000000 │\n│ 2040-12-30 16:40:50.000000 ┆ 2040-12-30T16:40:50.000000 │\n└────────────────────────────┴────────────────────────────┘", ">>> df.select(\n...     pl.col(\"dtm\"),\n...     s_dtm=pl.col(\"dtm\").dt.to_string(\"%Y/%m/%d (%H.%M.%S)\"),\n... )\nshape: (3, 2)\n┌─────────────────────┬───────────────────────┐\n│ dtm                 ┆ s_dtm                 │\n│ ---                 ┆ ---                   │\n│ datetime[μs]        ┆ str                   │\n╞═════════════════════╪═══════════════════════╡\n│ 1980-08-10 00:10:20 ┆ 1980/08/10 (00.10.20) │\n│ 2010-10-20 08:25:35 ┆ 2010/10/20 (08.25.35) │\n│ 2040-12-30 16:40:50 ┆ 2040/12/30 (16.40.50) │\n└─────────────────────┴───────────────────────┘", ">>> df.select(\n...     pl.col(\"td\"),\n...     s_td=pl.col(\"td\").dt.to_string(\"polars\"),\n... )\nshape: (3, 2)\n┌───────────────┬───────────────┐\n│ td            ┆ s_td          │\n│ ---           ┆ ---           │\n│ duration[μs]  ┆ str           │\n╞═══════════════╪═══════════════╡\n│ -1d -42s      ┆ -1d -42s      │\n│ 13d 14h 100µs ┆ 13d 14h 100µs │\n│ 0µs           ┆ 0µs           │\n└───────────────┴───────────────┘", ">>> df.select(\n...     pl.col(\"dt\"),\n...     day_name=pl.col(\"dtm\").dt.to_string(\"%A\"),\n...     month_name=pl.col(\"dtm\").dt.to_string(\"%B\"),\n... )\nshape: (3, 3)\n┌────────────┬───────────┬────────────┐\n│ dt         ┆ day_name  ┆ month_name │\n│ ---        ┆ ---       ┆ ---        │\n│ date       ┆ str       ┆ str        │\n╞════════════╪═══════════╪════════════╡\n│ 1999-03-01 ┆ Sunday    ┆ August     │\n│ 2020-05-03 ┆ Wednesday ┆ October    │\n│ 2077-07-05 ┆ Sunday    ┆ December   │\n└────────────┴───────────┴────────────┘"], "Parameters": [["format", "Format to use, refer to the chrono strftime documentation for specification. Example: \"%y-%m-%d\" . If no format is provided, the appropriate ISO format for the underlying\ndata type is used. This can be made explicit by passing \"iso\" or \"iso:strict\" as the format string (see notes below for details)."]], "Returns": [], "Category": ["Temporal"], "index": 386}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_days.html#polars.Expr.dt.total_days"], "Title": ["Expr.dt.total_days"], "Feature": ["Expr.dt.total_days"], "Description": ["Extract the total days from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 3, 1), datetime(2020, 5, 1), \"1mo\", eager=True\n...         ),\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"date\"),\n...         pl.col(\"date\").diff().dt.total_days().alias(\"days_diff\"),\n...     ]\n... )\nshape: (3, 2)\n┌─────────────────────┬───────────┐\n│ date                ┆ days_diff │\n│ ---                 ┆ ---       │\n│ datetime[μs]        ┆ i64       │\n╞═════════════════════╪═══════════╡\n│ 2020-03-01 00:00:00 ┆ null      │\n│ 2020-04-01 00:00:00 ┆ 31        │\n│ 2020-05-01 00:00:00 ┆ 30        │\n└─────────────────────┴───────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 387}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_hours.html#polars.Expr.dt.total_hours"], "Title": ["Expr.dt.total_hours"], "Feature": ["Expr.dt.total_hours"], "Description": ["Extract the total hours from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 1, 1), datetime(2020, 1, 4), \"1d\", eager=True\n...         ),\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"date\"),\n...         pl.col(\"date\").diff().dt.total_hours().alias(\"hours_diff\"),\n...     ]\n... )\nshape: (4, 2)\n┌─────────────────────┬────────────┐\n│ date                ┆ hours_diff │\n│ ---                 ┆ ---        │\n│ datetime[μs]        ┆ i64        │\n╞═════════════════════╪════════════╡\n│ 2020-01-01 00:00:00 ┆ null       │\n│ 2020-01-02 00:00:00 ┆ 24         │\n│ 2020-01-03 00:00:00 ┆ 24         │\n│ 2020-01-04 00:00:00 ┆ 24         │\n└─────────────────────┴────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 388}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_microseconds.html#polars.Expr.dt.total_microseconds"], "Title": ["Expr.dt.total_microseconds"], "Feature": ["Expr.dt.total_microseconds"], "Description": ["Extract the total microseconds from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 1, 1),\n...             datetime(2020, 1, 1, 0, 0, 1, 0),\n...             \"200ms\",\n...             eager=True,\n...         ),\n...     }\n... )\n>>> df.select(\n...     pl.col(\"date\"),\n...     milliseconds_diff=pl.col(\"date\").diff().dt.total_microseconds(),\n... )\nshape: (6, 2)\n┌─────────────────────────┬───────────────────┐\n│ date                    ┆ milliseconds_diff │\n│ ---                     ┆ ---               │\n│ datetime[μs]            ┆ i64               │\n╞═════════════════════════╪═══════════════════╡\n│ 2020-01-01 00:00:00     ┆ null              │\n│ 2020-01-01 00:00:00.200 ┆ 200000            │\n│ 2020-01-01 00:00:00.400 ┆ 200000            │\n│ 2020-01-01 00:00:00.600 ┆ 200000            │\n│ 2020-01-01 00:00:00.800 ┆ 200000            │\n│ 2020-01-01 00:00:01     ┆ 200000            │\n└─────────────────────────┴───────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 389}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.sort.html#polars.Expr.arr.sort"], "Title": ["Expr.arr.sort"], "Feature": ["Expr.arr.sort"], "Description": ["Sort the arrays in this column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[3, 2, 1], [9, 1, 2]],\n...     },\n...     schema={\"a\": pl.Array(pl.Int64, 3)},\n... )\n>>> df.with_columns(sort=pl.col(\"a\").arr.sort())\nshape: (2, 2)\n┌───────────────┬───────────────┐\n│ a             ┆ sort          │\n│ ---           ┆ ---           │\n│ array[i64, 3] ┆ array[i64, 3] │\n╞═══════════════╪═══════════════╡\n│ [3, 2, 1]     ┆ [1, 2, 3]     │\n│ [9, 1, 2]     ┆ [1, 2, 9]     │\n└───────────────┴───────────────┘\n>>> df.with_columns(sort=pl.col(\"a\").arr.sort(descending=True))\nshape: (2, 2)\n┌───────────────┬───────────────┐\n│ a             ┆ sort          │\n│ ---           ┆ ---           │\n│ array[i64, 3] ┆ array[i64, 3] │\n╞═══════════════╪═══════════════╡\n│ [3, 2, 1]     ┆ [3, 2, 1]     │\n│ [9, 1, 2]     ┆ [9, 2, 1]     │\n└───────────────┴───────────────┘"], "Parameters": [["descending", "Sort in descending order."], ["nulls_last", "Place null values last."]], "Returns": [], "Category": ["Array"], "index": 390}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_milliseconds.html#polars.Expr.dt.total_milliseconds"], "Title": ["Expr.dt.total_milliseconds"], "Feature": ["Expr.dt.total_milliseconds"], "Description": ["Extract the total milliseconds from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 1, 1),\n...             datetime(2020, 1, 1, 0, 0, 1, 0),\n...             \"200ms\",\n...             eager=True,\n...         ),\n...     }\n... )\n>>> df.select(\n...     pl.col(\"date\"),\n...     milliseconds_diff=pl.col(\"date\").diff().dt.total_milliseconds(),\n... )\nshape: (6, 2)\n┌─────────────────────────┬───────────────────┐\n│ date                    ┆ milliseconds_diff │\n│ ---                     ┆ ---               │\n│ datetime[μs]            ┆ i64               │\n╞═════════════════════════╪═══════════════════╡\n│ 2020-01-01 00:00:00     ┆ null              │\n│ 2020-01-01 00:00:00.200 ┆ 200               │\n│ 2020-01-01 00:00:00.400 ┆ 200               │\n│ 2020-01-01 00:00:00.600 ┆ 200               │\n│ 2020-01-01 00:00:00.800 ┆ 200               │\n│ 2020-01-01 00:00:01     ┆ 200               │\n└─────────────────────────┴───────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 391}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_minutes.html#polars.Expr.dt.total_minutes"], "Title": ["Expr.dt.total_minutes"], "Feature": ["Expr.dt.total_minutes"], "Description": ["Extract the total minutes from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 1, 1), datetime(2020, 1, 4), \"1d\", eager=True\n...         ),\n...     }\n... )\n>>> df.select(\n...     [\n...         pl.col(\"date\"),\n...         pl.col(\"date\").diff().dt.total_minutes().alias(\"minutes_diff\"),\n...     ]\n... )\nshape: (4, 2)\n┌─────────────────────┬──────────────┐\n│ date                ┆ minutes_diff │\n│ ---                 ┆ ---          │\n│ datetime[μs]        ┆ i64          │\n╞═════════════════════╪══════════════╡\n│ 2020-01-01 00:00:00 ┆ null         │\n│ 2020-01-02 00:00:00 ┆ 1440         │\n│ 2020-01-03 00:00:00 ┆ 1440         │\n│ 2020-01-04 00:00:00 ┆ 1440         │\n└─────────────────────┴──────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 392}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_nanoseconds.html#polars.Expr.dt.total_nanoseconds"], "Title": ["Expr.dt.total_nanoseconds"], "Feature": ["Expr.dt.total_nanoseconds"], "Description": ["Extract the total nanoseconds from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 1, 1),\n...             datetime(2020, 1, 1, 0, 0, 1, 0),\n...             \"200ms\",\n...             eager=True,\n...         ),\n...     }\n... )\n>>> df.select(\n...     pl.col(\"date\"),\n...     milliseconds_diff=pl.col(\"date\").diff().dt.total_nanoseconds(),\n... )\nshape: (6, 2)\n┌─────────────────────────┬───────────────────┐\n│ date                    ┆ milliseconds_diff │\n│ ---                     ┆ ---               │\n│ datetime[μs]            ┆ i64               │\n╞═════════════════════════╪═══════════════════╡\n│ 2020-01-01 00:00:00     ┆ null              │\n│ 2020-01-01 00:00:00.200 ┆ 200000000         │\n│ 2020-01-01 00:00:00.400 ┆ 200000000         │\n│ 2020-01-01 00:00:00.600 ┆ 200000000         │\n│ 2020-01-01 00:00:00.800 ┆ 200000000         │\n│ 2020-01-01 00:00:01     ┆ 200000000         │\n└─────────────────────────┴───────────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 393}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.total_seconds.html#polars.Expr.dt.total_seconds"], "Title": ["Expr.dt.total_seconds"], "Feature": ["Expr.dt.total_seconds"], "Description": ["Extract the total seconds from a Duration type."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2020, 1, 1),\n...             datetime(2020, 1, 1, 0, 4, 0),\n...             \"1m\",\n...             eager=True,\n...         ),\n...     }\n... )\n>>> df.select(\n...     pl.col(\"date\"),\n...     pl.col(\"date\").diff().dt.total_seconds().alias(\"seconds_diff\"),\n... )\nshape: (5, 2)\n┌─────────────────────┬──────────────┐\n│ date                ┆ seconds_diff │\n│ ---                 ┆ ---          │\n│ datetime[μs]        ┆ i64          │\n╞═════════════════════╪══════════════╡\n│ 2020-01-01 00:00:00 ┆ null         │\n│ 2020-01-01 00:01:00 ┆ 60           │\n│ 2020-01-01 00:02:00 ┆ 60           │\n│ 2020-01-01 00:03:00 ┆ 60           │\n│ 2020-01-01 00:04:00 ┆ 60           │\n└─────────────────────┴──────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int64 ."]], "Category": ["Temporal"], "index": 394}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.truncate.html#polars.Expr.dt.truncate"], "Title": ["Expr.dt.truncate"], "Feature": ["Expr.dt.truncate"], "Description": ["Divide the date/datetime range into buckets."], "Examples": [">>> from datetime import timedelta, datetime\n>>> df = (\n...     pl.datetime_range(\n...         datetime(2001, 1, 1),\n...         datetime(2001, 1, 2),\n...         timedelta(minutes=225),\n...         eager=True,\n...     )\n...     .alias(\"datetime\")\n...     .to_frame()\n... )\n>>> df\nshape: (7, 1)\n┌─────────────────────┐\n│ datetime            │\n│ ---                 │\n│ datetime[μs]        │\n╞═════════════════════╡\n│ 2001-01-01 00:00:00 │\n│ 2001-01-01 03:45:00 │\n│ 2001-01-01 07:30:00 │\n│ 2001-01-01 11:15:00 │\n│ 2001-01-01 15:00:00 │\n│ 2001-01-01 18:45:00 │\n│ 2001-01-01 22:30:00 │\n└─────────────────────┘\n>>> df.select(pl.col(\"datetime\").dt.truncate(\"1h\"))\nshape: (7, 1)\n┌─────────────────────┐\n│ datetime            │\n│ ---                 │\n│ datetime[μs]        │\n╞═════════════════════╡\n│ 2001-01-01 00:00:00 │\n│ 2001-01-01 03:00:00 │\n│ 2001-01-01 07:00:00 │\n│ 2001-01-01 11:00:00 │\n│ 2001-01-01 15:00:00 │\n│ 2001-01-01 18:00:00 │\n│ 2001-01-01 22:00:00 │\n└─────────────────────┘\n>>> truncate_str = df.select(pl.col(\"datetime\").dt.truncate(\"1h\"))\n>>> truncate_td = df.select(pl.col(\"datetime\").dt.truncate(timedelta(hours=1)))\n>>> truncate_str.equals(truncate_td)\nTrue", ">>> df = (\n...     pl.datetime_range(\n...         datetime(2001, 1, 1), datetime(2001, 1, 1, 1), \"10m\", eager=True\n...     )\n...     .alias(\"datetime\")\n...     .to_frame()\n... )\n>>> df.select(\n...     \"datetime\", pl.col(\"datetime\").dt.truncate(\"30m\").alias(\"truncate\")\n... )\nshape: (7, 2)\n┌─────────────────────┬─────────────────────┐\n│ datetime            ┆ truncate            │\n│ ---                 ┆ ---                 │\n│ datetime[μs]        ┆ datetime[μs]        │\n╞═════════════════════╪═════════════════════╡\n│ 2001-01-01 00:00:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-01 00:10:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-01 00:20:00 ┆ 2001-01-01 00:00:00 │\n│ 2001-01-01 00:30:00 ┆ 2001-01-01 00:30:00 │\n│ 2001-01-01 00:40:00 ┆ 2001-01-01 00:30:00 │\n│ 2001-01-01 00:50:00 ┆ 2001-01-01 00:30:00 │\n│ 2001-01-01 01:00:00 ┆ 2001-01-01 01:00:00 │\n└─────────────────────┴─────────────────────┘"], "Parameters": [["every", "The size of each bucket."]], "Returns": [["Expr", "Expression of data type Date or Datetime ."]], "Category": ["Temporal"], "index": 395}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.week.html#polars.Expr.dt.week"], "Title": ["Expr.dt.week"], "Feature": ["Expr.dt.week"], "Description": ["Extract the week from the underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\"date\": [date(2001, 1, 1), date(2001, 6, 30), date(2001, 12, 27)]}\n... )\n>>> df.with_columns(pl.col(\"date\").dt.week().alias(\"week\"))\nshape: (3, 2)\n┌────────────┬──────┐\n│ date       ┆ week │\n│ ---        ┆ ---  │\n│ date       ┆ i8   │\n╞════════════╪══════╡\n│ 2001-01-01 ┆ 1    │\n│ 2001-06-30 ┆ 26   │\n│ 2001-12-27 ┆ 52   │\n└────────────┴──────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 396}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.weekday.html#polars.Expr.dt.weekday"], "Title": ["Expr.dt.weekday"], "Feature": ["Expr.dt.weekday"], "Description": ["Extract the week day from the underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.date_range(\n...             date(2001, 12, 22), date(2001, 12, 25), eager=True\n...         )\n...     }\n... )\n>>> df.with_columns(\n...     pl.col(\"date\").dt.weekday().alias(\"weekday\"),\n...     pl.col(\"date\").dt.day().alias(\"day_of_month\"),\n...     pl.col(\"date\").dt.ordinal_day().alias(\"day_of_year\"),\n... )\nshape: (4, 4)\n┌────────────┬─────────┬──────────────┬─────────────┐\n│ date       ┆ weekday ┆ day_of_month ┆ day_of_year │\n│ ---        ┆ ---     ┆ ---          ┆ ---         │\n│ date       ┆ i8      ┆ i8           ┆ i16         │\n╞════════════╪═════════╪══════════════╪═════════════╡\n│ 2001-12-22 ┆ 6       ┆ 22           ┆ 356         │\n│ 2001-12-23 ┆ 7       ┆ 23           ┆ 357         │\n│ 2001-12-24 ┆ 1       ┆ 24           ┆ 358         │\n│ 2001-12-25 ┆ 2       ┆ 25           ┆ 359         │\n└────────────┴─────────┴──────────────┴─────────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int8 ."]], "Category": ["Temporal"], "index": 397}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.with_time_unit.html#polars.Expr.dt.with_time_unit"], "Title": ["Expr.dt.with_time_unit"], "Feature": ["Expr.dt.with_time_unit"], "Description": ["Set time unit of an expression of dtype Datetime or Duration."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"date\": pl.datetime_range(\n...             datetime(2001, 1, 1),\n...             datetime(2001, 1, 3),\n...             \"1d\",\n...             time_unit=\"ns\",\n...             eager=True,\n...         )\n...     }\n... )\n>>> df.select(\n...     pl.col(\"date\"),\n...     pl.col(\"date\").dt.with_time_unit(\"us\").alias(\"time_unit_us\"),\n... )  \nshape: (3, 2)\n┌─────────────────────┬───────────────────────┐\n│ date                ┆ time_unit_us          │\n│ ---                 ┆ ---                   │\n│ datetime[ns]        ┆ datetime[μs]          │\n╞═════════════════════╪═══════════════════════╡\n│ 2001-01-01 00:00:00 ┆ +32971-04-28 00:00:00 │\n│ 2001-01-02 00:00:00 ┆ +32974-01-22 00:00:00 │\n│ 2001-01-03 00:00:00 ┆ +32976-10-18 00:00:00 │\n└─────────────────────┴───────────────────────┘"], "Parameters": [["time_unit {‘ns’, ‘us’, ‘ms’}", "Unit of time for the Datetime or Duration expression."]], "Returns": [], "Category": ["Temporal"], "index": 398}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.year.html#polars.Expr.dt.year"], "Title": ["Expr.dt.year"], "Feature": ["Expr.dt.year"], "Description": ["Extract year from underlying Date representation."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\"date\": [date(1977, 1, 1), date(1978, 1, 1), date(1979, 1, 1)]}\n... )\n>>> df.with_columns(\n...     calendar_year=pl.col(\"date\").dt.year(),\n...     iso_year=pl.col(\"date\").dt.iso_year(),\n... )\nshape: (3, 3)\n┌────────────┬───────────────┬──────────┐\n│ date       ┆ calendar_year ┆ iso_year │\n│ ---        ┆ ---           ┆ ---      │\n│ date       ┆ i32           ┆ i32      │\n╞════════════╪═══════════════╪══════════╡\n│ 1977-01-01 ┆ 1977          ┆ 1976     │\n│ 1978-01-01 ┆ 1978          ┆ 1977     │\n│ 1979-01-01 ┆ 1979          ┆ 1979     │\n└────────────┴───────────────┴──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Int32 ."]], "Category": ["Temporal"], "index": 399}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.over.html#polars.Expr.over"], "Title": ["Expr.over"], "Feature": ["Expr.over"], "Description": ["Compute expressions over the given groups."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"a\", \"b\", \"b\", \"b\"],\n...         \"b\": [1, 2, 3, 5, 3],\n...         \"c\": [5, 4, 3, 2, 1],\n...     }\n... )\n>>> df.with_columns(c_max=pl.col(\"c\").max().over(\"a\"))\nshape: (5, 4)\n┌─────┬─────┬─────┬───────┐\n│ a   ┆ b   ┆ c   ┆ c_max │\n│ --- ┆ --- ┆ --- ┆ ---   │\n│ str ┆ i64 ┆ i64 ┆ i64   │\n╞═════╪═════╪═════╪═══════╡\n│ a   ┆ 1   ┆ 5   ┆ 5     │\n│ a   ┆ 2   ┆ 4   ┆ 5     │\n│ b   ┆ 3   ┆ 3   ┆ 3     │\n│ b   ┆ 5   ┆ 2   ┆ 3     │\n│ b   ┆ 3   ┆ 1   ┆ 3     │\n└─────┴─────┴─────┴───────┘", ">>> df.with_columns(c_max=pl.col(\"c\").max().over(pl.col(\"b\") // 2))\nshape: (5, 4)\n┌─────┬─────┬─────┬───────┐\n│ a   ┆ b   ┆ c   ┆ c_max │\n│ --- ┆ --- ┆ --- ┆ ---   │\n│ str ┆ i64 ┆ i64 ┆ i64   │\n╞═════╪═════╪═════╪═══════╡\n│ a   ┆ 1   ┆ 5   ┆ 5     │\n│ a   ┆ 2   ┆ 4   ┆ 4     │\n│ b   ┆ 3   ┆ 3   ┆ 4     │\n│ b   ┆ 5   ┆ 2   ┆ 2     │\n│ b   ┆ 3   ┆ 1   ┆ 4     │\n└─────┴─────┴─────┴───────┘", ">>> df.with_columns(c_min=pl.col(\"c\").min().over(\"a\", pl.col(\"b\") % 2))\nshape: (5, 4)\n┌─────┬─────┬─────┬───────┐\n│ a   ┆ b   ┆ c   ┆ c_min │\n│ --- ┆ --- ┆ --- ┆ ---   │\n│ str ┆ i64 ┆ i64 ┆ i64   │\n╞═════╪═════╪═════╪═══════╡\n│ a   ┆ 1   ┆ 5   ┆ 5     │\n│ a   ┆ 2   ┆ 4   ┆ 4     │\n│ b   ┆ 3   ┆ 3   ┆ 1     │\n│ b   ┆ 5   ┆ 2   ┆ 1     │\n│ b   ┆ 3   ┆ 1   ┆ 1     │\n└─────┴─────┴─────┴───────┘", ">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"store_id\": [\"a\", \"a\", \"b\", \"b\"],\n...         \"date\": [\n...             date(2024, 9, 18),\n...             date(2024, 9, 17),\n...             date(2024, 9, 18),\n...             date(2024, 9, 16),\n...         ],\n...         \"sales\": [7, 9, 8, 10],\n...     }\n... )\n>>> df.with_columns(\n...     cumulative_sales=pl.col(\"sales\")\n...     .cum_sum()\n...     .over(\"store_id\", order_by=\"date\")\n... )\nshape: (4, 4)\n┌──────────┬────────────┬───────┬──────────────────┐\n│ store_id ┆ date       ┆ sales ┆ cumulative_sales │\n│ ---      ┆ ---        ┆ ---   ┆ ---              │\n│ str      ┆ date       ┆ i64   ┆ i64              │\n╞══════════╪════════════╪═══════╪══════════════════╡\n│ a        ┆ 2024-09-18 ┆ 7     ┆ 16               │\n│ a        ┆ 2024-09-17 ┆ 9     ┆ 9                │\n│ b        ┆ 2024-09-18 ┆ 8     ┆ 18               │\n│ b        ┆ 2024-09-16 ┆ 10    ┆ 10               │\n└──────────┴────────────┴───────┴──────────────────┘", ">>> window = {\n...     \"partition_by\": \"store_id\",\n...     \"order_by\": \"date\",\n...     \"mapping_strategy\": \"explode\",\n... }\n>>> df.select(\n...     pl.all().over(**window),\n...     cumulative_sales=pl.col(\"sales\").cum_sum().over(**window),\n... )\nshape: (4, 4)\n┌──────────┬────────────┬───────┬──────────────────┐\n│ store_id ┆ date       ┆ sales ┆ cumulative_sales │\n│ ---      ┆ ---        ┆ ---   ┆ ---              │\n│ str      ┆ date       ┆ i64   ┆ i64              │\n╞══════════╪════════════╪═══════╪══════════════════╡\n│ a        ┆ 2024-09-17 ┆ 9     ┆ 9                │\n│ a        ┆ 2024-09-18 ┆ 7     ┆ 16               │\n│ b        ┆ 2024-09-16 ┆ 10    ┆ 10               │\n│ b        ┆ 2024-09-18 ┆ 8     ┆ 18               │\n└──────────┴────────────┴───────┴──────────────────┘"], "Parameters": [["partition_by", "Column(s) to group by. Accepts expression input. Strings are parsed as\ncolumn names."], ["*more_exprs", "Additional columns to group by, specified as positional arguments."], ["order_by", "Order the window functions/aggregations with the partitioned groups by the\nresult of the expression passed to order_by ."], ["descending", "In case ‘order_by’ is given, indicate whether to order in\nascending or descending order."], ["nulls_last", "In case ‘order_by’ is given, indicate whether to order\nthe nulls in last position."], ["mapping_strategy: {‘group_to_rows’, ‘join’, ‘explode’}", "group_to_rows If the aggregation results in multiple values, assign them back to their\nposition in the DataFrame. This can only be done if the group yields\nthe same elements before aggregation as after. join Join the groups as ‘List<group_dtype>’ to the row positions.\nwarning: this can be memory intensive. explode Explodes the grouped data into new rows, similar to the results of group_by + agg + explode . Sorting of the given groups is required\nif the groups are not part of the window operation for the operation,\notherwise the result would not make sense. This operation changes the\nnumber of rows."], ["group_to_rows", "If the aggregation results in multiple values, assign them back to their\nposition in the DataFrame. This can only be done if the group yields\nthe same elements before aggregation as after."], ["join", "Join the groups as ‘List<group_dtype>’ to the row positions.\nwarning: this can be memory intensive."], ["explode", "Explodes the grouped data into new rows, similar to the results of group_by + agg + explode . Sorting of the given groups is required\nif the groups are not part of the window operation for the operation,\notherwise the result would not make sense. This operation changes the\nnumber of rows."]], "Returns": [], "Category": ["Window"], "index": 400}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.std.html#polars.Expr.arr.std"], "Title": ["Expr.arr.std"], "Feature": ["Expr.arr.std"], "Description": ["Compute the std of the values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [4, 3]]},\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.std())\nshape: (2, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.707107 │\n│ 0.707107 │\n└──────────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 401}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.rolling.html#polars.Expr.rolling"], "Title": ["Expr.rolling"], "Feature": ["Expr.rolling"], "Description": ["Create rolling groups based on a temporal or integer column."], "Examples": [">>> dates = [\n...     \"2020-01-01 13:45:48\",\n...     \"2020-01-01 16:42:13\",\n...     \"2020-01-01 16:45:09\",\n...     \"2020-01-02 18:12:48\",\n...     \"2020-01-03 19:45:32\",\n...     \"2020-01-08 23:16:43\",\n... ]\n>>> df = pl.DataFrame({\"dt\": dates, \"a\": [3, 7, 5, 9, 2, 1]}).with_columns(\n...     pl.col(\"dt\").str.strptime(pl.Datetime).set_sorted()\n... )\n>>> df.with_columns(\n...     sum_a=pl.sum(\"a\").rolling(index_column=\"dt\", period=\"2d\"),\n...     min_a=pl.min(\"a\").rolling(index_column=\"dt\", period=\"2d\"),\n...     max_a=pl.max(\"a\").rolling(index_column=\"dt\", period=\"2d\"),\n... )\nshape: (6, 5)\n┌─────────────────────┬─────┬───────┬───────┬───────┐\n│ dt                  ┆ a   ┆ sum_a ┆ min_a ┆ max_a │\n│ ---                 ┆ --- ┆ ---   ┆ ---   ┆ ---   │\n│ datetime[μs]        ┆ i64 ┆ i64   ┆ i64   ┆ i64   │\n╞═════════════════════╪═════╪═══════╪═══════╪═══════╡\n│ 2020-01-01 13:45:48 ┆ 3   ┆ 3     ┆ 3     ┆ 3     │\n│ 2020-01-01 16:42:13 ┆ 7   ┆ 10    ┆ 3     ┆ 7     │\n│ 2020-01-01 16:45:09 ┆ 5   ┆ 15    ┆ 3     ┆ 7     │\n│ 2020-01-02 18:12:48 ┆ 9   ┆ 24    ┆ 3     ┆ 9     │\n│ 2020-01-03 19:45:32 ┆ 2   ┆ 11    ┆ 2     ┆ 9     │\n│ 2020-01-08 23:16:43 ┆ 1   ┆ 1     ┆ 1     ┆ 1     │\n└─────────────────────┴─────┴───────┴───────┴───────┘"], "Parameters": [["index_column", "Column used to group based on the time window.\nOften of type Date/Datetime.\nThis column must be sorted in ascending order.\nIn case of a rolling group by on indices, dtype needs to be one of\n{UInt32, UInt64, Int32, Int64}. Note that the first three get temporarily\ncast to Int64, so if performance matters use an Int64 column."], ["period", "Length of the window - must be non-negative."], ["offset", "Offset of the window. Default is -period ."], ["closed {‘right’, ‘left’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive)."]], "Returns": [], "Category": ["Window"], "index": 402}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.sum.html#polars.Expr.arr.sum"], "Title": ["Expr.arr.sum"], "Feature": ["Expr.arr.sum"], "Description": ["Compute the sum values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [4, 3]]},\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.sum())\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 3   │\n│ 7   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 403}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.to_list.html#polars.Expr.arr.to_list"], "Title": ["Expr.arr.to_list"], "Feature": ["Expr.arr.to_list"], "Description": ["Convert an Array column into a List column with the same inner data type."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [3, 4]]},\n...     schema={\"a\": pl.Array(pl.Int8, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.to_list())\nshape: (2, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ list[i8] │\n╞══════════╡\n│ [1, 2]   │\n│ [3, 4]   │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type List ."]], "Category": ["Array"], "index": 404}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.to_struct.html#polars.Expr.arr.to_struct"], "Title": ["Expr.arr.to_struct"], "Feature": ["Expr.arr.to_struct"], "Description": ["Convert the Series of typeArrayto a Series of typeStruct."], "Examples": [">>> df = pl.DataFrame(\n...     {\"n\": [[0, 1, 2], [3, 4, 5]]}, schema={\"n\": pl.Array(pl.Int8, 3)}\n... )\n>>> df.with_columns(struct=pl.col(\"n\").arr.to_struct())\nshape: (2, 2)\n┌──────────────┬───────────┐\n│ n            ┆ struct    │\n│ ---          ┆ ---       │\n│ array[i8, 3] ┆ struct[3] │\n╞══════════════╪═══════════╡\n│ [0, 1, 2]    ┆ {0,1,2}   │\n│ [3, 4, 5]    ┆ {3,4,5}   │\n└──────────────┴───────────┘", ">>> df = pl.DataFrame(\n...     {\"n\": [[0, 1, 2], [3, 4, 5]]}, schema={\"n\": pl.Array(pl.Int8, 3)}\n... )\n>>> df.select(pl.col(\"n\").arr.to_struct(fields=lambda idx: f\"n{idx}\")).rows(\n...     named=True\n... )\n[{'n': {'n0': 0, 'n1': 1, 'n2': 2}}, {'n': {'n0': 3, 'n1': 4, 'n2': 5}}]", ">>> df.select(pl.col(\"n\").arr.to_struct(fields=[\"c1\", \"c2\", \"c3\"])).rows(\n...     named=True\n... )\n[{'n': {'c1': 0, 'c2': 1, 'c3': 2}}, {'n': {'c1': 3, 'c2': 4, 'c3': 5}}]"], "Parameters": [["fields", "If the name and number of the desired fields is known in advance\na list of field names can be given, which will be assigned by index.\nOtherwise, to dynamically assign field names, a custom function can be\nused; if neither are set, fields will be field_0, field_1 .. field_n ."]], "Returns": [], "Category": ["Array"], "index": 405}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arg_min.html#polars.Expr.arg_min"], "Title": ["Expr.arg_min"], "Feature": ["Expr.arg_min"], "Description": ["Get the index of the minimal value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [20, 10, 30],\n...     }\n... )\n>>> df.select(pl.col(\"a\").arg_min())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 1   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 406}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.unique.html#polars.Expr.arr.unique"], "Title": ["Expr.arr.unique"], "Feature": ["Expr.arr.unique"], "Description": ["Get the unique/distinct values in the array."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [[1, 1, 2]],\n...     },\n...     schema={\"a\": pl.Array(pl.Int64, 3)},\n... )\n>>> df.select(pl.col(\"a\").arr.unique())\nshape: (1, 1)\n┌───────────┐\n│ a         │\n│ ---       │\n│ list[i64] │\n╞═══════════╡\n│ [1, 2]    │\n└───────────┘"], "Parameters": [["maintain_order", "Maintain order of data. This requires more work."]], "Returns": [], "Category": ["Array"], "index": 407}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.var.html#polars.Expr.arr.var"], "Title": ["Expr.arr.var"], "Feature": ["Expr.arr.var"], "Description": ["Compute the var of the values of the sub-arrays."], "Examples": [">>> df = pl.DataFrame(\n...     data={\"a\": [[1, 2], [4, 3]]},\n...     schema={\"a\": pl.Array(pl.Int64, 2)},\n... )\n>>> df.select(pl.col(\"a\").arr.var())\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.5 │\n│ 0.5 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Array"], "index": 408}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.all.html#polars.Expr.all"], "Title": ["Expr.all"], "Feature": ["Expr.all"], "Description": ["Return whether all values in the column areTrue."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, True],\n...         \"b\": [False, True],\n...         \"c\": [None, True],\n...     }\n... )\n>>> df.select(pl.col(\"*\").all())\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ true │\n└──────┴───────┴──────┘", ">>> df.select(pl.col(\"*\").all(ignore_nulls=False))\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ null │\n└──────┴───────┴──────┘"], "Parameters": [["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is True . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no False values,\nthe output is null."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 409}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.any.html#polars.Expr.any"], "Title": ["Expr.any"], "Feature": ["Expr.any"], "Description": ["Return whether any of the values in the column areTrue."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [True, False],\n...         \"b\": [False, False],\n...         \"c\": [None, False],\n...     }\n... )\n>>> df.select(pl.col(\"*\").any())\nshape: (1, 3)\n┌──────┬───────┬───────┐\n│ a    ┆ b     ┆ c     │\n│ ---  ┆ ---   ┆ ---   │\n│ bool ┆ bool  ┆ bool  │\n╞══════╪═══════╪═══════╡\n│ true ┆ false ┆ false │\n└──────┴───────┴───────┘", ">>> df.select(pl.col(\"*\").any(ignore_nulls=False))\nshape: (1, 3)\n┌──────┬───────┬──────┐\n│ a    ┆ b     ┆ c    │\n│ ---  ┆ ---   ┆ ---  │\n│ bool ┆ bool  ┆ bool │\n╞══════╪═══════╪══════╡\n│ true ┆ false ┆ null │\n└──────┴───────┴──────┘"], "Parameters": [["ignore_nulls", "If set to True (default), null values are ignored. If there\nare no non-null values, the output is False . If set to False , Kleene logic is used to deal with nulls:\nif the column contains any null values and no True values,\nthe output is null."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 410}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.has_nulls.html#polars.Expr.has_nulls"], "Title": ["Expr.has_nulls"], "Feature": ["Expr.has_nulls"], "Description": ["Check whether the expression contains one or more null values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [None, 1, None],\n...         \"b\": [10, None, 300],\n...         \"c\": [350, 650, 850],\n...     }\n... )\n>>> df.select(pl.all().has_nulls())\nshape: (1, 3)\n┌──────┬──────┬───────┐\n│ a    ┆ b    ┆ c     │\n│ ---  ┆ ---  ┆ ---   │\n│ bool ┆ bool ┆ bool  │\n╞══════╪══════╪═══════╡\n│ true ┆ true ┆ false │\n└──────┴──────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 411}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_between.html#polars.Expr.is_between"], "Title": ["Expr.is_between"], "Feature": ["Expr.is_between"], "Description": ["Check if this expression is between the given lower and upper bounds."], "Examples": [">>> df = pl.DataFrame({\"num\": [1, 2, 3, 4, 5]})\n>>> df.with_columns(pl.col(\"num\").is_between(2, 4).alias(\"is_between\"))\nshape: (5, 2)\n┌─────┬────────────┐\n│ num ┆ is_between │\n│ --- ┆ ---        │\n│ i64 ┆ bool       │\n╞═════╪════════════╡\n│ 1   ┆ false      │\n│ 2   ┆ true       │\n│ 3   ┆ true       │\n│ 4   ┆ true       │\n│ 5   ┆ false      │\n└─────┴────────────┘", ">>> df.with_columns(\n...     pl.col(\"num\").is_between(2, 4, closed=\"left\").alias(\"is_between\")\n... )\nshape: (5, 2)\n┌─────┬────────────┐\n│ num ┆ is_between │\n│ --- ┆ ---        │\n│ i64 ┆ bool       │\n╞═════╪════════════╡\n│ 1   ┆ false      │\n│ 2   ┆ true       │\n│ 3   ┆ true       │\n│ 4   ┆ false      │\n│ 5   ┆ false      │\n└─────┴────────────┘", ">>> df = pl.DataFrame({\"a\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n>>> df.with_columns(\n...     pl.col(\"a\")\n...     .is_between(pl.lit(\"a\"), pl.lit(\"c\"), closed=\"both\")\n...     .alias(\"is_between\")\n... )\nshape: (5, 2)\n┌─────┬────────────┐\n│ a   ┆ is_between │\n│ --- ┆ ---        │\n│ str ┆ bool       │\n╞═════╪════════════╡\n│ a   ┆ true       │\n│ b   ┆ true       │\n│ c   ┆ true       │\n│ d   ┆ false      │\n│ e   ┆ false      │\n└─────┴────────────┘", ">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4, 5], \"b\": [5, 4, 3, 2, 1]})\n>>> df.with_columns(\n...     pl.lit(3).is_between(pl.col(\"a\"), pl.col(\"b\")).alias(\"between_ab\")\n... )\nshape: (5, 3)\n┌─────┬─────┬────────────┐\n│ a   ┆ b   ┆ between_ab │\n│ --- ┆ --- ┆ ---        │\n│ i64 ┆ i64 ┆ bool       │\n╞═════╪═════╪════════════╡\n│ 1   ┆ 5   ┆ true       │\n│ 2   ┆ 4   ┆ true       │\n│ 3   ┆ 3   ┆ true       │\n│ 4   ┆ 2   ┆ false      │\n│ 5   ┆ 1   ┆ false      │\n└─────┴─────┴────────────┘"], "Parameters": [["lower_bound", "Lower bound value. Accepts expression input. Strings are parsed as column\nnames, other non-expression inputs are parsed as literals."], ["upper_bound", "Upper bound value. Accepts expression input. Strings are parsed as column\nnames, other non-expression inputs are parsed as literals."], ["closed {‘both’, ‘left’, ‘right’, ‘none’}", "Define which sides of the interval are closed (inclusive)."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 412}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_close.html#polars.Expr.is_close"], "Title": ["Expr.is_close"], "Feature": ["Expr.is_close"], "Description": ["Check if this expression is close, i.e. almost equal, to the other expression."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.5, 2.0, 2.5], \"b\": [1.55, 2.2, 3.0]})\n>>> df.with_columns(pl.col(\"a\").is_close(\"b\", abs_tol=0.1).alias(\"is_close\"))\nshape: (3, 3)\n┌─────┬──────┬──────────┐\n│ a   ┆ b    ┆ is_close │\n│ --- ┆ ---  ┆ ---      │\n│ f64 ┆ f64  ┆ bool     │\n╞═════╪══════╪══════════╡\n│ 1.5 ┆ 1.55 ┆ true     │\n│ 2.0 ┆ 2.2  ┆ false    │\n│ 2.5 ┆ 3.0  ┆ false    │\n└─────┴──────┴──────────┘"], "Parameters": [["abs_tol", "Absolute tolerance. This is the maximum allowed absolute difference between\ntwo values. Must be non-negative."], ["rel_tol", "Relative tolerance. This is the maximum allowed difference between two\nvalues, relative to the larger absolute value. Must be non-negative."], ["nans_equal", "Whether NaN values should be considered equal."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 413}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_duplicated.html#polars.Expr.is_duplicated"], "Title": ["Expr.is_duplicated"], "Feature": ["Expr.is_duplicated"], "Description": ["Return a boolean mask indicating duplicated values."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2]})\n>>> df.select(pl.col(\"a\").is_duplicated())\nshape: (3, 1)\n┌───────┐\n│ a     │\n│ ---   │\n│ bool  │\n╞═══════╡\n│ true  │\n│ true  │\n│ false │\n└───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 414}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_finite.html#polars.Expr.is_finite"], "Title": ["Expr.is_finite"], "Feature": ["Expr.is_finite"], "Description": ["Returns a boolean Series indicating which values are finite."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"A\": [1.0, 2],\n...         \"B\": [3.0, float(\"inf\")],\n...     }\n... )\n>>> df.select(pl.all().is_finite())\nshape: (2, 2)\n┌──────┬───────┐\n│ A    ┆ B     │\n│ ---  ┆ ---   │\n│ bool ┆ bool  │\n╞══════╪═══════╡\n│ true ┆ true  │\n│ true ┆ false │\n└──────┴───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 415}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_first_distinct.html#polars.Expr.is_first_distinct"], "Title": ["Expr.is_first_distinct"], "Feature": ["Expr.is_first_distinct"], "Description": ["Return a boolean mask indicating the first occurrence of each distinct value."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2, 3, 2]})\n>>> df.with_columns(pl.col(\"a\").is_first_distinct().alias(\"first\"))\nshape: (5, 2)\n┌─────┬───────┐\n│ a   ┆ first │\n│ --- ┆ ---   │\n│ i64 ┆ bool  │\n╞═════╪═══════╡\n│ 1   ┆ true  │\n│ 1   ┆ false │\n│ 2   ┆ true  │\n│ 3   ┆ true  │\n│ 2   ┆ false │\n└─────┴───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 416}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_and.html#polars.Expr.bitwise_and"], "Title": ["Expr.bitwise_and"], "Feature": ["Expr.bitwise_and"], "Description": ["Perform an aggregation of bitwise ANDs."], "Examples": [">>> df = pl.DataFrame({\"n\": [-1, 0, 1]})\n>>> df.select(pl.col(\"n\").bitwise_and())\nshape: (1, 1)\n┌─────┐\n│ n   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 0   │\n└─────┘\n>>> df = pl.DataFrame(\n...     {\"grouper\": [\"a\", \"a\", \"a\", \"b\", \"b\"], \"n\": [-1, 0, 1, -1, 1]}\n... )\n>>> df.group_by(\"grouper\", maintain_order=True).agg(pl.col(\"n\").bitwise_and())\nshape: (2, 2)\n┌─────────┬─────┐\n│ grouper ┆ n   │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ a       ┆ 0   │\n│ b       ┆ 1   │\n└─────────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 417}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_in.html#polars.Expr.is_in"], "Title": ["Expr.is_in"], "Feature": ["Expr.is_in"], "Description": ["Check if elements of this expression are present in the other Series."], "Examples": [">>> df = pl.DataFrame(\n...     {\"sets\": [[1, 2, 3], [1, 2], [9, 10]], \"optional_members\": [1, 2, 3]}\n... )\n>>> df.with_columns(contains=pl.col(\"optional_members\").is_in(\"sets\"))\nshape: (3, 3)\n┌───────────┬──────────────────┬──────────┐\n│ sets      ┆ optional_members ┆ contains │\n│ ---       ┆ ---              ┆ ---      │\n│ list[i64] ┆ i64              ┆ bool     │\n╞═══════════╪══════════════════╪══════════╡\n│ [1, 2, 3] ┆ 1                ┆ true     │\n│ [1, 2]    ┆ 2                ┆ true     │\n│ [9, 10]   ┆ 3                ┆ false    │\n└───────────┴──────────────────┴──────────┘"], "Parameters": [["other", "Series or sequence of primitive type."], ["nulls_equal bool, default False", "If True, treat null as a distinct value. Null values will not propagate."]], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 418}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_infinite.html#polars.Expr.is_infinite"], "Title": ["Expr.is_infinite"], "Feature": ["Expr.is_infinite"], "Description": ["Returns a boolean Series indicating which values are infinite."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"A\": [1.0, 2],\n...         \"B\": [3.0, float(\"inf\")],\n...     }\n... )\n>>> df.select(pl.all().is_infinite())\nshape: (2, 2)\n┌───────┬───────┐\n│ A     ┆ B     │\n│ ---   ┆ ---   │\n│ bool  ┆ bool  │\n╞═══════╪═══════╡\n│ false ┆ false │\n│ false ┆ true  │\n└───────┴───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 419}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_last_distinct.html#polars.Expr.is_last_distinct"], "Title": ["Expr.is_last_distinct"], "Feature": ["Expr.is_last_distinct"], "Description": ["Return a boolean mask indicating the last occurrence of each distinct value."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2, 3, 2]})\n>>> df.with_columns(pl.col(\"a\").is_last_distinct().alias(\"last\"))\nshape: (5, 2)\n┌─────┬───────┐\n│ a   ┆ last  │\n│ --- ┆ ---   │\n│ i64 ┆ bool  │\n╞═════╪═══════╡\n│ 1   ┆ false │\n│ 1   ┆ true  │\n│ 2   ┆ false │\n│ 3   ┆ true  │\n│ 2   ┆ true  │\n└─────┴───────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Boolean ."]], "Category": ["Boolean"], "index": 420}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_nan.html#polars.Expr.is_nan"], "Title": ["Expr.is_nan"], "Feature": ["Expr.is_nan"], "Description": ["Returns a boolean Series indicating which values are NaN."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None, 1, 5],\n...         \"b\": [1.0, 2.0, float(\"nan\"), 1.0, 5.0],\n...     }\n... )\n>>> df.with_columns(pl.col(pl.Float64).is_nan().name.suffix(\"_isnan\"))\nshape: (5, 3)\n┌──────┬─────┬─────────┐\n│ a    ┆ b   ┆ b_isnan │\n│ ---  ┆ --- ┆ ---     │\n│ i64  ┆ f64 ┆ bool    │\n╞══════╪═════╪═════════╡\n│ 1    ┆ 1.0 ┆ false   │\n│ 2    ┆ 2.0 ┆ false   │\n│ null ┆ NaN ┆ true    │\n│ 1    ┆ 1.0 ┆ false   │\n│ 5    ┆ 5.0 ┆ false   │\n└──────┴─────┴─────────┘"], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 421}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_not_nan.html#polars.Expr.is_not_nan"], "Title": ["Expr.is_not_nan"], "Feature": ["Expr.is_not_nan"], "Description": ["Returns a boolean Series indicating which values are not NaN."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None, 1, 5],\n...         \"b\": [1.0, 2.0, float(\"nan\"), 1.0, 5.0],\n...     }\n... )\n>>> df.with_columns(pl.col(pl.Float64).is_not_nan().name.suffix(\"_is_not_nan\"))\nshape: (5, 3)\n┌──────┬─────┬──────────────┐\n│ a    ┆ b   ┆ b_is_not_nan │\n│ ---  ┆ --- ┆ ---          │\n│ i64  ┆ f64 ┆ bool         │\n╞══════╪═════╪══════════════╡\n│ 1    ┆ 1.0 ┆ true         │\n│ 2    ┆ 2.0 ┆ true         │\n│ null ┆ NaN ┆ false        │\n│ 1    ┆ 1.0 ┆ true         │\n│ 5    ┆ 5.0 ┆ true         │\n└──────┴─────┴──────────────┘"], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 422}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_not_null.html#polars.Expr.is_not_null"], "Title": ["Expr.is_not_null"], "Feature": ["Expr.is_not_null"], "Description": ["Returns a boolean Series indicating which values are not null."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None, 1, 5],\n...         \"b\": [1.0, 2.0, float(\"nan\"), 1.0, 5.0],\n...     }\n... )\n>>> df.with_columns(\n...     pl.all().is_not_null().name.suffix(\"_not_null\")  # nan != null\n... )\nshape: (5, 4)\n┌──────┬─────┬────────────┬────────────┐\n│ a    ┆ b   ┆ a_not_null ┆ b_not_null │\n│ ---  ┆ --- ┆ ---        ┆ ---        │\n│ i64  ┆ f64 ┆ bool       ┆ bool       │\n╞══════╪═════╪════════════╪════════════╡\n│ 1    ┆ 1.0 ┆ true       ┆ true       │\n│ 2    ┆ 2.0 ┆ true       ┆ true       │\n│ null ┆ NaN ┆ false      ┆ true       │\n│ 1    ┆ 1.0 ┆ true       ┆ true       │\n│ 5    ┆ 5.0 ┆ true       ┆ true       │\n└──────┴─────┴────────────┴────────────┘"], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 423}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_null.html#polars.Expr.is_null"], "Title": ["Expr.is_null"], "Feature": ["Expr.is_null"], "Description": ["Returns a boolean Series indicating which values are null."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None, 1, 5],\n...         \"b\": [1.0, 2.0, float(\"nan\"), 1.0, 5.0],\n...     }\n... )\n>>> df.with_columns(pl.all().is_null().name.suffix(\"_isnull\"))  # nan != null\nshape: (5, 4)\n┌──────┬─────┬──────────┬──────────┐\n│ a    ┆ b   ┆ a_isnull ┆ b_isnull │\n│ ---  ┆ --- ┆ ---      ┆ ---      │\n│ i64  ┆ f64 ┆ bool     ┆ bool     │\n╞══════╪═════╪══════════╪══════════╡\n│ 1    ┆ 1.0 ┆ false    ┆ false    │\n│ 2    ┆ 2.0 ┆ false    ┆ false    │\n│ null ┆ NaN ┆ true     ┆ false    │\n│ 1    ┆ 1.0 ┆ false    ┆ false    │\n│ 5    ┆ 5.0 ┆ false    ┆ false    │\n└──────┴─────┴──────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 424}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.is_unique.html#polars.Expr.is_unique"], "Title": ["Expr.is_unique"], "Feature": ["Expr.is_unique"], "Description": ["Get mask of unique values."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 1, 2]})\n>>> df.select(pl.col(\"a\").is_unique())\nshape: (3, 1)\n┌───────┐\n│ a     │\n│ ---   │\n│ bool  │\n╞═══════╡\n│ false │\n│ false │\n│ true  │\n└───────┘"], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 425}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.not_.html#polars.Expr.not_"], "Title": ["Expr.not_"], "Feature": ["Expr.not_"], "Description": ["Negate a boolean expression."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Boolean"], "index": 426}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cat.ends_with.html#polars.Expr.cat.ends_with"], "Title": ["Expr.cat.ends_with"], "Feature": ["Expr.cat.ends_with"], "Description": ["Check if string representations of values end with a substring."], "Examples": [">>> df = pl.DataFrame(\n...     {\"fruits\": pl.Series([\"apple\", \"mango\", None], dtype=pl.Categorical)}\n... )\n>>> df.with_columns(pl.col(\"fruits\").cat.ends_with(\"go\").alias(\"has_suffix\"))\nshape: (3, 2)\n┌────────┬────────────┐\n│ fruits ┆ has_suffix │\n│ ---    ┆ ---        │\n│ cat    ┆ bool       │\n╞════════╪════════════╡\n│ apple  ┆ false      │\n│ mango  ┆ true       │\n│ null   ┆ null       │\n└────────┴────────────┘", ">>> df.filter(pl.col(\"fruits\").cat.ends_with(\"go\"))\nshape: (1, 1)\n┌────────┐\n│ fruits │\n│ ---    │\n│ cat    │\n╞════════╡\n│ mango  │\n└────────┘"], "Parameters": [["suffix", "Suffix substring."]], "Returns": [], "Category": ["Categories"], "index": 427}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_or.html#polars.Expr.bitwise_or"], "Title": ["Expr.bitwise_or"], "Feature": ["Expr.bitwise_or"], "Description": ["Perform an aggregation of bitwise ORs."], "Examples": [">>> df = pl.DataFrame({\"n\": [-1, 0, 1]})\n>>> df.select(pl.col(\"n\").bitwise_or())\nshape: (1, 1)\n┌─────┐\n│ n   │\n│ --- │\n│ i64 │\n╞═════╡\n│ -1  │\n└─────┘\n>>> df = pl.DataFrame(\n...     {\"grouper\": [\"a\", \"a\", \"a\", \"b\", \"b\"], \"n\": [-1, 0, 1, -1, 1]}\n... )\n>>> df.group_by(\"grouper\", maintain_order=True).agg(pl.col(\"n\").bitwise_or())\nshape: (2, 2)\n┌─────────┬─────┐\n│ grouper ┆ n   │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ a       ┆ -1  │\n│ b       ┆ -1  │\n└─────────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 428}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cat.get_categories.html#polars.Expr.cat.get_categories"], "Title": ["Expr.cat.get_categories"], "Feature": ["Expr.cat.get_categories"], "Description": ["Get the categories stored in this data type."], "Examples": [">>> df = pl.Series(\n...     \"cats\", [\"foo\", \"bar\", \"foo\", \"foo\", \"ham\"], dtype=pl.Categorical\n... ).to_frame()\n>>> df.select(pl.col(\"cats\").cat.get_categories())  \nshape: (3, 1)\n┌──────┐\n│ cats │\n│ ---  │\n│ str  │\n╞══════╡\n│ foo  │\n│ bar  │\n│ ham  │\n└──────┘"], "Parameters": [], "Returns": [], "Category": ["Categories"], "index": 429}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cat.len_bytes.html#polars.Expr.cat.len_bytes"], "Title": ["Expr.cat.len_bytes"], "Feature": ["Expr.cat.len_bytes"], "Description": ["Return the byte-length of the string representation of each value."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": pl.Series([\"Café\", \"345\", \"東京\", None], dtype=pl.Categorical)}\n... )\n>>> df.with_columns(\n...     pl.col(\"a\").cat.len_bytes().alias(\"n_bytes\"),\n...     pl.col(\"a\").cat.len_chars().alias(\"n_chars\"),\n... )\nshape: (4, 3)\n┌──────┬─────────┬─────────┐\n│ a    ┆ n_bytes ┆ n_chars │\n│ ---  ┆ ---     ┆ ---     │\n│ cat  ┆ u32     ┆ u32     │\n╞══════╪═════════╪═════════╡\n│ Café ┆ 5       ┆ 4       │\n│ 345  ┆ 3       ┆ 3       │\n│ 東京 ┆ 6       ┆ 2       │\n│ null ┆ null    ┆ null    │\n└──────┴─────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Categories"], "index": 430}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cat.len_chars.html#polars.Expr.cat.len_chars"], "Title": ["Expr.cat.len_chars"], "Feature": ["Expr.cat.len_chars"], "Description": ["Return the number of characters of the string representation of each value."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": pl.Series([\"Café\", \"345\", \"東京\", None], dtype=pl.Categorical)}\n... )\n>>> df.with_columns(\n...     pl.col(\"a\").cat.len_chars().alias(\"n_chars\"),\n...     pl.col(\"a\").cat.len_bytes().alias(\"n_bytes\"),\n... )\nshape: (4, 3)\n┌──────┬─────────┬─────────┐\n│ a    ┆ n_chars ┆ n_bytes │\n│ ---  ┆ ---     ┆ ---     │\n│ cat  ┆ u32     ┆ u32     │\n╞══════╪═════════╪═════════╡\n│ Café ┆ 4       ┆ 5       │\n│ 345  ┆ 3       ┆ 3       │\n│ 東京 ┆ 2       ┆ 6       │\n│ null ┆ null    ┆ null    │\n└──────┴─────────┴─────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Categories"], "index": 431}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cat.starts_with.html#polars.Expr.cat.starts_with"], "Title": ["Expr.cat.starts_with"], "Feature": ["Expr.cat.starts_with"], "Description": ["Check if string representations of values start with a substring."], "Examples": [">>> df = pl.DataFrame(\n...     {\"fruits\": pl.Series([\"apple\", \"mango\", None], dtype=pl.Categorical)}\n... )\n>>> df.with_columns(\n...     pl.col(\"fruits\").cat.starts_with(\"app\").alias(\"has_prefix\"),\n... )\nshape: (3, 2)\n┌────────┬────────────┐\n│ fruits ┆ has_prefix │\n│ ---    ┆ ---        │\n│ cat    ┆ bool       │\n╞════════╪════════════╡\n│ apple  ┆ true       │\n│ mango  ┆ false      │\n│ null   ┆ null       │\n└────────┴────────────┘", ">>> df.filter(pl.col(\"fruits\").cat.starts_with(\"app\"))\nshape: (1, 1)\n┌────────┐\n│ fruits │\n│ ---    │\n│ cat    │\n╞════════╡\n│ apple  │\n└────────┘"], "Parameters": [["prefix", "Prefix substring."]], "Returns": [], "Category": ["Categories"], "index": 432}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.abs.html#polars.Expr.abs"], "Title": ["Expr.abs"], "Feature": ["Expr.abs"], "Description": ["Compute absolute values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"A\": [-1.0, 0.0, 1.0, 2.0],\n...     }\n... )\n>>> df.select(pl.col(\"A\").abs())\nshape: (4, 1)\n┌─────┐\n│ A   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n│ 0.0 │\n│ 1.0 │\n│ 2.0 │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 433}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.approx_n_unique.html#polars.Expr.approx_n_unique"], "Title": ["Expr.approx_n_unique"], "Feature": ["Expr.approx_n_unique"], "Description": ["Approximate count of unique values."], "Examples": [">>> df = pl.DataFrame({\"n\": [1, 1, 2]})\n>>> df.select(pl.col(\"n\").approx_n_unique())\nshape: (1, 1)\n┌─────┐\n│ n   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 2   │\n└─────┘\n>>> df = pl.DataFrame({\"n\": range(1000)})\n>>> df.select(\n...     exact=pl.col(\"n\").n_unique(),\n...     approx=pl.col(\"n\").approx_n_unique(),\n... )  \nshape: (1, 2)\n┌───────┬────────┐\n│ exact ┆ approx │\n│ ---   ┆ ---    │\n│ u32   ┆ u32    │\n╞═══════╪════════╡\n│ 1000  ┆ 1005   │\n└───────┴────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 434}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arccos.html#polars.Expr.arccos"], "Title": ["Expr.arccos"], "Feature": ["Expr.arccos"], "Description": ["Compute the element-wise value for the inverse cosine."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.0]})\n>>> df.select(pl.col(\"a\").arccos())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.570796 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 435}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arccosh.html#polars.Expr.arccosh"], "Title": ["Expr.arccosh"], "Feature": ["Expr.arccosh"], "Description": ["Compute the element-wise value for the inverse hyperbolic cosine."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").arccosh())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 0.0 │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 436}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arcsin.html#polars.Expr.arcsin"], "Title": ["Expr.arcsin"], "Feature": ["Expr.arcsin"], "Description": ["Compute the element-wise value for the inverse sine."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").arcsin())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.570796 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 437}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arcsinh.html#polars.Expr.arcsinh"], "Title": ["Expr.arcsinh"], "Feature": ["Expr.arcsinh"], "Description": ["Compute the element-wise value for the inverse hyperbolic sine."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").arcsinh())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.881374 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 438}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_xor.html#polars.Expr.bitwise_xor"], "Title": ["Expr.bitwise_xor"], "Feature": ["Expr.bitwise_xor"], "Description": ["Perform an aggregation of bitwise XORs."], "Examples": [">>> df = pl.DataFrame({\"n\": [-1, 0, 1]})\n>>> df.select(pl.col(\"n\").bitwise_xor())\nshape: (1, 1)\n┌─────┐\n│ n   │\n│ --- │\n│ i64 │\n╞═════╡\n│ -2  │\n└─────┘\n>>> df = pl.DataFrame(\n...     {\"grouper\": [\"a\", \"a\", \"a\", \"b\", \"b\"], \"n\": [-1, 0, 1, -1, 1]}\n... )\n>>> df.group_by(\"grouper\", maintain_order=True).agg(pl.col(\"n\").bitwise_xor())\nshape: (2, 2)\n┌─────────┬─────┐\n│ grouper ┆ n   │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ a       ┆ -2  │\n│ b       ┆ -2  │\n└─────────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 439}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arctan.html#polars.Expr.arctan"], "Title": ["Expr.arctan"], "Feature": ["Expr.arctan"], "Description": ["Compute the element-wise value for the inverse tangent."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").arctan())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 0.785398 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 440}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arctanh.html#polars.Expr.arctanh"], "Title": ["Expr.arctanh"], "Feature": ["Expr.arctanh"], "Description": ["Compute the element-wise value for the inverse hyperbolic tangent."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").arctanh())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ inf │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 441}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arg_unique.html#polars.Expr.arg_unique"], "Title": ["Expr.arg_unique"], "Feature": ["Expr.arg_unique"], "Description": ["Get index of first unique value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [8, 9, 10],\n...         \"b\": [None, 4, 4],\n...     }\n... )\n>>> df.select(pl.col(\"a\").arg_unique())\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 0   │\n│ 1   │\n│ 2   │\n└─────┘\n>>> df.select(pl.col(\"b\").arg_unique())\nshape: (2, 1)\n┌─────┐\n│ b   │\n│ --- │\n│ u32 │\n╞═════╡\n│ 0   │\n│ 1   │\n└─────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 442}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_count_ones.html#polars.Expr.bitwise_count_ones"], "Title": ["Expr.bitwise_count_ones"], "Feature": ["Expr.bitwise_count_ones"], "Description": ["Evaluate the number of set bits."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 443}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_count_zeros.html#polars.Expr.bitwise_count_zeros"], "Title": ["Expr.bitwise_count_zeros"], "Feature": ["Expr.bitwise_count_zeros"], "Description": ["Evaluate the number of unset bits."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 444}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_leading_ones.html#polars.Expr.bitwise_leading_ones"], "Title": ["Expr.bitwise_leading_ones"], "Feature": ["Expr.bitwise_leading_ones"], "Description": ["Evaluate the number most-significant set bits before seeing an unset bit."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 445}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_leading_zeros.html#polars.Expr.bitwise_leading_zeros"], "Title": ["Expr.bitwise_leading_zeros"], "Feature": ["Expr.bitwise_leading_zeros"], "Description": ["Evaluate the number most-significant unset bits before seeing a set bit."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 446}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_trailing_ones.html#polars.Expr.bitwise_trailing_ones"], "Title": ["Expr.bitwise_trailing_ones"], "Feature": ["Expr.bitwise_trailing_ones"], "Description": ["Evaluate the number least-significant set bits before seeing an unset bit."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 447}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.bitwise_trailing_zeros.html#polars.Expr.bitwise_trailing_zeros"], "Title": ["Expr.bitwise_trailing_zeros"], "Feature": ["Expr.bitwise_trailing_zeros"], "Description": ["Evaluate the number least-significant unset bits before seeing a set bit."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 448}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cbrt.html#polars.Expr.cbrt"], "Title": ["Expr.cbrt"], "Feature": ["Expr.cbrt"], "Description": ["Compute the cube root of the elements."], "Examples": [">>> df = pl.DataFrame({\"values\": [1.0, 2.0, 4.0]})\n>>> df.select(pl.col(\"values\").cbrt())\nshape: (3, 1)\n┌──────────┐\n│ values   │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.0      │\n│ 1.259921 │\n│ 1.587401 │\n└──────────┘"], "Parameters": [], "Returns": [], "Category": ["Computation"], "index": 449}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.count.html#polars.Expr.count"], "Title": ["Expr.count"], "Feature": ["Expr.count"], "Description": ["Return the number of non-null elements in the column."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [None, 4, 4]})\n>>> df.select(pl.all().count())\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 3   ┆ 2   │\n└─────┴─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type UInt32 ."]], "Category": ["Aggregation"], "index": 450}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cos.html#polars.Expr.cos"], "Title": ["Expr.cos"], "Feature": ["Expr.cos"], "Description": ["Compute the element-wise value for the cosine."], "Examples": [">>> df = pl.DataFrame({\"a\": [0.0]})\n>>> df.select(pl.col(\"a\").cos())\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n└─────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 451}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cosh.html#polars.Expr.cosh"], "Title": ["Expr.cosh"], "Feature": ["Expr.cosh"], "Description": ["Compute the element-wise value for the hyperbolic cosine."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").cosh())\nshape: (1, 1)\n┌──────────┐\n│ a        │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.543081 │\n└──────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 452}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cot.html#polars.Expr.cot"], "Title": ["Expr.cot"], "Feature": ["Expr.cot"], "Description": ["Compute the element-wise value for the cotangent."], "Examples": [">>> df = pl.DataFrame({\"a\": [1.0]})\n>>> df.select(pl.col(\"a\").cot().round(2))\nshape: (1, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ f64  │\n╞══════╡\n│ 0.64 │\n└──────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 453}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cum_count.html#polars.Expr.cum_count"], "Title": ["Expr.cum_count"], "Feature": ["Expr.cum_count"], "Description": ["Return the cumulative count of the non-null values in the column."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"x\", \"k\", None, \"d\"]})\n>>> df.with_columns(\n...     pl.col(\"a\").cum_count().alias(\"cum_count\"),\n...     pl.col(\"a\").cum_count(reverse=True).alias(\"cum_count_reverse\"),\n... )\nshape: (4, 3)\n┌──────┬───────────┬───────────────────┐\n│ a    ┆ cum_count ┆ cum_count_reverse │\n│ ---  ┆ ---       ┆ ---               │\n│ str  ┆ u32       ┆ u32               │\n╞══════╪═══════════╪═══════════════════╡\n│ x    ┆ 1         ┆ 3                 │\n│ k    ┆ 2         ┆ 2                 │\n│ null ┆ 2         ┆ 1                 │\n│ d    ┆ 3         ┆ 1                 │\n└──────┴───────────┴───────────────────┘"], "Parameters": [["reverse", "Reverse the operation."]], "Returns": [], "Category": ["Computation"], "index": 454}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cum_max.html#polars.Expr.cum_max"], "Title": ["Expr.cum_max"], "Feature": ["Expr.cum_max"], "Description": ["Get an array with the cumulative max computed at every element."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 3, 2]})\n>>> df.with_columns(\n...     pl.col(\"a\").cum_max().alias(\"cum_max\"),\n...     pl.col(\"a\").cum_max(reverse=True).alias(\"cum_max_reverse\"),\n... )\nshape: (3, 3)\n┌─────┬─────────┬─────────────────┐\n│ a   ┆ cum_max ┆ cum_max_reverse │\n│ --- ┆ ---     ┆ ---             │\n│ i64 ┆ i64     ┆ i64             │\n╞═════╪═════════╪═════════════════╡\n│ 1   ┆ 1       ┆ 3               │\n│ 3   ┆ 3       ┆ 3               │\n│ 2   ┆ 3       ┆ 2               │\n└─────┴─────────┴─────────────────┘", ">>> df = pl.DataFrame({\"values\": [None, 10, None, 8, 9, None, 16, None]})\n>>> df.with_columns(\n...     pl.col(\"values\").cum_max().alias(\"cum_max\"),\n...     pl.col(\"values\")\n...     .cum_max()\n...     .fill_null(strategy=\"forward\")\n...     .alias(\"cum_max_all_filled\"),\n... )\nshape: (8, 3)\n┌────────┬─────────┬────────────────────┐\n│ values ┆ cum_max ┆ cum_max_all_filled │\n│ ---    ┆ ---     ┆ ---                │\n│ i64    ┆ i64     ┆ i64                │\n╞════════╪═════════╪════════════════════╡\n│ null   ┆ null    ┆ null               │\n│ 10     ┆ 10      ┆ 10                 │\n│ null   ┆ null    ┆ 10                 │\n│ 8      ┆ 10      ┆ 10                 │\n│ 9      ┆ 10      ┆ 10                 │\n│ null   ┆ null    ┆ 10                 │\n│ 16     ┆ 16      ┆ 16                 │\n│ null   ┆ null    ┆ 16                 │\n└────────┴─────────┴────────────────────┘"], "Parameters": [["reverse", "Reverse the operation."]], "Returns": [], "Category": ["Computation"], "index": 455}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cum_min.html#polars.Expr.cum_min"], "Title": ["Expr.cum_min"], "Feature": ["Expr.cum_min"], "Description": ["Get an array with the cumulative min computed at every element."], "Examples": [">>> df = pl.DataFrame({\"a\": [3, 1, 2]})\n>>> df.with_columns(\n...     pl.col(\"a\").cum_min().alias(\"cum_min\"),\n...     pl.col(\"a\").cum_min(reverse=True).alias(\"cum_min_reverse\"),\n... )\nshape: (3, 3)\n┌─────┬─────────┬─────────────────┐\n│ a   ┆ cum_min ┆ cum_min_reverse │\n│ --- ┆ ---     ┆ ---             │\n│ i64 ┆ i64     ┆ i64             │\n╞═════╪═════════╪═════════════════╡\n│ 3   ┆ 3       ┆ 1               │\n│ 1   ┆ 1       ┆ 1               │\n│ 2   ┆ 1       ┆ 2               │\n└─────┴─────────┴─────────────────┘"], "Parameters": [["reverse", "Reverse the operation."]], "Returns": [], "Category": ["Computation"], "index": 456}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cum_prod.html#polars.Expr.cum_prod"], "Title": ["Expr.cum_prod"], "Feature": ["Expr.cum_prod"], "Description": ["Get an array with the cumulative product computed at every element."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4]})\n>>> df.with_columns(\n...     pl.col(\"a\").cum_prod().alias(\"cum_prod\"),\n...     pl.col(\"a\").cum_prod(reverse=True).alias(\"cum_prod_reverse\"),\n... )\nshape: (4, 3)\n┌─────┬──────────┬──────────────────┐\n│ a   ┆ cum_prod ┆ cum_prod_reverse │\n│ --- ┆ ---      ┆ ---              │\n│ i64 ┆ i64      ┆ i64              │\n╞═════╪══════════╪══════════════════╡\n│ 1   ┆ 1        ┆ 24               │\n│ 2   ┆ 2        ┆ 24               │\n│ 3   ┆ 6        ┆ 12               │\n│ 4   ┆ 24       ┆ 4                │\n└─────┴──────────┴──────────────────┘"], "Parameters": [["reverse", "Reverse the operation."]], "Returns": [], "Category": ["Computation"], "index": 457}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cum_sum.html#polars.Expr.cum_sum"], "Title": ["Expr.cum_sum"], "Feature": ["Expr.cum_sum"], "Description": ["Get an array with the cumulative sum computed at every element."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4]})\n>>> df.with_columns(\n...     pl.col(\"a\").cum_sum().alias(\"cum_sum\"),\n...     pl.col(\"a\").cum_sum(reverse=True).alias(\"cum_sum_reverse\"),\n... )\nshape: (4, 3)\n┌─────┬─────────┬─────────────────┐\n│ a   ┆ cum_sum ┆ cum_sum_reverse │\n│ --- ┆ ---     ┆ ---             │\n│ i64 ┆ i64     ┆ i64             │\n╞═════╪═════════╪═════════════════╡\n│ 1   ┆ 1       ┆ 10              │\n│ 2   ┆ 3       ┆ 9               │\n│ 3   ┆ 6       ┆ 7               │\n│ 4   ┆ 10      ┆ 4               │\n└─────┴─────────┴─────────────────┘", ">>> df = pl.DataFrame({\"values\": [None, 10, None, 8, 9, None, 16, None]})\n>>> df.with_columns(\n...     pl.col(\"values\").cum_sum().alias(\"value_cum_sum\"),\n...     pl.col(\"values\")\n...     .cum_sum()\n...     .fill_null(strategy=\"forward\")\n...     .alias(\"value_cum_sum_all_filled\"),\n... )\nshape: (8, 3)\n┌────────┬───────────────┬──────────────────────────┐\n│ values ┆ value_cum_sum ┆ value_cum_sum_all_filled │\n│ ---    ┆ ---           ┆ ---                      │\n│ i64    ┆ i64           ┆ i64                      │\n╞════════╪═══════════════╪══════════════════════════╡\n│ null   ┆ null          ┆ null                     │\n│ 10     ┆ 10            ┆ 10                       │\n│ null   ┆ null          ┆ 10                       │\n│ 8      ┆ 18            ┆ 18                       │\n│ 9      ┆ 27            ┆ 27                       │\n│ null   ┆ null          ┆ 27                       │\n│ 16     ┆ 43            ┆ 43                       │\n│ null   ┆ null          ┆ 43                       │\n└────────┴───────────────┴──────────────────────────┘"], "Parameters": [["reverse", "Reverse the operation."]], "Returns": [], "Category": ["Computation"], "index": 458}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.cumulative_eval.html#polars.Expr.cumulative_eval"], "Title": ["Expr.cumulative_eval"], "Feature": ["Expr.cumulative_eval"], "Description": ["Run an expression over a sliding window that increases1slot every iteration."], "Examples": [">>> df = pl.DataFrame({\"values\": [1, 2, 3, 4, 5]})\n>>> df.select(\n...     [\n...         pl.col(\"values\").cumulative_eval(\n...             pl.element().first() - pl.element().last() ** 2\n...         )\n...     ]\n... )\nshape: (5, 1)\n┌────────┐\n│ values │\n│ ---    │\n│ i64    │\n╞════════╡\n│ 0      │\n│ -3     │\n│ -8     │\n│ -15    │\n│ -24    │\n└────────┘"], "Parameters": [["expr", "Expression to evaluate"], ["min_samples", "Number of valid values there should be in the window before the expression\nis evaluated. valid values = length - null_count"]], "Returns": [], "Category": ["Computation"], "index": 459}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.degrees.html#polars.Expr.degrees"], "Title": ["Expr.degrees"], "Feature": ["Expr.degrees"], "Description": ["Convert from radians to degrees."], "Examples": [">>> import math\n>>> df = pl.DataFrame({\"a\": [x * math.pi for x in range(-4, 5)]})\n>>> df.select(pl.col(\"a\").degrees())\nshape: (9, 1)\n┌────────┐\n│ a      │\n│ ---    │\n│ f64    │\n╞════════╡\n│ -720.0 │\n│ -540.0 │\n│ -360.0 │\n│ -180.0 │\n│ 0.0    │\n│ 180.0  │\n│ 360.0  │\n│ 540.0  │\n│ 720.0  │\n└────────┘"], "Parameters": [], "Returns": [["Expr", "Expression of data type Float64 ."]], "Category": ["Computation"], "index": 460}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.count.html#polars.DataFrame.count"], "Title": ["DataFrame.count"], "Feature": ["DataFrame.count"], "Description": ["Return the number of non-null elements for each column."], "Examples": [">>> df = pl.DataFrame(\n...     {\"a\": [1, 2, 3, 4], \"b\": [1, 2, 1, None], \"c\": [None, None, None, None]}\n... )\n>>> df.count()\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ u32 ┆ u32 ┆ u32 │\n╞═════╪═════╪═════╡\n│ 4   ┆ 3   ┆ 0   │\n└─────┴─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 461}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.max.html#polars.DataFrame.max"], "Title": ["DataFrame.max"], "Feature": ["DataFrame.max"], "Description": ["Aggregate the columns of this DataFrame to their maximum value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.max()\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 3   ┆ 8   ┆ c   │\n└─────┴─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 462}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.std.html#polars.DataFrame.std"], "Title": ["DataFrame.std"], "Feature": ["DataFrame.std"], "Description": ["Aggregate the columns of this DataFrame to their standard deviation value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.std()\nshape: (1, 3)\n┌─────┬─────┬──────┐\n│ foo ┆ bar ┆ ham  │\n│ --- ┆ --- ┆ ---  │\n│ f64 ┆ f64 ┆ str  │\n╞═════╪═════╪══════╡\n│ 1.0 ┆ 1.0 ┆ null │\n└─────┴─────┴──────┘\n>>> df.std(ddof=0)\nshape: (1, 3)\n┌──────────┬──────────┬──────┐\n│ foo      ┆ bar      ┆ ham  │\n│ ---      ┆ ---      ┆ ---  │\n│ f64      ┆ f64      ┆ str  │\n╞══════════╪══════════╪══════╡\n│ 0.816497 ┆ 0.816497 ┆ null │\n└──────────┴──────────┴──────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Aggregation"], "index": 463}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.select_seq.html#polars.DataFrame.select_seq"], "Title": ["DataFrame.select_seq"], "Feature": ["DataFrame.select_seq"], "Description": ["Select columns from this DataFrame."], "Examples": [], "Parameters": [["*exprs", "Column(s) to select, specified as positional arguments.\nAccepts expression input. Strings are parsed as column names,\nother non-expression inputs are parsed as literals."], ["**named_exprs", "Additional columns to select, specified as keyword arguments.\nThe columns will be renamed to the keyword used."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 464}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.set_sorted.html#polars.DataFrame.set_sorted"], "Title": ["DataFrame.set_sorted"], "Feature": ["DataFrame.set_sorted"], "Description": ["Flag a column as sorted."], "Examples": [], "Parameters": [["column", "Column that is sorted"], ["descending", "Whether the column is sorted in descending order."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 465}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.shift.html#polars.DataFrame.shift"], "Title": ["DataFrame.shift"], "Feature": ["DataFrame.shift"], "Description": ["Shift values by the given number of indices."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [5, 6, 7, 8],\n...     }\n... )\n>>> df.shift()\nshape: (4, 2)\n┌──────┬──────┐\n│ a    ┆ b    │\n│ ---  ┆ ---  │\n│ i64  ┆ i64  │\n╞══════╪══════╡\n│ null ┆ null │\n│ 1    ┆ 5    │\n│ 2    ┆ 6    │\n│ 3    ┆ 7    │\n└──────┴──────┘", ">>> df.shift(-2)\nshape: (4, 2)\n┌──────┬──────┐\n│ a    ┆ b    │\n│ ---  ┆ ---  │\n│ i64  ┆ i64  │\n╞══════╪══════╡\n│ 3    ┆ 7    │\n│ 4    ┆ 8    │\n│ null ┆ null │\n│ null ┆ null │\n└──────┴──────┘", ">>> df.shift(-2, fill_value=100)\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 3   ┆ 7   │\n│ 4   ┆ 8   │\n│ 100 ┆ 100 │\n│ 100 ┆ 100 │\n└─────┴─────┘"], "Parameters": [["n", "Number of indices to shift forward. If a negative value is passed, values\nare shifted in the opposite direction instead."], ["fill_value", "Fill the resulting null values with this value. Accepts scalar expression\ninput. Non-expression inputs are parsed as literals."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 466}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.shrink_to_fit.html#polars.DataFrame.shrink_to_fit"], "Title": ["DataFrame.shrink_to_fit"], "Feature": ["DataFrame.shrink_to_fit"], "Description": ["Shrink DataFrame memory usage."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 467}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.tail.html#polars.DataFrame.tail"], "Title": ["DataFrame.tail"], "Feature": ["DataFrame.tail"], "Description": ["Get the lastnrows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3, 4, 5],\n...         \"bar\": [6, 7, 8, 9, 10],\n...         \"ham\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n>>> df.tail(3)\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 3   ┆ 8   ┆ c   │\n│ 4   ┆ 9   ┆ d   │\n│ 5   ┆ 10  ┆ e   │\n└─────┴─────┴─────┘", ">>> df.tail(-3)\nshape: (2, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 4   ┆ 9   ┆ d   │\n│ 5   ┆ 10  ┆ e   │\n└─────┴─────┴─────┘"], "Parameters": [["n", "Number of rows to return. If a negative value is passed, return all rows\nexcept the first abs(n) ."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 471}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.to_dummies.html#polars.DataFrame.to_dummies"], "Title": ["DataFrame.to_dummies"], "Feature": ["DataFrame.to_dummies"], "Description": ["Convert categorical variables into dummy/indicator variables."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2],\n...         \"bar\": [3, 4],\n...         \"ham\": [\"a\", \"b\"],\n...     }\n... )\n>>> df.to_dummies()\nshape: (2, 6)\n┌───────┬───────┬───────┬───────┬───────┬───────┐\n│ foo_1 ┆ foo_2 ┆ bar_3 ┆ bar_4 ┆ ham_a ┆ ham_b │\n│ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n│ u8    ┆ u8    ┆ u8    ┆ u8    ┆ u8    ┆ u8    │\n╞═══════╪═══════╪═══════╪═══════╪═══════╪═══════╡\n│ 1     ┆ 0     ┆ 1     ┆ 0     ┆ 1     ┆ 0     │\n│ 0     ┆ 1     ┆ 0     ┆ 1     ┆ 0     ┆ 1     │\n└───────┴───────┴───────┴───────┴───────┴───────┘", ">>> df.to_dummies(drop_first=True)\nshape: (2, 3)\n┌───────┬───────┬───────┐\n│ foo_2 ┆ bar_4 ┆ ham_b │\n│ ---   ┆ ---   ┆ ---   │\n│ u8    ┆ u8    ┆ u8    │\n╞═══════╪═══════╪═══════╡\n│ 0     ┆ 0     ┆ 0     │\n│ 1     ┆ 1     ┆ 1     │\n└───────┴───────┴───────┘", ">>> import polars.selectors as cs\n>>> df.to_dummies(cs.integer(), separator=\":\")\nshape: (2, 5)\n┌───────┬───────┬───────┬───────┬─────┐\n│ foo:1 ┆ foo:2 ┆ bar:3 ┆ bar:4 ┆ ham │\n│ ---   ┆ ---   ┆ ---   ┆ ---   ┆ --- │\n│ u8    ┆ u8    ┆ u8    ┆ u8    ┆ str │\n╞═══════╪═══════╪═══════╪═══════╪═════╡\n│ 1     ┆ 0     ┆ 1     ┆ 0     ┆ a   │\n│ 0     ┆ 1     ┆ 0     ┆ 1     ┆ b   │\n└───────┴───────┴───────┴───────┴─────┘", ">>> df.to_dummies(cs.integer(), drop_first=True, separator=\":\")\nshape: (2, 3)\n┌───────┬───────┬─────┐\n│ foo:2 ┆ bar:4 ┆ ham │\n│ ---   ┆ ---   ┆ --- │\n│ u8    ┆ u8    ┆ str │\n╞═══════╪═══════╪═════╡\n│ 0     ┆ 0     ┆ a   │\n│ 1     ┆ 1     ┆ b   │\n└───────┴───────┴─────┘"], "Parameters": [["columns", "Column name(s) or selector(s) that should be converted to dummy\nvariables. If set to None (default), convert all columns."], ["separator", "Separator/delimiter used when generating column names."], ["drop_first", "Remove the first category from the variables being encoded."], ["drop_nulls", "If there are None values in the series, a null column is not generated"]], "Returns": [], "Category": ["Manipulation_selection"], "index": 472}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.to_series.html#polars.DataFrame.to_series"], "Title": ["DataFrame.to_series"], "Feature": ["DataFrame.to_series"], "Description": ["Select column as Series at index location."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.to_series(1)\nshape: (3,)\nSeries: 'bar' [i64]\n[\n        6\n        7\n        8\n]"], "Parameters": [["index", "Location of selection."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 473}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.sum.html#polars.DataFrame.sum"], "Title": ["DataFrame.sum"], "Feature": ["DataFrame.sum"], "Description": ["Aggregate the columns of this DataFrame to their sum value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.sum()\nshape: (1, 3)\n┌─────┬─────┬──────┐\n│ foo ┆ bar ┆ ham  │\n│ --- ┆ --- ┆ ---  │\n│ i64 ┆ i64 ┆ str  │\n╞═════╪═════╪══════╡\n│ 6   ┆ 21  ┆ null │\n└─────┴─────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 474}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.top_k.html#polars.DataFrame.top_k"], "Title": ["DataFrame.top_k"], "Feature": ["DataFrame.top_k"], "Description": ["Return theklargest rows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n...         \"b\": [2, 1, 1, 3, 2, 1],\n...     }\n... )", ">>> df.top_k(4, by=\"b\")\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ b   ┆ 3   │\n│ a   ┆ 2   │\n│ b   ┆ 2   │\n│ b   ┆ 1   │\n└─────┴─────┘", ">>> df.top_k(4, by=[\"b\", \"a\"])\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ b   ┆ 3   │\n│ b   ┆ 2   │\n│ a   ┆ 2   │\n│ c   ┆ 1   │\n└─────┴─────┘"], "Parameters": [["k", "Number of rows to return."], ["by", "Column(s) used to determine the top rows.\nAccepts expression input. Strings are parsed as column names."], ["reverse", "Consider the k smallest elements of the by column(s) (instead of the k largest). This can be specified per column by passing a sequence of\nbooleans."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 475}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.transpose.html#polars.DataFrame.transpose"], "Title": ["DataFrame.transpose"], "Feature": ["DataFrame.transpose"], "Description": ["Transpose a DataFrame over the diagonal."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n>>> df.transpose(include_header=True)\nshape: (2, 4)\n┌────────┬──────────┬──────────┬──────────┐\n│ column ┆ column_0 ┆ column_1 ┆ column_2 │\n│ ---    ┆ ---      ┆ ---      ┆ ---      │\n│ str    ┆ i64      ┆ i64      ┆ i64      │\n╞════════╪══════════╪══════════╪══════════╡\n│ a      ┆ 1        ┆ 2        ┆ 3        │\n│ b      ┆ 4        ┆ 5        ┆ 6        │\n└────────┴──────────┴──────────┴──────────┘", ">>> df.transpose(include_header=False, column_names=[\"x\", \"y\", \"z\"])\nshape: (2, 3)\n┌─────┬─────┬─────┐\n│ x   ┆ y   ┆ z   │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 2   ┆ 3   │\n│ 4   ┆ 5   ┆ 6   │\n└─────┴─────┴─────┘", ">>> df.transpose(\n...     include_header=True, header_name=\"foo\", column_names=[\"x\", \"y\", \"z\"]\n... )\nshape: (2, 4)\n┌─────┬─────┬─────┬─────┐\n│ foo ┆ x   ┆ y   ┆ z   │\n│ --- ┆ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╪═════╡\n│ a   ┆ 1   ┆ 2   ┆ 3   │\n│ b   ┆ 4   ┆ 5   ┆ 6   │\n└─────┴─────┴─────┴─────┘", ">>> def name_generator():\n...     base_name = \"my_column_\"\n...     count = 0\n...     while True:\n...         yield f\"{base_name}{count}\"\n...         count += 1\n>>> df.transpose(include_header=False, column_names=name_generator())\nshape: (2, 3)\n┌─────────────┬─────────────┬─────────────┐\n│ my_column_0 ┆ my_column_1 ┆ my_column_2 │\n│ ---         ┆ ---         ┆ ---         │\n│ i64         ┆ i64         ┆ i64         │\n╞═════════════╪═════════════╪═════════════╡\n│ 1           ┆ 2           ┆ 3           │\n│ 4           ┆ 5           ┆ 6           │\n└─────────────┴─────────────┴─────────────┘", ">>> df = pl.DataFrame(dict(id=[\"i\", \"j\", \"k\"], a=[1, 2, 3], b=[4, 5, 6]))\n>>> df.transpose(column_names=\"id\")\nshape: (2, 3)\n┌─────┬─────┬─────┐\n│ i   ┆ j   ┆ k   │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 2   ┆ 3   │\n│ 4   ┆ 5   ┆ 6   │\n└─────┴─────┴─────┘\n>>> df.transpose(include_header=True, header_name=\"new_id\", column_names=\"id\")\nshape: (2, 4)\n┌────────┬─────┬─────┬─────┐\n│ new_id ┆ i   ┆ j   ┆ k   │\n│ ---    ┆ --- ┆ --- ┆ --- │\n│ str    ┆ i64 ┆ i64 ┆ i64 │\n╞════════╪═════╪═════╪═════╡\n│ a      ┆ 1   ┆ 2   ┆ 3   │\n│ b      ┆ 4   ┆ 5   ┆ 6   │\n└────────┴─────┴─────┴─────┘"], "Parameters": [["include_header", "If set, the column names will be added as first column."], ["header_name", "If include_header is set, this determines the name of the column that will\nbe inserted."], ["column_names", "Optional iterable yielding strings or a string naming an existing column.\nThese will name the value (non-header) columns in the transposed data."]], "Returns": [["DataFrame", ""]], "Category": ["Manipulation_selection"], "index": 476}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.unnest.html#polars.DataFrame.unnest"], "Title": ["DataFrame.unnest"], "Feature": ["DataFrame.unnest"], "Description": ["Decompose struct columns into separate columns for each of their fields."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"before\": [\"foo\", \"bar\"],\n...         \"t_a\": [1, 2],\n...         \"t_b\": [\"a\", \"b\"],\n...         \"t_c\": [True, None],\n...         \"t_d\": [[1, 2], [3]],\n...         \"after\": [\"baz\", \"womp\"],\n...     }\n... ).select(\"before\", pl.struct(pl.col(\"^t_.$\")).alias(\"t_struct\"), \"after\")\n>>> df\nshape: (2, 3)\n┌────────┬─────────────────────┬───────┐\n│ before ┆ t_struct            ┆ after │\n│ ---    ┆ ---                 ┆ ---   │\n│ str    ┆ struct[4]           ┆ str   │\n╞════════╪═════════════════════╪═══════╡\n│ foo    ┆ {1,\"a\",true,[1, 2]} ┆ baz   │\n│ bar    ┆ {2,\"b\",null,[3]}    ┆ womp  │\n└────────┴─────────────────────┴───────┘\n>>> df.unnest(\"t_struct\")\nshape: (2, 6)\n┌────────┬─────┬─────┬──────┬───────────┬───────┐\n│ before ┆ t_a ┆ t_b ┆ t_c  ┆ t_d       ┆ after │\n│ ---    ┆ --- ┆ --- ┆ ---  ┆ ---       ┆ ---   │\n│ str    ┆ i64 ┆ str ┆ bool ┆ list[i64] ┆ str   │\n╞════════╪═════╪═════╪══════╪═══════════╪═══════╡\n│ foo    ┆ 1   ┆ a   ┆ true ┆ [1, 2]    ┆ baz   │\n│ bar    ┆ 2   ┆ b   ┆ null ┆ [3]       ┆ womp  │\n└────────┴─────┴─────┴──────┴───────────┴───────┘\n>>> df = pl.DataFrame(\n...     {\n...         \"before\": [\"foo\", \"bar\"],\n...         \"t_a\": [1, 2],\n...         \"t_b\": [\"a\", \"b\"],\n...         \"t_c\": [True, None],\n...         \"t_d\": [[1, 2], [3]],\n...         \"after\": [\"baz\", \"womp\"],\n...     }\n... ).select(\n...     \"before\",\n...     pl.struct(pl.col(\"^t_.$\").name.map(lambda t: t[2:])).alias(\"t\"),\n...     \"after\",\n... )\n>>> df.unnest(\"t\", separator=\"::\")\nshape: (2, 6)\n┌────────┬──────┬──────┬──────┬───────────┬───────┐\n│ before ┆ t::a ┆ t::b ┆ t::c ┆ t::d      ┆ after │\n│ ---    ┆ ---  ┆ ---  ┆ ---  ┆ ---       ┆ ---   │\n│ str    ┆ i64  ┆ str  ┆ bool ┆ list[i64] ┆ str   │\n╞════════╪══════╪══════╪══════╪═══════════╪═══════╡\n│ foo    ┆ 1    ┆ a    ┆ true ┆ [1, 2]    ┆ baz   │\n│ bar    ┆ 2    ┆ b    ┆ null ┆ [3]       ┆ womp  │\n└────────┴──────┴──────┴──────┴───────────┴───────┘"], "Parameters": [["columns", "Name of the struct column(s) that should be unnested."], ["*more_columns", "Additional columns to unnest, specified as positional arguments."], ["separator", "Rename output column names as combination of the struct column name,\nname separator and field name."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 478}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.unpivot.html#polars.DataFrame.unpivot"], "Title": ["DataFrame.unpivot"], "Feature": ["DataFrame.unpivot"], "Description": ["Unpivot a DataFrame from wide to long format."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"x\", \"y\", \"z\"],\n...         \"b\": [1, 3, 5],\n...         \"c\": [2, 4, 6],\n...     }\n... )\n>>> import polars.selectors as cs\n>>> df.unpivot(cs.numeric(), index=\"a\")\nshape: (6, 3)\n┌─────┬──────────┬───────┐\n│ a   ┆ variable ┆ value │\n│ --- ┆ ---      ┆ ---   │\n│ str ┆ str      ┆ i64   │\n╞═════╪══════════╪═══════╡\n│ x   ┆ b        ┆ 1     │\n│ y   ┆ b        ┆ 3     │\n│ z   ┆ b        ┆ 5     │\n│ x   ┆ c        ┆ 2     │\n│ y   ┆ c        ┆ 4     │\n│ z   ┆ c        ┆ 6     │\n└─────┴──────────┴───────┘"], "Parameters": [["on", "Column(s) or selector(s) to use as values variables; if on is empty all columns that are not in index will be used."], ["index", "Column(s) or selector(s) to use as identifier variables."], ["variable_name", "Name to give to the variable column. Defaults to “variable”"], ["value_name", "Name to give to the value column. Defaults to “value”"]], "Returns": [], "Category": ["Manipulation_selection"], "index": 479}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.unstack.html#polars.DataFrame.unstack"], "Title": ["DataFrame.unstack"], "Feature": ["DataFrame.unstack"], "Description": ["Unstack a long table to a wide form without doing an aggregation."], "Examples": [">>> from string import ascii_uppercase\n>>> df = pl.DataFrame(\n...     {\n...         \"x\": list(ascii_uppercase[0:8]),\n...         \"y\": pl.int_range(1, 9, eager=True),\n...     }\n... ).with_columns(\n...     z=pl.int_ranges(pl.col(\"y\"), pl.col(\"y\") + 2, dtype=pl.UInt8),\n... )\n>>> df\nshape: (8, 3)\n┌─────┬─────┬──────────┐\n│ x   ┆ y   ┆ z        │\n│ --- ┆ --- ┆ ---      │\n│ str ┆ i64 ┆ list[u8] │\n╞═════╪═════╪══════════╡\n│ A   ┆ 1   ┆ [1, 2]   │\n│ B   ┆ 2   ┆ [2, 3]   │\n│ C   ┆ 3   ┆ [3, 4]   │\n│ D   ┆ 4   ┆ [4, 5]   │\n│ E   ┆ 5   ┆ [5, 6]   │\n│ F   ┆ 6   ┆ [6, 7]   │\n│ G   ┆ 7   ┆ [7, 8]   │\n│ H   ┆ 8   ┆ [8, 9]   │\n└─────┴─────┴──────────┘\n>>> df.unstack(step=4, how=\"vertical\")\nshape: (4, 6)\n┌─────┬─────┬─────┬─────┬──────────┬──────────┐\n│ x_0 ┆ x_1 ┆ y_0 ┆ y_1 ┆ z_0      ┆ z_1      │\n│ --- ┆ --- ┆ --- ┆ --- ┆ ---      ┆ ---      │\n│ str ┆ str ┆ i64 ┆ i64 ┆ list[u8] ┆ list[u8] │\n╞═════╪═════╪═════╪═════╪══════════╪══════════╡\n│ A   ┆ E   ┆ 1   ┆ 5   ┆ [1, 2]   ┆ [5, 6]   │\n│ B   ┆ F   ┆ 2   ┆ 6   ┆ [2, 3]   ┆ [6, 7]   │\n│ C   ┆ G   ┆ 3   ┆ 7   ┆ [3, 4]   ┆ [7, 8]   │\n│ D   ┆ H   ┆ 4   ┆ 8   ┆ [4, 5]   ┆ [8, 9]   │\n└─────┴─────┴─────┴─────┴──────────┴──────────┘\n>>> df.unstack(step=2, how=\"horizontal\")\nshape: (4, 6)\n┌─────┬─────┬─────┬─────┬──────────┬──────────┐\n│ x_0 ┆ x_1 ┆ y_0 ┆ y_1 ┆ z_0      ┆ z_1      │\n│ --- ┆ --- ┆ --- ┆ --- ┆ ---      ┆ ---      │\n│ str ┆ str ┆ i64 ┆ i64 ┆ list[u8] ┆ list[u8] │\n╞═════╪═════╪═════╪═════╪══════════╪══════════╡\n│ A   ┆ B   ┆ 1   ┆ 2   ┆ [1, 2]   ┆ [2, 3]   │\n│ C   ┆ D   ┆ 3   ┆ 4   ┆ [3, 4]   ┆ [4, 5]   │\n│ E   ┆ F   ┆ 5   ┆ 6   ┆ [5, 6]   ┆ [6, 7]   │\n│ G   ┆ H   ┆ 7   ┆ 8   ┆ [7, 8]   ┆ [8, 9]   │\n└─────┴─────┴─────┴─────┴──────────┴──────────┘\n>>> import polars.selectors as cs\n>>> df.unstack(step=5, columns=cs.numeric(), fill_values=0)\nshape: (5, 2)\n┌─────┬─────┐\n│ y_0 ┆ y_1 │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 6   │\n│ 2   ┆ 7   │\n│ 3   ┆ 8   │\n│ 4   ┆ 0   │\n│ 5   ┆ 0   │\n└─────┴─────┘"], "Parameters": [["step", "Number of rows in the unstacked frame."], ["how { ‘vertical’, ‘horizontal’ }", "Direction of the unstack."], ["columns", "Column name(s) or selector(s) to include in the operation.\nIf set to None (default), use all columns."], ["fill_values", "Fill values that don’t fit the new size with this value."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 480}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.update.html#polars.DataFrame.update"], "Title": ["DataFrame.update"], "Feature": ["DataFrame.update"], "Description": ["Update the values in thisDataFramewith the values inother."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"A\": [1, 2, 3, 4],\n...         \"B\": [400, 500, 600, 700],\n...     }\n... )\n>>> df\nshape: (4, 2)\n┌─────┬─────┐\n│ A   ┆ B   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 400 │\n│ 2   ┆ 500 │\n│ 3   ┆ 600 │\n│ 4   ┆ 700 │\n└─────┴─────┘\n>>> new_df = pl.DataFrame(\n...     {\n...         \"B\": [-66, None, -99],\n...         \"C\": [5, 3, 1],\n...     }\n... )", ">>> df.update(new_df)\nshape: (4, 2)\n┌─────┬─────┐\n│ A   ┆ B   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ -66 │\n│ 2   ┆ 500 │\n│ 3   ┆ -99 │\n│ 4   ┆ 700 │\n└─────┴─────┘", ">>> df.update(new_df, how=\"inner\")\nshape: (3, 2)\n┌─────┬─────┐\n│ A   ┆ B   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ -66 │\n│ 2   ┆ 500 │\n│ 3   ┆ -99 │\n└─────┴─────┘", ">>> df.update(new_df, left_on=[\"A\"], right_on=[\"C\"], how=\"full\")\nshape: (5, 2)\n┌─────┬─────┐\n│ A   ┆ B   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ -99 │\n│ 2   ┆ 500 │\n│ 3   ┆ 600 │\n│ 4   ┆ 700 │\n│ 5   ┆ -66 │\n└─────┴─────┘", ">>> df.update(new_df, left_on=\"A\", right_on=\"C\", how=\"full\", include_nulls=True)\nshape: (5, 2)\n┌─────┬──────┐\n│ A   ┆ B    │\n│ --- ┆ ---  │\n│ i64 ┆ i64  │\n╞═════╪══════╡\n│ 1   ┆ -99  │\n│ 2   ┆ 500  │\n│ 3   ┆ null │\n│ 4   ┆ 700  │\n│ 5   ┆ -66  │\n└─────┴──────┘"], "Parameters": [["other", "DataFrame that will be used to update the values"], ["on", "Column names that will be joined on. If set to None (default),\nthe implicit row index of each frame is used as a join key."], ["how {‘left’, ‘inner’, ‘full’}", "‘left’ will keep all rows from the left table; rows may be duplicated\nif multiple rows in the right frame match the left row’s key. ‘inner’ keeps only those rows where the key exists in both frames. ‘full’ will update existing rows where the key matches while also\nadding any new rows contained in the given frame."], ["left_on", "Join column(s) of the left DataFrame."], ["right_on", "Join column(s) of the right DataFrame."], ["include_nulls", "Overwrite values in the left frame with null values from the right frame.\nIf set to False (default), null values in the right frame are ignored."], ["maintain_order {‘none’, ‘left’, ‘right’, ‘left_right’, ‘right_left’}", "Which order of rows from the inputs to preserve. See join() for details. Unlike join this function preserves the left order by\ndefault."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 481}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.upsample.html#polars.DataFrame.upsample"], "Title": ["DataFrame.upsample"], "Feature": ["DataFrame.upsample"], "Description": ["Upsample a DataFrame at a regular frequency."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"time\": [\n...             datetime(2021, 2, 1),\n...             datetime(2021, 4, 1),\n...             datetime(2021, 5, 1),\n...             datetime(2021, 6, 1),\n...         ],\n...         \"groups\": [\"A\", \"B\", \"A\", \"B\"],\n...         \"values\": [0, 1, 2, 3],\n...     }\n... ).set_sorted(\"time\")\n>>> df.upsample(\n...     time_column=\"time\", every=\"1mo\", group_by=\"groups\", maintain_order=True\n... ).select(pl.all().fill_null(strategy=\"forward\"))\nshape: (7, 3)\n┌─────────────────────┬────────┬────────┐\n│ time                ┆ groups ┆ values │\n│ ---                 ┆ ---    ┆ ---    │\n│ datetime[μs]        ┆ str    ┆ i64    │\n╞═════════════════════╪════════╪════════╡\n│ 2021-02-01 00:00:00 ┆ A      ┆ 0      │\n│ 2021-03-01 00:00:00 ┆ A      ┆ 0      │\n│ 2021-04-01 00:00:00 ┆ A      ┆ 0      │\n│ 2021-05-01 00:00:00 ┆ A      ┆ 2      │\n│ 2021-04-01 00:00:00 ┆ B      ┆ 1      │\n│ 2021-05-01 00:00:00 ┆ B      ┆ 1      │\n│ 2021-06-01 00:00:00 ┆ B      ┆ 3      │\n└─────────────────────┴────────┴────────┘"], "Parameters": [["time_column", "Time column will be used to determine a date_range.\nNote that this column has to be sorted for the output to make sense."], ["every", "Interval will start ‘every’ duration."], ["group_by", "First group by these columns and then upsample for every group."], ["maintain_order", "Keep the ordering predictable. This is slower."]], "Returns": [["DataFrame", "Result will be sorted by time_column (but note that if group_by columns\nare passed, it will only be sorted within each group)."]], "Category": ["Manipulation_selection"], "index": 482}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.vstack.html#polars.DataFrame.vstack"], "Title": ["DataFrame.vstack"], "Feature": ["DataFrame.vstack"], "Description": ["Grow this DataFrame vertically by stacking a DataFrame to it."], "Examples": [">>> df1 = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2],\n...         \"bar\": [6, 7],\n...         \"ham\": [\"a\", \"b\"],\n...     }\n... )\n>>> df2 = pl.DataFrame(\n...     {\n...         \"foo\": [3, 4],\n...         \"bar\": [8, 9],\n...         \"ham\": [\"c\", \"d\"],\n...     }\n... )\n>>> df1.vstack(df2)\nshape: (4, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6   ┆ a   │\n│ 2   ┆ 7   ┆ b   │\n│ 3   ┆ 8   ┆ c   │\n│ 4   ┆ 9   ┆ d   │\n└─────┴─────┴─────┘"], "Parameters": [["other", "DataFrame to stack."], ["in_place", "Modify in place."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 483}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_columns.html#polars.DataFrame.with_columns"], "Title": ["DataFrame.with_columns"], "Feature": ["DataFrame.with_columns"], "Description": ["Add columns to this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [0.5, 4, 10, 13],\n...         \"c\": [True, True, False, True],\n...     }\n... )\n>>> df.with_columns((pl.col(\"a\") ** 2).alias(\"a^2\"))\nshape: (4, 4)\n┌─────┬──────┬───────┬─────┐\n│ a   ┆ b    ┆ c     ┆ a^2 │\n│ --- ┆ ---  ┆ ---   ┆ --- │\n│ i64 ┆ f64  ┆ bool  ┆ i64 │\n╞═════╪══════╪═══════╪═════╡\n│ 1   ┆ 0.5  ┆ true  ┆ 1   │\n│ 2   ┆ 4.0  ┆ true  ┆ 4   │\n│ 3   ┆ 10.0 ┆ false ┆ 9   │\n│ 4   ┆ 13.0 ┆ true  ┆ 16  │\n└─────┴──────┴───────┴─────┘", ">>> df.with_columns(pl.col(\"a\").cast(pl.Float64))\nshape: (4, 3)\n┌─────┬──────┬───────┐\n│ a   ┆ b    ┆ c     │\n│ --- ┆ ---  ┆ ---   │\n│ f64 ┆ f64  ┆ bool  │\n╞═════╪══════╪═══════╡\n│ 1.0 ┆ 0.5  ┆ true  │\n│ 2.0 ┆ 4.0  ┆ true  │\n│ 3.0 ┆ 10.0 ┆ false │\n│ 4.0 ┆ 13.0 ┆ true  │\n└─────┴──────┴───────┘", ">>> df.with_columns(\n...     (pl.col(\"a\") ** 2).alias(\"a^2\"),\n...     (pl.col(\"b\") / 2).alias(\"b/2\"),\n...     (pl.col(\"c\").not_()).alias(\"not c\"),\n... )\nshape: (4, 6)\n┌─────┬──────┬───────┬─────┬──────┬───────┐\n│ a   ┆ b    ┆ c     ┆ a^2 ┆ b/2  ┆ not c │\n│ --- ┆ ---  ┆ ---   ┆ --- ┆ ---  ┆ ---   │\n│ i64 ┆ f64  ┆ bool  ┆ i64 ┆ f64  ┆ bool  │\n╞═════╪══════╪═══════╪═════╪══════╪═══════╡\n│ 1   ┆ 0.5  ┆ true  ┆ 1   ┆ 0.25 ┆ false │\n│ 2   ┆ 4.0  ┆ true  ┆ 4   ┆ 2.0  ┆ false │\n│ 3   ┆ 10.0 ┆ false ┆ 9   ┆ 5.0  ┆ true  │\n│ 4   ┆ 13.0 ┆ true  ┆ 16  ┆ 6.5  ┆ false │\n└─────┴──────┴───────┴─────┴──────┴───────┘", ">>> df.with_columns(\n...     [\n...         (pl.col(\"a\") ** 2).alias(\"a^2\"),\n...         (pl.col(\"b\") / 2).alias(\"b/2\"),\n...         (pl.col(\"c\").not_()).alias(\"not c\"),\n...     ]\n... )\nshape: (4, 6)\n┌─────┬──────┬───────┬─────┬──────┬───────┐\n│ a   ┆ b    ┆ c     ┆ a^2 ┆ b/2  ┆ not c │\n│ --- ┆ ---  ┆ ---   ┆ --- ┆ ---  ┆ ---   │\n│ i64 ┆ f64  ┆ bool  ┆ i64 ┆ f64  ┆ bool  │\n╞═════╪══════╪═══════╪═════╪══════╪═══════╡\n│ 1   ┆ 0.5  ┆ true  ┆ 1   ┆ 0.25 ┆ false │\n│ 2   ┆ 4.0  ┆ true  ┆ 4   ┆ 2.0  ┆ false │\n│ 3   ┆ 10.0 ┆ false ┆ 9   ┆ 5.0  ┆ true  │\n│ 4   ┆ 13.0 ┆ true  ┆ 16  ┆ 6.5  ┆ false │\n└─────┴──────┴───────┴─────┴──────┴───────┘", ">>> df.with_columns(\n...     ab=pl.col(\"a\") * pl.col(\"b\"),\n...     not_c=pl.col(\"c\").not_(),\n... )\nshape: (4, 5)\n┌─────┬──────┬───────┬──────┬───────┐\n│ a   ┆ b    ┆ c     ┆ ab   ┆ not_c │\n│ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---   │\n│ i64 ┆ f64  ┆ bool  ┆ f64  ┆ bool  │\n╞═════╪══════╪═══════╪══════╪═══════╡\n│ 1   ┆ 0.5  ┆ true  ┆ 0.5  ┆ false │\n│ 2   ┆ 4.0  ┆ true  ┆ 8.0  ┆ false │\n│ 3   ┆ 10.0 ┆ false ┆ 30.0 ┆ true  │\n│ 4   ┆ 13.0 ┆ true  ┆ 52.0 ┆ false │\n└─────┴──────┴───────┴──────┴───────┘"], "Parameters": [["*exprs", "Column(s) to add, specified as positional arguments.\nAccepts expression input. Strings are parsed as column names, other\nnon-expression inputs are parsed as literals."], ["**named_exprs", "Additional columns to add, specified as keyword arguments.\nThe columns will be renamed to the keyword used."]], "Returns": [["DataFrame", "A new DataFrame with the columns added."]], "Category": ["Manipulation_selection"], "index": 484}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.sum_horizontal.html#polars.DataFrame.sum_horizontal"], "Title": ["DataFrame.sum_horizontal"], "Feature": ["DataFrame.sum_horizontal"], "Description": ["Sum all values horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [4.0, 5.0, 6.0],\n...     }\n... )\n>>> df.sum_horizontal()\nshape: (3,)\nSeries: 'sum' [f64]\n[\n        5.0\n        7.0\n        9.0\n]"], "Parameters": [["ignore_nulls", "Ignore null values (default).\nIf set to False , any null value in the input will lead to a null output."]], "Returns": [["Series", "A Series named \"sum\" ."]], "Category": ["Aggregation"], "index": 485}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_columns_seq.html#polars.DataFrame.with_columns_seq"], "Title": ["DataFrame.with_columns_seq"], "Feature": ["DataFrame.with_columns_seq"], "Description": ["Add columns to this DataFrame."], "Examples": [], "Parameters": [["*exprs", "Column(s) to add, specified as positional arguments.\nAccepts expression input. Strings are parsed as column names, other\nnon-expression inputs are parsed as literals."], ["**named_exprs", "Additional columns to add, specified as keyword arguments.\nThe columns will be renamed to the keyword used."]], "Returns": [["DataFrame", "A new DataFrame with the columns added."]], "Category": ["Manipulation_selection"], "index": 486}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_row_count.html#polars.DataFrame.with_row_count"], "Title": ["DataFrame.with_row_count"], "Feature": ["DataFrame.with_row_count"], "Description": ["Add a column at index 0 that counts the rows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 3, 5],\n...         \"b\": [2, 4, 6],\n...     }\n... )\n>>> df.with_row_count()  \nshape: (3, 3)\n┌────────┬─────┬─────┐\n│ row_nr ┆ a   ┆ b   │\n│ ---    ┆ --- ┆ --- │\n│ u32    ┆ i64 ┆ i64 │\n╞════════╪═════╪═════╡\n│ 0      ┆ 1   ┆ 2   │\n│ 1      ┆ 3   ┆ 4   │\n│ 2      ┆ 5   ┆ 6   │\n└────────┴─────┴─────┘"], "Parameters": [["name", "Name of the column to add."], ["offset", "Start the row count at this offset. Default = 0"]], "Returns": [], "Category": ["Manipulation_selection"], "index": 487}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_row_index.html#polars.DataFrame.with_row_index"], "Title": ["DataFrame.with_row_index"], "Feature": ["DataFrame.with_row_index"], "Description": ["Add a row index as the first column in the DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 3, 5],\n...         \"b\": [2, 4, 6],\n...     }\n... )\n>>> df.with_row_index()\nshape: (3, 3)\n┌───────┬─────┬─────┐\n│ index ┆ a   ┆ b   │\n│ ---   ┆ --- ┆ --- │\n│ u32   ┆ i64 ┆ i64 │\n╞═══════╪═════╪═════╡\n│ 0     ┆ 1   ┆ 2   │\n│ 1     ┆ 3   ┆ 4   │\n│ 2     ┆ 5   ┆ 6   │\n└───────┴─────┴─────┘\n>>> df.with_row_index(\"id\", offset=1000)\nshape: (3, 3)\n┌──────┬─────┬─────┐\n│ id   ┆ a   ┆ b   │\n│ ---  ┆ --- ┆ --- │\n│ u32  ┆ i64 ┆ i64 │\n╞══════╪═════╪═════╡\n│ 1000 ┆ 1   ┆ 2   │\n│ 1001 ┆ 3   ┆ 4   │\n│ 1002 ┆ 5   ┆ 6   │\n└──────┴─────┴─────┘", ">>> df.select(\n...     pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"index\"),\n...     pl.all(),\n... )\nshape: (3, 3)\n┌───────┬─────┬─────┐\n│ index ┆ a   ┆ b   │\n│ ---   ┆ --- ┆ --- │\n│ u32   ┆ i64 ┆ i64 │\n╞═══════╪═════╪═════╡\n│ 0     ┆ 1   ┆ 2   │\n│ 1     ┆ 3   ┆ 4   │\n│ 2     ┆ 5   ┆ 6   │\n└───────┴─────┴─────┘"], "Parameters": [["name", "Name of the index column."], ["offset", "Start the index at this offset. Cannot be negative."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 488}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.collect_schema.html#polars.DataFrame.collect_schema"], "Title": ["DataFrame.collect_schema"], "Feature": ["DataFrame.collect_schema"], "Description": ["Get an ordered mapping of column names to their data type."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6.0, 7.0, 8.0],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.collect_schema()\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})", ">>> schema = df.collect_schema()\n>>> schema[\"bar\"]\nFloat64\n>>> schema.names()\n['foo', 'bar', 'ham']\n>>> schema.dtypes()\n[Int64, Float64, String]\n>>> schema.len()\n3"], "Parameters": [], "Returns": [], "Category": ["Miscellaneous"], "index": 489}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.corr.html#polars.DataFrame.corr"], "Title": ["DataFrame.corr"], "Feature": ["DataFrame.corr"], "Description": ["Return pairwise Pearson product-moment correlation coefficients between columns."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [3, 2, 1], \"ham\": [7, 8, 9]})\n>>> df.corr()\nshape: (3, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ f64  ┆ f64  ┆ f64  │\n╞══════╪══════╪══════╡\n│ 1.0  ┆ -1.0 ┆ 1.0  │\n│ -1.0 ┆ 1.0  ┆ -1.0 │\n│ 1.0  ┆ -1.0 ┆ 1.0  │\n└──────┴──────┴──────┘"], "Parameters": [["**kwargs", "Keyword arguments are passed to numpy corrcoef ."]], "Returns": [], "Category": ["Miscellaneous"], "index": 490}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.equals.html#polars.DataFrame.equals"], "Title": ["DataFrame.equals"], "Feature": ["DataFrame.equals"], "Description": ["Check whether the DataFrame is equal to another DataFrame."], "Examples": [">>> df1 = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6.0, 7.0, 8.0],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df2 = pl.DataFrame(\n...     {\n...         \"foo\": [3, 2, 1],\n...         \"bar\": [8.0, 7.0, 6.0],\n...         \"ham\": [\"c\", \"b\", \"a\"],\n...     }\n... )\n>>> df1.equals(df1)\nTrue\n>>> df1.equals(df2)\nFalse"], "Parameters": [["other", "DataFrame to compare with."], ["null_equal", "Consider null values as equal."]], "Returns": [], "Category": ["Miscellaneous"], "index": 491}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.map_columns.html#polars.DataFrame.map_columns"], "Title": ["DataFrame.map_columns"], "Feature": ["DataFrame.map_columns"], "Description": ["Apply eager functions to columns of a DataFrame."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3, 4], \"b\": [\"10\", \"20\", \"30\", \"40\"]})\n>>> df.map_columns(\"a\", lambda s: s.shrink_dtype())\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i8  ┆ str │\n╞═════╪═════╡\n│ 1   ┆ 10  │\n│ 2   ┆ 20  │\n│ 3   ┆ 30  │\n│ 4   ┆ 40  │\n└─────┴─────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": ['{\"x\":\"a\"}', None, '{\"x\":\"b\"}', None],\n...         \"b\": ['{\"a\":1, \"b\": true}', None, '{\"a\":2, \"b\": false}', None],\n...     }\n... )\n>>> df.map_columns([\"a\", \"b\"], lambda s: s.str.json_decode())\nshape: (4, 2)\n┌───────────┬───────────┐\n│ a         ┆ b         │\n│ ---       ┆ ---       │\n│ struct[1] ┆ struct[2] │\n╞═══════════╪═══════════╡\n│ {\"a\"}     ┆ {1,true}  │\n│ null      ┆ null      │\n│ {\"b\"}     ┆ {2,false} │\n│ null      ┆ null      │\n└───────────┴───────────┘\n>>> import polars.selectors as cs\n>>> df.map_columns(cs.all(), lambda s: s.str.json_decode())\nshape: (4, 2)\n┌───────────┬───────────┐\n│ a         ┆ b         │\n│ ---       ┆ ---       │\n│ struct[1] ┆ struct[2] │\n╞═══════════╪═══════════╡\n│ {\"a\"}     ┆ {1,true}  │\n│ null      ┆ null      │\n│ {\"b\"}     ┆ {2,false} │\n│ null      ┆ null      │\n└───────────┴───────────┘"], "Parameters": [["column_names", "The columns to apply the UDF to."], ["function", "Callable; will receive a column series as the first parameter,\nfollowed by any given args/kwargs."], ["*args", "Arguments to pass to the UDF."], ["**kwargs", "Keyword arguments to pass to the UDF."]], "Returns": [], "Category": ["Miscellaneous"], "index": 493}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.map_rows.html#polars.DataFrame.map_rows"], "Title": ["DataFrame.map_rows"], "Feature": ["DataFrame.map_rows"], "Description": ["Apply a custom/user-defined function (UDF) over the rows of the DataFrame."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [-1, 5, 8]})", ">>> df.map_rows(lambda t: (t[0] * 2, t[1] * 3))\nshape: (3, 2)\n┌──────────┬──────────┐\n│ column_0 ┆ column_1 │\n│ ---      ┆ ---      │\n│ i64      ┆ i64      │\n╞══════════╪══════════╡\n│ 2        ┆ -3       │\n│ 4        ┆ 15       │\n│ 6        ┆ 24       │\n└──────────┴──────────┘", ">>> df.select(\n...     pl.col(\"foo\") * 2,\n...     pl.col(\"bar\") * 3,\n... )", ">>> df.map_rows(lambda t: (t[0] * 2 + t[1]))\nshape: (3, 1)\n┌─────┐\n│ map │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 9   │\n│ 14  │\n└─────┘", ">>> df.select(pl.col(\"foo\") * 2 + pl.col(\"bar\"))"], "Parameters": [["function", "Custom function or lambda."], ["return_dtype", "Output type of the operation. If none given, Polars tries to infer the type."], ["inference_size", "Only used in the case when the custom function returns rows.\nThis uses the first n rows to determine the output schema."]], "Returns": [], "Category": ["Miscellaneous"], "index": 494}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.deserialize.html#polars.DataFrame.deserialize"], "Title": ["DataFrame.deserialize"], "Feature": ["DataFrame.deserialize"], "Description": ["Read a serialized DataFrame from a file."], "Examples": [">>> import io\n>>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4.0, 5.0, 6.0]})\n>>> bytes = df.serialize()\n>>> pl.DataFrame.deserialize(io.BytesIO(bytes))\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ f64 │\n╞═════╪═════╡\n│ 1   ┆ 4.0 │\n│ 2   ┆ 5.0 │\n│ 3   ┆ 6.0 │\n└─────┴─────┘"], "Parameters": [["source", "Path to a file or a file-like object (by file-like object, we refer to\nobjects that have a read() method, such as a file handler (e.g.\nvia builtin open function) or BytesIO )."], ["format", "The format with which the DataFrame was serialized. Options: \"binary\" : Deserialize from binary format (bytes). This is the default. \"json\" : Deserialize from JSON format (string)."]], "Returns": [], "Category": ["Miscellaneous"], "index": 495}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.var.html#polars.DataFrame.var"], "Title": ["DataFrame.var"], "Feature": ["DataFrame.var"], "Description": ["Aggregate the columns of this DataFrame to their variance value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.var()\nshape: (1, 3)\n┌─────┬─────┬──────┐\n│ foo ┆ bar ┆ ham  │\n│ --- ┆ --- ┆ ---  │\n│ f64 ┆ f64 ┆ str  │\n╞═════╪═════╪══════╡\n│ 1.0 ┆ 1.0 ┆ null │\n└─────┴─────┴──────┘\n>>> df.var(ddof=0)\nshape: (1, 3)\n┌──────────┬──────────┬──────┐\n│ foo      ┆ bar      ┆ ham  │\n│ ---      ┆ ---      ┆ ---  │\n│ f64      ┆ f64      ┆ str  │\n╞══════════╪══════════╪══════╡\n│ 0.666667 ┆ 0.666667 ┆ null │\n└──────────┴──────────┴──────┘"], "Parameters": [["ddof", "“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof,\nwhere N represents the number of elements.\nBy default ddof is 1."]], "Returns": [], "Category": ["Aggregation"], "index": 496}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.serialize.html#polars.DataFrame.serialize"], "Title": ["DataFrame.serialize"], "Feature": ["DataFrame.serialize"], "Description": ["Serialize this DataFrame to a file or string in JSON format."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...     }\n... )\n>>> bytes = df.serialize()\n>>> type(bytes)\n<class 'bytes'>", ">>> import io\n>>> pl.DataFrame.deserialize(io.BytesIO(bytes))\nshape: (3, 2)\n┌─────┬─────┐\n│ foo ┆ bar │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 6   │\n│ 2   ┆ 7   │\n│ 3   ┆ 8   │\n└─────┴─────┘"], "Parameters": [["file", "File path or writable file-like object to which the result will be written.\nIf set to None (default), the output is returned as a string instead."], ["format", "The format in which to serialize. Options: \"binary\" : Serialize to binary format (bytes). This is the default. \"json\" : Serialize to JSON format (string)."]], "Returns": [], "Category": ["Miscellaneous"], "index": 497}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.columns.html#polars.DataFrame.columns"], "Title": ["DataFrame.columns"], "Feature": ["DataFrame.columns"], "Description": ["Get or set column names."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.columns\n['foo', 'bar', 'ham']", ">>> df.columns = [\"apple\", \"banana\", \"orange\"]\n>>> df\nshape: (3, 3)\n┌───────┬────────┬────────┐\n│ apple ┆ banana ┆ orange │\n│ ---   ┆ ---    ┆ ---    │\n│ i64   ┆ i64    ┆ str    │\n╞═══════╪════════╪════════╡\n│ 1     ┆ 6      ┆ a      │\n│ 2     ┆ 7      ┆ b      │\n│ 3     ┆ 8      ┆ c      │\n└───────┴────────┴────────┘"], "Parameters": [], "Returns": [["list of str", "A list containing the name of each column in order."]], "Category": ["Attributes"], "index": 498}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.dtypes.html#polars.DataFrame.dtypes"], "Title": ["DataFrame.dtypes"], "Feature": ["DataFrame.dtypes"], "Description": ["Get the column data types."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6.0, 7.0, 8.0],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.dtypes\n[Int64, Float64, String]\n>>> df\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ f64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6.0 ┆ a   │\n│ 2   ┆ 7.0 ┆ b   │\n│ 3   ┆ 8.0 ┆ c   │\n└─────┴─────┴─────┘"], "Parameters": [], "Returns": [["list of DataType", "A list containing the data type of each column in order."]], "Category": ["Attributes"], "index": 499}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.flags.html#polars.DataFrame.flags"], "Title": ["DataFrame.flags"], "Feature": ["DataFrame.flags"], "Description": ["Get flags that are set on the columns of this DataFrame."], "Examples": [], "Parameters": [], "Returns": [["dict", "Mapping from column names to column flags."]], "Category": ["Attributes"], "index": 500}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.height.html#polars.DataFrame.height"], "Title": ["DataFrame.height"], "Feature": ["DataFrame.height"], "Description": ["Get the number of rows."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5]})\n>>> df.height\n5"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Attributes"], "index": 501}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.schema.html#polars.DataFrame.schema"], "Title": ["DataFrame.schema"], "Feature": ["DataFrame.schema"], "Description": ["Get an ordered mapping of column names to their data type."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6.0, 7.0, 8.0],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.schema\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})"], "Parameters": [], "Returns": [], "Category": ["Attributes"], "index": 502}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.shape.html#polars.DataFrame.shape"], "Title": ["DataFrame.shape"], "Feature": ["DataFrame.shape"], "Description": ["Get the shape of the DataFrame."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3, 4, 5]})\n>>> df.shape\n(5, 1)"], "Parameters": [], "Returns": [], "Category": ["Attributes"], "index": 503}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.max_horizontal.html#polars.DataFrame.max_horizontal"], "Title": ["DataFrame.max_horizontal"], "Feature": ["DataFrame.max_horizontal"], "Description": ["Get the maximum value horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [4.0, 5.0, 6.0],\n...     }\n... )\n>>> df.max_horizontal()\nshape: (3,)\nSeries: 'max' [f64]\n[\n        4.0\n        5.0\n        6.0\n]"], "Parameters": [], "Returns": [["Series", "A Series named \"max\" ."]], "Category": ["Aggregation"], "index": 504}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.width.html#polars.DataFrame.width"], "Title": ["DataFrame.width"], "Feature": ["DataFrame.width"], "Description": ["Get the number of columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [4, 5, 6],\n...     }\n... )\n>>> df.width\n2"], "Parameters": [], "Returns": [["int", ""]], "Category": ["Attributes"], "index": 505}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.fold.html#polars.DataFrame.fold"], "Title": ["DataFrame.fold"], "Feature": ["DataFrame.fold"], "Description": ["Apply a horizontal reduction on a DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [2, 1, 3],\n...         \"b\": [1, 2, 3],\n...         \"c\": [1.0, 2.0, 3.0],\n...     }\n... )\n>>> df.fold(lambda s1, s2: s1 + s2)\nshape: (3,)\nSeries: 'a' [f64]\n[\n    4.0\n    5.0\n    9.0\n]", ">>> df = pl.DataFrame({\"a\": [2, 1, 3], \"b\": [1, 2, 3], \"c\": [1.0, 2.0, 3.0]})\n>>> df.fold(lambda s1, s2: s1.zip_with(s1 < s2, s2))\nshape: (3,)\nSeries: 'a' [f64]\n[\n    1.0\n    1.0\n    3.0\n]", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"foo\", \"bar\", None],\n...         \"b\": [1, 2, 3],\n...         \"c\": [1.0, 2.0, 3.0],\n...     }\n... )\n>>> df.fold(lambda s1, s2: s1 + s2)\nshape: (3,)\nSeries: 'a' [str]\n[\n    \"foo11.0\"\n    \"bar22.0\"\n    null\n]", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [False, False, True],\n...         \"b\": [False, True, False],\n...     }\n... )\n>>> df.fold(lambda s1, s2: s1 | s2)\nshape: (3,)\nSeries: 'a' [bool]\n[\n        false\n        true\n        true\n]"], "Parameters": [["operation", "function that takes two Series and returns a Series ."]], "Returns": [], "Category": ["Computation"], "index": 506}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.hash_rows.html#polars.DataFrame.hash_rows"], "Title": ["DataFrame.hash_rows"], "Feature": ["DataFrame.hash_rows"], "Description": ["Hash and combine the rows in this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, None, 3, 4],\n...         \"ham\": [\"a\", \"b\", None, \"d\"],\n...     }\n... )\n>>> df.hash_rows(seed=42)  \nshape: (4,)\nSeries: '' [u64]\n[\n    10783150408545073287\n    1438741209321515184\n    10047419486152048166\n    2047317070637311557\n]"], "Parameters": [["seed", "Random seed parameter. Defaults to 0."], ["seed_1", "Random seed parameter. Defaults to seed if not set."], ["seed_2", "Random seed parameter. Defaults to seed if not set."], ["seed_3", "Random seed parameter. Defaults to seed if not set."]], "Returns": [], "Category": ["Computation"], "index": 507}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.approx_n_unique.html#polars.DataFrame.approx_n_unique"], "Title": ["DataFrame.approx_n_unique"], "Feature": ["DataFrame.approx_n_unique"], "Description": ["Approximate count of unique values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [1, 2, 1, 1],\n...     }\n... )\n>>> df.approx_n_unique()  \nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ u32 ┆ u32 │\n╞═════╪═════╡\n│ 4   ┆ 2   │\n└─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Descriptive"], "index": 508}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.describe.html#polars.DataFrame.describe"], "Title": ["DataFrame.describe"], "Feature": ["DataFrame.describe"], "Description": ["Summary statistics for a DataFrame."], "Examples": [">>> from datetime import date, time\n>>> df = pl.DataFrame(\n...     {\n...         \"float\": [1.0, 2.8, 3.0],\n...         \"int\": [40, 50, None],\n...         \"bool\": [True, False, True],\n...         \"str\": [\"zz\", \"xx\", \"yy\"],\n...         \"date\": [date(2020, 1, 1), date(2021, 7, 5), date(2022, 12, 31)],\n...         \"time\": [time(10, 20, 30), time(14, 45, 50), time(23, 15, 10)],\n...     }\n... )", ">>> df.describe()\nshape: (9, 7)\n┌────────────┬──────────┬──────────┬──────────┬──────┬─────────────────────┬──────────┐\n│ statistic  ┆ float    ┆ int      ┆ bool     ┆ str  ┆ date                ┆ time     │\n│ ---        ┆ ---      ┆ ---      ┆ ---      ┆ ---  ┆ ---                 ┆ ---      │\n│ str        ┆ f64      ┆ f64      ┆ f64      ┆ str  ┆ str                 ┆ str      │\n╞════════════╪══════════╪══════════╪══════════╪══════╪═════════════════════╪══════════╡\n│ count      ┆ 3.0      ┆ 2.0      ┆ 3.0      ┆ 3    ┆ 3                   ┆ 3        │\n│ null_count ┆ 0.0      ┆ 1.0      ┆ 0.0      ┆ 0    ┆ 0                   ┆ 0        │\n│ mean       ┆ 2.266667 ┆ 45.0     ┆ 0.666667 ┆ null ┆ 2021-07-02 16:00:00 ┆ 16:07:10 │\n│ std        ┆ 1.101514 ┆ 7.071068 ┆ null     ┆ null ┆ null                ┆ null     │\n│ min        ┆ 1.0      ┆ 40.0     ┆ 0.0      ┆ xx   ┆ 2020-01-01          ┆ 10:20:30 │\n│ 25%        ┆ 2.8      ┆ 40.0     ┆ null     ┆ null ┆ 2021-07-05          ┆ 14:45:50 │\n│ 50%        ┆ 2.8      ┆ 50.0     ┆ null     ┆ null ┆ 2021-07-05          ┆ 14:45:50 │\n│ 75%        ┆ 3.0      ┆ 50.0     ┆ null     ┆ null ┆ 2022-12-31          ┆ 23:15:10 │\n│ max        ┆ 3.0      ┆ 50.0     ┆ 1.0      ┆ zz   ┆ 2022-12-31          ┆ 23:15:10 │\n└────────────┴──────────┴──────────┴──────────┴──────┴─────────────────────┴──────────┘", ">>> with pl.Config(tbl_rows=12):\n...     df.describe(\n...         percentiles=[0.1, 0.3, 0.5, 0.7, 0.9],\n...         interpolation=\"linear\",\n...     )\nshape: (11, 7)\n┌────────────┬──────────┬──────────┬──────────┬──────┬─────────────────────┬──────────┐\n│ statistic  ┆ float    ┆ int      ┆ bool     ┆ str  ┆ date                ┆ time     │\n│ ---        ┆ ---      ┆ ---      ┆ ---      ┆ ---  ┆ ---                 ┆ ---      │\n│ str        ┆ f64      ┆ f64      ┆ f64      ┆ str  ┆ str                 ┆ str      │\n╞════════════╪══════════╪══════════╪══════════╪══════╪═════════════════════╪══════════╡\n│ count      ┆ 3.0      ┆ 2.0      ┆ 3.0      ┆ 3    ┆ 3                   ┆ 3        │\n│ null_count ┆ 0.0      ┆ 1.0      ┆ 0.0      ┆ 0    ┆ 0                   ┆ 0        │\n│ mean       ┆ 2.266667 ┆ 45.0     ┆ 0.666667 ┆ null ┆ 2021-07-02 16:00:00 ┆ 16:07:10 │\n│ std        ┆ 1.101514 ┆ 7.071068 ┆ null     ┆ null ┆ null                ┆ null     │\n│ min        ┆ 1.0      ┆ 40.0     ┆ 0.0      ┆ xx   ┆ 2020-01-01          ┆ 10:20:30 │\n│ 10%        ┆ 1.36     ┆ 41.0     ┆ null     ┆ null ┆ 2020-04-20          ┆ 11:13:34 │\n│ 30%        ┆ 2.08     ┆ 43.0     ┆ null     ┆ null ┆ 2020-11-26          ┆ 12:59:42 │\n│ 50%        ┆ 2.8      ┆ 45.0     ┆ null     ┆ null ┆ 2021-07-05          ┆ 14:45:50 │\n│ 70%        ┆ 2.88     ┆ 47.0     ┆ null     ┆ null ┆ 2022-02-07          ┆ 18:09:34 │\n│ 90%        ┆ 2.96     ┆ 49.0     ┆ null     ┆ null ┆ 2022-09-13          ┆ 21:33:18 │\n│ max        ┆ 3.0      ┆ 50.0     ┆ 1.0      ┆ zz   ┆ 2022-12-31          ┆ 23:15:10 │\n└────────────┴──────────┴──────────┴──────────┴──────┴─────────────────────┴──────────┘"], "Parameters": [["percentiles", "One or more percentiles to include in the summary statistics.\nAll values must be in the range [0, 1] ."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method used when calculating percentiles."]], "Returns": [], "Category": ["Descriptive"], "index": 509}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.estimated_size.html#polars.DataFrame.estimated_size"], "Title": ["DataFrame.estimated_size"], "Feature": ["DataFrame.estimated_size"], "Description": ["Return an estimation of the total (heap) allocated size of theDataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"x\": list(reversed(range(1_000_000))),\n...         \"y\": [v / 1000 for v in range(1_000_000)],\n...         \"z\": [str(v) for v in range(1_000_000)],\n...     },\n...     schema=[(\"x\", pl.UInt32), (\"y\", pl.Float64), (\"z\", pl.String)],\n... )\n>>> df.estimated_size()\n17888890\n>>> df.estimated_size(\"mb\")\n17.0601749420166"], "Parameters": [["unit {‘b’, ‘kb’, ‘mb’, ‘gb’, ‘tb’}", "Scale the returned size to the given unit."]], "Returns": [], "Category": ["Descriptive"], "index": 510}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.glimpse.html#polars.DataFrame.glimpse"], "Title": ["DataFrame.glimpse"], "Feature": ["DataFrame.glimpse"], "Description": ["Return a dense preview of the DataFrame."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"a\": [1.0, 2.8, 3.0],\n...         \"b\": [4, 5, None],\n...         \"c\": [True, False, True],\n...         \"d\": [None, \"b\", \"c\"],\n...         \"e\": [\"usd\", \"eur\", None],\n...         \"f\": [date(2020, 1, 1), date(2021, 1, 2), date(2022, 1, 1)],\n...     }\n... )", ">>> res = df.glimpse()\nRows: 3\nColumns: 6\n$ a  <f64> 1.0, 2.8, 3.0\n$ b  <i64> 4, 5, null\n$ c <bool> True, False, True\n$ d  <str> null, 'b', 'c'\n$ e  <str> 'usd', 'eur', null\n$ f <date> 2020-01-01, 2021-01-02, 2022-01-01\n>>> res is None\nTrue", ">>> res = df.glimpse(return_type=\"string\")\n>>> isinstance(res, str)\nTrue", ">>> df.glimpse(return_type=\"frame\")\nshape: (6, 3)\n┌────────┬───────┬─────────────────────────────────┐\n│ column ┆ dtype ┆ values                          │\n│ ---    ┆ ---   ┆ ---                             │\n│ str    ┆ str   ┆ list[str]                       │\n╞════════╪═══════╪═════════════════════════════════╡\n│ a      ┆ f64   ┆ [\"1.0\", \"2.8\", \"3.0\"]           │\n│ b      ┆ i64   ┆ [\"4\", \"5\", null]                │\n│ c      ┆ bool  ┆ [\"True\", \"False\", \"True\"]       │\n│ d      ┆ str   ┆ [null, \"'b'\", \"'c'\"]            │\n│ e      ┆ str   ┆ [\"'usd'\", \"'eur'\", null]        │\n│ f      ┆ date  ┆ [\"2020-01-01\", \"2021-01-02\", \"… │\n└────────┴───────┴─────────────────────────────────┘", ">>> res = df.glimpse(return_type=\"self\")\nRows: 3\nColumns: 6\n$ a  <f64> 1.0, 2.8, 3.0\n$ b  <i64> 4, 5, null\n$ c <bool> True, False, True\n$ d  <str> null, 'b', 'c'\n$ e  <str> 'usd', 'eur', null\n$ f <date> 2020-01-01, 2021-01-02, 2022-01-01\n>>> res\nshape: (3, 6)\n┌─────┬──────┬───────┬──────┬──────┬────────────┐\n│ a   ┆ b    ┆ c     ┆ d    ┆ e    ┆ f          │\n│ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---  ┆ ---        │\n│ f64 ┆ i64  ┆ bool  ┆ str  ┆ str  ┆ date       │\n╞═════╪══════╪═══════╪══════╪══════╪════════════╡\n│ 1.0 ┆ 4    ┆ true  ┆ null ┆ usd  ┆ 2020-01-01 │\n│ 2.8 ┆ 5    ┆ false ┆ b    ┆ eur  ┆ 2021-01-02 │\n│ 3.0 ┆ null ┆ true  ┆ c    ┆ null ┆ 2022-01-01 │\n└─────┴──────┴───────┴──────┴──────┴────────────┘"], "Parameters": [["max_items_per_column", "Maximum number of items to show per column."], ["max_colname_length", "Maximum length of the displayed column names; values that exceed\nthis value are truncated with a trailing ellipsis."], ["return_type", "Modify the return format: None (default): Print the glimpse output to stdout, returning None . \"self\" : Print the glimpse output to stdout, returning the original frame. \"frame\" : Return the glimpse output as a new DataFrame. \"string\" : Return the glimpse output as a string."]], "Returns": [], "Category": ["Descriptive"], "index": 511}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.is_duplicated.html#polars.DataFrame.is_duplicated"], "Title": ["DataFrame.is_duplicated"], "Feature": ["DataFrame.is_duplicated"], "Description": ["Get a mask of all duplicated rows in this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 1],\n...         \"b\": [\"x\", \"y\", \"z\", \"x\"],\n...     }\n... )\n>>> df.is_duplicated()\nshape: (4,)\nSeries: '' [bool]\n[\n        true\n        false\n        false\n        true\n]", ">>> df.filter(df.is_duplicated())\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ str │\n╞═════╪═════╡\n│ 1   ┆ x   │\n│ 1   ┆ x   │\n└─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Descriptive"], "index": 512}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.is_empty.html#polars.DataFrame.is_empty"], "Title": ["DataFrame.is_empty"], "Feature": ["DataFrame.is_empty"], "Description": ["ReturnsTrueif the DataFrame contains no rows."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n>>> df.is_empty()\nFalse\n>>> df.filter(pl.col(\"foo\") > 99).is_empty()\nTrue"], "Parameters": [], "Returns": [], "Category": ["Descriptive"], "index": 513}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.is_unique.html#polars.DataFrame.is_unique"], "Title": ["DataFrame.is_unique"], "Feature": ["DataFrame.is_unique"], "Description": ["Get a mask of all unique rows in this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 1],\n...         \"b\": [\"x\", \"y\", \"z\", \"x\"],\n...     }\n... )\n>>> df.is_unique()\nshape: (4,)\nSeries: '' [bool]\n[\n        false\n        true\n        true\n        false\n]", ">>> df.filter(df.is_unique())\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ str │\n╞═════╪═════╡\n│ 2   ┆ y   │\n│ 3   ┆ z   │\n└─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Descriptive"], "index": 514}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.mean.html#polars.DataFrame.mean"], "Title": ["DataFrame.mean"], "Feature": ["DataFrame.mean"], "Description": ["Aggregate the columns of this DataFrame to their mean value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...         \"spam\": [True, False, None],\n...     }\n... )\n>>> df.mean()\nshape: (1, 4)\n┌─────┬─────┬──────┬──────┐\n│ foo ┆ bar ┆ ham  ┆ spam │\n│ --- ┆ --- ┆ ---  ┆ ---  │\n│ f64 ┆ f64 ┆ str  ┆ f64  │\n╞═════╪═════╪══════╪══════╡\n│ 2.0 ┆ 7.0 ┆ null ┆ 0.5  │\n└─────┴─────┴──────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 515}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.n_chunks.html#polars.DataFrame.n_chunks"], "Title": ["DataFrame.n_chunks"], "Feature": ["DataFrame.n_chunks"], "Description": ["Get number of chunks used by the ChunkedArrays of this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [0.5, 4, 10, 13],\n...         \"c\": [True, True, False, True],\n...     }\n... )\n>>> df.n_chunks()\n1\n>>> df.n_chunks(strategy=\"all\")\n[1, 1, 1]"], "Parameters": [["strategy {‘first’, ‘all’}", "Return the number of chunks of the ‘first’ column,\nor ‘all’ columns in this DataFrame."]], "Returns": [], "Category": ["Descriptive"], "index": 516}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.n_unique.html#polars.DataFrame.n_unique"], "Title": ["DataFrame.n_unique"], "Feature": ["DataFrame.n_unique"], "Description": ["Return the number of unique rows, or the number of unique row-subsets."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 1, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 1.0, 2.0, 3.0, 3.0],\n...         \"c\": [True, True, True, False, True, True],\n...     }\n... )\n>>> df.n_unique()\n5", ">>> df.n_unique(subset=[\"b\", \"c\"])\n4", ">>> df.n_unique(\n...     subset=[\n...         (pl.col(\"a\") // 2),\n...         (pl.col(\"c\") | (pl.col(\"b\") >= 2)),\n...     ],\n... )\n3"], "Parameters": [["subset", "One or more columns/expressions that define what to count;\nomit to return the count of unique rows."]], "Returns": [], "Category": ["Descriptive"], "index": 517}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.null_count.html#polars.DataFrame.null_count"], "Title": ["DataFrame.null_count"], "Feature": ["DataFrame.null_count"], "Description": ["Create a new DataFrame that shows the null counts per column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, None, 3],\n...         \"bar\": [6, 7, None],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.null_count()\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ u32 ┆ u32 ┆ u32 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 1   ┆ 0   │\n└─────┴─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Descriptive"], "index": 518}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.agg.html#polars.dataframe.group_by.GroupBy.agg"], "Title": ["GroupBy.agg"], "Feature": ["GroupBy.agg"], "Description": ["Compute aggregations for each group of a group by operation."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...         \"b\": [1, 2, 1, 3, 3],\n...         \"c\": [5, 4, 3, 2, 1],\n...     }\n... )\n>>> df.group_by(\"a\").agg(pl.col(\"b\"), pl.col(\"c\"))  \nshape: (3, 3)\n┌─────┬───────────┬───────────┐\n│ a   ┆ b         ┆ c         │\n│ --- ┆ ---       ┆ ---       │\n│ str ┆ list[i64] ┆ list[i64] │\n╞═════╪═══════════╪═══════════╡\n│ a   ┆ [1, 1]    ┆ [5, 3]    │\n├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ b   ┆ [2, 3]    ┆ [4, 2]    │\n├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ c   ┆ [3]       ┆ [1]       │\n└─────┴───────────┴───────────┘", ">>> df.group_by(\"a\").agg(pl.col(\"b\").sum())  \nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ a   ┆ 2   │\n│ b   ┆ 5   │\n│ c   ┆ 3   │\n└─────┴─────┘", ">>> df.group_by(\"a\").agg([pl.sum(\"b\"), pl.mean(\"c\")])  \nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ f64 │\n╞═════╪═════╪═════╡\n│ c   ┆ 3   ┆ 1.0 │\n│ a   ┆ 2   ┆ 4.0 │\n│ b   ┆ 5   ┆ 3.0 │\n└─────┴─────┴─────┘", ">>> df.group_by(\"a\").agg(\n...     pl.sum(\"b\").name.suffix(\"_sum\"),\n...     (pl.col(\"c\") ** 2).mean().name.suffix(\"_mean_squared\"),\n... )  \nshape: (3, 3)\n┌─────┬───────┬────────────────┐\n│ a   ┆ b_sum ┆ c_mean_squared │\n│ --- ┆ ---   ┆ ---            │\n│ str ┆ i64   ┆ f64            │\n╞═════╪═══════╪════════════════╡\n│ a   ┆ 2     ┆ 17.0           │\n│ c   ┆ 3     ┆ 1.0            │\n│ b   ┆ 5     ┆ 10.0           │\n└─────┴───────┴────────────────┘", ">>> df.group_by(\"a\").agg(\n...     b_sum=pl.sum(\"b\"),\n...     c_mean_squared=(pl.col(\"c\") ** 2).mean(),\n... )  \nshape: (3, 3)\n┌─────┬───────┬────────────────┐\n│ a   ┆ b_sum ┆ c_mean_squared │\n│ --- ┆ ---   ┆ ---            │\n│ str ┆ i64   ┆ f64            │\n╞═════╪═══════╪════════════════╡\n│ a   ┆ 2     ┆ 17.0           │\n│ c   ┆ 3     ┆ 1.0            │\n│ b   ┆ 5     ┆ 10.0           │\n└─────┴───────┴────────────────┘"], "Parameters": [["*aggs", "Aggregations to compute for each group of the group by operation,\nspecified as positional arguments.\nAccepts expression input. Strings are parsed as column names."], ["**named_aggs", "Additional aggregations, specified as keyword arguments.\nThe resulting columns will be renamed to the keyword used."]], "Returns": [], "Category": ["GroupBy"], "index": 520}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.all.html#polars.dataframe.group_by.GroupBy.all"], "Title": ["GroupBy.all"], "Feature": ["GroupBy.all"], "Description": ["Aggregate the groups into Series."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"one\", \"two\", \"one\", \"two\"], \"b\": [1, 2, 3, 4]})\n>>> df.group_by(\"a\", maintain_order=True).all()\nshape: (2, 2)\n┌─────┬───────────┐\n│ a   ┆ b         │\n│ --- ┆ ---       │\n│ str ┆ list[i64] │\n╞═════╪═══════════╡\n│ one ┆ [1, 3]    │\n│ two ┆ [2, 4]    │\n└─────┴───────────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 521}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.count.html#polars.dataframe.group_by.GroupBy.count"], "Title": ["GroupBy.count"], "Feature": ["GroupBy.count"], "Description": ["Return the number of rows in each group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"Apple\", \"Apple\", \"Orange\"],\n...         \"b\": [1, None, 2],\n...     }\n... )\n>>> df.group_by(\"a\").count()  \nshape: (2, 2)\n┌────────┬───────┐\n│ a      ┆ count │\n│ ---    ┆ ---   │\n│ str    ┆ u32   │\n╞════════╪═══════╡\n│ Apple  ┆ 2     │\n│ Orange ┆ 1     │\n└────────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 522}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.first.html#polars.dataframe.group_by.GroupBy.first"], "Title": ["GroupBy.first"], "Feature": ["GroupBy.first"], "Description": ["Aggregate the first values in the group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"c\": [True, True, True, False, False, True],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).first()\nshape: (3, 4)\n┌────────┬─────┬──────┬───────┐\n│ d      ┆ a   ┆ b    ┆ c     │\n│ ---    ┆ --- ┆ ---  ┆ ---   │\n│ str    ┆ i64 ┆ f64  ┆ bool  │\n╞════════╪═════╪══════╪═══════╡\n│ Apple  ┆ 1   ┆ 0.5  ┆ true  │\n│ Orange ┆ 2   ┆ 0.5  ┆ true  │\n│ Banana ┆ 4   ┆ 13.0 ┆ false │\n└────────┴─────┴──────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 523}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.head.html#polars.dataframe.group_by.GroupBy.head"], "Title": ["GroupBy.head"], "Feature": ["GroupBy.head"], "Description": ["Get the firstnrows of each group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"letters\": [\"c\", \"c\", \"a\", \"c\", \"a\", \"b\"],\n...         \"nrs\": [1, 2, 3, 4, 5, 6],\n...     }\n... )\n>>> df\nshape: (6, 2)\n┌─────────┬─────┐\n│ letters ┆ nrs │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ c       ┆ 1   │\n│ c       ┆ 2   │\n│ a       ┆ 3   │\n│ c       ┆ 4   │\n│ a       ┆ 5   │\n│ b       ┆ 6   │\n└─────────┴─────┘\n>>> df.group_by(\"letters\").head(2).sort(\"letters\")\nshape: (5, 2)\n┌─────────┬─────┐\n│ letters ┆ nrs │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ a       ┆ 3   │\n│ a       ┆ 5   │\n│ b       ┆ 6   │\n│ c       ┆ 1   │\n│ c       ┆ 2   │\n└─────────┴─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["GroupBy"], "index": 524}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.last.html#polars.dataframe.group_by.GroupBy.last"], "Title": ["GroupBy.last"], "Feature": ["GroupBy.last"], "Description": ["Aggregate the last values in the group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 14, 13],\n...         \"c\": [True, True, True, False, False, True],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).last()\nshape: (3, 4)\n┌────────┬─────┬──────┬───────┐\n│ d      ┆ a   ┆ b    ┆ c     │\n│ ---    ┆ --- ┆ ---  ┆ ---   │\n│ str    ┆ i64 ┆ f64  ┆ bool  │\n╞════════╪═════╪══════╪═══════╡\n│ Apple  ┆ 3   ┆ 10.0 ┆ false │\n│ Orange ┆ 2   ┆ 0.5  ┆ true  │\n│ Banana ┆ 5   ┆ 13.0 ┆ true  │\n└────────┴─────┴──────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 525}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.mean_horizontal.html#polars.DataFrame.mean_horizontal"], "Title": ["DataFrame.mean_horizontal"], "Feature": ["DataFrame.mean_horizontal"], "Description": ["Take the mean of all values horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [4.0, 5.0, 6.0],\n...     }\n... )\n>>> df.mean_horizontal()\nshape: (3,)\nSeries: 'mean' [f64]\n[\n        2.5\n        3.5\n        4.5\n]"], "Parameters": [["ignore_nulls", "Ignore null values (default).\nIf set to False , any null value in the input will lead to a null output."]], "Returns": [["Series", "A Series named \"mean\" ."]], "Category": ["Aggregation"], "index": 526}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.len.html#polars.dataframe.group_by.GroupBy.len"], "Title": ["GroupBy.len"], "Feature": ["GroupBy.len"], "Description": ["Return the number of rows in each group."], "Examples": [">>> df = pl.DataFrame({\"a\": [\"Apple\", \"Apple\", \"Orange\"], \"b\": [1, None, 2]})\n>>> df.group_by(\"a\").len()  \nshape: (2, 2)\n┌────────┬─────┐\n│ a      ┆ len │\n│ ---    ┆ --- │\n│ str    ┆ u32 │\n╞════════╪═════╡\n│ Apple  ┆ 2   │\n│ Orange ┆ 1   │\n└────────┴─────┘\n>>> df.group_by(\"a\").len(name=\"n\")  \nshape: (2, 2)\n┌────────┬─────┐\n│ a      ┆ n   │\n│ ---    ┆ --- │\n│ str    ┆ u32 │\n╞════════╪═════╡\n│ Apple  ┆ 2   │\n│ Orange ┆ 1   │\n└────────┴─────┘"], "Parameters": [["name", "Assign a name to the resulting column; if unset, defaults to “len”."]], "Returns": [], "Category": ["GroupBy"], "index": 527}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.map_groups.html#polars.dataframe.group_by.GroupBy.map_groups"], "Title": ["GroupBy.map_groups"], "Feature": ["GroupBy.map_groups"], "Description": ["Apply a custom/user-defined function (UDF) over the groups as a sub-DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"id\": [0, 1, 2, 3, 4],\n...         \"color\": [\"red\", \"green\", \"green\", \"red\", \"red\"],\n...         \"shape\": [\"square\", \"triangle\", \"square\", \"triangle\", \"square\"],\n...     }\n... )\n>>> df.group_by(\"color\").map_groups(\n...     lambda group_df: group_df.sample(2)\n... )  \nshape: (4, 3)\n┌─────┬───────┬──────────┐\n│ id  ┆ color ┆ shape    │\n│ --- ┆ ---   ┆ ---      │\n│ i64 ┆ str   ┆ str      │\n╞═════╪═══════╪══════════╡\n│ 1   ┆ green ┆ triangle │\n│ 2   ┆ green ┆ square   │\n│ 4   ┆ red   ┆ square   │\n│ 3   ┆ red   ┆ triangle │\n└─────┴───────┴──────────┘", ">>> df.filter(\n...     pl.int_range(pl.len()).shuffle().over(\"color\") < 2\n... )"], "Parameters": [["function", "Custom function that receives a DataFrame and returns a DataFrame."]], "Returns": [["DataFrame", ""]], "Category": ["GroupBy"], "index": 528}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.max.html#polars.dataframe.group_by.GroupBy.max"], "Title": ["GroupBy.max"], "Feature": ["GroupBy.max"], "Description": ["Reduce the groups to the maximal value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"c\": [True, True, True, False, False, True],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).max()\nshape: (3, 4)\n┌────────┬─────┬──────┬──────┐\n│ d      ┆ a   ┆ b    ┆ c    │\n│ ---    ┆ --- ┆ ---  ┆ ---  │\n│ str    ┆ i64 ┆ f64  ┆ bool │\n╞════════╪═════╪══════╪══════╡\n│ Apple  ┆ 3   ┆ 10.0 ┆ true │\n│ Orange ┆ 2   ┆ 0.5  ┆ true │\n│ Banana ┆ 5   ┆ 14.0 ┆ true │\n└────────┴─────┴──────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 529}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.mean.html#polars.dataframe.group_by.GroupBy.mean"], "Title": ["GroupBy.mean"], "Feature": ["GroupBy.mean"], "Description": ["Reduce the groups to the mean values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"c\": [True, True, True, False, False, True],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).mean()\nshape: (3, 4)\n┌────────┬─────┬──────────┬──────────┐\n│ d      ┆ a   ┆ b        ┆ c        │\n│ ---    ┆ --- ┆ ---      ┆ ---      │\n│ str    ┆ f64 ┆ f64      ┆ f64      │\n╞════════╪═════╪══════════╪══════════╡\n│ Apple  ┆ 2.0 ┆ 4.833333 ┆ 0.666667 │\n│ Orange ┆ 2.0 ┆ 0.5      ┆ 1.0      │\n│ Banana ┆ 4.5 ┆ 13.5     ┆ 0.5      │\n└────────┴─────┴──────────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 530}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.median.html#polars.dataframe.group_by.GroupBy.median"], "Title": ["GroupBy.median"], "Feature": ["GroupBy.median"], "Description": ["Return the median per group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"d\": [\"Apple\", \"Banana\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).median()\nshape: (2, 3)\n┌────────┬─────┬──────┐\n│ d      ┆ a   ┆ b    │\n│ ---    ┆ --- ┆ ---  │\n│ str    ┆ f64 ┆ f64  │\n╞════════╪═════╪══════╡\n│ Apple  ┆ 2.0 ┆ 4.0  │\n│ Banana ┆ 4.0 ┆ 13.0 │\n└────────┴─────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 531}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.min.html#polars.dataframe.group_by.GroupBy.min"], "Title": ["GroupBy.min"], "Feature": ["GroupBy.min"], "Description": ["Reduce the groups to the minimal value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"c\": [True, True, True, False, False, True],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).min()\nshape: (3, 4)\n┌────────┬─────┬──────┬───────┐\n│ d      ┆ a   ┆ b    ┆ c     │\n│ ---    ┆ --- ┆ ---  ┆ ---   │\n│ str    ┆ i64 ┆ f64  ┆ bool  │\n╞════════╪═════╪══════╪═══════╡\n│ Apple  ┆ 1   ┆ 0.5  ┆ false │\n│ Orange ┆ 2   ┆ 0.5  ┆ true  │\n│ Banana ┆ 4   ┆ 13.0 ┆ false │\n└────────┴─────┴──────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 532}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.n_unique.html#polars.dataframe.group_by.GroupBy.n_unique"], "Title": ["GroupBy.n_unique"], "Feature": ["GroupBy.n_unique"], "Description": ["Count the unique values per group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 1, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 0.5, 10, 13, 14],\n...         \"d\": [\"Apple\", \"Banana\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).n_unique()\nshape: (2, 3)\n┌────────┬─────┬─────┐\n│ d      ┆ a   ┆ b   │\n│ ---    ┆ --- ┆ --- │\n│ str    ┆ u32 ┆ u32 │\n╞════════╪═════╪═════╡\n│ Apple  ┆ 2   ┆ 2   │\n│ Banana ┆ 3   ┆ 3   │\n└────────┴─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 533}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.quantile.html#polars.dataframe.group_by.GroupBy.quantile"], "Title": ["GroupBy.quantile"], "Feature": ["GroupBy.quantile"], "Description": ["Compute the quantile per group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).quantile(1)\nshape: (3, 3)\n┌────────┬─────┬──────┐\n│ d      ┆ a   ┆ b    │\n│ ---    ┆ --- ┆ ---  │\n│ str    ┆ f64 ┆ f64  │\n╞════════╪═════╪══════╡\n│ Apple  ┆ 3.0 ┆ 10.0 │\n│ Orange ┆ 2.0 ┆ 0.5  │\n│ Banana ┆ 5.0 ┆ 14.0 │\n└────────┴─────┴──────┘"], "Parameters": [["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."]], "Returns": [], "Category": ["GroupBy"], "index": 534}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.sum.html#polars.dataframe.group_by.GroupBy.sum"], "Title": ["GroupBy.sum"], "Feature": ["GroupBy.sum"], "Description": ["Reduce the groups to the sum."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 2, 3, 4, 5],\n...         \"b\": [0.5, 0.5, 4, 10, 13, 14],\n...         \"c\": [True, True, True, False, False, True],\n...         \"d\": [\"Apple\", \"Orange\", \"Apple\", \"Apple\", \"Banana\", \"Banana\"],\n...     }\n... )\n>>> df.group_by(\"d\", maintain_order=True).sum()\nshape: (3, 4)\n┌────────┬─────┬──────┬─────┐\n│ d      ┆ a   ┆ b    ┆ c   │\n│ ---    ┆ --- ┆ ---  ┆ --- │\n│ str    ┆ i64 ┆ f64  ┆ u32 │\n╞════════╪═════╪══════╪═════╡\n│ Apple  ┆ 6   ┆ 14.5 ┆ 2   │\n│ Orange ┆ 2   ┆ 0.5  ┆ 1   │\n│ Banana ┆ 9   ┆ 27.0 ┆ 1   │\n└────────┴─────┴──────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["GroupBy"], "index": 535}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.tail.html#polars.dataframe.group_by.GroupBy.tail"], "Title": ["GroupBy.tail"], "Feature": ["GroupBy.tail"], "Description": ["Get the lastnrows of each group."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"letters\": [\"c\", \"c\", \"a\", \"c\", \"a\", \"b\"],\n...         \"nrs\": [1, 2, 3, 4, 5, 6],\n...     }\n... )\n>>> df\nshape: (6, 2)\n┌─────────┬─────┐\n│ letters ┆ nrs │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ c       ┆ 1   │\n│ c       ┆ 2   │\n│ a       ┆ 3   │\n│ c       ┆ 4   │\n│ a       ┆ 5   │\n│ b       ┆ 6   │\n└─────────┴─────┘\n>>> df.group_by(\"letters\").tail(2).sort(\"letters\")\nshape: (5, 2)\n┌─────────┬─────┐\n│ letters ┆ nrs │\n│ ---     ┆ --- │\n│ str     ┆ i64 │\n╞═════════╪═════╡\n│ a       ┆ 3   │\n│ a       ┆ 5   │\n│ b       ┆ 6   │\n│ c       ┆ 2   │\n│ c       ┆ 4   │\n└─────────┴─────┘"], "Parameters": [["n", "Number of rows to return."]], "Returns": [], "Category": ["GroupBy"], "index": 536}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.median.html#polars.DataFrame.median"], "Title": ["DataFrame.median"], "Feature": ["DataFrame.median"], "Description": ["Aggregate the columns of this DataFrame to their median value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.median()\nshape: (1, 3)\n┌─────┬─────┬──────┐\n│ foo ┆ bar ┆ ham  │\n│ --- ┆ --- ┆ ---  │\n│ f64 ┆ f64 ┆ str  │\n╞═════╪═════╪══════╡\n│ 2.0 ┆ 7.0 ┆ null │\n└─────┴─────┴──────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 537}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.bottom_k.html#polars.DataFrame.bottom_k"], "Title": ["DataFrame.bottom_k"], "Feature": ["DataFrame.bottom_k"], "Description": ["Return theksmallest rows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n...         \"b\": [2, 1, 1, 3, 2, 1],\n...     }\n... )", ">>> df.bottom_k(4, by=\"b\")\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ b   ┆ 1   │\n│ a   ┆ 1   │\n│ c   ┆ 1   │\n│ a   ┆ 2   │\n└─────┴─────┘", ">>> df.bottom_k(4, by=[\"a\", \"b\"])\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ a   ┆ 1   │\n│ a   ┆ 2   │\n│ b   ┆ 1   │\n│ b   ┆ 2   │\n└─────┴─────┘"], "Parameters": [["k", "Number of rows to return."], ["by", "Column(s) used to determine the bottom rows.\nAccepts expression input. Strings are parsed as column names."], ["reverse", "Consider the k largest elements of the by column(s) (instead of the k smallest). This can be specified per column by passing a sequence of\nbooleans."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 540}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.cast.html#polars.DataFrame.cast"], "Title": ["DataFrame.cast"], "Feature": ["DataFrame.cast"], "Description": ["Cast DataFrame column(s) to the specified dtype(s)."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6.0, 7.0, 8.0],\n...         \"ham\": [date(2020, 1, 2), date(2021, 3, 4), date(2022, 5, 6)],\n...     }\n... )", ">>> df.cast({\"foo\": pl.Float32, \"bar\": pl.UInt8})\nshape: (3, 3)\n┌─────┬─────┬────────────┐\n│ foo ┆ bar ┆ ham        │\n│ --- ┆ --- ┆ ---        │\n│ f32 ┆ u8  ┆ date       │\n╞═════╪═════╪════════════╡\n│ 1.0 ┆ 6   ┆ 2020-01-02 │\n│ 2.0 ┆ 7   ┆ 2021-03-04 │\n│ 3.0 ┆ 8   ┆ 2022-05-06 │\n└─────┴─────┴────────────┘", ">>> df.cast({pl.Date: pl.Datetime})\nshape: (3, 3)\n┌─────┬─────┬─────────────────────┐\n│ foo ┆ bar ┆ ham                 │\n│ --- ┆ --- ┆ ---                 │\n│ i64 ┆ f64 ┆ datetime[μs]        │\n╞═════╪═════╪═════════════════════╡\n│ 1   ┆ 6.0 ┆ 2020-01-02 00:00:00 │\n│ 2   ┆ 7.0 ┆ 2021-03-04 00:00:00 │\n│ 3   ┆ 8.0 ┆ 2022-05-06 00:00:00 │\n└─────┴─────┴─────────────────────┘", ">>> import polars.selectors as cs\n>>> df.cast({cs.numeric(): pl.UInt32, cs.temporal(): pl.String})\nshape: (3, 3)\n┌─────┬─────┬────────────┐\n│ foo ┆ bar ┆ ham        │\n│ --- ┆ --- ┆ ---        │\n│ u32 ┆ u32 ┆ str        │\n╞═════╪═════╪════════════╡\n│ 1   ┆ 6   ┆ 2020-01-02 │\n│ 2   ┆ 7   ┆ 2021-03-04 │\n│ 3   ┆ 8   ┆ 2022-05-06 │\n└─────┴─────┴────────────┘", ">>> df.cast(pl.String).to_dict(as_series=False)\n{'foo': ['1', '2', '3'],\n 'bar': ['6.0', '7.0', '8.0'],\n 'ham': ['2020-01-02', '2021-03-04', '2022-05-06']}"], "Parameters": [["dtypes", "Mapping of column names (or selector) to dtypes, or a single dtype\nto which all columns will be cast."], ["strict", "Raise if cast is invalid on rows after predicates are pushed down.\nIf False , invalid casts will produce null values."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 541}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.clear.html#polars.DataFrame.clear"], "Title": ["DataFrame.clear"], "Feature": ["DataFrame.clear"], "Description": ["Create an empty (n=0) orn-row null-filled (n>0) copy of the DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [None, 2, 3, 4],\n...         \"b\": [0.5, None, 2.5, 13],\n...         \"c\": [True, True, False, None],\n...     }\n... )\n>>> df.clear()\nshape: (0, 3)\n┌─────┬─────┬──────┐\n│ a   ┆ b   ┆ c    │\n│ --- ┆ --- ┆ ---  │\n│ i64 ┆ f64 ┆ bool │\n╞═════╪═════╪══════╡\n└─────┴─────┴──────┘", ">>> df.clear(n=2)\nshape: (2, 3)\n┌──────┬──────┬──────┐\n│ a    ┆ b    ┆ c    │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ f64  ┆ bool │\n╞══════╪══════╪══════╡\n│ null ┆ null ┆ null │\n│ null ┆ null ┆ null │\n└──────┴──────┴──────┘"], "Parameters": [["n", "Number of (null-filled) rows to return in the cleared frame."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 542}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.clone.html#polars.DataFrame.clone"], "Title": ["DataFrame.clone"], "Feature": ["DataFrame.clone"], "Description": ["Create a copy of this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [0.5, 4, 10, 13],\n...         \"c\": [True, True, False, True],\n...     }\n... )\n>>> df.clone()\nshape: (4, 3)\n┌─────┬──────┬───────┐\n│ a   ┆ b    ┆ c     │\n│ --- ┆ ---  ┆ ---   │\n│ i64 ┆ f64  ┆ bool  │\n╞═════╪══════╪═══════╡\n│ 1   ┆ 0.5  ┆ true  │\n│ 2   ┆ 4.0  ┆ true  │\n│ 3   ┆ 10.0 ┆ false │\n│ 4   ┆ 13.0 ┆ true  │\n└─────┴──────┴───────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 543}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.drop.html#polars.DataFrame.drop"], "Title": ["DataFrame.drop"], "Feature": ["DataFrame.drop"], "Description": ["Remove columns from the dataframe."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6.0, 7.0, 8.0],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.drop(\"ham\")\nshape: (3, 2)\n┌─────┬─────┐\n│ foo ┆ bar │\n│ --- ┆ --- │\n│ i64 ┆ f64 │\n╞═════╪═════╡\n│ 1   ┆ 6.0 │\n│ 2   ┆ 7.0 │\n│ 3   ┆ 8.0 │\n└─────┴─────┘", ">>> df.drop([\"bar\", \"ham\"])\nshape: (3, 1)\n┌─────┐\n│ foo │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n└─────┘", ">>> import polars.selectors as cs\n>>> df.drop(cs.numeric())\nshape: (3, 1)\n┌─────┐\n│ ham │\n│ --- │\n│ str │\n╞═════╡\n│ a   │\n│ b   │\n│ c   │\n└─────┘", ">>> df.drop(\"foo\", \"ham\")\nshape: (3, 1)\n┌─────┐\n│ bar │\n│ --- │\n│ f64 │\n╞═════╡\n│ 6.0 │\n│ 7.0 │\n│ 8.0 │\n└─────┘"], "Parameters": [["*columns", "Names of the columns that should be removed from the dataframe.\nAccepts column selector input."], ["strict", "Validate that all column names exist in the current schema,\nand throw an exception if any do not."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 544}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.drop_in_place.html#polars.DataFrame.drop_in_place"], "Title": ["DataFrame.drop_in_place"], "Feature": ["DataFrame.drop_in_place"], "Description": ["Drop a single column in-place and return the dropped column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.drop_in_place(\"ham\")\nshape: (3,)\nSeries: 'ham' [str]\n[\n    \"a\"\n    \"b\"\n    \"c\"\n]"], "Parameters": [["name", "Name of the column to drop."]], "Returns": [["Series", "The dropped column."]], "Category": ["Manipulation_selection"], "index": 545}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.drop_nans.html#polars.DataFrame.drop_nans"], "Title": ["DataFrame.drop_nans"], "Feature": ["DataFrame.drop_nans"], "Description": ["Drop all rows that contain one or more NaN values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [-20.5, float(\"nan\"), 80.0],\n...         \"bar\": [float(\"nan\"), 110.0, 25.5],\n...         \"ham\": [\"xxx\", \"yyy\", None],\n...     }\n... )", ">>> df.drop_nans()\nshape: (1, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ f64  ┆ f64  ┆ str  │\n╞══════╪══════╪══════╡\n│ 80.0 ┆ 25.5 ┆ null │\n└──────┴──────┴──────┘", ">>> df.drop_nans(subset=[\"bar\"])\nshape: (2, 3)\n┌──────┬───────┬──────┐\n│ foo  ┆ bar   ┆ ham  │\n│ ---  ┆ ---   ┆ ---  │\n│ f64  ┆ f64   ┆ str  │\n╞══════╪═══════╪══════╡\n│ NaN  ┆ 110.0 ┆ yyy  │\n│ 80.0 ┆ 25.5  ┆ null │\n└──────┴───────┴──────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\")],\n...         \"b\": [10.0, 2.5, float(\"nan\"), 5.25],\n...         \"c\": [65.75, float(\"nan\"), float(\"nan\"), 10.5],\n...     }\n... )\n>>> df.filter(~pl.all_horizontal(pl.all().is_nan()))\nshape: (3, 3)\n┌─────┬──────┬───────┐\n│ a   ┆ b    ┆ c     │\n│ --- ┆ ---  ┆ ---   │\n│ f64 ┆ f64  ┆ f64   │\n╞═════╪══════╪═══════╡\n│ NaN ┆ 10.0 ┆ 65.75 │\n│ NaN ┆ 2.5  ┆ NaN   │\n│ NaN ┆ 5.25 ┆ 10.5  │\n└─────┴──────┴───────┘"], "Parameters": [["subset", "Column name(s) for which NaN values are considered; if set to None (default), use all columns (note that only floating-point columns\ncan contain NaNs)."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 546}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.drop_nulls.html#polars.DataFrame.drop_nulls"], "Title": ["DataFrame.drop_nulls"], "Feature": ["DataFrame.drop_nulls"], "Description": ["Drop all rows that contain one or more null values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, None, 8],\n...         \"ham\": [\"a\", \"b\", None],\n...     }\n... )", ">>> df.drop_nulls()\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6   ┆ a   │\n└─────┴─────┴─────┘", ">>> import polars.selectors as cs\n>>> df.drop_nulls(subset=cs.integer())\nshape: (2, 3)\n┌─────┬─────┬──────┐\n│ foo ┆ bar ┆ ham  │\n│ --- ┆ --- ┆ ---  │\n│ i64 ┆ i64 ┆ str  │\n╞═════╪═════╪══════╡\n│ 1   ┆ 6   ┆ a    │\n│ 3   ┆ 8   ┆ null │\n└─────┴─────┴──────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [None, None, None, None],\n...         \"b\": [1, 2, None, 1],\n...         \"c\": [1, None, None, 1],\n...     }\n... )\n>>> df\nshape: (4, 3)\n┌──────┬──────┬──────┐\n│ a    ┆ b    ┆ c    │\n│ ---  ┆ ---  ┆ ---  │\n│ null ┆ i64  ┆ i64  │\n╞══════╪══════╪══════╡\n│ null ┆ 1    ┆ 1    │\n│ null ┆ 2    ┆ null │\n│ null ┆ null ┆ null │\n│ null ┆ 1    ┆ 1    │\n└──────┴──────┴──────┘", ">>> df.filter(~pl.all_horizontal(pl.all().is_null()))\nshape: (3, 3)\n┌──────┬─────┬──────┐\n│ a    ┆ b   ┆ c    │\n│ ---  ┆ --- ┆ ---  │\n│ null ┆ i64 ┆ i64  │\n╞══════╪═════╪══════╡\n│ null ┆ 1   ┆ 1    │\n│ null ┆ 2   ┆ null │\n│ null ┆ 1   ┆ 1    │\n└──────┴─────┴──────┘", ">>> df[[s.name for s in df if not (s.null_count() == df.height)]]\nshape: (4, 2)\n┌──────┬──────┐\n│ b    ┆ c    │\n│ ---  ┆ ---  │\n│ i64  ┆ i64  │\n╞══════╪══════╡\n│ 1    ┆ 1    │\n│ 2    ┆ null │\n│ null ┆ null │\n│ 1    ┆ 1    │\n└──────┴──────┘"], "Parameters": [["subset", "Column name(s) for which null values are considered.\nIf set to None (default), use all columns."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 547}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.min.html#polars.DataFrame.min"], "Title": ["DataFrame.min"], "Feature": ["DataFrame.min"], "Description": ["Aggregate the columns of this DataFrame to their minimum value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.min()\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6   ┆ a   │\n└─────┴─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 548}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.explode.html#polars.DataFrame.explode"], "Title": ["DataFrame.explode"], "Feature": ["DataFrame.explode"], "Description": ["Explode the dataframe to long format by exploding the given columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"letters\": [\"a\", \"a\", \"b\", \"c\"],\n...         \"numbers\": [[1], [2, 3], [4, 5], [6, 7, 8]],\n...     }\n... )\n>>> df\nshape: (4, 2)\n┌─────────┬───────────┐\n│ letters ┆ numbers   │\n│ ---     ┆ ---       │\n│ str     ┆ list[i64] │\n╞═════════╪═══════════╡\n│ a       ┆ [1]       │\n│ a       ┆ [2, 3]    │\n│ b       ┆ [4, 5]    │\n│ c       ┆ [6, 7, 8] │\n└─────────┴───────────┘\n>>> df.explode(\"numbers\")\nshape: (8, 2)\n┌─────────┬─────────┐\n│ letters ┆ numbers │\n│ ---     ┆ ---     │\n│ str     ┆ i64     │\n╞═════════╪═════════╡\n│ a       ┆ 1       │\n│ a       ┆ 2       │\n│ a       ┆ 3       │\n│ b       ┆ 4       │\n│ b       ┆ 5       │\n│ c       ┆ 6       │\n│ c       ┆ 7       │\n│ c       ┆ 8       │\n└─────────┴─────────┘"], "Parameters": [["columns", "Column names, expressions, or a selector defining them. The underlying\ncolumns being exploded must be of the List or Array data type."], ["*more_columns", "Additional names of columns to explode, specified as positional arguments."]], "Returns": [["DataFrame", ""]], "Category": ["Manipulation_selection"], "index": 549}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.extend.html#polars.DataFrame.extend"], "Title": ["DataFrame.extend"], "Feature": ["DataFrame.extend"], "Description": ["Extend the memory backed by thisDataFramewith the values fromother."], "Examples": [">>> df1 = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n>>> df2 = pl.DataFrame({\"foo\": [10, 20, 30], \"bar\": [40, 50, 60]})\n>>> df1.extend(df2)\nshape: (6, 2)\n┌─────┬─────┐\n│ foo ┆ bar │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 4   │\n│ 2   ┆ 5   │\n│ 3   ┆ 6   │\n│ 10  ┆ 40  │\n│ 20  ┆ 50  │\n│ 30  ┆ 60  │\n└─────┴─────┘"], "Parameters": [["other", "DataFrame to vertically add."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 550}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.fill_nan.html#polars.DataFrame.fill_nan"], "Title": ["DataFrame.fill_nan"], "Feature": ["DataFrame.fill_nan"], "Description": ["Fill floating point NaN values by an Expression evaluation."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1.5, 2, float(\"nan\"), 4],\n...         \"b\": [0.5, 4, float(\"nan\"), 13],\n...     }\n... )\n>>> df.fill_nan(99)\nshape: (4, 2)\n┌──────┬──────┐\n│ a    ┆ b    │\n│ ---  ┆ ---  │\n│ f64  ┆ f64  │\n╞══════╪══════╡\n│ 1.5  ┆ 0.5  │\n│ 2.0  ┆ 4.0  │\n│ 99.0 ┆ 99.0 │\n│ 4.0  ┆ 13.0 │\n└──────┴──────┘"], "Parameters": [["value", "Value used to fill NaN values."]], "Returns": [["DataFrame", "DataFrame with NaN values replaced by the given value."]], "Category": ["Manipulation_selection"], "index": 551}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.fill_null.html#polars.DataFrame.fill_null"], "Title": ["DataFrame.fill_null"], "Feature": ["DataFrame.fill_null"], "Description": ["Fill null values using the specified value or strategy."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, None, 4],\n...         \"b\": [0.5, 4, None, 13],\n...     }\n... )\n>>> df.fill_null(99)\nshape: (4, 2)\n┌─────┬──────┐\n│ a   ┆ b    │\n│ --- ┆ ---  │\n│ i64 ┆ f64  │\n╞═════╪══════╡\n│ 1   ┆ 0.5  │\n│ 2   ┆ 4.0  │\n│ 99  ┆ 99.0 │\n│ 4   ┆ 13.0 │\n└─────┴──────┘\n>>> df.fill_null(strategy=\"forward\")\nshape: (4, 2)\n┌─────┬──────┐\n│ a   ┆ b    │\n│ --- ┆ ---  │\n│ i64 ┆ f64  │\n╞═════╪══════╡\n│ 1   ┆ 0.5  │\n│ 2   ┆ 4.0  │\n│ 2   ┆ 4.0  │\n│ 4   ┆ 13.0 │\n└─────┴──────┘", ">>> df.fill_null(strategy=\"max\")\nshape: (4, 2)\n┌─────┬──────┐\n│ a   ┆ b    │\n│ --- ┆ ---  │\n│ i64 ┆ f64  │\n╞═════╪══════╡\n│ 1   ┆ 0.5  │\n│ 2   ┆ 4.0  │\n│ 4   ┆ 13.0 │\n│ 4   ┆ 13.0 │\n└─────┴──────┘", ">>> df.fill_null(strategy=\"zero\")\nshape: (4, 2)\n┌─────┬──────┐\n│ a   ┆ b    │\n│ --- ┆ ---  │\n│ i64 ┆ f64  │\n╞═════╪══════╡\n│ 1   ┆ 0.5  │\n│ 2   ┆ 4.0  │\n│ 0   ┆ 0.0  │\n│ 4   ┆ 13.0 │\n└─────┴──────┘"], "Parameters": [["value", "Value used to fill null values."], ["strategy {None, ‘forward’, ‘backward’, ‘min’, ‘max’, ‘mean’, ‘zero’, ‘one’}", "Strategy used to fill null values."], ["limit", "Number of consecutive null values to fill when using the ‘forward’ or\n‘backward’ strategy."], ["matches_supertype", "Fill all matching supertype of the fill value ."]], "Returns": [["DataFrame", "DataFrame with None values replaced by the filling strategy."]], "Category": ["Manipulation_selection"], "index": 552}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.gather_every.html#polars.DataFrame.gather_every"], "Title": ["DataFrame.gather_every"], "Feature": ["DataFrame.gather_every"], "Description": ["Take every nth row in the DataFrame and return as a new DataFrame."], "Examples": [">>> s = pl.DataFrame({\"a\": [1, 2, 3, 4], \"b\": [5, 6, 7, 8]})\n>>> s.gather_every(2)\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 5   │\n│ 3   ┆ 7   │\n└─────┴─────┘", ">>> s.gather_every(2, offset=1)\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 2   ┆ 6   │\n│ 4   ┆ 8   │\n└─────┴─────┘"], "Parameters": [["n", "Gather every n -th row."], ["offset", "Starting index."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 554}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.get_column.html#polars.DataFrame.get_column"], "Title": ["DataFrame.get_column"], "Feature": ["DataFrame.get_column"], "Description": ["Get a single column by name."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n>>> df.get_column(\"foo\")\nshape: (3,)\nSeries: 'foo' [i64]\n[\n    1\n    2\n    3\n]", ">>> df.get_column(\"baz\", default=pl.Series(\"baz\", [\"?\", \"?\", \"?\"]))\nshape: (3,)\nSeries: 'baz' [str]\n[\n    \"?\"\n    \"?\"\n    \"?\"\n]\n>>> res = df.get_column(\"baz\", default=None)\n>>> res is None\nTrue"], "Parameters": [["name", "String name of the column to retrieve."], ["default", "Value to return if the column does not exist; if not explicitly set and\nthe column is not present a ColumnNotFoundError exception is raised."]], "Returns": [["Series (or arbitrary default value, if specified).", ""]], "Category": ["Manipulation_selection"], "index": 555}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.get_column_index.html#polars.DataFrame.get_column_index"], "Title": ["DataFrame.get_column_index"], "Feature": ["DataFrame.get_column_index"], "Description": ["Find the index of a column by name."], "Examples": [">>> df = pl.DataFrame(\n...     {\"foo\": [1, 2, 3], \"bar\": [6, 7, 8], \"ham\": [\"a\", \"b\", \"c\"]}\n... )\n>>> df.get_column_index(\"ham\")\n2\n>>> df.get_column_index(\"sandwich\")  \nColumnNotFoundError: sandwich"], "Parameters": [["name", "Name of the column to find."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 556}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.get_columns.html#polars.DataFrame.get_columns"], "Title": ["DataFrame.get_columns"], "Feature": ["DataFrame.get_columns"], "Description": ["Get the DataFrame as a List of Series."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n>>> df.get_columns()\n[shape: (3,)\nSeries: 'foo' [i64]\n[\n        1\n        2\n        3\n], shape: (3,)\nSeries: 'bar' [i64]\n[\n        4\n        5\n        6\n]]", ">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3, 4],\n...         \"b\": [0.5, 4, 10, 13],\n...         \"c\": [True, True, False, True],\n...     }\n... )\n>>> df.get_columns()\n[shape: (4,)\nSeries: 'a' [i64]\n[\n    1\n    2\n    3\n    4\n], shape: (4,)\nSeries: 'b' [f64]\n[\n    0.5\n    4.0\n    10.0\n    13.0\n], shape: (4,)\nSeries: 'c' [bool]\n[\n    true\n    true\n    false\n    true\n]]"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 557}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.min_horizontal.html#polars.DataFrame.min_horizontal"], "Title": ["DataFrame.min_horizontal"], "Feature": ["DataFrame.min_horizontal"], "Description": ["Get the minimum value horizontally across columns."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [4.0, 5.0, 6.0],\n...     }\n... )\n>>> df.min_horizontal()\nshape: (3,)\nSeries: 'min' [f64]\n[\n        1.0\n        2.0\n        3.0\n]"], "Parameters": [], "Returns": [["Series", "A Series named \"min\" ."]], "Category": ["Aggregation"], "index": 559}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.group_by_dynamic.html#polars.DataFrame.group_by_dynamic"], "Title": ["DataFrame.group_by_dynamic"], "Feature": ["DataFrame.group_by_dynamic"], "Description": ["Group based on a time value (or index value of type Int32, Int64)."], "Examples": [">>> from datetime import datetime\n>>> df = pl.DataFrame(\n...     {\n...         \"time\": pl.datetime_range(\n...             start=datetime(2021, 12, 16),\n...             end=datetime(2021, 12, 16, 3),\n...             interval=\"30m\",\n...             eager=True,\n...         ),\n...         \"n\": range(7),\n...     }\n... )\n>>> df\nshape: (7, 2)\n┌─────────────────────┬─────┐\n│ time                ┆ n   │\n│ ---                 ┆ --- │\n│ datetime[μs]        ┆ i64 │\n╞═════════════════════╪═════╡\n│ 2021-12-16 00:00:00 ┆ 0   │\n│ 2021-12-16 00:30:00 ┆ 1   │\n│ 2021-12-16 01:00:00 ┆ 2   │\n│ 2021-12-16 01:30:00 ┆ 3   │\n│ 2021-12-16 02:00:00 ┆ 4   │\n│ 2021-12-16 02:30:00 ┆ 5   │\n│ 2021-12-16 03:00:00 ┆ 6   │\n└─────────────────────┴─────┘", ">>> df.group_by_dynamic(\"time\", every=\"1h\", closed=\"right\").agg(pl.col(\"n\"))\nshape: (4, 2)\n┌─────────────────────┬───────────┐\n│ time                ┆ n         │\n│ ---                 ┆ ---       │\n│ datetime[μs]        ┆ list[i64] │\n╞═════════════════════╪═══════════╡\n│ 2021-12-15 23:00:00 ┆ [0]       │\n│ 2021-12-16 00:00:00 ┆ [1, 2]    │\n│ 2021-12-16 01:00:00 ┆ [3, 4]    │\n│ 2021-12-16 02:00:00 ┆ [5, 6]    │\n└─────────────────────┴───────────┘", ">>> df.group_by_dynamic(\n...     \"time\", every=\"1h\", include_boundaries=True, closed=\"right\"\n... ).agg(pl.col(\"n\").mean())\nshape: (4, 4)\n┌─────────────────────┬─────────────────────┬─────────────────────┬─────┐\n│ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n   │\n│ ---                 ┆ ---                 ┆ ---                 ┆ --- │\n│ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ f64 │\n╞═════════════════════╪═════════════════════╪═════════════════════╪═════╡\n│ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ 0.0 │\n│ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ 1.5 │\n│ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 3.5 │\n│ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 5.5 │\n└─────────────────────┴─────────────────────┴─────────────────────┴─────┘", ">>> df.group_by_dynamic(\"time\", every=\"1h\", closed=\"left\").agg(pl.col(\"n\"))\nshape: (4, 2)\n┌─────────────────────┬───────────┐\n│ time                ┆ n         │\n│ ---                 ┆ ---       │\n│ datetime[μs]        ┆ list[i64] │\n╞═════════════════════╪═══════════╡\n│ 2021-12-16 00:00:00 ┆ [0, 1]    │\n│ 2021-12-16 01:00:00 ┆ [2, 3]    │\n│ 2021-12-16 02:00:00 ┆ [4, 5]    │\n│ 2021-12-16 03:00:00 ┆ [6]       │\n└─────────────────────┴───────────┘", ">>> df.group_by_dynamic(\"time\", every=\"1h\", closed=\"both\").agg(pl.col(\"n\"))\nshape: (4, 2)\n┌─────────────────────┬───────────┐\n│ time                ┆ n         │\n│ ---                 ┆ ---       │\n│ datetime[μs]        ┆ list[i64] │\n╞═════════════════════╪═══════════╡\n│ 2021-12-16 00:00:00 ┆ [0, 1, 2] │\n│ 2021-12-16 01:00:00 ┆ [2, 3, 4] │\n│ 2021-12-16 02:00:00 ┆ [4, 5, 6] │\n│ 2021-12-16 03:00:00 ┆ [6]       │\n└─────────────────────┴───────────┘", ">>> df = df.with_columns(groups=pl.Series([\"a\", \"a\", \"a\", \"b\", \"b\", \"a\", \"a\"]))\n>>> df\nshape: (7, 3)\n┌─────────────────────┬─────┬────────┐\n│ time                ┆ n   ┆ groups │\n│ ---                 ┆ --- ┆ ---    │\n│ datetime[μs]        ┆ i64 ┆ str    │\n╞═════════════════════╪═════╪════════╡\n│ 2021-12-16 00:00:00 ┆ 0   ┆ a      │\n│ 2021-12-16 00:30:00 ┆ 1   ┆ a      │\n│ 2021-12-16 01:00:00 ┆ 2   ┆ a      │\n│ 2021-12-16 01:30:00 ┆ 3   ┆ b      │\n│ 2021-12-16 02:00:00 ┆ 4   ┆ b      │\n│ 2021-12-16 02:30:00 ┆ 5   ┆ a      │\n│ 2021-12-16 03:00:00 ┆ 6   ┆ a      │\n└─────────────────────┴─────┴────────┘\n>>> df.group_by_dynamic(\n...     \"time\",\n...     every=\"1h\",\n...     closed=\"both\",\n...     group_by=\"groups\",\n...     include_boundaries=True,\n... ).agg(pl.col(\"n\"))\nshape: (6, 5)\n┌────────┬─────────────────────┬─────────────────────┬─────────────────────┬───────────┐\n│ groups ┆ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │\n│ ---    ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---       │\n│ str    ┆ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │\n╞════════╪═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡\n│ a      ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ [0, 1, 2] │\n│ a      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [2]       │\n│ a      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [5, 6]    │\n│ a      ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 04:00:00 ┆ 2021-12-16 03:00:00 ┆ [6]       │\n│ b      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [3, 4]    │\n│ b      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [4]       │\n└────────┴─────────────────────┴─────────────────────┴─────────────────────┴───────────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"idx\": pl.int_range(0, 6, eager=True),\n...         \"A\": [\"A\", \"A\", \"B\", \"B\", \"B\", \"C\"],\n...     }\n... )\n>>> (\n...     df.group_by_dynamic(\n...         \"idx\",\n...         every=\"2i\",\n...         period=\"3i\",\n...         include_boundaries=True,\n...         closed=\"right\",\n...     ).agg(pl.col(\"A\").alias(\"A_agg_list\"))\n... )\nshape: (4, 4)\n┌─────────────────┬─────────────────┬─────┬─────────────────┐\n│ _lower_boundary ┆ _upper_boundary ┆ idx ┆ A_agg_list      │\n│ ---             ┆ ---             ┆ --- ┆ ---             │\n│ i64             ┆ i64             ┆ i64 ┆ list[str]       │\n╞═════════════════╪═════════════════╪═════╪═════════════════╡\n│ -2              ┆ 1               ┆ -2  ┆ [\"A\", \"A\"]      │\n│ 0               ┆ 3               ┆ 0   ┆ [\"A\", \"B\", \"B\"] │\n│ 2               ┆ 5               ┆ 2   ┆ [\"B\", \"B\", \"C\"] │\n│ 4               ┆ 7               ┆ 4   ┆ [\"C\"]           │\n└─────────────────┴─────────────────┴─────┴─────────────────┘"], "Parameters": [["index_column", "Column used to group based on the time window.\nOften of type Date/Datetime.\nThis column must be sorted in ascending order (or, if group_by is specified,\nthen it must be sorted in ascending order within each group). In case of a dynamic group by on indices, dtype needs to be one of\n{Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if\nperformance matters use an Int64 column."], ["every", "interval of the window"], ["period", "length of the window, if None it will equal ‘every’"], ["offset", "offset of the window, does not take effect if start_by is ‘datapoint’.\nDefaults to zero."], ["include_boundaries", "Add the lower and upper bound of the window to the “_lower_boundary” and\n“_upper_boundary” columns. This will impact performance because it’s harder to\nparallelize"], ["closed {‘left’, ‘right’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive)."], ["label {‘left’, ‘right’, ‘datapoint’}", "Define which label to use for the window: ‘left’: lower boundary of the window ‘right’: upper boundary of the window ‘datapoint’: the first value of the index column in the given window.\nIf you don’t need the label to be at one of the boundaries, choose this\noption for maximum performance"], ["group_by", "Also group by this column/these columns"], ["start_by {‘window’, ‘datapoint’, ‘monday’, ‘tuesday’, ‘wednesday’, ‘thursday’, ‘friday’, ‘saturday’, ‘sunday’}", "The strategy to determine the start of the first window by. ‘window’: Start by taking the earliest timestamp, truncating it with every , and then adding offset .\nNote that weekly windows start on Monday. ‘datapoint’: Start from the first encountered data point. a day of the week (only takes effect if every contains 'w' ): ‘monday’: Start the window on the Monday before the first data point. ‘tuesday’: Start the window on the Tuesday before the first data point. … ‘sunday’: Start the window on the Sunday before the first data point. The resulting window is then shifted back until the earliest datapoint\nis in or in front of it."]], "Returns": [["DynamicGroupBy", "Object you can call .agg on to aggregate by groups, the result\nof which will be sorted by index_column (but note that if group_by columns are\npassed, it will only be sorted within each group)."]], "Category": ["Manipulation_selection"], "index": 560}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.head.html#polars.DataFrame.head"], "Title": ["DataFrame.head"], "Feature": ["DataFrame.head"], "Description": ["Get the firstnrows."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3, 4, 5],\n...         \"bar\": [6, 7, 8, 9, 10],\n...         \"ham\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n>>> df.head(3)\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6   ┆ a   │\n│ 2   ┆ 7   ┆ b   │\n│ 3   ┆ 8   ┆ c   │\n└─────┴─────┴─────┘", ">>> df.head(-3)\nshape: (2, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6   ┆ a   │\n│ 2   ┆ 7   ┆ b   │\n└─────┴─────┴─────┘"], "Parameters": [["n", "Number of rows to return. If a negative value is passed, return all rows\nexcept the last abs(n) ."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 561}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.hstack.html#polars.DataFrame.hstack"], "Title": ["DataFrame.hstack"], "Feature": ["DataFrame.hstack"], "Description": ["Return a new DataFrame grown horizontally by stacking multiple Series to it."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> x = pl.Series(\"apple\", [10, 20, 30])\n>>> df.hstack([x])\nshape: (3, 4)\n┌─────┬─────┬─────┬───────┐\n│ foo ┆ bar ┆ ham ┆ apple │\n│ --- ┆ --- ┆ --- ┆ ---   │\n│ i64 ┆ i64 ┆ str ┆ i64   │\n╞═════╪═════╪═════╪═══════╡\n│ 1   ┆ 6   ┆ a   ┆ 10    │\n│ 2   ┆ 7   ┆ b   ┆ 20    │\n│ 3   ┆ 8   ┆ c   ┆ 30    │\n└─────┴─────┴─────┴───────┘"], "Parameters": [["columns", "Series to stack."], ["in_place", "Modify in place."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 562}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.insert_column.html#polars.DataFrame.insert_column"], "Title": ["DataFrame.insert_column"], "Feature": ["DataFrame.insert_column"], "Description": ["Insert a Series (or expression) at a certain column index."], "Examples": [">>> df = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n>>> s = pl.Series(\"baz\", [97, 98, 99])\n>>> df.insert_column(1, s)\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ baz ┆ bar │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 97  ┆ 4   │\n│ 2   ┆ 98  ┆ 5   │\n│ 3   ┆ 99  ┆ 6   │\n└─────┴─────┴─────┘", ">>> df = pl.DataFrame(\n...     {\"a\": [2, 4, 2], \"b\": [0.5, 4, 10], \"c\": [\"xx\", \"yy\", \"zz\"]}\n... )\n>>> expr = (pl.col(\"b\") / pl.col(\"a\")).alias(\"b_div_a\")\n>>> df.insert_column(2, expr)\nshape: (3, 4)\n┌─────┬──────┬─────────┬─────┐\n│ a   ┆ b    ┆ b_div_a ┆ c   │\n│ --- ┆ ---  ┆ ---     ┆ --- │\n│ i64 ┆ f64  ┆ f64     ┆ str │\n╞═════╪══════╪═════════╪═════╡\n│ 2   ┆ 0.5  ┆ 0.25    ┆ xx  │\n│ 4   ┆ 4.0  ┆ 1.0     ┆ yy  │\n│ 2   ┆ 10.0 ┆ 5.0     ┆ zz  │\n└─────┴──────┴─────────┴─────┘"], "Parameters": [["index", "Index at which to insert the new column."], ["column", "Series or expression to insert."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 563}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.interpolate.html#polars.DataFrame.interpolate"], "Title": ["DataFrame.interpolate"], "Feature": ["DataFrame.interpolate"], "Description": ["Interpolate intermediate values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, None, 9, 10],\n...         \"bar\": [6, 7, 9, None],\n...         \"baz\": [1, None, None, 9],\n...     }\n... )\n>>> df.interpolate()\nshape: (4, 3)\n┌──────┬──────┬──────────┐\n│ foo  ┆ bar  ┆ baz      │\n│ ---  ┆ ---  ┆ ---      │\n│ f64  ┆ f64  ┆ f64      │\n╞══════╪══════╪══════════╡\n│ 1.0  ┆ 6.0  ┆ 1.0      │\n│ 5.0  ┆ 7.0  ┆ 3.666667 │\n│ 9.0  ┆ 9.0  ┆ 6.333333 │\n│ 10.0 ┆ null ┆ 9.0      │\n└──────┴──────┴──────────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 564}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.item.html#polars.DataFrame.item"], "Title": ["DataFrame.item"], "Feature": ["DataFrame.item"], "Description": ["Return the DataFrame as a scalar, or return the element at the given row/column."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n>>> df.select((pl.col(\"a\") * pl.col(\"b\")).sum()).item()\n32\n>>> df.item(1, 1)\n5\n>>> df.item(2, \"b\")\n6"], "Parameters": [["row", "Optional row index."], ["column", "Optional column index or name."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 565}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.iter_columns.html#polars.DataFrame.iter_columns"], "Title": ["DataFrame.iter_columns"], "Feature": ["DataFrame.iter_columns"], "Description": ["Returns an iterator over the columns of this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 3, 5],\n...         \"b\": [2, 4, 6],\n...     }\n... )\n>>> [s.name for s in df.iter_columns()]\n['a', 'b']", ">>> # Do NOT do this\n>>> pl.DataFrame(column * 2 for column in df.iter_columns())\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 2   ┆ 4   │\n│ 6   ┆ 8   │\n│ 10  ┆ 12  │\n└─────┴─────┘", ">>> df.select(pl.all() * 2)\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 2   ┆ 4   │\n│ 6   ┆ 8   │\n│ 10  ┆ 12  │\n└─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 566}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.iter_rows.html#polars.DataFrame.iter_rows"], "Title": ["DataFrame.iter_rows"], "Feature": ["DataFrame.iter_rows"], "Description": ["Returns an iterator over the DataFrame of rows of python-native values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 3, 5],\n...         \"b\": [2, 4, 6],\n...     }\n... )\n>>> [row[0] for row in df.iter_rows()]\n[1, 3, 5]\n>>> [row[\"b\"] for row in df.iter_rows(named=True)]\n[2, 4, 6]"], "Parameters": [["named", "Return dictionaries instead of tuples. The dictionaries are a mapping of\ncolumn name to row value. This is more expensive than returning a regular\ntuple, but allows for accessing values by column name."], ["buffer_size", "Determines the number of rows that are buffered internally while iterating\nover the data; you should only modify this in very specific cases where the\ndefault value is determined not to be a good fit to your access pattern, as\nthe speedup from using the buffer is significant (~2-4x). Setting this\nvalue to zero disables row buffering (not recommended)."]], "Returns": [["iterator of tuples (default) or dictionaries (if named) of python row values", ""]], "Category": ["Manipulation_selection"], "index": 567}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.iter_slices.html#polars.DataFrame.iter_slices"], "Title": ["DataFrame.iter_slices"], "Feature": ["DataFrame.iter_slices"], "Description": ["Returns a non-copying iterator of slices over the underlying DataFrame."], "Examples": [">>> from datetime import date\n>>> df = pl.DataFrame(\n...     data={\n...         \"a\": range(17_500),\n...         \"b\": date(2023, 1, 1),\n...         \"c\": \"klmnoopqrstuvwxyz\",\n...     },\n...     schema_overrides={\"a\": pl.Int32},\n... )\n>>> for idx, frame in enumerate(df.iter_slices()):\n...     print(f\"{type(frame).__name__}:[{idx}]:{len(frame)}\")\nDataFrame:[0]:10000\nDataFrame:[1]:7500", ">>> for frame in df.iter_slices(n_rows=15_000):\n...     record_batch = frame.to_arrow().to_batches()[0]\n...     print(f\"{record_batch.schema}\\n<< {len(record_batch)}\")\na: int32\nb: date32[day]\nc: large_string\n<< 15000\na: int32\nb: date32[day]\nc: large_string\n<< 2500"], "Parameters": [["n_rows", "Determines the number of rows contained in each DataFrame slice."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 568}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.product.html#polars.DataFrame.product"], "Title": ["DataFrame.product"], "Feature": ["DataFrame.product"], "Description": ["Aggregate the columns of this DataFrame to their product values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [1, 2, 3],\n...         \"b\": [0.5, 4, 10],\n...         \"c\": [True, True, False],\n...     }\n... )", ">>> df.product()\nshape: (1, 3)\n┌─────┬──────┬─────┐\n│ a   ┆ b    ┆ c   │\n│ --- ┆ ---  ┆ --- │\n│ i64 ┆ f64  ┆ i64 │\n╞═════╪══════╪═════╡\n│ 6   ┆ 20.0 ┆ 0   │\n└─────┴──────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Aggregation"], "index": 570}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.join_asof.html#polars.DataFrame.join_asof"], "Title": ["DataFrame.join_asof"], "Feature": ["DataFrame.join_asof"], "Description": ["Perform an asof join."], "Examples": [">>> from datetime import date\n>>> gdp = pl.DataFrame(\n...     {\n...         \"date\": pl.date_range(\n...             date(2016, 1, 1),\n...             date(2020, 1, 1),\n...             \"1y\",\n...             eager=True,\n...         ),\n...         \"gdp\": [4164, 4411, 4566, 4696, 4827],\n...     }\n... )\n>>> gdp\nshape: (5, 2)\n┌────────────┬──────┐\n│ date       ┆ gdp  │\n│ ---        ┆ ---  │\n│ date       ┆ i64  │\n╞════════════╪══════╡\n│ 2016-01-01 ┆ 4164 │\n│ 2017-01-01 ┆ 4411 │\n│ 2018-01-01 ┆ 4566 │\n│ 2019-01-01 ┆ 4696 │\n│ 2020-01-01 ┆ 4827 │\n└────────────┴──────┘", ">>> population = pl.DataFrame(\n...     {\n...         \"date\": [date(2016, 3, 1), date(2018, 8, 1), date(2019, 1, 1)],\n...         \"population\": [82.19, 82.66, 83.12],\n...     }\n... ).sort(\"date\")\n>>> population\nshape: (3, 2)\n┌────────────┬────────────┐\n│ date       ┆ population │\n│ ---        ┆ ---        │\n│ date       ┆ f64        │\n╞════════════╪════════════╡\n│ 2016-03-01 ┆ 82.19      │\n│ 2018-08-01 ┆ 82.66      │\n│ 2019-01-01 ┆ 83.12      │\n└────────────┴────────────┘", ">>> population.join_asof(gdp, on=\"date\", strategy=\"backward\")\nshape: (3, 3)\n┌────────────┬────────────┬──────┐\n│ date       ┆ population ┆ gdp  │\n│ ---        ┆ ---        ┆ ---  │\n│ date       ┆ f64        ┆ i64  │\n╞════════════╪════════════╪══════╡\n│ 2016-03-01 ┆ 82.19      ┆ 4164 │\n│ 2018-08-01 ┆ 82.66      ┆ 4566 │\n│ 2019-01-01 ┆ 83.12      ┆ 4696 │\n└────────────┴────────────┴──────┘", ">>> population.join_asof(gdp, on=\"date\", strategy=\"backward\", coalesce=False)\nshape: (3, 4)\n┌────────────┬────────────┬────────────┬──────┐\n│ date       ┆ population ┆ date_right ┆ gdp  │\n│ ---        ┆ ---        ┆ ---        ┆ ---  │\n│ date       ┆ f64        ┆ date       ┆ i64  │\n╞════════════╪════════════╪════════════╪══════╡\n│ 2016-03-01 ┆ 82.19      ┆ 2016-01-01 ┆ 4164 │\n│ 2018-08-01 ┆ 82.66      ┆ 2018-01-01 ┆ 4566 │\n│ 2019-01-01 ┆ 83.12      ┆ 2019-01-01 ┆ 4696 │\n└────────────┴────────────┴────────────┴──────┘", ">>> population.join_asof(gdp, on=\"date\", strategy=\"forward\")\nshape: (3, 3)\n┌────────────┬────────────┬──────┐\n│ date       ┆ population ┆ gdp  │\n│ ---        ┆ ---        ┆ ---  │\n│ date       ┆ f64        ┆ i64  │\n╞════════════╪════════════╪══════╡\n│ 2016-03-01 ┆ 82.19      ┆ 4411 │\n│ 2018-08-01 ┆ 82.66      ┆ 4696 │\n│ 2019-01-01 ┆ 83.12      ┆ 4696 │\n└────────────┴────────────┴──────┘", ">>> population.join_asof(gdp, on=\"date\", strategy=\"nearest\")\nshape: (3, 3)\n┌────────────┬────────────┬──────┐\n│ date       ┆ population ┆ gdp  │\n│ ---        ┆ ---        ┆ ---  │\n│ date       ┆ f64        ┆ i64  │\n╞════════════╪════════════╪══════╡\n│ 2016-03-01 ┆ 82.19      ┆ 4164 │\n│ 2018-08-01 ┆ 82.66      ┆ 4696 │\n│ 2019-01-01 ┆ 83.12      ┆ 4696 │\n└────────────┴────────────┴──────┘", ">>> gdp_dates = pl.date_range(  # fmt: skip\n...     date(2016, 1, 1), date(2020, 1, 1), \"1y\", eager=True\n... )\n>>> gdp2 = pl.DataFrame(\n...     {\n...         \"country\": [\"Germany\"] * 5 + [\"Netherlands\"] * 5,\n...         \"date\": pl.concat([gdp_dates, gdp_dates]),\n...         \"gdp\": [4164, 4411, 4566, 4696, 4827, 784, 833, 914, 910, 909],\n...     }\n... ).sort(\"country\", \"date\")\n>>>\n>>> gdp2\nshape: (10, 3)\n┌─────────────┬────────────┬──────┐\n│ country     ┆ date       ┆ gdp  │\n│ ---         ┆ ---        ┆ ---  │\n│ str         ┆ date       ┆ i64  │\n╞═════════════╪════════════╪══════╡\n│ Germany     ┆ 2016-01-01 ┆ 4164 │\n│ Germany     ┆ 2017-01-01 ┆ 4411 │\n│ Germany     ┆ 2018-01-01 ┆ 4566 │\n│ Germany     ┆ 2019-01-01 ┆ 4696 │\n│ Germany     ┆ 2020-01-01 ┆ 4827 │\n│ Netherlands ┆ 2016-01-01 ┆ 784  │\n│ Netherlands ┆ 2017-01-01 ┆ 833  │\n│ Netherlands ┆ 2018-01-01 ┆ 914  │\n│ Netherlands ┆ 2019-01-01 ┆ 910  │\n│ Netherlands ┆ 2020-01-01 ┆ 909  │\n└─────────────┴────────────┴──────┘\n>>> pop2 = pl.DataFrame(\n...     {\n...         \"country\": [\"Germany\"] * 3 + [\"Netherlands\"] * 3,\n...         \"date\": [\n...             date(2016, 3, 1),\n...             date(2018, 8, 1),\n...             date(2019, 1, 1),\n...             date(2016, 3, 1),\n...             date(2018, 8, 1),\n...             date(2019, 1, 1),\n...         ],\n...         \"population\": [82.19, 82.66, 83.12, 17.11, 17.32, 17.40],\n...     }\n... ).sort(\"country\", \"date\")\n>>>\n>>> pop2\nshape: (6, 3)\n┌─────────────┬────────────┬────────────┐\n│ country     ┆ date       ┆ population │\n│ ---         ┆ ---        ┆ ---        │\n│ str         ┆ date       ┆ f64        │\n╞═════════════╪════════════╪════════════╡\n│ Germany     ┆ 2016-03-01 ┆ 82.19      │\n│ Germany     ┆ 2018-08-01 ┆ 82.66      │\n│ Germany     ┆ 2019-01-01 ┆ 83.12      │\n│ Netherlands ┆ 2016-03-01 ┆ 17.11      │\n│ Netherlands ┆ 2018-08-01 ┆ 17.32      │\n│ Netherlands ┆ 2019-01-01 ┆ 17.4       │\n└─────────────┴────────────┴────────────┘\n>>> pop2.join_asof(gdp2, by=\"country\", on=\"date\", strategy=\"nearest\")\nshape: (6, 4)\n┌─────────────┬────────────┬────────────┬──────┐\n│ country     ┆ date       ┆ population ┆ gdp  │\n│ ---         ┆ ---        ┆ ---        ┆ ---  │\n│ str         ┆ date       ┆ f64        ┆ i64  │\n╞═════════════╪════════════╪════════════╪══════╡\n│ Germany     ┆ 2016-03-01 ┆ 82.19      ┆ 4164 │\n│ Germany     ┆ 2018-08-01 ┆ 82.66      ┆ 4696 │\n│ Germany     ┆ 2019-01-01 ┆ 83.12      ┆ 4696 │\n│ Netherlands ┆ 2016-03-01 ┆ 17.11      ┆ 784  │\n│ Netherlands ┆ 2018-08-01 ┆ 17.32      ┆ 910  │\n│ Netherlands ┆ 2019-01-01 ┆ 17.4       ┆ 910  │\n└─────────────┴────────────┴────────────┴──────┘"], "Parameters": [["other", "Lazy DataFrame to join with."], ["left_on", "Join column of the left DataFrame."], ["right_on", "Join column of the right DataFrame."], ["on", "Join column of both DataFrames. If set, left_on and right_on should be\nNone."], ["by", "Join on these columns before doing asof join"], ["by_left", "Join on these columns before doing asof join"], ["by_right", "Join on these columns before doing asof join"], ["strategy {‘backward’, ‘forward’, ‘nearest’}", "Join strategy."], ["suffix", "Suffix to append to columns with a duplicate name."], ["tolerance", "Numeric tolerance. By setting this the join will only be done if the near\nkeys are within this distance. If an asof join is done on columns of dtype\n“Date”, “Datetime”, “Duration” or “Time”, use either a datetime.timedelta\nobject or the following string language: 1ns   (1 nanosecond) 1us   (1 microsecond) 1ms   (1 millisecond) 1s    (1 second) 1m    (1 minute) 1h    (1 hour) 1d    (1 calendar day) 1w    (1 calendar week) 1mo   (1 calendar month) 1q    (1 calendar quarter) 1y    (1 calendar year) Or combine them:\n“3d12h4m25s” # 3 days, 12 hours, 4 minutes, and 25 seconds By “calendar day”, we mean the corresponding time on the next day\n(which may not be 24 hours, due to daylight savings). Similarly for\n“calendar week”, “calendar month”, “calendar quarter”, and\n“calendar year”."], ["allow_parallel", "Allow the physical plan to optionally evaluate the computation of both\nDataFrames up to the join in parallel."], ["force_parallel", "Force the physical plan to evaluate the computation of both DataFrames up to\nthe join in parallel."], ["coalesce", "Coalescing behavior (merging of on / left_on / right_on columns): True : Always coalesce join columns. False : Never coalesce join columns. Note that joining on any other expressions than col will turn off coalescing."], ["allow_exact_matches", "Whether exact matches are valid join predicates. If True, allow matching with the same on value (i.e. less-than-or-equal-to / greater-than-or-equal-to) If False, don’t match the same on value (i.e., strictly less-than / strictly greater-than)."], ["If True, allow matching with the same on value", "(i.e. less-than-or-equal-to / greater-than-or-equal-to)"], ["If False, don’t match the same on value", "(i.e., strictly less-than / strictly greater-than)."], ["check_sortedness", "Check the sortedness of the asof keys. If the keys are not sorted Polars\nwill error. Currently, sortedness cannot be checked if ‘by’ groups are\nprovided."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 571}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.join_where.html#polars.DataFrame.join_where"], "Title": ["DataFrame.join_where"], "Feature": ["DataFrame.join_where"], "Description": ["Perform a join based on one or multiple (in)equality predicates."], "Examples": [">>> east = pl.DataFrame(\n...     {\n...         \"id\": [100, 101, 102],\n...         \"dur\": [120, 140, 160],\n...         \"rev\": [12, 14, 16],\n...         \"cores\": [2, 8, 4],\n...     }\n... )\n>>> west = pl.DataFrame(\n...     {\n...         \"t_id\": [404, 498, 676, 742],\n...         \"time\": [90, 130, 150, 170],\n...         \"cost\": [9, 13, 15, 16],\n...         \"cores\": [4, 2, 1, 4],\n...     }\n... )\n>>> east.join_where(\n...     west,\n...     pl.col(\"dur\") < pl.col(\"time\"),\n...     pl.col(\"rev\") < pl.col(\"cost\"),\n... )\nshape: (5, 8)\n┌─────┬─────┬─────┬───────┬──────┬──────┬──────┬─────────────┐\n│ id  ┆ dur ┆ rev ┆ cores ┆ t_id ┆ time ┆ cost ┆ cores_right │\n│ --- ┆ --- ┆ --- ┆ ---   ┆ ---  ┆ ---  ┆ ---  ┆ ---         │\n│ i64 ┆ i64 ┆ i64 ┆ i64   ┆ i64  ┆ i64  ┆ i64  ┆ i64         │\n╞═════╪═════╪═════╪═══════╪══════╪══════╪══════╪═════════════╡\n│ 100 ┆ 120 ┆ 12  ┆ 2     ┆ 498  ┆ 130  ┆ 13   ┆ 2           │\n│ 100 ┆ 120 ┆ 12  ┆ 2     ┆ 676  ┆ 150  ┆ 15   ┆ 1           │\n│ 100 ┆ 120 ┆ 12  ┆ 2     ┆ 742  ┆ 170  ┆ 16   ┆ 4           │\n│ 101 ┆ 140 ┆ 14  ┆ 8     ┆ 676  ┆ 150  ┆ 15   ┆ 1           │\n│ 101 ┆ 140 ┆ 14  ┆ 8     ┆ 742  ┆ 170  ┆ 16   ┆ 4           │\n└─────┴─────┴─────┴───────┴──────┴──────┴──────┴─────────────┘", ">>> east.join_where(\n...     west,\n...     (pl.col(\"dur\") < pl.col(\"time\")) | (pl.col(\"rev\") < pl.col(\"cost\")),\n... )\nshape: (6, 8)\n┌─────┬─────┬─────┬───────┬──────┬──────┬──────┬─────────────┐\n│ id  ┆ dur ┆ rev ┆ cores ┆ t_id ┆ time ┆ cost ┆ cores_right │\n│ --- ┆ --- ┆ --- ┆ ---   ┆ ---  ┆ ---  ┆ ---  ┆ ---         │\n│ i64 ┆ i64 ┆ i64 ┆ i64   ┆ i64  ┆ i64  ┆ i64  ┆ i64         │\n╞═════╪═════╪═════╪═══════╪══════╪══════╪══════╪═════════════╡\n│ 100 ┆ 120 ┆ 12  ┆ 2     ┆ 498  ┆ 130  ┆ 13   ┆ 2           │\n│ 100 ┆ 120 ┆ 12  ┆ 2     ┆ 676  ┆ 150  ┆ 15   ┆ 1           │\n│ 100 ┆ 120 ┆ 12  ┆ 2     ┆ 742  ┆ 170  ┆ 16   ┆ 4           │\n│ 101 ┆ 140 ┆ 14  ┆ 8     ┆ 676  ┆ 150  ┆ 15   ┆ 1           │\n│ 101 ┆ 140 ┆ 14  ┆ 8     ┆ 742  ┆ 170  ┆ 16   ┆ 4           │\n│ 102 ┆ 160 ┆ 16  ┆ 4     ┆ 742  ┆ 170  ┆ 16   ┆ 4           │\n└─────┴─────┴─────┴───────┴──────┴──────┴──────┴─────────────┘"], "Parameters": [["other", "DataFrame to join with."], ["*predicates", "(In)Equality condition to join the two tables on.\nWhen a column name occurs in both tables, the proper suffix must\nbe applied in the predicate."], ["suffix", "Suffix to append to columns with a duplicate name."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 572}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.match_to_schema.html#polars.DataFrame.match_to_schema"], "Title": ["DataFrame.match_to_schema"], "Feature": ["DataFrame.match_to_schema"], "Description": ["Match or evolve the schema of a LazyFrame into a specific schema."], "Examples": [">>> df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [\"A\", \"B\", \"C\"]})\n>>> df.match_to_schema({\"a\": pl.Int64, \"b\": pl.String})\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ str │\n╞═════╪═════╡\n│ 1   ┆ A   │\n│ 2   ┆ B   │\n│ 3   ┆ C   │\n└─────┴─────┘\n>>> df.match_to_schema({\"a\": pl.Int64})  \npolars.exceptions.SchemaError: extra columns in `match_to_schema`: \"b\"", ">>> (\n...     pl.DataFrame({\"a\": [1, 2, 3]}).match_to_schema(\n...         {\"a\": pl.Int64, \"b\": pl.String},\n...         missing_columns=\"insert\",\n...     )\n... )\nshape: (3, 2)\n┌─────┬──────┐\n│ a   ┆ b    │\n│ --- ┆ ---  │\n│ i64 ┆ str  │\n╞═════╪══════╡\n│ 1   ┆ null │\n│ 2   ┆ null │\n│ 3   ┆ null │\n└─────┴──────┘\n>>> (\n...     pl.DataFrame({\"a\": [1, 2, 3]}).match_to_schema(\n...         {\"a\": pl.Int64, \"b\": pl.String},\n...         missing_columns={\"b\": pl.col.a.cast(pl.String)},\n...     )\n... )\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ str │\n╞═════╪═════╡\n│ 1   ┆ 1   │\n│ 2   ┆ 2   │\n│ 3   ┆ 3   │\n└─────┴─────┘", ">>> (\n...     pl.DataFrame({\"a\": [1, 2, 3], \"b\": [\"A\", \"B\", \"C\"]}).match_to_schema(\n...         {\"a\": pl.Int64},\n...         extra_columns=\"ignore\",\n...     )\n... )\nshape: (3, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n│ 3   │\n└─────┘", ">>> (\n...     pl.DataFrame(\n...         {\"a\": [1, 2, 3], \"b\": [1.0, 2.0, 3.0]},\n...         schema={\"a\": pl.Int32, \"b\": pl.Float32},\n...     ).match_to_schema(\n...         {\"a\": pl.Int64, \"b\": pl.Float64},\n...         integer_cast=\"upcast\",\n...         float_cast=\"upcast\",\n...     )\n... )\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ f64 │\n╞═════╪═════╡\n│ 1   ┆ 1.0 │\n│ 2   ┆ 2.0 │\n│ 3   ┆ 3.0 │\n└─────┴─────┘"], "Parameters": [["schema", "Target schema to match or evolve to."], ["missing_columns", "Raise of insert missing columns from the input with respect to the schema . This can also be an expression per column with what to insert if it is\nmissing."], ["missing_struct_fields", "Raise of insert missing struct fields from the input with respect to the schema ."], ["extra_columns", "Raise of ignore extra columns from the input with respect to the schema ."], ["extra_struct_fields", "Raise of ignore extra struct fields from the input with respect to the schema ."], ["integer_cast", "Forbid of upcast for integer columns from the input to the respective column\nin schema ."], ["float_cast", "Forbid of upcast for float columns from the input to the respective column\nin schema ."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 574}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.melt.html#polars.DataFrame.melt"], "Title": ["DataFrame.melt"], "Feature": ["DataFrame.melt"], "Description": ["Unpivot a DataFrame from wide to long format."], "Examples": [], "Parameters": [["id_vars", "Column(s) or selector(s) to use as identifier variables."], ["value_vars", "Column(s) or selector(s) to use as values variables; if value_vars is empty all columns that are not in id_vars will be used."], ["variable_name", "Name to give to the variable column. Defaults to “variable”"], ["value_name", "Name to give to the value column. Defaults to “value”"]], "Returns": [], "Category": ["Manipulation_selection"], "index": 575}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.merge_sorted.html#polars.DataFrame.merge_sorted"], "Title": ["DataFrame.merge_sorted"], "Feature": ["DataFrame.merge_sorted"], "Description": ["Take two sorted DataFrames and merge them by the sorted key."], "Examples": [">>> df0 = pl.DataFrame(\n...     {\"name\": [\"steve\", \"elise\", \"bob\"], \"age\": [42, 44, 18]}\n... ).sort(\"age\")\n>>> df0\nshape: (3, 2)\n┌───────┬─────┐\n│ name  ┆ age │\n│ ---   ┆ --- │\n│ str   ┆ i64 │\n╞═══════╪═════╡\n│ bob   ┆ 18  │\n│ steve ┆ 42  │\n│ elise ┆ 44  │\n└───────┴─────┘\n>>> df1 = pl.DataFrame(\n...     {\"name\": [\"anna\", \"megan\", \"steve\", \"thomas\"], \"age\": [21, 33, 42, 20]}\n... ).sort(\"age\")\n>>> df1\nshape: (4, 2)\n┌────────┬─────┐\n│ name   ┆ age │\n│ ---    ┆ --- │\n│ str    ┆ i64 │\n╞════════╪═════╡\n│ thomas ┆ 20  │\n│ anna   ┆ 21  │\n│ megan  ┆ 33  │\n│ steve  ┆ 42  │\n└────────┴─────┘\n>>> df0.merge_sorted(df1, key=\"age\")\nshape: (7, 2)\n┌────────┬─────┐\n│ name   ┆ age │\n│ ---    ┆ --- │\n│ str    ┆ i64 │\n╞════════╪═════╡\n│ bob    ┆ 18  │\n│ thomas ┆ 20  │\n│ anna   ┆ 21  │\n│ megan  ┆ 33  │\n│ steve  ┆ 42  │\n│ steve  ┆ 42  │\n│ elise  ┆ 44  │\n└────────┴─────┘"], "Parameters": [["other", "Other DataFrame that must be merged"], ["key", "Key that is sorted."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 576}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.partition_by.html#polars.DataFrame.partition_by"], "Title": ["DataFrame.partition_by"], "Feature": ["DataFrame.partition_by"], "Description": ["Group by the given columns and return the groups as separate dataframes."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...         \"b\": [1, 2, 1, 3, 3],\n...         \"c\": [5, 4, 3, 2, 1],\n...     }\n... )\n>>> df.partition_by(\"a\")  \n[shape: (2, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ a   ┆ 1   ┆ 5   │\n│ a   ┆ 1   ┆ 3   │\n└─────┴─────┴─────┘,\nshape: (2, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ b   ┆ 2   ┆ 4   │\n│ b   ┆ 3   ┆ 2   │\n└─────┴─────┴─────┘,\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ c   ┆ 3   ┆ 1   │\n└─────┴─────┴─────┘]", ">>> df.partition_by(\"a\", \"b\")  \n[shape: (2, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ a   ┆ 1   ┆ 5   │\n│ a   ┆ 1   ┆ 3   │\n└─────┴─────┴─────┘,\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ b   ┆ 2   ┆ 4   │\n└─────┴─────┴─────┘,\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ b   ┆ 3   ┆ 2   │\n└─────┴─────┴─────┘,\nshape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ c   ┆ 3   ┆ 1   │\n└─────┴─────┴─────┘]", ">>> import polars.selectors as cs\n>>> df.partition_by(cs.string(), as_dict=True)  \n{('a',): shape: (2, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ a   ┆ 1   ┆ 5   │\n│ a   ┆ 1   ┆ 3   │\n└─────┴─────┴─────┘,\n('b',): shape: (2, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ b   ┆ 2   ┆ 4   │\n│ b   ┆ 3   ┆ 2   │\n└─────┴─────┴─────┘,\n('c',): shape: (1, 3)\n┌─────┬─────┬─────┐\n│ a   ┆ b   ┆ c   │\n│ --- ┆ --- ┆ --- │\n│ str ┆ i64 ┆ i64 │\n╞═════╪═════╪═════╡\n│ c   ┆ 3   ┆ 1   │\n└─────┴─────┴─────┘}"], "Parameters": [["by", "Column name(s) or selector(s) to group by."], ["*more_by", "Additional names of columns to group by, specified as positional arguments."], ["maintain_order", "Ensure that the order of the groups is consistent with the input data.\nThis is slower than a default partition by operation."], ["include_key", "Include the columns used to partition the DataFrame in the output."], ["as_dict", "Return a dictionary instead of a list. The dictionary keys are tuples of\nthe distinct group values that identify each group."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 577}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.pipe.html#polars.DataFrame.pipe"], "Title": ["DataFrame.pipe"], "Feature": ["DataFrame.pipe"], "Description": ["Offers a structured way to apply a sequence of user-defined functions (UDFs)."], "Examples": [">>> def cast_str_to_int(data, col_name):\n...     return data.with_columns(pl.col(col_name).cast(pl.Int64))\n>>> df = pl.DataFrame({\"a\": [1, 2, 3, 4], \"b\": [\"10\", \"20\", \"30\", \"40\"]})\n>>> df.pipe(cast_str_to_int, col_name=\"b\")\nshape: (4, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 10  │\n│ 2   ┆ 20  │\n│ 3   ┆ 30  │\n│ 4   ┆ 40  │\n└─────┴─────┘", ">>> df = pl.DataFrame({\"b\": [1, 2], \"a\": [3, 4]})\n>>> df\nshape: (2, 2)\n┌─────┬─────┐\n│ b   ┆ a   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 3   │\n│ 2   ┆ 4   │\n└─────┴─────┘\n>>> df.pipe(lambda tdf: tdf.select(sorted(tdf.columns)))\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 3   ┆ 1   │\n│ 4   ┆ 2   │\n└─────┴─────┘"], "Parameters": [["function", "Callable; will receive the frame as the first parameter,\nfollowed by any given args/kwargs."], ["*args", "Arguments to pass to the UDF."], ["**kwargs", "Keyword arguments to pass to the UDF."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 578}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.pivot.html#polars.DataFrame.pivot"], "Title": ["DataFrame.pivot"], "Feature": ["DataFrame.pivot"], "Description": ["Create a spreadsheet-style pivot table as a DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"name\": [\"Cady\", \"Cady\", \"Karen\", \"Karen\"],\n...         \"subject\": [\"maths\", \"physics\", \"maths\", \"physics\"],\n...         \"test_1\": [98, 99, 61, 58],\n...         \"test_2\": [100, 100, 60, 60],\n...     }\n... )\n>>> df\nshape: (4, 4)\n┌───────┬─────────┬────────┬────────┐\n│ name  ┆ subject ┆ test_1 ┆ test_2 │\n│ ---   ┆ ---     ┆ ---    ┆ ---    │\n│ str   ┆ str     ┆ i64    ┆ i64    │\n╞═══════╪═════════╪════════╪════════╡\n│ Cady  ┆ maths   ┆ 98     ┆ 100    │\n│ Cady  ┆ physics ┆ 99     ┆ 100    │\n│ Karen ┆ maths   ┆ 61     ┆ 60     │\n│ Karen ┆ physics ┆ 58     ┆ 60     │\n└───────┴─────────┴────────┴────────┘", ">>> df.pivot(\"subject\", index=\"name\", values=\"test_1\")\nshape: (2, 3)\n┌───────┬───────┬─────────┐\n│ name  ┆ maths ┆ physics │\n│ ---   ┆ ---   ┆ ---     │\n│ str   ┆ i64   ┆ i64     │\n╞═══════╪═══════╪═════════╡\n│ Cady  ┆ 98    ┆ 99      │\n│ Karen ┆ 61    ┆ 58      │\n└───────┴───────┴─────────┘", ">>> import polars.selectors as cs\n>>> df.pivot(\"subject\", values=cs.starts_with(\"test\"))\nshape: (2, 5)\n┌───────┬──────────────┬────────────────┬──────────────┬────────────────┐\n│ name  ┆ test_1_maths ┆ test_1_physics ┆ test_2_maths ┆ test_2_physics │\n│ ---   ┆ ---          ┆ ---            ┆ ---          ┆ ---            │\n│ str   ┆ i64          ┆ i64            ┆ i64          ┆ i64            │\n╞═══════╪══════════════╪════════════════╪══════════════╪════════════════╡\n│ Cady  ┆ 98           ┆ 99             ┆ 100          ┆ 100            │\n│ Karen ┆ 61           ┆ 58             ┆ 60           ┆ 60             │\n└───────┴──────────────┴────────────────┴──────────────┴────────────────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"ix\": [1, 1, 2, 2, 1, 2],\n...         \"col\": [\"a\", \"a\", \"a\", \"a\", \"b\", \"b\"],\n...         \"foo\": [0, 1, 2, 2, 7, 1],\n...         \"bar\": [0, 2, 0, 0, 9, 4],\n...     }\n... )\n>>> df.pivot(\"col\", index=\"ix\", aggregate_function=\"sum\")\nshape: (2, 5)\n┌─────┬───────┬───────┬───────┬───────┐\n│ ix  ┆ foo_a ┆ foo_b ┆ bar_a ┆ bar_b │\n│ --- ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n│ i64 ┆ i64   ┆ i64   ┆ i64   ┆ i64   │\n╞═════╪═══════╪═══════╪═══════╪═══════╡\n│ 1   ┆ 1     ┆ 7     ┆ 2     ┆ 9     │\n│ 2   ┆ 4     ┆ 1     ┆ 0     ┆ 4     │\n└─────┴───────┴───────┴───────┴───────┘", ">>> df = pl.DataFrame(\n...     {\n...         \"col1\": [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"],\n...         \"col2\": [\"x\", \"x\", \"x\", \"x\", \"y\", \"y\"],\n...         \"col3\": [6, 7, 3, 2, 5, 7],\n...     }\n... )\n>>> df.pivot(\n...     \"col2\",\n...     index=\"col1\",\n...     values=\"col3\",\n...     aggregate_function=pl.element().tanh().mean(),\n... )\nshape: (2, 3)\n┌──────┬──────────┬──────────┐\n│ col1 ┆ x        ┆ y        │\n│ ---  ┆ ---      ┆ ---      │\n│ str  ┆ f64      ┆ f64      │\n╞══════╪══════════╪══════════╡\n│ a    ┆ 0.998347 ┆ null     │\n│ b    ┆ 0.964028 ┆ 0.999954 │\n└──────┴──────────┴──────────┘", ">>> index = pl.col(\"col1\")\n>>> on = pl.col(\"col2\")\n>>> values = pl.col(\"col3\")\n>>> unique_column_values = [\"x\", \"y\"]\n>>> aggregate_function = lambda col: col.tanh().mean()\n>>> df.lazy().group_by(index).agg(\n...     aggregate_function(values.filter(on == value)).alias(value)\n...     for value in unique_column_values\n... ).collect()  \nshape: (2, 3)\n┌──────┬──────────┬──────────┐\n│ col1 ┆ x        ┆ y        │\n│ ---  ┆ ---      ┆ ---      │\n│ str  ┆ f64      ┆ f64      │\n╞══════╪══════════╪══════════╡\n│ a    ┆ 0.998347 ┆ null     │\n│ b    ┆ 0.964028 ┆ 0.999954 │\n└──────┴──────────┴──────────┘"], "Parameters": [["on", "The column(s) whose values will be used as the new columns of the output\nDataFrame."], ["index", "The column(s) that remain from the input to the output. The output DataFrame will have one row\nfor each unique combination of the index ’s values.\nIf None, all remaining columns not specified on on and values will be used. At least one\nof index and values must be specified."], ["values", "The existing column(s) of values which will be moved under the new columns from index. If an\naggregation is specified, these are the values on which the aggregation will be computed.\nIf None, all remaining columns not specified on on and index will be used.\nAt least one of index and values must be specified."], ["aggregate_function", "Choose from: None: no aggregation takes place, will raise error if multiple values are in group. A predefined aggregate function string, one of\n{‘min’, ‘max’, ‘first’, ‘last’, ‘sum’, ‘mean’, ‘median’, ‘len’} An expression to do the aggregation. The expression can only access data from the respective\n‘values’ columns as generated by pivot, through pl.element() ."], ["maintain_order", "Ensure the values of index are sorted by discovery order."], ["sort_columns", "Sort the transposed columns by name. Default is by order of discovery."], ["separator", "Used as separator/delimiter in generated column names in case of multiple values columns."]], "Returns": [["DataFrame", ""]], "Category": ["Manipulation_selection"], "index": 579}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.rechunk.html#polars.DataFrame.rechunk"], "Title": ["DataFrame.rechunk"], "Feature": ["DataFrame.rechunk"], "Description": ["Rechunk the data in this DataFrame to a contiguous allocation."], "Examples": [], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 580}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.quantile.html#polars.DataFrame.quantile"], "Title": ["DataFrame.quantile"], "Feature": ["DataFrame.quantile"], "Description": ["Aggregate the columns of this DataFrame to their quantile value."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.quantile(0.5, \"nearest\")\nshape: (1, 3)\n┌─────┬─────┬──────┐\n│ foo ┆ bar ┆ ham  │\n│ --- ┆ --- ┆ ---  │\n│ f64 ┆ f64 ┆ str  │\n╞═════╪═════╪══════╡\n│ 2.0 ┆ 7.0 ┆ null │\n└─────┴─────┴──────┘"], "Parameters": [["quantile", "Quantile between 0.0 and 1.0."], ["interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’, ‘equiprobable’}", "Interpolation method."]], "Returns": [], "Category": ["Aggregation"], "index": 581}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.remove.html#polars.DataFrame.remove"], "Title": ["DataFrame.remove"], "Feature": ["DataFrame.remove"], "Description": ["Remove rows, dropping those that match the given predicate expression(s)."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [2, 3, None, 4, 0],\n...         \"bar\": [5, 6, None, None, 0],\n...         \"ham\": [\"a\", \"b\", None, \"c\", \"d\"],\n...     }\n... )", ">>> df.remove(pl.col(\"bar\") >= 5)\nshape: (3, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ str  │\n╞══════╪══════╪══════╡\n│ null ┆ null ┆ null │\n│ 4    ┆ null ┆ c    │\n│ 0    ┆ 0    ┆ d    │\n└──────┴──────┴──────┘", ">>> df.remove(\n...     (pl.col(\"foo\") >= 0) & (pl.col(\"bar\") >= 0),\n... )\nshape: (2, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ str  │\n╞══════╪══════╪══════╡\n│ null ┆ null ┆ null │\n│ 4    ┆ null ┆ c    │\n└──────┴──────┴──────┘", ">>> df.remove(\n...     (pl.col(\"foo\") >= 0) | (pl.col(\"bar\") >= 0),\n... )\nshape: (1, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ str  │\n╞══════╪══════╪══════╡\n│ null ┆ null ┆ null │\n└──────┴──────┴──────┘", ">>> df.remove(\n...     pl.col(\"ham\").is_not_null(),\n...     pl.col(\"bar\") >= 0,\n... )\nshape: (2, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ str  │\n╞══════╪══════╪══════╡\n│ null ┆ null ┆ null │\n│ 4    ┆ null ┆ c    │\n└──────┴──────┴──────┘", ">>> df.remove(foo=0, bar=0)\nshape: (4, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ str  │\n╞══════╪══════╪══════╡\n│ 2    ┆ 5    ┆ a    │\n│ 3    ┆ 6    ┆ b    │\n│ null ┆ null ┆ null │\n│ 4    ┆ null ┆ c    │\n└──────┴──────┴──────┘", ">>> df.remove(\n...     pl.col(\"foo\").ne_missing(pl.col(\"bar\")),\n... )\nshape: (2, 3)\n┌──────┬──────┬──────┐\n│ foo  ┆ bar  ┆ ham  │\n│ ---  ┆ ---  ┆ ---  │\n│ i64  ┆ i64  ┆ str  │\n╞══════╪══════╪══════╡\n│ null ┆ null ┆ null │\n│ 0    ┆ 0    ┆ d    │\n└──────┴──────┴──────┘"], "Parameters": [["predicates", "Expression that evaluates to a boolean Series."], ["constraints", "Column filters; use name = value to filter columns using the supplied\nvalue. Each constraint behaves the same as pl.col(name).eq(value) ,\nand is implicitly joined with the other filter conditions using & ."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 582}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.rename.html#polars.DataFrame.rename"], "Title": ["DataFrame.rename"], "Feature": ["DataFrame.rename"], "Description": ["Rename column names."], "Examples": [">>> df = pl.DataFrame(\n...     {\"foo\": [1, 2, 3], \"bar\": [6, 7, 8], \"ham\": [\"a\", \"b\", \"c\"]}\n... )\n>>> df.rename({\"foo\": \"apple\"})\nshape: (3, 3)\n┌───────┬─────┬─────┐\n│ apple ┆ bar ┆ ham │\n│ ---   ┆ --- ┆ --- │\n│ i64   ┆ i64 ┆ str │\n╞═══════╪═════╪═════╡\n│ 1     ┆ 6   ┆ a   │\n│ 2     ┆ 7   ┆ b   │\n│ 3     ┆ 8   ┆ c   │\n└───────┴─────┴─────┘\n>>> df.rename(lambda column_name: \"c\" + column_name[1:])\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ coo ┆ car ┆ cam │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 1   ┆ 6   ┆ a   │\n│ 2   ┆ 7   ┆ b   │\n│ 3   ┆ 8   ┆ c   │\n└─────┴─────┴─────┘"], "Parameters": [["mapping", "Key value pairs that map from old name to new name, or a function\nthat takes the old name as input and returns the new name."], ["strict", "Validate that all column names exist in the current schema,\nand throw an exception if any do not. (Note that this parameter\nis a no-op when passing a function to mapping )."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 583}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.replace_column.html#polars.DataFrame.replace_column"], "Title": ["DataFrame.replace_column"], "Feature": ["DataFrame.replace_column"], "Description": ["Replace a column at an index location."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> s = pl.Series(\"apple\", [10, 20, 30])\n>>> df.replace_column(0, s)\nshape: (3, 3)\n┌───────┬─────┬─────┐\n│ apple ┆ bar ┆ ham │\n│ ---   ┆ --- ┆ --- │\n│ i64   ┆ i64 ┆ str │\n╞═══════╪═════╪═════╡\n│ 10    ┆ 6   ┆ a   │\n│ 20    ┆ 7   ┆ b   │\n│ 30    ┆ 8   ┆ c   │\n└───────┴─────┴─────┘"], "Parameters": [["index", "Column index."], ["column", "Series that will replace the column."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 584}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.reverse.html#polars.DataFrame.reverse"], "Title": ["DataFrame.reverse"], "Feature": ["DataFrame.reverse"], "Description": ["Reverse the DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"key\": [\"a\", \"b\", \"c\"],\n...         \"val\": [1, 2, 3],\n...     }\n... )\n>>> df.reverse()\nshape: (3, 2)\n┌─────┬─────┐\n│ key ┆ val │\n│ --- ┆ --- │\n│ str ┆ i64 │\n╞═════╪═════╡\n│ c   ┆ 3   │\n│ b   ┆ 2   │\n│ a   ┆ 1   │\n└─────┴─────┘"], "Parameters": [], "Returns": [], "Category": ["Manipulation_selection"], "index": 585}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.rolling.html#polars.DataFrame.rolling"], "Title": ["DataFrame.rolling"], "Feature": ["DataFrame.rolling"], "Description": ["Create rolling groups based on a temporal or integer column."], "Examples": [">>> dates = [\n...     \"2020-01-01 13:45:48\",\n...     \"2020-01-01 16:42:13\",\n...     \"2020-01-01 16:45:09\",\n...     \"2020-01-02 18:12:48\",\n...     \"2020-01-03 19:45:32\",\n...     \"2020-01-08 23:16:43\",\n... ]\n>>> df = pl.DataFrame({\"dt\": dates, \"a\": [3, 7, 5, 9, 2, 1]}).with_columns(\n...     pl.col(\"dt\").str.strptime(pl.Datetime).set_sorted()\n... )\n>>> out = df.rolling(index_column=\"dt\", period=\"2d\").agg(\n...     [\n...         pl.sum(\"a\").alias(\"sum_a\"),\n...         pl.min(\"a\").alias(\"min_a\"),\n...         pl.max(\"a\").alias(\"max_a\"),\n...     ]\n... )\n>>> assert out[\"sum_a\"].to_list() == [3, 10, 15, 24, 11, 1]\n>>> assert out[\"max_a\"].to_list() == [3, 7, 7, 9, 9, 1]\n>>> assert out[\"min_a\"].to_list() == [3, 3, 3, 3, 2, 1]\n>>> out\nshape: (6, 4)\n┌─────────────────────┬───────┬───────┬───────┐\n│ dt                  ┆ sum_a ┆ min_a ┆ max_a │\n│ ---                 ┆ ---   ┆ ---   ┆ ---   │\n│ datetime[μs]        ┆ i64   ┆ i64   ┆ i64   │\n╞═════════════════════╪═══════╪═══════╪═══════╡\n│ 2020-01-01 13:45:48 ┆ 3     ┆ 3     ┆ 3     │\n│ 2020-01-01 16:42:13 ┆ 10    ┆ 3     ┆ 7     │\n│ 2020-01-01 16:45:09 ┆ 15    ┆ 3     ┆ 7     │\n│ 2020-01-02 18:12:48 ┆ 24    ┆ 3     ┆ 9     │\n│ 2020-01-03 19:45:32 ┆ 11    ┆ 2     ┆ 9     │\n│ 2020-01-08 23:16:43 ┆ 1     ┆ 1     ┆ 1     │\n└─────────────────────┴───────┴───────┴───────┘", ">>> df = pl.DataFrame({\"int\": [0, 4, 5, 6, 8], \"value\": [1, 4, 2, 4, 1]})\n>>> df.rolling(\"int\", period=\"3i\").agg(pl.col(\"int\").alias(\"aggregated\"))\nshape: (5, 2)\n┌─────┬────────────┐\n│ int ┆ aggregated │\n│ --- ┆ ---        │\n│ i64 ┆ list[i64]  │\n╞═════╪════════════╡\n│ 0   ┆ [0]        │\n│ 4   ┆ [4]        │\n│ 5   ┆ [4, 5]     │\n│ 6   ┆ [4, 5, 6]  │\n│ 8   ┆ [6, 8]     │\n└─────┴────────────┘"], "Parameters": [["index_column", "Column used to group based on the time window.\nOften of type Date/Datetime.\nThis column must be sorted in ascending order (or, if group_by is\nspecified, then it must be sorted in ascending order within each group). In case of a rolling operation on indices, dtype needs to be one of\n{UInt32, UInt64, Int32, Int64}. Note that the first three get temporarily\ncast to Int64, so if performance matters use an Int64 column."], ["period", "Length of the window - must be non-negative."], ["offset", "Offset of the window. Default is -period ."], ["closed {‘right’, ‘left’, ‘both’, ‘none’}", "Define which sides of the temporal interval are closed (inclusive)."], ["group_by", "Also group by this column/these columns"]], "Returns": [["RollingGroupBy", "Object you can call .agg on to aggregate by groups, the result\nof which will be sorted by index_column (but note that if group_by columns are passed, it will only be sorted within each group)."]], "Category": ["Manipulation_selection"], "index": 586}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.row.html#polars.DataFrame.row"], "Title": ["DataFrame.row"], "Feature": ["DataFrame.row"], "Description": ["Get the values of a single row, either by index or by predicate."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.row(2)\n(3, 8, 'c')", ">>> df.row(2, named=True)\n{'foo': 3, 'bar': 8, 'ham': 'c'}", ">>> df.row(by_predicate=(pl.col(\"ham\") == \"b\"))\n(2, 7, 'b')"], "Parameters": [["index", "Row index."], ["by_predicate", "Select the row according to a given expression/predicate."], ["named", "Return a dictionary instead of a tuple. The dictionary is a mapping of\ncolumn name to row value. This is more expensive than returning a regular\ntuple, but allows for accessing values by column name."]], "Returns": [["tuple (default) or dictionary of row values", ""]], "Category": ["Manipulation_selection"], "index": 587}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.rows.html#polars.DataFrame.rows"], "Title": ["DataFrame.rows"], "Feature": ["DataFrame.rows"], "Description": ["Returns all data in the DataFrame as a list of rows of python-native values."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"x\": [\"a\", \"b\", \"b\", \"a\"],\n...         \"y\": [1, 2, 3, 4],\n...         \"z\": [0, 3, 6, 9],\n...     }\n... )\n>>> df.rows()\n[('a', 1, 0), ('b', 2, 3), ('b', 3, 6), ('a', 4, 9)]\n>>> df.rows(named=True)\n[{'x': 'a', 'y': 1, 'z': 0},\n {'x': 'b', 'y': 2, 'z': 3},\n {'x': 'b', 'y': 3, 'z': 6},\n {'x': 'a', 'y': 4, 'z': 9}]"], "Parameters": [["named", "Return dictionaries instead of tuples. The dictionaries are a mapping of\ncolumn name to row value. This is more expensive than returning a regular\ntuple, but allows for accessing values by column name."]], "Returns": [["list of row value tuples (default), or list of dictionaries (if named=True ).", ""]], "Category": ["Manipulation_selection"], "index": 588}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.rows_by_key.html#polars.DataFrame.rows_by_key"], "Title": ["DataFrame.rows_by_key"], "Feature": ["DataFrame.rows_by_key"], "Description": ["Returns all data as a dictionary of python-native values keyed by some column."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"w\": [\"a\", \"b\", \"b\", \"a\"],\n...         \"x\": [\"q\", \"q\", \"q\", \"k\"],\n...         \"y\": [1.0, 2.5, 3.0, 4.5],\n...         \"z\": [9, 8, 7, 6],\n...     }\n... )", ">>> df.rows_by_key(key=[\"w\"])\ndefaultdict(<class 'list'>,\n    {'a': [('q', 1.0, 9), ('k', 4.5, 6)],\n     'b': [('q', 2.5, 8), ('q', 3.0, 7)]})", ">>> df.rows_by_key(key=[\"w\"], named=True)\ndefaultdict(<class 'list'>,\n    {'a': [{'x': 'q', 'y': 1.0, 'z': 9},\n           {'x': 'k', 'y': 4.5, 'z': 6}],\n     'b': [{'x': 'q', 'y': 2.5, 'z': 8},\n           {'x': 'q', 'y': 3.0, 'z': 7}]})", ">>> df.rows_by_key(key=[\"z\"], unique=True)\n{9: ('a', 'q', 1.0),\n 8: ('b', 'q', 2.5),\n 7: ('b', 'q', 3.0),\n 6: ('a', 'k', 4.5)}", ">>> df.rows_by_key(key=[\"z\"], named=True, unique=True)\n{9: {'w': 'a', 'x': 'q', 'y': 1.0},\n 8: {'w': 'b', 'x': 'q', 'y': 2.5},\n 7: {'w': 'b', 'x': 'q', 'y': 3.0},\n 6: {'w': 'a', 'x': 'k', 'y': 4.5}}", ">>> df.rows_by_key(key=[\"w\", \"x\"], named=True, include_key=True)\ndefaultdict(<class 'list'>,\n    {('a', 'q'): [{'w': 'a', 'x': 'q', 'y': 1.0, 'z': 9}],\n     ('b', 'q'): [{'w': 'b', 'x': 'q', 'y': 2.5, 'z': 8},\n                  {'w': 'b', 'x': 'q', 'y': 3.0, 'z': 7}],\n     ('a', 'k'): [{'w': 'a', 'x': 'k', 'y': 4.5, 'z': 6}]})"], "Parameters": [["key", "The column(s) to use as the key for the returned dictionary. If multiple\ncolumns are specified, the key will be a tuple of those values, otherwise\nit will be a string."], ["named", "Return dictionary rows instead of tuples, mapping column name to row value."], ["include_key", "Include key values inline with the associated data (by default the key\nvalues are omitted as a memory/performance optimisation, as they can be\nreoconstructed from the key)."], ["unique", "Indicate that the key is unique; this will result in a 1:1 mapping from\nkey to a single associated row. Note that if the key is not actually\nunique the last row with the given key will be returned."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 589}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.sample.html#polars.DataFrame.sample"], "Title": ["DataFrame.sample"], "Feature": ["DataFrame.sample"], "Description": ["Sample from this DataFrame."], "Examples": [">>> df = pl.DataFrame(\n...     {\n...         \"foo\": [1, 2, 3],\n...         \"bar\": [6, 7, 8],\n...         \"ham\": [\"a\", \"b\", \"c\"],\n...     }\n... )\n>>> df.sample(n=2, seed=0)  \nshape: (2, 3)\n┌─────┬─────┬─────┐\n│ foo ┆ bar ┆ ham │\n│ --- ┆ --- ┆ --- │\n│ i64 ┆ i64 ┆ str │\n╞═════╪═════╪═════╡\n│ 3   ┆ 8   ┆ c   │\n│ 2   ┆ 7   ┆ b   │\n└─────┴─────┴─────┘"], "Parameters": [["n", "Number of items to return. Cannot be used with fraction . Defaults to 1 if fraction is None."], ["fraction", "Fraction of items to return. Cannot be used with n ."], ["with_replacement", "Allow values to be sampled more than once."], ["shuffle", "If set to True, the order of the sampled rows will be shuffled. If\nset to False (default), the order of the returned rows will be\nneither stable nor fully random."], ["seed", "Seed for the random number generator. If set to None (default), a\nrandom seed is generated for each sample operation."]], "Returns": [], "Category": ["Manipulation_selection"], "index": 590}
{"HTML": ["https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.arr.agg.html#polars.Expr.arr.agg"], "Title": ["Expr.arr.agg"], "Feature": ["Expr.arr.agg"], "Description": ["Run any polars aggregation expression against the arrays' elements."], "Examples": [">>> df = pl.Series(\n...     \"a\", [[1, None], [42, 13], [None, None]], pl.Array(pl.Int64, 2)\n... ).to_frame()\n>>> df.with_columns(null_count=pl.col.a.arr.agg(pl.element().null_count()))\nshape: (3, 2)\n┌───────────────┬────────────┐\n│ a             ┆ null_count │\n│ ---           ┆ ---        │\n│ array[i64, 2] ┆ u32        │\n╞═══════════════╪════════════╡\n│ [1, null]     ┆ 1          │\n│ [42, 13]      ┆ 0          │\n│ [null, null]  ┆ 2          │\n└───────────────┴────────────┘\n>>> df.with_columns(no_nulls=pl.col.a.arr.agg(pl.element().drop_nulls()))\nshape: (3, 2)\n┌───────────────┬───────────┐\n│ a             ┆ no_nulls  │\n│ ---           ┆ ---       │\n│ array[i64, 2] ┆ list[i64] │\n╞═══════════════╪═══════════╡\n│ [1, null]     ┆ [1]       │\n│ [42, 13]      ┆ [42, 13]  │\n│ [null, null]  ┆ []        │\n└───────────────┴───────────┘"], "Parameters": [["expr", "Expression to run. Note that you can select an element with pl.element() ."]], "Returns": [], "Category": ["Array"], "index": 591}