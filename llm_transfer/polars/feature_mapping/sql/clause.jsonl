{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/select"], "Title": ["SELECT"], "Feature": ["SELECT"], "Description": ["The SELECT clause specifies the list of columns that will be returned by the query. While it appears first in the clause, logically the expressions here are executed only at the end. The SELECT clause can contain arbitrary expressions that transform the output, as well as aggregates and window functions."], "Examples": ["Select all columns from the table called table_name:\nSELECT * FROM table_name;\nPerform arithmetic on the columns in a table, and provide an alias:\nSELECT col1 + col2 AS res, sqrt(col1) AS root FROM table_name;\nUse prefix aliases:\nSELECT\n    res: col1 + col2,\n    root: sqrt(col1)\nFROM table_name;\nSelect all unique cities from the addresses table:\nSELECT DISTINCT city FROM addresses;\nReturn the total number of rows in the addresses table:\nSELECT count(*) FROM addresses;\nSelect all columns except the city column from the addresses table:\nSELECT * EXCLUDE (city) FROM addresses;\nSelect all columns from the addresses table, but replace city with lower(city):\nSELECT * REPLACE (lower(city) AS city) FROM addresses;\nSelect all columns matching the given regular expression from the table:\nSELECT COLUMNS('number\\d+') FROM addresses;\nCompute a function on all given columns of a table:\nSELECT min(COLUMNS(*)) FROM addresses;\nTo select columns with spaces or special characters, use double quotes (\"):\nSELECT \"Some Column Name\" FROM tbl;"], "Category": ["SELECT Clause"], "index": 0}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/from"], "Title": ["JOIN"], "Feature": ["JOIN"], "Description": ["Joins are a fundamental relational operation used to connect two tables or relations horizontally. The relations are referred to as the left and right sides of the join based on how they are written in the join clause. Each result row has the columns from both relations.\nA join uses a rule to match pairs of rows from each relation. Often this is a predicate, but there are other implied rules that may be specified.\nOuter Joins\nRows that do not have any matches can still be returned if an OUTER join is specified. Outer joins can be one of:\nLEFT (All rows from the left relation appear at least once)\nRIGHT (All rows from the right relation appear at least once)\nFULL (All rows from both relations appear at least once)\nA join that is not OUTER is INNER (only rows that get paired are returned).\nWhen an unpaired row is returned, the attributes from the other table are set to NULL.\nCross Product Joins (Cartesian Product)\nThe simplest type of join is a CROSS JOIN. There are no conditions for this type of join, and it just returns all the possible pairs.\nReturn all pairs of rows:\nSELECT a.*, b.*\nFROM a\nCROSS JOIN b;\nThis is equivalent to omitting the JOIN clause:\nSELECT a.*, b.*\nFROM a, b;\nConditional Joins\nMost joins are specified by a predicate that connects attributes from one side to attributes from the other side. The conditions can be explicitly specified using an ON clause with the join (clearer) or implied by the WHERE clause (old-fashioned).\nWe use the l_regions and the l_nations tables from the TPC-H schema:\nCREATE TABLE l_regions (\n    r_regionkey INTEGER NOT NULL PRIMARY KEY,\n    r_name      CHAR(25) NOT NULL,\n    r_comment   VARCHAR(152)\n);\nCREATE TABLE l_nations (\n    n_nationkey INTEGER NOT NULL PRIMARY KEY,\n    n_name      CHAR(25) NOT NULL,\n    n_regionkey INTEGER NOT NULL,\n    n_comment   VARCHAR(152),\n    FOREIGN KEY (n_regionkey) REFERENCES l_regions(r_regionkey)\n);\nReturn the regions for the nations:\nSELECT n.*, r.*\nFROM l_nations n\nJOIN l_regions r ON (n_regionkey = r_regionkey);\nIf the column names are the same and are required to be equal, then the simpler USING syntax can be used:\nCREATE TABLE l_regions (regionkey INTEGER NOT NULL PRIMARY KEY,\n                        name      CHAR(25) NOT NULL,\n                        comment   VARCHAR(152));\nCREATE TABLE l_nations (nationkey INTEGER NOT NULL PRIMARY KEY,\n                        name      CHAR(25) NOT NULL,\n                        regionkey INTEGER NOT NULL,\n                        comment   VARCHAR(152),\n                        FOREIGN KEY (regionkey) REFERENCES l_regions(regionkey));\nReturn the regions for the nations:\nSELECT n.*, r.*\nFROM l_nations n\nJOIN l_regions r USING (regionkey);\nThe expressions do not have to be equalities – any predicate can be used:\nReturn the pairs of jobs where one ran longer but cost less:\nSELECT s1.t_id, s2.t_id\nFROM west s1, west s2\nWHERE s1.time > s2.time\n  AND s1.cost < s2.cost;\nNatural Joins\nNatural joins join two tables based on attributes that share the same name.\nFor example, take the following example with cities, airport codes and airport names. Note that both tables are intentionally incomplete, i.e., they do not have a matching pair in the other table.\nCREATE TABLE city_airport (city_name VARCHAR, iata VARCHAR);\nCREATE TABLE airport_names (iata VARCHAR, airport_name VARCHAR);\nINSERT INTO city_airport VALUES\n    ('Amsterdam', 'AMS'),\n    ('Rotterdam', 'RTM'),\n    ('Eindhoven', 'EIN'),\n    ('Groningen', 'GRQ');\nINSERT INTO airport_names VALUES\n    ('AMS', 'Amsterdam Airport Schiphol'),\n    ('RTM', 'Rotterdam The Hague Airport'),\n    ('MST', 'Maastricht Aachen Airport');\nTo join the tables on their shared IATA attributes, run:\nSELECT *\nFROM city_airport\nNATURAL JOIN airport_names;\nThis produces the following result:\ncity_name\tiata\tairport_name\nAmsterdam\tAMS\tAmsterdam Airport Schiphol\nRotterdam\tRTM\tRotterdam The Hague Airport\nNote that only rows where the same iata attribute was present in both tables were included in the result.\nWe can also express query using the vanilla JOIN clause with the USING keyword:\nSELECT *\nFROM city_airport\nJOIN airport_names\nUSING (iata);\nSemi and Anti Joins\nSemi joins return rows from the left table that have at least one match in the right table. Anti joins return rows from the left table that have no matches in the right table. When using a semi or anti join the result will never have more rows than the left hand side table. Semi joins provide the same logic as the IN operator statement. Anti joins provide the same logic as the NOT IN operator, except anti joins ignore NULL values from the right table.\nSemi Join Example\nReturn a list of city–airport code pairs from the city_airport table where the airport name is available in the airport_names table:\nSELECT *\nFROM city_airport\nSEMI JOIN airport_names\n    USING (iata);\ncity_name\tiata\nAmsterdam\tAMS\nRotterdam\tRTM\nThis query is equivalent with:\nSELECT *\nFROM city_airport\nWHERE iata IN (SELECT iata FROM airport_names);\nAnti Join Example\nReturn a list of city–airport code pairs from the city_airport table where the airport name is not available in the airport_names table:\nSELECT *\nFROM city_airport\nANTI JOIN airport_names\n    USING (iata);\ncity_name\tiata\nEindhoven\tEIN\nGroningen\tGRQ\nThis query is equivalent with:\nSELECT *\nFROM city_airport\nWHERE iata NOT IN (SELECT iata FROM airport_names WHERE iata IS NOT NULL);\nLateral Joins\nThe LATERAL keyword allows subqueries in the FROM clause to refer to previous subqueries. This feature is also known as a lateral join.\nSELECT *\nFROM range(3) t(i), LATERAL (SELECT i + 1) t2(j);\ni\tj\n0\t1\n2\t3\n1\t2\nLateral joins are a generalization of correlated subqueries, as they can return multiple values per input value rather than only a single value.\nSELECT *\nFROM\n    generate_series(0, 1) t(i),\n    LATERAL (SELECT i + 10 UNION ALL SELECT i + 100) t2(j);\ni\tj\n0\t10\n1\t11\n0\t100\n1\t101\nIt may be helpful to think about LATERAL as a loop where we iterate through the rows of the first subquery and use it as input to the second (LATERAL) subquery. In the examples above, we iterate through table t and refer to its column i from the definition of table t2. The rows of t2 form column j in the result.\nIt is possible to refer to multiple attributes from the LATERAL subquery. Using the table from the first example:\nCREATE TABLE t1 AS\n    SELECT *\n    FROM range(3) t(i), LATERAL (SELECT i + 1) t2(j);\nSELECT *\n    FROM t1, LATERAL (SELECT i + j) t2(k)\n    ORDER BY ALL;\ni\tj\tk\n0\t1\t1\n1\t2\t3\n2\t3\t5\nDuckDB detects when LATERAL joins should be used, making the use of the LATERAL keyword optional.\nPositional Joins\nWhen working with data frames or other embedded tables of the same size, the rows may have a natural correspondence based on their physical order. In scripting languages, this is easily expressed using a loop:\nfor (i = 0; i < n; i++) {\n    f(t1.a[i], t2.b[i]);\n}\nIt is difficult to express this in standard SQL because relational tables are not ordered, but imported tables such as data frames or disk files (like CSVs or Parquet files) do have a natural ordering.\nConnecting them using this ordering is called a positional join:\nCREATE TABLE t1 (x INTEGER);\nCREATE TABLE t2 (s VARCHAR);\nINSERT INTO t1 VALUES (1), (2), (3);\nINSERT INTO t2 VALUES ('a'), ('b');\nSELECT *\nFROM t1\nPOSITIONAL JOIN t2;\nx\ts\n1\ta\n2\tb\n3\tNULL\nPositional joins are always FULL OUTER joins, i.e., missing values (the last values in the shorter column) are set to NULL.\nAs-Of Joins\nA common operation when working with temporal or similarly-ordered data is to find the nearest (first) event in a reference table (such as prices). This is called an as-of join:\nAttach prices to stock trades:\nSELECT t.*, p.price\nFROM trades t\nASOF JOIN prices p\n       ON t.symbol = p.symbol AND t.when >= p.when;\nThe ASOF join requires at least one inequality condition on the ordering field. The inequality can be any inequality condition (>=, >, <=, <) on any data type, but the most common form is >= on a temporal type. Any other conditions must be equalities (or NOT DISTINCT). This means that the left/right order of the tables is significant.\nASOF joins each left side row with at most one right side row. It can be specified as an OUTER join to find unpaired rows (e.g., trades without prices or prices which have no trades.)\nAttach prices or NULLs to stock trades:\nSELECT *\nFROM trades t\nASOF LEFT JOIN prices p\n            ON t.symbol = p.symbol\n           AND t.when >= p.when;\nASOF joins can also specify join conditions on matching column names with the USING syntax, but the last attribute in the list must be the inequality, which will be greater than or equal to (>=):\nSELECT *\nFROM trades t\nASOF JOIN prices p USING (symbol, \"when\");\nReturns symbol, trades.when, price (but NOT prices.when):\nIf you combine USING with a SELECT * like this, the query will return the left side (probe) column values for the matches, not the right side (build) column values. To get the prices times in the example, you will need to list the columns explicitly:\nSELECT t.symbol, t.when AS trade_when, p.when AS price_when, price\nFROM trades t\nASOF LEFT JOIN prices p USING (symbol, \"when\");\nSelf-Joins\nDuckDB allows self-joins for all types of joins. Note that tables need to be aliased, using the same table name without aliases will result in an error:\nCREATE TABLE t (x INTEGER);\nSELECT * FROM t JOIN t USING(x);\nBinder Error:\nDuplicate alias \"t\" in query!\nAdding the aliases allows the query to parse successfully:\nSELECT * FROM t AS t t1 JOIN t t2 USING(x);\nShorthands in the JOIN Clause\nYou can specify column names in the JOIN clause:\nCREATE TABLE t1 (x INTEGER);\nCREATE TABLE t2 (y INTEGER);\nINSERT INTO t1 VALUES (1), (2), (4);\nINSERT INTO t2 VALUES (2), (3);\nSELECT * FROM t1 NATURAL JOIN t2 t2(x);\nx\n2\nYou can also use the VALUES clause in the JOIN clause:\nSELECT * FROM t1 NATURAL JOIN (VALUES (2), (4)) _(x);\nx\n2\n4"], "Examples": [""], "Category": ["FROM and JOIN Clauses"], "index": 1}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/with"], "Title": ["WITH"], "Feature": ["WITH"], "Description": ["The WITH clause allows you to specify common table expressions (CTEs). Regular (non-recursive) common-table-expressions are essentially views that are limited in scope to a particular query. CTEs can reference each-other and can be nested. Recursive CTEs can reference themselves.\nBasic CTE Examples\nCreate a CTE called cte and use it in the main query:\nWITH cte AS (SELECT 42 AS x)\nSELECT * FROM cte;\nx\n42\nCreate two CTEs cte1 and cte2, where the second CTE references the first CTE:\nWITH\n    cte1 AS (SELECT 42 AS i),\n    cte2 AS (SELECT i * 100 AS x FROM cte1)\nSELECT * FROM cte2;\nx\n4200\nYou can specify column names for CTEs:\nWITH cte(j) AS (SELECT 42 AS i)\nFROM cte;"], "Examples": [], "Category": ["WITH Clause"], "index": 2}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/qualify"], "Title": ["QUALIFY"], "Feature": ["QUALIFY"], "Description": ["The QUALIFY clause is used to filter the results of WINDOW functions. This filtering of results is similar to how a HAVING clause filters the results of aggregate functions applied based on the GROUP BY clause.\nThe QUALIFY clause avoids the need for a subquery or WITH clause to perform this filtering (much like HAVING avoids a subquery). An example using a WITH clause instead of QUALIFY is included below the QUALIFY examples.\nNote that this is filtering based on WINDOW functions, not necessarily based on the WINDOW clause. The WINDOW clause is optional and can be used to simplify the creation of multiple WINDOW function expressions.\nThe position of where to specify a QUALIFY clause is following the WINDOW clause in a SELECT statement (WINDOW does not need to be specified), and before the ORDER BY."], "Examples": ["Each of the following examples produce the same output, located below.\nFilter based on a window function defined in the QUALIFY clause:\nSELECT\n    schema_name,\n    function_name,\n    -- In this example the function_rank column in the select clause is for reference\n    row_number() OVER (PARTITION BY schema_name ORDER BY function_name) AS function_rank\nFROM duckdb_functions()\nQUALIFY\n    row_number() OVER (PARTITION BY schema_name ORDER BY function_name) < 3;\nFilter based on a window function defined in the SELECT clause:\nSELECT\n    schema_name,\n    function_name,\n    row_number() OVER (PARTITION BY schema_name ORDER BY function_name) AS function_rank\nFROM duckdb_functions()\nQUALIFY\n    function_rank < 3;\nFilter based on a window function defined in the QUALIFY clause, but using the WINDOW clause:\nSELECT\n    schema_name,\n    function_name,\n    -- In this example the function_rank column in the select clause is for reference\n    row_number() OVER my_window AS function_rank\nFROM duckdb_functions()\nWINDOW\n    my_window AS (PARTITION BY schema_name ORDER BY function_name)\nQUALIFY\n    row_number() OVER my_window < 3;\nFilter based on a window function defined in the SELECT clause, but using the WINDOW clause:\nSELECT\n    schema_name,\n    function_name,\n    row_number() OVER my_window AS function_rank\nFROM duckdb_functions()\nWINDOW\n    my_window AS (PARTITION BY schema_name ORDER BY function_name)\nQUALIFY\n    function_rank < 3;\nEquivalent query based on a WITH clause (without a QUALIFY clause):\nWITH ranked_functions AS (\n    SELECT\n        schema_name,\n        function_name,\n        row_number() OVER (PARTITION BY schema_name ORDER BY function_name) AS function_rank\n    FROM duckdb_functions()\n)\nSELECT\n    *\nFROM ranked_functions\nWHERE\n    function_rank < 3;\nschema_name\tfunction_name\tfunction_rank\nmain\t!__postfix\t1\nmain\t!~~\t2\npg_catalog\tcol_description\t1\npg_catalog\tformat_pg_type\t2"], "Category": ["QUALIFY Clause"], "index": 3}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/filter"], "Title": ["FILTER"], "Feature": ["FILTER"], "Description": ["The FILTER clause may optionally follow an aggregate function in a SELECT statement. This will filter the rows of data that are fed into the aggregate function in the same way that a WHERE clause filters rows, but localized to the specific aggregate function.\nThere are multiple types of situations where this is useful, including when evaluating multiple aggregates with different filters, and when creating a pivoted view of a dataset. FILTER provides a cleaner syntax for pivoting data when compared with the more traditional CASE WHEN approach discussed below.\nSome aggregate functions also do not filter out NULL values, so using a FILTER clause will return valid results when at times the CASE WHEN approach will not. This occurs with the functions first and last, which are desirable in a non-aggregating pivot operation where the goal is to simply re-orient the data into columns rather than re-aggregate it. FILTER also improves NULL handling when using the list and array_agg functions, as the CASE WHEN approach will include NULL values in the list result, while the FILTER clause will remove them."], "Examples": ["Return the following:\nThe total number of rows\nThe number of rows where i <= 5\nThe number of rows where i is odd\nSELECT\n    count() AS total_rows,\n    count() FILTER (i <= 5) AS lte_five,\n    count() FILTER (i % 2 = 1) AS odds\nFROM generate_series(1, 10) tbl(i);\ntotal_rows\tlte_five\todds\n10\t5\t5\nSimply counting rows that satisfy a condition can also be achieved without FILTER clause, using the boolean sum aggregate function, e.g., sum(i <= 5).\nDifferent aggregate functions may be used, and multiple WHERE expressions are also permitted:\nSELECT\n    sum(i) FILTER (i <= 5) AS lte_five_sum,\n    median(i) FILTER (i % 2 = 1) AS odds_median,\n    median(i) FILTER (i % 2 = 1 AND i <= 5) AS odds_lte_five_median\nFROM generate_series(1, 10) tbl(i);\nlte_five_sum\todds_median\todds_lte_five_median\n15\t5.0\t3.0\nThe FILTER clause can also be used to pivot data from rows into columns. This is a static pivot, as columns must be defined prior to runtime in SQL. However, this kind of statement can be dynamically generated in a host programming language to leverage DuckDB's SQL engine for rapid, larger than memory pivoting.\nFirst generate an example dataset:\nCREATE TEMP TABLE stacked_data AS\n    SELECT\n        i,\n        CASE WHEN i <= rows * 0.25  THEN 2022\n             WHEN i <= rows * 0.5   THEN 2023\n             WHEN i <= rows * 0.75  THEN 2024\n             WHEN i <= rows * 0.875 THEN 2025\n             ELSE NULL\n             END AS year\n    FROM (\n        SELECT\n            i,\n            count(*) OVER () AS rows\n        FROM generate_series(1, 100_000_000) tbl(i)\n    ) tbl;\n“Pivot” the data out by year (move each year out to a separate column):\nSELECT\n    count(i) FILTER (year = 2022) AS \"2022\",\n    count(i) FILTER (year = 2023) AS \"2023\",\n    count(i) FILTER (year = 2024) AS \"2024\",\n    count(i) FILTER (year = 2025) AS \"2025\",\n    count(i) FILTER (year IS NULL) AS \"NULLs\"\nFROM stacked_data;\nThis syntax produces the same results as the FILTER clauses above:\nSELECT\n    count(CASE WHEN year = 2022 THEN i END) AS \"2022\",\n    count(CASE WHEN year = 2023 THEN i END) AS \"2023\",\n    count(CASE WHEN year = 2024 THEN i END) AS \"2024\",\n    count(CASE WHEN year = 2025 THEN i END) AS \"2025\",\n    count(CASE WHEN year IS NULL THEN i END) AS \"NULLs\"\nFROM stacked_data;\n2022\t2023\t2024\t2025\tNULLs\n25000000\t25000000\t25000000\t12500000\t12500000\nHowever, the CASE WHEN approach will not work as expected when using an aggregate function that does not ignore NULL values. The first function falls into this category, so FILTER is preferred in this case.\n“Pivot” the data out by year (move each year out to a separate column):\nSELECT\n    first(i) FILTER (year = 2022) AS \"2022\",\n    first(i) FILTER (year = 2023) AS \"2023\",\n    first(i) FILTER (year = 2024) AS \"2024\",\n    first(i) FILTER (year = 2025) AS \"2025\",\n    first(i) FILTER (year IS NULL) AS \"NULLs\"\nFROM stacked_data;\n2022\t2023\t2024\t2025\tNULLs\n1474561\t25804801\t50749441\t76431361\t87500001\nThis will produce NULL values whenever the first evaluation of the CASE WHEN clause returns a NULL:\nSELECT\n    first(CASE WHEN year = 2022 THEN i END) AS \"2022\",\n    first(CASE WHEN year = 2023 THEN i END) AS \"2023\",\n    first(CASE WHEN year = 2024 THEN i END) AS \"2024\",\n    first(CASE WHEN year = 2025 THEN i END) AS \"2025\",\n    first(CASE WHEN year IS NULL THEN i END) AS \"NULLs\"\nFROM stacked_data;\n2022\t2023\t2024\t2025\tNULLs\n1228801\tNULL\tNULL\tNULL\tNULL"], "Category": ["FILTER Clause"], "index": 4}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/where"], "Title": ["WHERE"], "Feature": ["WHERE"], "Description": ["The WHERE clause specifies any filters to apply to the data. This allows you to select only a subset of the data in which you are interested. Logically the WHERE clause is applied immediately after the FROM clause."], "Examples": ["Select all rows that where the id is equal to 3:\nSELECT *\nFROM table_name\nWHERE id = 3;\nSelect all rows that match the given case-sensitive LIKE expression:\nSELECT *\nFROM table_name\nWHERE name LIKE '%mark%';\nSelect all rows that match the given case-insensitive expression formulated with the ILIKE operator:\nSELECT *\nFROM table_name\nWHERE name ILIKE '%mark%';\nSelect all rows that match the given composite expression:\nSELECT *\nFROM table_name\nWHERE id = 3 OR id = 7;"], "Category": ["WHERE Clause"], "index": 5}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/groupby"], "Title": ["GROUP BY"], "Feature": ["GROUP BY"], "Description": ["The GROUP BY clause specifies which grouping columns should be used to perform any aggregations in the SELECT clause. If the GROUP BY clause is specified, the query is always an aggregate query, even if no aggregations are present in the SELECT clause.\nWhen a GROUP BY clause is specified, all tuples that have matching data in the grouping columns (i.e., all tuples that belong to the same group) will be combined. The values of the grouping columns themselves are unchanged, and any other columns can be combined using an aggregate function (such as count, sum, avg, etc).\nGROUP BY ALL\nUse GROUP BY ALL to GROUP BY all columns in the SELECT statement that are not wrapped in aggregate functions. This simplifies the syntax by allowing the columns list to be maintained in a single location, and prevents bugs by keeping the SELECT granularity aligned to the GROUP BY granularity (e.g., it prevents duplication). See examples below and additional examples in the “Friendlier SQL with DuckDB” blog post.\nMultiple Dimensions\nNormally, the GROUP BY clause groups along a single dimension. Using the GROUPING SETS, CUBE or ROLLUP clauses it is possible to group along multiple dimensions. See the GROUPING SETS page for more information."], "Examples": ["Count the number of entries in the addresses table that belong to each different city:\nSELECT city, count(*)\nFROM addresses\nGROUP BY city;\nCompute the average income per city per street_name:\nSELECT city, street_name, avg(income)\nFROM addresses\nGROUP BY city, street_name;\nGROUP BY ALL Examples\nGroup by city and street_name to remove any duplicate values:\nSELECT city, street_name\nFROM addresses\nGROUP BY ALL;\nCompute the average income per city per street_name. Since income is wrapped in an aggregate function, do not include it in the GROUP BY:\nSELECT city, street_name, avg(income)\nFROM addresses\nGROUP BY ALL;\n-- GROUP BY city, street_name:"], "Category": ["GROUP BY Clause"], "index": 6}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/grouping_sets"], "Title": ["GROUPING SETS"], "Feature": ["GROUPING SETS"], "Description": ["GROUPING SETS, ROLLUP and CUBE can be used in the GROUP BY clause to perform a grouping over multiple dimensions within the same query. Note that this syntax is not compatible with GROUP BY ALL.", "GROUPING SETS perform the same aggregate across different GROUP BY clauses in a single query.\nCREATE TABLE students (course VARCHAR, type VARCHAR);\nINSERT INTO students (course, type)\nVALUES\n    ('CS', 'Bachelor'), ('CS', 'Bachelor'), ('CS', 'PhD'), ('Math', 'Masters'),\n    ('CS', NULL), ('CS', NULL), ('Math', NULL);\nSELECT course, type, count(*)\nFROM students\nGROUP BY GROUPING SETS ((course, type), course, type, ());\ncourse\ttype\tcount_star()\nMath\tNULL\t1\nNULL\tNULL\t7\nCS\tPhD\t1\nCS\tBachelor\t2\nMath\tMasters\t1\nCS\tNULL\t2\nMath\tNULL\t2\nCS\tNULL\t5\nNULL\tNULL\t3\nNULL\tMasters\t1\nNULL\tBachelor\t2\nNULL\tPhD\t1\nIn the above query, we group across four different sets: course, type, course, type and () (the empty group). The result contains NULL for a group which is not in the grouping set for the result, i.e., the above query is equivalent to the following statement of UNION ALL clauses:\n-- Group by course, type:\nSELECT course, type, count(*)\nFROM students\nGROUP BY course, type\nUNION ALL\n-- Group by type:\nSELECT NULL AS course, type, count(*)\nFROM students\nGROUP BY type\nUNION ALL\n-- Group by course:\nSELECT course, NULL AS type, count(*)\nFROM students\nGROUP BY course\nUNION ALL\n-- Group by nothing:\nSELECT NULL AS course, NULL AS type, count(*)\nFROM students;\nCUBE and ROLLUP are syntactic sugar to easily produce commonly used grouping sets.\nThe ROLLUP clause will produce all “sub-groups” of a grouping set, e.g., ROLLUP (country, city, zip) produces the grouping sets (country, city, zip), (country, city), (country), (). This can be useful for producing different levels of detail of a group by clause. This produces n+1 grouping sets where n is the amount of terms in the ROLLUP clause.\nCUBE produces grouping sets for all combinations of the inputs, e.g., CUBE (country, city, zip) will produce (country, city, zip), (country, city), (country, zip), (city, zip), (country), (city), (zip), (). This produces 2^n grouping sets.\nIdentifying Grouping Sets with GROUPING_ID()\nThe super-aggregate rows generated by GROUPING SETS, ROLLUP and CUBE can often be identified by NULL-values returned for the respective column in the grouping. But if the columns used in the grouping can themselves contain actual NULL-values, then it can be challenging to distinguish whether the value in the resultset is a “real” NULL-value coming out of the data itself, or a NULL-value generated by the grouping construct. The GROUPING_ID() or GROUPING() function is designed to identify which groups generated the super-aggregate rows in the result.\nGROUPING_ID() is an aggregate function that takes the column expressions that make up the grouping(s). It returns a BIGINT value. The return value is 0 for the rows that are not super-aggregate rows. But for the super-aggregate rows, it returns an integer value that identifies the combination of expressions that make up the group for which the super-aggregate is generated. At this point, an example might help. Consider the following query:\nWITH days AS (\n    SELECT\n        year(\"generate_series\")    AS y,\n        quarter(\"generate_series\") AS q,\n        month(\"generate_series\")   AS m\n    FROM generate_series(DATE '2023-01-01', DATE '2023-12-31', INTERVAL 1 DAY)\n)\nSELECT y, q, m, GROUPING_ID(y, q, m) AS \"grouping_id()\"\nFROM days\nGROUP BY GROUPING SETS (\n    (y, q, m),\n    (y, q),\n    (y),\n    ()\n)\nORDER BY y, q, m;\nThese are the results:\ny\tq\tm\tgrouping_id()\n2023\t1\t1\t0\n2023\t1\t2\t0\n2023\t1\t3\t0\n2023\t1\tNULL\t1\n2023\t2\t4\t0\n2023\t2\t5\t0\n2023\t2\t6\t0\n2023\t2\tNULL\t1\n2023\t3\t7\t0\n2023\t3\t8\t0\n2023\t3\t9\t0\n2023\t3\tNULL\t1\n2023\t4\t10\t0\n2023\t4\t11\t0\n2023\t4\t12\t0\n2023\t4\tNULL\t1\n2023\tNULL\tNULL\t3\nNULL\tNULL\tNULL\t7\nIn this example, the lowest level of grouping is at the month level, defined by the grouping set (y, q, m). Result rows corresponding to that level are simply aggregate rows and the GROUPING_ID(y, q, m) function returns 0 for those. The grouping set (y, q) results in super-aggregate rows over the month level, leaving a NULL-value for the m column, and for which GROUPING_ID(y, q, m) returns 1. The grouping set (y) results in super-aggregate rows over the quarter level, leaving NULL-values for the m and q column, for which GROUPING_ID(y, q, m) returns 3. Finally, the () grouping set results in one super-aggregate row for the entire resultset, leaving NULL-values for y, q and m and for which GROUPING_ID(y, q, m) returns 7.\nTo understand the relationship between the return value and the grouping set, you can think of GROUPING_ID(y, q, m) writing to a bitfield, where the first bit corresponds to the last expression passed to GROUPING_ID(), the second bit to the one-but-last expression passed to GROUPING_ID(), and so on. This may become clearer by casting GROUPING_ID() to BIT:\nWITH days AS (\n    SELECT\n        year(\"generate_series\")    AS y,\n        quarter(\"generate_series\") AS q,\n        month(\"generate_series\")   AS m\n    FROM generate_series(DATE '2023-01-01', DATE '2023-12-31', INTERVAL 1 DAY)\n)\nSELECT\n    y, q, m,\n    GROUPING_ID(y, q, m) AS \"grouping_id(y, q, m)\",\n    right(GROUPING_ID(y, q, m)::BIT::VARCHAR, 3) AS \"y_q_m_bits\"\nFROM days\nGROUP BY GROUPING SETS (\n    (y, q, m),\n    (y, q),\n    (y),\n    ()\n)\nORDER BY y, q, m;\nWhich returns these results:\ny\tq\tm\tgrouping_id(y, q, m)\ty_q_m_bits\n2023\t1\t1\t0\t000\n2023\t1\t2\t0\t000\n2023\t1\t3\t0\t000\n2023\t1\tNULL\t1\t001\n2023\t2\t4\t0\t000\n2023\t2\t5\t0\t000\n2023\t2\t6\t0\t000\n2023\t2\tNULL\t1\t001\n2023\t3\t7\t0\t000\n2023\t3\t8\t0\t000\n2023\t3\t9\t0\t000\n2023\t3\tNULL\t1\t001\n2023\t4\t10\t0\t000\n2023\t4\t11\t0\t000\n2023\t4\t12\t0\t000\n2023\t4\tNULL\t1\t001\n2023\tNULL\tNULL\t3\t011\nNULL\tNULL\tNULL\t7\t111\nNote that the number of expressions passed to GROUPING_ID(), or the order in which they are passed is independent from the actual group definitions appearing in the GROUPING SETS-clause (or the groups implied by ROLLUP and CUBE). As long as the expressions passed to GROUPING_ID() are expressions that appear some where in the GROUPING SETS-clause, GROUPING_ID() will set a bit corresponding to the position of the expression whenever that expression is rolled up to a super-aggregate."], "Examples": ["Compute the average income along the provided four different dimensions:\n-- the syntax () denotes the empty set (i.e., computing an ungrouped aggregate)\nSELECT city, street_name, avg(income)\nFROM addresses\nGROUP BY GROUPING SETS ((city, street_name), (city), (street_name), ());\nCompute the average income along the same dimensions:\nSELECT city, street_name, avg(income)\nFROM addresses\nGROUP BY CUBE (city, street_name);\nCompute the average income along the dimensions (city, street_name), (city) and ():\nSELECT city, street_name, avg(income)\nFROM addresses\nGROUP BY ROLLUP (city, street_name);"], "Category": ["GROUPING SETS"], "index": 7}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/having"], "Title": ["HAVING"], "Feature": ["HAVING"], "Description": ["The HAVING clause can be used after the GROUP BY clause to provide filter criteria after the grouping has been completed. In terms of syntax the HAVING clause is identical to the WHERE clause, but while the WHERE clause occurs before the grouping, the HAVING clause occurs after the grouping."], "Examples": ["Count the number of entries in the addresses table that belong to each different city, filtering out cities with a count below 50:\nSELECT city, count(*)\nFROM addresses\nGROUP BY city\nHAVING count(*) >= 50;\nCompute the average income per city per street_name, filtering out cities with an average income bigger than twice the median income:\nSELECT city, street_name, avg(income)\nFROM addresses\nGROUP BY city, street_name\nHAVING avg(income) > 2 * median(income);"], "Category": ["HAVING Clause"], "index": 8}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/orderby"], "Title": ["ORDER BY"], "Feature": ["ORDER BY"], "Description": ["ORDER BY is an output modifier. Logically it is applied near the very end of the query (just prior to LIMIT or OFFSET, if present). The ORDER BY clause sorts the rows on the sorting criteria in either ascending or descending order. In addition, every order clause can specify whether NULL values should be moved to the beginning or to the end.\nThe ORDER BY clause may contain one or more expressions, separated by commas. An error will be thrown if no expressions are included, since the ORDER BY clause should be removed in that situation. The expressions may begin with either an arbitrary scalar expression (which could be a column name), a column position number (where the indexing starts from 1), or the keyword ALL. Each expression can optionally be followed by an order modifier (ASC or DESC, default is ASC), and/or a NULL order modifier (NULLS FIRST or NULLS LAST, default is NULLS LAST).\nORDER BY ALL\nThe ALL keyword indicates that the output should be sorted by every column in order from left to right. The direction of this sort may be modified using either ORDER BY ALL ASC or ORDER BY ALL DESC and/or NULLS FIRST or NULLS LAST. Note that ALL may not be used in combination with other expressions in the ORDER BY clause – it must be by itself. See examples below.\nNULL Order Modifier\nBy default, DuckDB sorts ASC and NULLS LAST, i.e., the values are sorted in ascending order and NULL values are placed last. This is identical to the default sort order of PostgreSQL. The default sort order can be changed with the following configuration options.\nUse the default_null_order option to change the default NULL sorting order to either NULLS_FIRST, NULLS_LAST, NULLS_FIRST_ON_ASC_LAST_ON_DESC or NULLS_LAST_ON_ASC_FIRST_ON_DESC:\nSET default_null_order = 'NULLS_FIRST';\nUse the default_order to change the direction of the default sorting order to either DESC or ASC:\nSET default_order = 'DESC';\nCollations\nText is sorted using the binary comparison collation by default, which means values are sorted on their binary UTF-8 values. While this works well for ASCII text (e.g., for English language data), the sorting order can be incorrect for other languages. For this purpose, DuckDB provides collations. For more information on collations, see the Collation page."], "Examples": ["All examples use this example table:\nCREATE OR REPLACE TABLE addresses AS\n    SELECT '123 Quack Blvd' AS address, 'DuckTown' AS city, '11111' AS zip\n    UNION ALL\n    SELECT '111 Duck Duck Goose Ln', 'DuckTown', '11111'\n    UNION ALL\n    SELECT '111 Duck Duck Goose Ln', 'Duck Town', '11111'\n    UNION ALL\n    SELECT '111 Duck Duck Goose Ln', 'Duck Town', '11111-0001';\nSelect the addresses, ordered by city name using the default NULL order and default order:\nSELECT *\nFROM addresses\nORDER BY city;\nSelect the addresses, ordered by city name in descending order with nulls at the end:\nSELECT *\nFROM addresses\nORDER BY city DESC NULLS LAST;\nOrder by city and then by zip code, both using the default orderings:\nSELECT *\nFROM addresses\nORDER BY city, zip;\nOrder by city using German collation rules:\nSELECT *\nFROM addresses\nORDER BY city COLLATE DE;\nORDER BY ALL Examples\nOrder from left to right (by address, then by city, then by zip) in ascending order:\nSELECT *\nFROM addresses\nORDER BY ALL;\naddress\tcity\tzip\n111 Duck Duck Goose Ln\tDuck Town\t11111\n111 Duck Duck Goose Ln\tDuck Town\t11111-0001\n111 Duck Duck Goose Ln\tDuckTown\t11111\n123 Quack Blvd\tDuckTown\t11111\nOrder from left to right (by address, then by city, then by zip) in descending order:\nSELECT *\nFROM addresses\nORDER BY ALL DESC;\naddress\tcity\tzip\n123 Quack Blvd\tDuckTown\t11111\n111 Duck Duck Goose Ln\tDuckTown\t11111\n111 Duck Duck Goose Ln\tDuck Town\t11111-0001\n111 Duck Duck Goose Ln\tDuck Town\t11111"], "Category": ["ORDER BY Clause"], "index": 9}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/limit"], "Title": ["LIMIT"], "Feature": ["LIMIT"], "Description": ["LIMIT is an output modifier. Logically it is applied at the very end of the query. The LIMIT clause restricts the amount of rows fetched. The OFFSET clause indicates at which position to start reading the values, i.e., the first OFFSET values are ignored.\nNote that while LIMIT can be used without an ORDER BY clause, the results might not be deterministic without the ORDER BY clause. This can still be useful, however, for example when you want to inspect a quick snapshot of the data."], "Examples": ["Select the first 5 rows from the addresses table:\nSELECT *\nFROM addresses\nLIMIT 5;\nSelect the 5 rows from the addresses table, starting at position 5 (i.e., ignoring the first 5 rows):\nSELECT *\nFROM addresses\nLIMIT 5\nOFFSET 5;\nSelect the top 5 cities with the highest population:\nSELECT city, count(*) AS population\nFROM addresses\nGROUP BY city\nORDER BY population DESC\nLIMIT 5;\nSelect 10% of the rows from the addresses table:\nSELECT *\nFROM addresses\nLIMIT 10%;"], "Category": ["LIMIT and OFFSET Clauses"], "index": 10}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/limit"], "Title": ["OFFSET"], "Feature": ["OFFSET"], "Description": ["LIMIT is an output modifier. Logically it is applied at the very end of the query. The LIMIT clause restricts the amount of rows fetched. The OFFSET clause indicates at which position to start reading the values, i.e., the first OFFSET values are ignored.\nNote that while LIMIT can be used without an ORDER BY clause, the results might not be deterministic without the ORDER BY clause. This can still be useful, however, for example when you want to inspect a quick snapshot of the data."], "Examples": ["Select the first 5 rows from the addresses table:\nSELECT *\nFROM addresses\nLIMIT 5;\nSelect the 5 rows from the addresses table, starting at position 5 (i.e., ignoring the first 5 rows):\nSELECT *\nFROM addresses\nLIMIT 5\nOFFSET 5;\nSelect the top 5 cities with the highest population:\nSELECT city, count(*) AS population\nFROM addresses\nGROUP BY city\nORDER BY population DESC\nLIMIT 5;\nSelect 10% of the rows from the addresses table:\nSELECT *\nFROM addresses\nLIMIT 10%;"], "Category": ["LIMIT and OFFSET Clauses"], "index": 11}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/sample"], "Title": ["SAMPLE"], "Feature": ["SAMPLE"], "Description": ["The SAMPLE clause allows you to run the query on a sample from the base table. This can significantly speed up processing of queries, at the expense of accuracy in the result. Samples can also be used to quickly see a snapshot of the data when exploring a data set. The sample clause is applied right after anything in the FROM clause (i.e., after any joins, but before the WHERE clause or any aggregates). See the SAMPLE page for more information."], "Examples": ["Select a sample of 1% of the addresses table using default (system) sampling:\nSELECT *\nFROM addresses\nUSING SAMPLE 1%;\nSelect a sample of 1% of the addresses table using bernoulli sampling:\nSELECT *\nFROM addresses\nUSING SAMPLE 1% (bernoulli);\nSelect a sample of 10 rows from the subquery:\nSELECT *\nFROM (SELECT * FROM addresses)\nUSING SAMPLE 10 ROWS;"], "Category": ["LIMIT and OFFSET Clauses"], "index": 12}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/select"], "Title": ["DISTINCT"], "Feature": ["DISTINCT"], "Description": ["Select all unique cities from the addresses table:\nSELECT DISTINCT city\nFROM addresses;\nThe DISTINCT clause can be used to return only the unique rows in the result – so that any duplicate rows are filtered out.\nQueries starting with SELECT DISTINCT run deduplication, which is an expensive operation. Therefore, only use DISTINCT if necessary."], "Examples": [""], "Category": ["LIMIT and OFFSET Clauses"], "index": 13}
{"HTML": ["https://duckdb.org/docs/stable/sql/query_syntax/setops"], "Title": ["UNION"], "Feature": ["UNION"], "Description": ["The UNION clause can be used to combine rows from multiple queries. The queries are required to return the same number of columns. Implicit casting to one of the returned types is performed to combine columns of different types where necessary. If this is not possible, the UNION clause throws an error.\nVanilla UNION (Set Semantics)\nThe vanilla UNION clause follows set semantics, therefore it performs duplicate elimination, i.e., only unique rows will be included in the result.\nSELECT * FROM range(2) t1(x)\nUNION\nSELECT * FROM range(3) t2(x);\nx\n2\n1\n0\nUNION ALL (Bag Semantics)\nUNION ALL returns all rows of both queries following bag semantics, i.e., without duplicate elimination.\nSELECT * FROM range(2) t1(x)\nUNION ALL\nSELECT * FROM range(3) t2(x);\nx\n0\n1\n0\n1\n2\nUNION [ALL] BY NAME\nThe UNION [ALL] BY NAME clause can be used to combine rows from different tables by name, instead of by position. UNION BY NAME does not require both queries to have the same number of columns. Any columns that are only found in one of the queries are filled with NULL values for the other query.\nTake the following tables for example:\nCREATE TABLE capitals (city VARCHAR, country VARCHAR);\nINSERT INTO capitals VALUES\n    ('Amsterdam', 'NL'),\n    ('Berlin', 'Germany');\nCREATE TABLE weather (city VARCHAR, degrees INTEGER, date DATE);\nINSERT INTO weather VALUES\n    ('Amsterdam', 10, '2022-10-14'),\n    ('Seattle', 8, '2022-10-12');\nSELECT * FROM capitals\nUNION BY NAME\nSELECT * FROM weather;\ncity\tcountry\tdegrees\tdate\nSeattle\tNULL\t8\t2022-10-12\nAmsterdam\tNL\tNULL\tNULL\nBerlin\tGermany\tNULL\tNULL\nAmsterdam\tNULL\t10\t2022-10-14\nUNION BY NAME follows set semantics (therefore it performs duplicate elimination), whereas UNION ALL BY NAME follows bag semantics."], "Examples": [""], "Category": ["Set Operations"], "index": 14}
